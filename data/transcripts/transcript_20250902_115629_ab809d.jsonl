{"ts": "00:00", "speaker": "I", "text": "Können Sie kurz den aktuellen Stand des Orion Edge Gateway Projekts beschreiben? Ich möchte verstehen, wie weit Sie in der Build-Phase sind."}
{"ts": "03:10", "speaker": "E", "text": "Ja, wir sind aktuell in Sprint 8 von 12 im Build, der Großteil der Kernfunktionen – API Routing, Rate Limiting, mTLS-basierte Authentifizierung – ist implementiert. Wir arbeiten jetzt an der Feinjustierung der Policies aus POL-SEC-001 und führen Pen-Tests im Staging durch."}
{"ts": "06:20", "speaker": "I", "text": "Sie erwähnen POL-SEC-001 – wie haben Sie diese Vorgaben in Ihrer Pipeline umgesetzt?"}
{"ts": "09:30", "speaker": "E", "text": "Wir haben eine statische Policy-Prüfung eingebaut, die bei jedem Merge ins main-Branch die IaC-Templates gegen die mTLS-Policy-Matrix validiert. Zusätzlich läuft ein Container Security Scan, der sicherstellt, dass nur genehmigte TLS-Cipher verwendet werden."}
{"ts": "12:40", "speaker": "I", "text": "Welche Authentifizierungsmechanismen sind derzeit implementiert?"}
{"ts": "15:50", "speaker": "E", "text": "Primär mTLS für Service-to-Service Traffic. Für User-facing APIs nutzen wir OAuth2 mit JWT, was via Aegis IAM bereitgestellt wird. JIT-Access wird durch temporäre Tokens unterstützt, die wir über einen Sidecar-Container validieren."}
{"ts": "19:00", "speaker": "I", "text": "Wie stellen Sie sicher, dass Ihre IaC-Templates den mTLS-Policy-Matrix-Konventionen entsprechen?"}
{"ts": "22:15", "speaker": "E", "text": "Wir haben ein internes Linter-Tool, das YAML- und HCL-Files gegen die Matrix vergleicht. Bei Abweichungen wird der Build geblockt und ein Verweis auf das entsprechende Kapitel im Runbook RB-GW-011 ausgegeben."}
{"ts": "25:30", "speaker": "I", "text": "Wie genau referenzieren Sie das Runbook RB-GW-011 in der CI/CD-Pipeline?"}
{"ts": "28:45", "speaker": "E", "text": "In der GitLab-CI YAML gibt es einen eigenen Job 'rb-check', der bei jedem Pipeline-Lauf die Version des Runbooks aus unserem internen Nexus zieht. Dann werden die relevanten Playbooks für Rolling Deployments automatisch geladen."}
{"ts": "32:00", "speaker": "I", "text": "Und wie vermeiden Sie, dass Secrets versehentlich im Code landen?"}
{"ts": "35:15", "speaker": "E", "text": "Wir nutzen ein Pre-Commit-Hook-Skript, das mit Regex-Patterns und einem internen Secrets-Scanner arbeitet. Zusätzlich enforced der Code-Review-Prozess, dass API Keys nur aus Vault-Variablen injiziert werden."}
{"ts": "38:30", "speaker": "I", "text": "Kommen wir zur Integration mit Aegis IAM – wie wird das Gateway für JIT-Access integriert?"}
{"ts": "41:45", "speaker": "E", "text": "Das Gateway ruft bei Bedarf ein JIT-Token vom Aegis IAM ab. Dieser Request ist selbst mTLS-gesichert. Die Tokens sind nur 5 Minuten gültig, und wir loggen jeden Abruf in Nimbus, um Audit-Trails gegen SLA-ORI-02 zu prüfen."}
{"ts": "45:00", "speaker": "I", "text": "Und welche Observability-Mechanismen aus Nimbus nutzen Sie, um SLA-ORI-02 zu überwachen?"}
{"ts": "48:15", "speaker": "E", "text": "Wir haben ein zentrales Dashboard mit Latenz-Heatmaps und Fehlerquoten. Ein Alert-Rule-Set triggert bei >200ms Median-Latenz über 5 Minuten. Die Alerts sind mit den RFC-Change-IDs verknüpft, damit wir schnell sehen, ob ein Deployment die Ursache ist."}
{"ts": "90:00", "speaker": "I", "text": "Lassen Sie uns jetzt tiefer auf die Risiken bei Rolling Deployments in einer Multi-Tenant-Umgebung eingehen – konkret im Kontext des Runbooks RB-GW-011. Was sind aus Ihrer Sicht die größten Stolpersteine?"}
{"ts": "90:18", "speaker": "E", "text": "Also, ähm, das Hauptproblem ist wirklich, dass bei einem Rolling Deployment mTLS Handshakes tenantübergreifend zeitgleich gestört werden können, wenn der Node-Pool nicht sauber drainiert wird. RB-GW-011 schreibt explizit vor, dass wir vor dem Austausch der Pods die Session-Tickets invalidieren müssen, um Cross-Tenant-Leaks zu verhindern."}
{"ts": "90:45", "speaker": "I", "text": "Und wie minimieren Sie den sogenannten Blast Radius, falls es doch zu einer Störung wie in Ticket GW-4821 kommt?"}
{"ts": "91:02", "speaker": "E", "text": "In GW-4821 hatten wir exakt so einen Fall. Wir haben daraufhin im Runbook einen Canary-Node eingeführt, der nur für einen isolierten Tenant arbeitet. So erkennen wir Handshake-Anomalien nach 30 Sekunden und stoppen das Rollout. Parallel wird ein Incident-Bridge-Call nach IRP-026 aufgesetzt."}
{"ts": "91:30", "speaker": "I", "text": "Können Sie ein Beispiel geben, wie diese Canary-Strategie mit den Observability-Daten aus Nimbus verknüpft wird?"}
{"ts": "91:47", "speaker": "E", "text": "Ja, wir haben im Nimbus-Dashboard ein spezielles Panel 'mTLS Error Rate Canary' angelegt. Das zieht die Error-Codes aus dem Envoy-Log-Stream, korreliert sie mit Tenant-IDs aus Aegis IAM und markiert, wenn der Wert 0,5% überschreitet. Das Triggersignal fließt dann via Webhook zurück in die CI/CD Pipeline, um das Deployment zu pausieren."}
{"ts": "92:15", "speaker": "I", "text": "Das klingt sehr integriert. Aber wie stellen Sie sicher, dass solche Mechanismen auch in Audits nachvollziehbar dokumentiert sind?"}
{"ts": "92:30", "speaker": "E", "text": "Wir führen für jede relevante Änderung ein Decision Record im ADR-Format. Darin dokumentieren wir den Trade-off, z.B. zwischen Latenzsteigerung um 15ms und höherer Sicherheit. Diese ADRs sind in unserem internen Audit-Repository revisionssicher abgelegt, verlinkt mit den zugehörigen RFC-IDs und Tickets."}
{"ts": "92:58", "speaker": "I", "text": "Apropos Trade-offs: Wie sind Sie bei der Wahl zwischen Blue/Green und Canary konkret vorgegangen?"}
{"ts": "93:15", "speaker": "E", "text": "Wir haben beide Strategien in einer Staging-Umgebung mit Lastprofilen aus SLA-ORI-02 getestet. Blue/Green hat uns eine klarere Trennung und schnellere Rollback-Zeiten gegeben, aber Canary war feiner granuliert für Sicherheitsvalidierung. Am Ende haben wir hybrid entschieden: Blue/Green für Major-Releases, Canary für sicherheitskritische Patches."}
{"ts": "93:45", "speaker": "I", "text": "Gab es dabei Performanceeinbußen, die Sie in Kauf nehmen mussten?"}
{"ts": "94:00", "speaker": "E", "text": "Ja, bei Canary-Deployments lag die Latenz im Schnitt 8–12 ms höher, weil zusätzliche mTLS Checks und Feature-Flag-Abfragen im Request Path lagen. Das war innerhalb der 50 ms Budgetgrenze von SLA-ORI-02, aber wir mussten die Upstream-Timeouts in den IaC-Templates anpassen."}
{"ts": "94:28", "speaker": "I", "text": "Wie gehen Sie mit Secrets um, die für solche Deployments nötig sind?"}
{"ts": "94:42", "speaker": "E", "text": "Wir nutzen eine Kombination aus Vault-Integration und Kubernetes Secrets, wobei die IaC-Templates nur Referenzen enthalten. POL-SEC-001 verbietet hartecodierte Secrets, daher prüfen wir in der Pipeline mit einem Secret-Scanner-Step. Verstöße blockieren den Merge-Request automatisch."}
{"ts": "95:05", "speaker": "I", "text": "Wenn Sie auf die Lessons Learned aus den letzten Incidents schauen – was war die wichtigste Anpassung für den Blast Radius?"}
{"ts": "95:20", "speaker": "E", "text": "Die wichtigste Anpassung war, dass wir alle Tenant-Verbindungen klar taggen und isolieren. Früher liefen manche Background-Jobs quer über Tenants, was den Blast Radius bei einem Fehler vergrößerte. Jetzt erzwingen wir über die Policy-Matrix, dass jeder Job nur im Kontext seines Tenants operiert."}
{"ts": "98:00", "speaker": "I", "text": "Lassen Sie uns jetzt auf die Risikobewertung eingehen. Welche Risiken sehen Sie bei Rolling Deployments, wie sie im Runbook RB-GW-011 beschrieben sind, insbesondere in einer Multi-Tenant-Umgebung?"}
{"ts": "98:18", "speaker": "E", "text": "Das Haupt­risiko ist, dass bei einem Rolling Deployment ein Tenant bereits auf einer neuen Gateway-Version läuft, während andere noch die alte nutzen. Das kann zu mTLS-Handshake-Inkompatibilitäten führen, wenn z. B. Cipher Suites aktualisiert wurden. Deshalb haben wir in RB-GW-011 einen Compatibility Check vor jedem Rollout eingebaut, der die Policy-Matrix gegen beide Versionen testet."}
{"ts": "98:46", "speaker": "I", "text": "Wie würden Sie konkret mit einer mTLS Handshake-Störung umgehen, wie sie in Ticket GW-4821 dokumentiert ist?"}
{"ts": "99:02", "speaker": "E", "text": "In GW-4821 hatten wir einen Fall, wo der Handshake bei bestimmten IoT-Clients fehlschlug. Unser Runbook RB-SEC-014 beschreibt, wie wir per Feature Flag auf die vorherige Cipher Suite zurückschalten können. Parallel dazu wird ein Hotfix-Build getriggert, der die neue Suite optional macht. Wir haben das in weniger als 20 Minuten umgesetzt, um den Blast Radius klein zu halten."}
{"ts": "99:34", "speaker": "I", "text": "Gab es Lessons Learned aus solchen Incidents in Bezug auf den Blast Radius?"}
{"ts": "99:48", "speaker": "E", "text": "Ja, wir haben gelernt, dass ein isolierter Canary-Node pro Tenant-Gruppe Pflicht ist. So können wir neue TLS-Settings zunächst nur auf einen kleinen Prozentsatz anwenden. Außerdem haben wir SLA-ORI-02 ergänzt um einen Recovery-Zeitindikator, der jetzt im Nimbus Dashboard sichtbar ist."}
{"ts": "100:18", "speaker": "I", "text": "Kommen wir zu den Trade-offs: Wie haben Sie den Zielkonflikt zwischen Latenz gemäß SLA-ORI-02 und zusätzlichen Security Checks bewertet?"}
{"ts": "100:36", "speaker": "E", "text": "Wir haben Messungen durchgeführt: Jeder zusätzliche JWT-Claim-Check fügt im Schnitt 2,3 ms hinzu. Für SLA-ORI-02 dürfen End-to-End maximal 150 ms anfallen. Wir haben entschieden, Checks bei internen Service-Calls zu reduzieren, aber extern alles strikt zu prüfen. Das ist dokumentiert in unserem Entscheidungsprotokoll DEC-ORI-07."}
{"ts": "101:04", "speaker": "I", "text": "Warum haben Sie sich für Blue/Green Deployments gegenüber Canary entschieden, obwohl Canary den Blast Radius oft besser begrenzt?"}
{"ts": "101:21", "speaker": "E", "text": "Blue/Green erlaubt uns, komplette Environment-Snapshots zu validieren, inkl. Aegis IAM-Integration und Nimbus Hooks, bevor wir umschalten. Canary ist bei uns schwieriger, weil Multi-Tenant-Routing komplexe Session Affinity verlangt. Wir nutzen Canary nur für TLS-Änderungen oder Library-Upgrades, nicht für komplette Releases."}
{"ts": "101:50", "speaker": "I", "text": "Wie dokumentieren Sie solche Entscheidungen, damit sie auditierbar bleiben?"}
{"ts": "102:05", "speaker": "E", "text": "Alle Architektur- und Deployment-Entscheidungen landen in unserem internen Confluence unter 'ORI-DEC'. Wir verlinken dort auf relevante RFCs, Runbooks und Tickets, z. B. RFC-ORI-152 für den Blue/Green-Switch. Für Audits exportieren wir PDF-Snapshots und signieren sie digital."}
{"ts": "102:32", "speaker": "I", "text": "Gibt es ungeschriebene Regeln, die Sie bei der Bewertung von Risiken und Trade-offs anwenden?"}
{"ts": "102:46", "speaker": "E", "text": "Definitiv. Eine Faustregel ist: 'Wenn du es nachts deployen würdest, ohne Pager, dann ist es noch nicht sicher genug.' Außerdem gilt bei uns: Jeder Security-relevante Parameter muss in IaC-Templates parametrierbar sein, sonst wird er abgelehnt."}
{"ts": "103:10", "speaker": "I", "text": "Wie fließen diese Regeln in die Schulung neuer Teammitglieder ein?"}
{"ts": "103:25", "speaker": "E", "text": "Wir haben ein Onboarding-Playbook 'ORI-OB-SEC', das sowohl harte Policies wie POL-SEC-001 als auch diese heuristischen Regeln enthält. Neue Kolleg:innen müssen ein Simulationstraining durchlaufen, bei dem sie einen Incident wie GW-4821 nachstellen und Entscheidungen dokumentieren."}
{"ts": "114:00", "speaker": "I", "text": "Lassen Sie uns nun zu den Risiken bei Rolling Deployments in der Multi-Tenant-Umgebung zurückkommen. Welche speziellen Punkte sehen Sie aktuell kritisch?"}
{"ts": "114:25", "speaker": "E", "text": "Ein Hauptpunkt ist die Gefahr eines MTLS-Handshake-Failures in nur einem Tenant, der dann aber durch shared Ressourcen den gesamten Pool beeinflusst. Wir haben im Runbook RB-GW-011 einen Staging-Check eingebaut, der pro Tenant ein Preflight mTLS-Verification macht, bevor Traffic umgeschwenkt wird."}
{"ts": "114:56", "speaker": "I", "text": "Und wie würden Sie konkret reagieren, wenn so ein Handshake-Problem wie in Ticket GW-4821 wieder auftritt?"}
{"ts": "115:14", "speaker": "E", "text": "Da haben wir gelernt: sofortiges Isolieren der betroffenen mTLS-Session IDs per Envoy-Filter, dann rückwärts in die vorherige Gateway-Version rollen. Parallel prüfen wir den Zertifikatspool im Secrets-Manager, um abgelaufene oder fehlerhafte Entrys zu finden."}
{"ts": "115:45", "speaker": "I", "text": "Das klingt reaktiv. Gibt es proaktive Maßnahmen, die Sie danach etabliert haben?"}
{"ts": "116:02", "speaker": "E", "text": "Ja, wir haben einen wöchentlichen Zertifikats-Drift-Report eingebaut, der mit dem Nimbus Observability Alert-Framework gekoppelt ist. Damit erreichen wir, dass SLA-ORI-02 nicht nur reaktiv, sondern auch präventiv eingehalten wird."}
{"ts": "116:28", "speaker": "I", "text": "Sie erwähnten vorhin den Blast Radius. Was genau haben Sie aus den letzten Incidents dazu gelernt?"}
{"ts": "116:47", "speaker": "E", "text": "Früher hatten wir keinen klaren Tenant-Segmentierungsplan. Nach dem Incident INC-GW-2023-09 haben wir im IaC-Template eine logische Trennung auf Subnetz-Level eingebaut, sodass ein Ausfall sich nur auf maximal 5% der Tenants auswirkt."}
{"ts": "117:15", "speaker": "I", "text": "Kommen wir zu den Trade-offs. Wie haben Sie den Zielkonflikt zwischen Latenz nach SLA-ORI-02 und zusätzlichen Security Checks bewertet?"}
{"ts": "117:32", "speaker": "E", "text": "Wir haben Latenztests unter Realverkehr gemacht: die zusätzlichen Checks (z.B. JIT-Token-Validation gegen Aegis IAM) addieren ca. 12 ms. Das lag noch unter dem SLA-Budget von 50 ms für Edge-Processing. Daher haben wir die Security Checks beibehalten."}
{"ts": "117:58", "speaker": "I", "text": "Warum haben Sie sich bei den Deployments für Blue/Green und nicht für Canary entschieden?"}
{"ts": "118:15", "speaker": "E", "text": "Blue/Green erlaubt uns, komplette Tenant-Gruppen atomar umzuschalten. Canary war in Multi-Tenant schwierig, weil wir inter-Tenant Traffic Isolation nicht sauber hinbekommen haben – siehe auch die Lessons aus RFC-GW-044."}
{"ts": "118:42", "speaker": "I", "text": "Wie dokumentieren Sie solche Entscheidungen, damit sie auditierbar sind?"}
{"ts": "118:57", "speaker": "E", "text": "Wir pflegen ein internes Decision-Log im Confluence-ähnlichen System, referenzieren Tickets und RFCs, und verlinken die Test-Ergebnisse. Für Blue/Green gibt es z.B. Eintrag DEC-GW-2023-12 mit allen Metriken und Abwägungen."}
{"ts": "119:22", "speaker": "I", "text": "Gibt es Risiken, dass Blue/Green bei bestimmten Tenants zu Dateninkonsistenzen führt?"}
{"ts": "119:40", "speaker": "E", "text": "Ja, bei Tenants mit aktivem Session-Caching kann es beim Umschalten zu kurzzeitigen Inkonsistenzen kommen. Wir mitigieren das mit einer Synchronisationsphase, die in RB-GW-011 Schritt 7 genau beschrieben ist."}
{"ts": "120:00", "speaker": "I", "text": "Kommen wir zu den Rolling Deployments. Welche spezifischen Risiken sehen Sie in einer Multi-Tenant Umgebung, wenn wir das Runbook RB-GW-011 befolgen?"}
{"ts": "120:15", "speaker": "E", "text": "Das Hauptrisiko ist, dass ein fehlerhaftes Gateway-Modul in einer Tenant-Partition ausgerollt wird und durch interne Cross-Tenant Calls den Traffic anderer Tenants beeinflusst. RB-GW-011 sieht zwar Health Checks vor, aber die greifen erst nach dem Switch. Wir haben daher einen Pre-Switch Smoke Test implementiert, der API-Keys aus drei verschiedenen Tenants simuliert."}
{"ts": "120:45", "speaker": "I", "text": "Und wie stellen Sie sicher, dass dieser Smoke Test aktuell bleibt?"}
{"ts": "121:00", "speaker": "E", "text": "Wir haben ein eigenes IaC-Modul 'smoke_test_seed' im Terraform-Repo, das wöchentlich mit den neuesten Schema-Änderungen aus Aegis IAM abgeglichen wird. Das ist im internen Wiki unter IaC-PRC-07 dokumentiert."}
{"ts": "121:25", "speaker": "I", "text": "Ok, Ticket GW-4821 beschreibt ja eine MTLS Handshake Störung. Wie sind Sie da genau vorgegangen?"}
{"ts": "121:40", "speaker": "E", "text": "Wir haben zuerst die mTLS-Handshake-Logs aus Nimbus Observability extrahiert und festgestellt, dass der TLS-Version-Mismatch zu 1.2 nur bei einem Subset von Edge Nodes auftrat. Laut Runbook RB-GW-009 haben wir dann ein Rolling Restart mit erzwungenem Cipher-Suite-Update gefahren und parallel CRL-Checks aktiviert."}
{"ts": "122:10", "speaker": "I", "text": "Gab es dadurch Downtime, und wie wurde SLA-ORI-02 eingehalten?"}
{"ts": "122:25", "speaker": "E", "text": "Wir haben das in einem Blue/Green-ähnlichen Muster gemacht, d.h. betroffene Nodes sukzessive aus dem Pool genommen. Nimbus Alert-Streams wurden so konfiguriert, dass wir unter der 200ms-Latenzgrenze geblieben sind. SLA-ORI-02 wurde laut letzter Auswertung zu 99,97% erfüllt."}
{"ts": "122:55", "speaker": "I", "text": "Das bringt uns zum Thema Blast Radius. Welche Lessons Learned haben Sie aus vergangenen Incidents gezogen?"}
{"ts": "123:10", "speaker": "E", "text": "Ein wichtiger Punkt: Feature Flags müssen Tenant-spezifisch ausrollbar sein. In Incident ORI-INC-17 hat ein global gesetzter Flag das Auth-Timeout-Handling verändert und 8 Tenants gleichzeitig beeinträchtigt. Jetzt erzwingen wir Flag-Scopes im Deployment-Manifest (siehe RFC-ORI-044)."}
{"ts": "123:40", "speaker": "I", "text": "Wie haben Sie den Trade-off zwischen Latenz und zusätzlichen Security Checks bewertet?"}
{"ts": "123:55", "speaker": "E", "text": "Wir haben Benchmarks mit und ohne Deep Packet Inspection gefahren. Ergebnis: +35ms im Median. Basierend auf dem Security Review SR-ORI-08 haben wir entschieden, DPI nur auf High-Risk-Endpoints zu aktivieren und im Rest auf mTLS + Request-Signing zu setzen."}
{"ts": "124:25", "speaker": "I", "text": "Warum haben Sie Blue/Green gegenüber Canary bevorzugt?"}
{"ts": "124:40", "speaker": "E", "text": "Blue/Green ließ uns in der Build-Phase einfacher komplette Stacks parallel betreiben und im Notfall sofort zurückschalten. Canary hätte feinere Kontrolle geboten, aber in einer Multi-Tenant-Topologie wäre das Routing deutlich komplexer gewesen (vgl. Tech-Note TN-ORI-12)."}
{"ts": "125:05", "speaker": "I", "text": "Wie dokumentieren Sie solche Entscheidungen für Audits?"}
{"ts": "125:20", "speaker": "E", "text": "Jede Architekturentscheidung landet in unserem ADR-Repo (Architecture Decision Records) mit Verweis auf das zugehörige RFC und die Metriken. Für Blue/Green vs. Canary ist das ADR-ORI-07, inklusive Performance-Traces und Security-Evaluierung."}
{"ts": "135:00", "speaker": "I", "text": "Lassen Sie uns mal genauer auf die Entscheidung Blue/Green versus Canary eingehen. Welche Faktoren waren ausschlaggebend für das Orion Edge Gateway?"}
{"ts": "135:05", "speaker": "E", "text": "Wir haben da eine Matrix aus SLA-ORI-02, der MTLS-Policy und den Lessons Learned aus Runbook RB-GW-011 herangezogen. Canary hätte uns feingranulare Inkremente erlaubt, aber bei Multi-Tenant wurde das Blast Radius Risiko durch nicht vorhersagbare Tenant-Auslastung zu hoch."}
{"ts": "135:12", "speaker": "I", "text": "Gab es messbare Unterschiede in der Latenz, die Sie bei dieser Entscheidung berücksichtigt haben?"}
{"ts": "135:18", "speaker": "E", "text": "Ja, bei Canary-Rollouts stieg die 95th-Percentile-Latenz in unseren Staging-Tests um 18 ms. Blue/Green hat uns in der Testumgebung stabil bei unter 5 ms gehalten, da die Umschaltung atomar erfolgte und keine parallelen Versionen mit mTLS-Rehandshakes liefen."}
{"ts": "135:26", "speaker": "I", "text": "Wie haben Sie diese Entscheidung für Audits dokumentiert?"}
{"ts": "135:32", "speaker": "E", "text": "Im RFC-Log, konkret RFC-ORI-27, ist eine Entscheidungsvorlage hinterlegt, die die Metriken, Risikoanalyse und Referenzen zu Tickets wie GW-4821 enthält. Zusätzlich gibt es einen Verweis auf die Compliance-Prüfung nach POL-SEC-001."}
{"ts": "135:40", "speaker": "I", "text": "Und wie gehen Sie im Betrieb mit einem potenziellen MTLS-Handshake-Ausfall während eines Blue/Green-Switchovers um?"}
{"ts": "135:47", "speaker": "E", "text": "Da greifen wir auf Runbook RB-GW-014 zurück – das ist ein Update von RB-GW-011 speziell für Switchover-Fallbacks. Es beschreibt, wie wir per IaC-Template die alte Green-Instanz reaktivieren und die mTLS-Truststore-Config aus dem Vault neu initialisieren."}
{"ts": "135:56", "speaker": "I", "text": "Haben Sie dafür automatisierte Tests in der CI/CD-Pipeline?"}
{"ts": "136:02", "speaker": "E", "text": "Ja, im Jenkinsfile gibt es einen Step `mtls_fallback_test`, der simulierte Handshake-Fehler injiziert. Das basiert auf den Szenarien aus Incident GW-4821 und prüft, ob der Fallback-Pfad innerhalb von 3 Sekunden greift."}
{"ts": "136:11", "speaker": "I", "text": "Wie fließen Observability-Daten aus Nimbus in diese Entscheidungen ein?"}
{"ts": "136:17", "speaker": "E", "text": "Nimbus liefert uns Real-Time-Streams zu Latenzen und Error-Rates. Wir haben ein Alerting-Rule-Set `ORI-BG-SWITCH` konfiguriert, das innerhalb von 500 ms Abweichungen in SLA-ORI-02 meldet. Diese Alerts sind auch im Audit-Dashboard sichtbar."}
{"ts": "136:26", "speaker": "I", "text": "Gab es schon einen Vorfall, bei dem dieses Alerting ausgelöst wurde?"}
{"ts": "136:31", "speaker": "E", "text": "Ja, in Testlauf 2024-Q1-17. Beim Switchover kam es zu einem temporären Zertifikatsfehler im Aegis IAM JIT-Access. Nimbus erkannte die erhöhte Auth-Latenz, wir haben sofort auf Green zurückgeschaltet. Der gesamte Vorgang dauerte 12 Sekunden."}
{"ts": "136:41", "speaker": "I", "text": "Welche Lessons Learned haben Sie daraus gezogen?"}
{"ts": "136:46", "speaker": "E", "text": "Dass wir die Zertifikatsrotation im Aegis IAM nicht parallel zum Blue/Green-Switch fahren sollten. Das ist jetzt als Constraint in unseren Deployment-Policies hinterlegt und wird automatisch im IaC-Validator geprüft."}
{"ts": "136:36", "speaker": "I", "text": "Sie haben vorhin die Latenzanforderungen aus SLA-ORI-02 erwähnt. Können Sie genauer erläutern, wie Sie die Security Checks so gestalten, dass die 200 ms Budget eingehalten werden?"}
{"ts": "136:41", "speaker": "E", "text": "Ja, wir haben da ein zweistufiges Modell. Inline-Checks wie mTLS Handshake und JWT-Validierung laufen synchron im Gateway-Thread, aber tiefergehende Threat-Analysen werden asynchron in einer Sidecar-Analyse-Engine gefahren, sodass der Response Path nicht blockiert wird."}
{"ts": "136:49", "speaker": "I", "text": "Aber ist das nicht ein Risiko, wenn die asynchronen Checks erst nach der Antwort greifen?"}
{"ts": "136:53", "speaker": "E", "text": "Teilweise, ja. Deshalb setzen wir auf eine Quarantäne-Flag-Logik: falls die Sidecar-Engine einen Treffer meldet, wird die Session ID in Redis geblacklistet und alle Folgeanfragen blockiert. Das ist in RB-GW-015 dokumentiert."}
{"ts": "137:00", "speaker": "I", "text": "Sie haben sich für Blue/Green-Deployments entschieden. Was waren die Kriterien gegen Canary in diesem Kontext?"}
{"ts": "137:04", "speaker": "E", "text": "Vor allem Isolierung. Bei Blue/Green können wir komplette Tenant-Segmente umschalten, ohne dass Mischverkehr entsteht. Mit Canary hätten wir in Multi-Tenant-Szenarien riskante Cross-Impact-Szenarien, wie auch in Lessons Learned zu Incident GW-4590 beschrieben."}
{"ts": "137:11", "speaker": "I", "text": "Wie dokumentieren Sie diese Entscheidungen, damit Auditoren sie nachvollziehen können?"}
{"ts": "137:14", "speaker": "E", "text": "Wir führen eine Decision Log Section im Confluence-Space ORI-ARCH, jede Entscheidung bekommt eine DEC-ID, z. B. DEC-ORI-07 für Blue/Green. Dazu hängen wir Performance-Messungen und Sicherheitsbewertungen aus den Testumgebungen an."}
{"ts": "137:21", "speaker": "I", "text": "Gab es Performanceeinbußen durch zusätzliche Authentifizierungsmechanismen?"}
{"ts": "137:24", "speaker": "E", "text": "Minimal. Durch Session Resumption im mTLS sparen wir Handshake-Zeit. Außerdem wird OCSP-Stapling genutzt, damit die Zertifikatsprüfung nicht jedes Mal externe Latenz verursacht."}
{"ts": "137:30", "speaker": "I", "text": "Wie fließen diese Optimierungen in die IaC-Templates ein?"}
{"ts": "137:34", "speaker": "E", "text": "Wir haben Module in Terraform, die die NGINX-Konfiguration mit den Session-Cache-Parametern provisionieren. Ein Pre-Commit Hook prüft gegen die mTLS-Policy-Matrix, dass die Cache-TTLs nicht unter das Minimum aus POL-SEC-001 fallen."}
{"ts": "137:42", "speaker": "I", "text": "Und beim Incident Response – wie verhält es sich, wenn während eines Blue/Green-Switches eine mTLS-Störung wie in GW-4821 auftritt?"}
{"ts": "137:47", "speaker": "E", "text": "Dann stoppen wir den Switch sofort und rollen auf die funktionierende Farbe zurück. Laut RB-GW-011 ist das ein automatisierter Health-Check-Trigger, der innerhalb von 30 Sekunden reagiert."}
{"ts": "137:53", "speaker": "I", "text": "Sehen Sie Risiken in der Abhängigkeit von der Health-Check-Logik?"}
{"ts": "137:56", "speaker": "E", "text": "Ja, wenn der Health-Check nicht alle relevanten Fehlerarten erkennt, könnten wir einen defekten Release live schalten. Deshalb haben wir eine manuelle Override-Funktion, die in Runbook RB-GW-020 beschrieben ist, um im Zweifel den Blast Radius zu begrenzen."}
{"ts": "138:08", "speaker": "I", "text": "Kommen wir noch einmal zu den Trade-offs zurück – konkret, wie haben Sie die Auswirkungen zusätzlicher mTLS-Session-Revalidierungen auf die Latenz im Orion Edge Gateway gemessen?"}
{"ts": "138:14", "speaker": "E", "text": "Wir haben dafür den Performance-Benchmark aus SLA-ORI-02 herangezogen und in der Staging-Umgebung mit aktiviertem Extended Handshake getestet. Das ergab im Mittel +12 ms pro Request; wir haben das gegen den Security-Gewinn aus POL-SEC-001 abgewogen."}
{"ts": "138:28", "speaker": "I", "text": "Und was war letztlich ausschlaggebend, um diese Revalidierungen dennoch zu aktivieren?"}
{"ts": "138:33", "speaker": "E", "text": "Die Risikoanalyse im RFC-ORI-77 hat gezeigt, dass ohne Revalidierung Replay-Angriffe im Multi-Tenant-Szenario wahrscheinlicher sind. Die 12 ms liegen noch innerhalb des Latenz-Budgets von 150 ms laut SLA-ORI-02."}
{"ts": "138:47", "speaker": "I", "text": "Sie sprachen vorhin Blue/Green an – gab es in den Runbooks spezifische Anpassungen für diesen Ansatz?"}
{"ts": "138:52", "speaker": "E", "text": "Ja, im RB-GW-011 haben wir den Abschnitt zu Traffic Shift erweitert, um mTLS-Session-Daten zwischen den Environments synchron zu halten. Das vermeidet Abbrüche beim Umschalten."}
{"ts": "139:05", "speaker": "I", "text": "Gab es bei dieser Synchronisation Probleme, z. B. in Form von Inkompatibilitäten zu alten Clients?"}
{"ts": "139:10", "speaker": "E", "text": "Einmal, bei Ticket GW-4932, haben ältere IoT-Clients den Session-Resumption-Mechanismus nicht unterstützt. Wir mussten temporär ein Downgrade-Flag setzen und das in IaC-Templates dokumentieren."}
{"ts": "139:26", "speaker": "I", "text": "Wie sichern Sie ab, dass solche temporären Flags nicht in Produktion verbleiben?"}
{"ts": "139:31", "speaker": "E", "text": "Wir haben in der CI/CD-Pipeline einen Linter, der gegen die Flag-Liste aus CFG-SEC-012 prüft. Ein PR wird blockiert, wenn ein als 'temp' gekennzeichnetes Flag noch aktiv ist."}
{"ts": "139:45", "speaker": "I", "text": "Interessant. Und wie wird diese Liste gepflegt?"}
{"ts": "139:49", "speaker": "E", "text": "Sie ist Teil des internen Git-Repos 'sec-configs', Änderungen bedürfen eines genehmigten RFCs und werden von Security-Architektur-Team reviewed."}
{"ts": "140:00", "speaker": "I", "text": "Noch eine letzte Frage: Wie dokumentieren Sie diese gesamten Entscheidungsprozesse für ein mögliches Audit?"}
{"ts": "140:05", "speaker": "E", "text": "Wir nutzen das Decision Log DL-ORI, verlinken dort relevante RFCs, Tickets, Benchmarks und Runbook-Versionen. Das Audit-Team kann so jederzeit die Begründung nachvollziehen."}
{"ts": "140:17", "speaker": "I", "text": "Haben Sie dabei auch Lessons Learned aus Incident GW-4821 eingepflegt?"}
{"ts": "140:22", "speaker": "E", "text": "Ja, insbesondere die Maßnahme, mTLS-Handshake-Timeouts dynamisch zu konfigurieren. Das steht jetzt als Best Practice im DL-ORI und im RB-GW-011, damit zukünftige Deployments resilienter sind."}
{"ts": "143:55", "speaker": "I", "text": "Sie hatten ja eben die Entscheidung Blue/Green vs. Canary erläutert. Mich würde noch interessieren, wie Sie dabei das Runbook RB-GW-011 konkret angewendet haben."}
{"ts": "144:00", "speaker": "E", "text": "Im Runbook RB-GW-011 gibt es ein Kapitel 4.2, in dem genau beschrieben ist, wie die Umschaltlogik zwischen Green und Blue-Stacks zu erfolgen hat. Wir haben das eins zu eins in unseren Jenkins-Pipeline-Job integriert, inklusive Pre-Switch mTLS-Handshake-Checks."}
{"ts": "144:06", "speaker": "I", "text": "Gab es denn Abweichungen vom Runbook, um SLA-ORI-02 einzuhalten?"}
{"ts": "144:10", "speaker": "E", "text": "Ja, minimal: Wir haben die Health-Check-Intervalle von 30s auf 15s reduziert, um die Latenz beim Switchover zu minimieren, ohne den Blast Radius zu vergrößern. Das war auch im Ticket GW-4923 dokumentiert."}
{"ts": "144:17", "speaker": "I", "text": "Wie haben Sie die Risiken dieser Anpassung bewertet?"}
{"ts": "144:21", "speaker": "E", "text": "Wir haben eine Risikoabschätzung nach POL-SEC-001 durchgeführt. Da die Checks doppelt so häufig laufen, steigt zwar kurzzeitig die Last, aber wir haben in den Load-Tests (siehe Testreport TR-GW-07) keine negativen Effekte gefunden."}
{"ts": "144:29", "speaker": "I", "text": "Und in Bezug auf das Aegis IAM – gab es Schnittstellen, die beim Switchover kritisch waren?"}
{"ts": "144:34", "speaker": "E", "text": "Ja, das Just-in-Time Access Provisioning muss synchronisiert werden. Beim Blue/Green Wechsel muss der neue Stack sofort vom IAM erkannt werden, sonst gibt’s 401 Errors. Wir haben dazu in der Pipeline einen Hook, der den Aegis Connector neu initialisiert."}
{"ts": "144:42", "speaker": "I", "text": "Wie haben Sie das getestet?"}
{"ts": "144:45", "speaker": "E", "text": "Mit einer Simulation in unserer Staging-Zone, wo wir mithilfe des Nimbus Observability Agents Latency-Spikes und Auth-Failure-Rates in Echtzeit überwachen konnten. Die Ergebnisse wurden im CI-Bericht an QA übergeben."}
{"ts": "144:53", "speaker": "I", "text": "Gab es dabei unerwartete Findings?"}
{"ts": "144:56", "speaker": "E", "text": "Einmal hat der Nimbus-Agent selbst einen Memory-Leak verursacht – das stand später in Incident GW-5001. Wir haben daraufhin den Agent nach jedem Switchover neu gestartet."}
{"ts": "145:02", "speaker": "I", "text": "Klingt nach einer pragmatischen Lösung. Würden Sie diese Lessons Learned auch auf künftige Projekte übertragen?"}
{"ts": "145:06", "speaker": "E", "text": "Definitiv. Vor allem der Teil, dass wir Observability-Tools nicht isoliert betrachten dürfen. Sie sind Teil des Deployments und können selbst ein Risk-Faktor sein."}
{"ts": "145:12", "speaker": "I", "text": "Wie dokumentieren Sie solche Cross-Tool-Risiken?"}
{"ts": "145:15", "speaker": "E", "text": "Wir pflegen dafür im Confluence einen Abschnitt 'Toolchain Risks' pro Projekt, verlinkt mit den relevanten RFCs und Runbooks. So kann Audit später nachvollziehen, welche Workarounds implementiert wurden."}
{"ts": "145:55", "speaker": "I", "text": "Noch einmal zu den mTLS-Handshake-Störungen aus Ticket GW-4821: Was hat sich aus Ihrer Sicht bei der letzten Analyse als Hauptursache herauskristallisiert?"}
{"ts": "146:04", "speaker": "E", "text": "Wir haben festgestellt, dass in etwa 70 % der Fälle ein fehlerhaftes Zwischenzertifikat im Test-Mandanten verwendet wurde. Laut Runbook RB-GW-011 hätte das Pre-Deployment-Skript eigentlich via Check 'cert-chain-validate' greifen müssen, wurde aber in der Canary-Stufe übersprungen."}
{"ts": "146:17", "speaker": "I", "text": "Warum wurde dieser Check übersprungen? War das ein bewusster Trade-off oder ein Implementierungsfehler?"}
{"ts": "146:24", "speaker": "E", "text": "Das war leider ein Implementierungsfehler. In der CI/CD-Konfiguration war der Hook nur für Blue/Green-Pipelines aktiv. Als wir testweise eine Canary-Route gefahren sind, hat der Parameter 'strictCertCheck' gefehlt."}
{"ts": "146:37", "speaker": "I", "text": "Sie sprachen in einer früheren Session von einer Policy-Matrix. Wie wurde diese in den IaC-Templates überprüft?"}
{"ts": "146:44", "speaker": "E", "text": "Wir haben YAML-basierte Templates mit einem Pre-Commit-Hook versehen, der die mTLS-Policy-Matrix aus POL-SEC-001 gegen die Resource-Definitionen prüft. Das wird auch im Merge-Check protokolliert und in den Audit-Logs hinterlegt."}
{"ts": "146:57", "speaker": "I", "text": "Gab es dabei Abhängigkeiten zu anderen Systemen, etwa Aegis IAM?"}
{"ts": "147:03", "speaker": "E", "text": "Ja, die Zertifikatsvalidierung hängt indirekt an den JIT-Access-Mechanismen von Aegis IAM. Wird ein Access Token ausgestellt, muss es im Gateway über mTLS gesichert sein. Fällt die mTLS-Kette, verweigert Aegis den Token-Refresh."}
{"ts": "147:17", "speaker": "I", "text": "Und wie spiegelt sich das in der Observability über Nimbus wider?"}
{"ts": "147:23", "speaker": "E", "text": "Nimbus Observability sammelt Metriken wie 'handshake_fail_rate' und korreliert sie mit SLA-ORI-02. Wir haben Alerts konfiguriert, die bei einem Schwellenwert von 0,5 % auslösen. Das wurde im Incident GW-4821 auch dokumentiert."}
{"ts": "147:37", "speaker": "I", "text": "Wie koordinieren Sie bei solchen Vorfällen mehrere RFCs gleichzeitig?"}
{"ts": "147:43", "speaker": "E", "text": "Wir nutzen ein internes Change-Board. Für GW-4821 liefen parallel RFC-ORI-14 für den Cert-Check-Fix und RFC-ORI-15 für die Anpassung der Canary-Pipeline. Das Board priorisiert nach Auswirkung auf SLA und Security."}
{"ts": "147:56", "speaker": "I", "text": "Welche Risiken sehen Sie noch bei Rolling Deployments in Multi-Tenant-Umgebungen, abgesehen von Zertifikatsproblemen?"}
{"ts": "148:03", "speaker": "E", "text": "Ein wesentliches Risiko ist der 'noisy neighbor' Effekt: Bei unzureichender Ressourcenisolierung kann ein Tenant mit hohem Traffic das mTLS-Handshake-Timing eines anderen Tenants negativ beeinflussen. Das kann SLA-Verletzungen verursachen."}
{"ts": "148:16", "speaker": "I", "text": "Wie mitigieren Sie diesen Effekt?"}
{"ts": "148:22", "speaker": "E", "text": "Wir haben in RB-GW-011 einen Schritt ergänzt: Vor dem Rolling Deployment wird pro Tenant ein Limit-Check auf CPU/Memory-Quotas gefahren. Zusätzlich werden Test-Handshakes simuliert, um Latenzspitzen vorab zu erkennen."}
{"ts": "147:31", "speaker": "I", "text": "Sie hatten ja vorhin schon das Runbook RB-GW-011 angesprochen. Können Sie noch einmal präzisieren, wie es im Orion Edge Gateway bei einem Rolling Deployment tatsächlich zur Anwendung kommt?"}
{"ts": "147:36", "speaker": "E", "text": "Ja, klar. RB-GW-011 ist fest in der CI/CD-Pipeline verankert, direkt zwischen Build- und Deploy-Stage. Wir triggern es über ein Jenkins-Stage-Skript, das auch die Policy-Checks aus POL-SEC-001 noch mal ausführt, bevor der Traffic umgeleitet wird."}
{"ts": "147:41", "speaker": "I", "text": "Und wie wird dabei sichergestellt, dass keine mTLS-Konfigurationen übersehen werden?"}
{"ts": "147:46", "speaker": "E", "text": "Das passiert über unsere IaC-Templates. Wir haben ein Validation-Script in Terraform, das gegen die mTLS-Policy-Matrix läuft. Wenn ein Eintrag fehlt oder falsch ist, bricht der Pipeline-Job sofort mit einem Fehlercode ab."}
{"ts": "147:51", "speaker": "I", "text": "Sie haben auch Nimbus Observability eingebunden – wie hilft Ihnen das bei der Einhaltung von SLA-ORI-02?"}
{"ts": "147:56", "speaker": "E", "text": "Nimbus liefert uns Realtime-Metriken zur Latenz pro API-Route. Wir haben Alerts konfiguriert, die bei 80% der Grenzwerte aus SLA-ORI-02 auslösen, sodass wir proaktiv optimieren können."}
{"ts": "148:01", "speaker": "I", "text": "Gab es in letzter Zeit ein konkretes Beispiel, wo dieser Alert ausgelöst wurde?"}
{"ts": "148:06", "speaker": "E", "text": "Ja, am 14.05. ging ein Alert auf der /partner/v1-Route hoch. Wir haben festgestellt, dass ein zusätzlicher JWT-Verification-Call die Latenz um 35ms erhöht hat. Daraufhin haben wir den Check in einen asynchronen Preloading-Mechanismus ausgelagert."}
{"ts": "148:11", "speaker": "I", "text": "Interessant. Wie koordinieren Sie solche Änderungen in Bezug auf andere RFCs?"}
{"ts": "148:16", "speaker": "E", "text": "Wir nutzen ein internes RFC-Board, wo jede Änderung einen Cross-Impact-Review bekommt. Für den JWT-Case war das RFC-0921, das mit RFC-0880 aus Aegis IAM abgestimmt wurde, um sicherzustellen, dass sich die Token-Lebensdauer nicht verändert."}
{"ts": "148:21", "speaker": "I", "text": "Wie sieht das mit Risiken bei Rolling Deployments in Multi-Tenant-Umgebungen aus? Gab es Lessons Learned aus Ticket GW-4821?"}
{"ts": "148:26", "speaker": "E", "text": "GW-4821 war ein MTLS-Handshake-Fehler, der nur einen Tenant betraf, aber die gesamte Node-Gruppe gebremst hat. Lesson Learned: wir isolieren jetzt Tenants auf Service-Ebene und fahren Deployments tenantweise aus, um den Blast Radius zu minimieren."}
{"ts": "148:31", "speaker": "I", "text": "Das klingt nach einer deutlichen Prozessänderung. Wie haben Sie diesen Trade-off mit der Time-to-Deploy bewertet?"}
{"ts": "148:36", "speaker": "E", "text": "Es verlängert die Rollout-Zeit um etwa 15%, aber das Risiko, mehrere Tenants gleichzeitig zu beeinträchtigen, sinkt signifikant. Das haben wir in unserem Risiko-Register RSK-ORI-07 dokumentiert und vom Security Council absegnen lassen."}
{"ts": "148:41", "speaker": "I", "text": "Wie dokumentieren Sie diese Entscheidungen auditfähig?"}
{"ts": "148:46", "speaker": "E", "text": "Wir pflegen ein Confluence-Log mit den Referenzen zu Runbooks, Tickets und RFCs, plus eine kurze Begründung. Für Audits exportieren wir diese Einträge als PDF mit Sign-off der verantwortlichen Leads."}
{"ts": "148:51", "speaker": "I", "text": "Sie hatten vorhin erwähnt, dass beim Blue/Green-Deployment im Build-Phase-Setup noch ein zusätzlicher Auth-Check eingeführt wurde. Können Sie das bitte noch mal konkret mit Bezug auf POL-SEC-001 erläutern?"}
{"ts": "148:56", "speaker": "E", "text": "Ja, klar. POL-SEC-001 schreibt ja vor, dass alle externen API-Endpunkte vor Live-Schaltung einen doppelten Authentifizierungs-Flow durchlaufen müssen. Im Blue/Green-Setup haben wir in der Green-Umgebung den mTLS-Handshake plus einen JWT-Validator aus Aegis IAM gebunden, bevor der Traffic umgeschwenkt wird."}
{"ts": "149:02", "speaker": "I", "text": "Und wie haben Sie das in der Pipeline abgesichert?"}
{"ts": "149:05", "speaker": "E", "text": "Über unser IaC-Template, das die SecurityGroup- und Listener-Configs aus dem Runbook RB-GW-011 zieht. In der CI-Stufe gibt es einen Policy Linter, der die mTLS-Policy-Matrix gegen die Vorlagen prüft. Erst wenn alle Checks durch sind, wird das Green-Cluster als 'ready' markiert."}
{"ts": "149:12", "speaker": "I", "text": "Gab es da mal einen Vorfall, bei dem dieser Linter etwas Kritisches geblockt hat?"}
{"ts": "149:15", "speaker": "E", "text": "Ja, bei Ticket GW-4932 hat der Linter ein fehlendes RootCA-Bundle erkannt. Das hätte in der Multi-Tenant-Stage zu einem mTLS-Handshake Failure geführt wie wir ihn in GW-4821 schon gesehen hatten. Durch den Block konnten wir das vorab beheben."}
{"ts": "149:21", "speaker": "I", "text": "Wie war der Fixprozess in dem Fall?"}
{"ts": "149:24", "speaker": "E", "text": "Wir haben das IaC-Template gemäß RFC-ORI-78 angepasst, das neue RootCA eingebunden und via Blue/Green erneut ausgerollt. Die Observability-Hooks aus Nimbus haben wir genutzt, um den Handshake in Echtzeit zu monitoren und die SLA-ORI-02 Metriken zu prüfen."}
{"ts": "149:31", "speaker": "I", "text": "Apropos Nimbus: Welche Datenpunkte ziehen Sie konkret für die SLA-ORI-02 Überwachung?"}
{"ts": "149:35", "speaker": "E", "text": "Primär die 95th-Percentile-Latenz pro Endpoint, den Error-Rate-Moving-Average über 5 Minuten und spezifische mTLS-Handshake-Dauerwerte. Letztere sind vor allem bei Security-Patches kritisch, weil sie sich direkt auf die Latenz auswirken."}
{"ts": "149:42", "speaker": "I", "text": "Gab es schon mal die Situation, dass Sie das SLA halten mussten, obwohl ein Security-Patch eingespielt wurde?"}
{"ts": "149:46", "speaker": "E", "text": "Ja, im März-Build. Da mussten wir ein OpenID-Provider-Zertifikat rotieren. Wir haben das Blue/Green-Deployment mit vorgeheizten TLS-Sessions kombiniert, um die Latenzspitzen abzufangen. War ein enger Spagat, aber SLA-ORI-02 blieb grün."}
{"ts": "149:53", "speaker": "I", "text": "Wie dokumentieren Sie solche Sondermaßnahmen für spätere Audits?"}
{"ts": "149:56", "speaker": "E", "text": "Im Change-Log des RFC und im Security-Appendix der Deployment-Doku. Wir referenzieren dort die Metriken aus Nimbus und verlinken auf die relevanten Runbook-Abschnitte, damit Audit-Teams die Maßnahmen nachvollziehen können."}
{"ts": "150:02", "speaker": "I", "text": "Gibt es aus Ihrer Sicht noch offene Risiken bei diesem Vorgehen?"}
{"ts": "150:06", "speaker": "E", "text": "Ein Restrisiko ist immer die Koordination mehrerer RFCs parallel. Wenn etwa ein IAM-Update aus Aegis und ein Gateway-Patch zeitgleich laufen, können ungetestete Interaktionen auftreten. Unser Ansatz ist, diese in einer Staging-Multi-Tenant-Umgebung mit synthetischem Traffic aus dem Incident-Simulator zu testen, bevor wir live gehen."}
{"ts": "150:27", "speaker": "I", "text": "Bevor wir schließen, möchte ich noch auf die Integration mit Nimbus Observability zurückkommen – gerade im Hinblick auf SLA‑ORI‑02. Können Sie konkret erklären, wie Sie die Latenz‑Metriken aus Nimbus in Ihr Gateway‑Monitoring einbinden?"}
{"ts": "150:34", "speaker": "E", "text": "Ja, wir haben im Build‑Branch eine Sidecar‑Integration implementiert, die die Prometheus‑Exports aus dem Orion Edge Gateway in den Nimbus Collector streamed. Dort werden sie gegen die SLA‑ORI‑02 Schwellenwerte korreliert. Über einen Alertmanager‑Hook haben wir zusätzlich das Runbook RB‑GW‑015 verlinkt, das genau beschreibt, wie bei Überschreitung der 200ms‑Marke zu reagieren ist."}
{"ts": "150:48", "speaker": "I", "text": "Und dieser Hook – wird der auch bei Rolling Deployments aktiv, oder nur bei Blue/Green?"}
{"ts": "150:53", "speaker": "E", "text": "Er ist unabhängig vom Deployment‑Pattern. Im RB‑GW‑011 ist unter Abschnitt 4.3 dokumentiert, dass die Observability‑Hooks in allen Stages aktiviert bleiben, um gerade beim Switch zwischen Blue und Green die Performance zu validieren."}
{"ts": "151:04", "speaker": "I", "text": "Gab es dabei irgendwelche Probleme mit den mTLS‑Verbindungen, wie wir sie im Ticket GW‑4821 gesehen haben?"}
{"ts": "151:09", "speaker": "E", "text": "Kurzzeitig ja – damals hatte der Sidecar noch nicht die aktualisierten Root‑CAs aus Aegis IAM geladen. Laut Incident‑Postmortem IPC‑21‑07 hat das dazu geführt, dass die Telemetrie‑Streams unterbrochen wurden. Wir haben daraus gelernt, die Zertifikats‑Rotation synchron mit den Observability‑Jobs auszuführen."}
{"ts": "151:23", "speaker": "I", "text": "Wie wird das jetzt technisch in der Pipeline sichergestellt?"}
{"ts": "151:27", "speaker": "E", "text": "In der IaC‑Definition gibt es ein Pre‑Deploy‑Script, das per Terraform‑Provisioner die aktuellen mTLS‑Policies aus der Policy‑Matrix zieht und auf alle Sidecars repliziert. Erst wenn der Health‑Check für den Certificate‑Store grün ist, fährt die Pipeline den nächsten Step."}
{"ts": "151:40", "speaker": "I", "text": "Das heißt, Sie koppeln Security und Observability sehr eng. Gab es Bedenken, dass dadurch die Deployment‑Zeit steigt?"}
{"ts": "151:45", "speaker": "E", "text": "Ja, das war ein klassischer Trade‑off. Wir haben in RFC‑ORI‑27 dokumentiert, dass die zusätzlichen 15 Sekunden Zertifikatsprüfung akzeptabel sind, weil sie das Risiko eines Blindflugs im Monitoring signifikant senken."}
{"ts": "151:56", "speaker": "I", "text": "Wie haben Sie diesen Trade‑off gegenüber dem Management argumentiert?"}
{"ts": "152:00", "speaker": "E", "text": "Wir haben eine Simulation aus der Staging‑Umgebung vorgelegt: ein Deployment ohne diese Prüfung führte in 3 von 10 Fällen zu fehlenden Alerts, was direkt SLA‑Verletzungen verursachte. Mit Prüfung trat das Problem nicht mehr auf – das war ausschlaggebend."}
{"ts": "152:13", "speaker": "I", "text": "Und wie wird das für künftige Audits nachvollziehbar gemacht?"}
{"ts": "152:17", "speaker": "E", "text": "Alle Entscheidungen sind im Confluence‑Space 'ORI‑SEC‑DEC' hinterlegt, mit Verweisen auf RFCs, Tickets und Runbooks. Für Audits exportieren wir daraus ein PDF‑Bundle, das auch die relevanten Log‑Snippets aus Nimbus enthält."}
{"ts": "152:28", "speaker": "I", "text": "Letzte Frage: Gibt es aus Ihrer Sicht noch offene Risiken, die wir adressieren müssen, bevor wir in die nächste Phase gehen?"}
{"ts": "152:33", "speaker": "E", "text": "Das größte Restrisiko sehe ich in der JIT‑Access‑Integration mit Aegis IAM. Wenn deren API in einer Peak‑Load Phase verzögert antwortet, könnte das Auth‑Handshakes verlangsamen. Wir planen daher, in RFC‑ORI‑32 einen Grace‑Cache einzuführen, um den Impact zu minimieren."}
{"ts": "152:03", "speaker": "I", "text": "Sie hatten vorhin angedeutet, dass bei Multi-Tenant Deployments besondere Risiken bestehen. Können Sie das bitte noch konkretisieren?"}
{"ts": "152:12", "speaker": "E", "text": "Ja, gern. In einer Multi-Tenant-Umgebung besteht das Risiko, dass ein fehlerhaftes mTLS-Zertifikat oder ein falscher Rate-Limit-Parameter Auswirkungen auf mehrere Mandanten hat. Laut RB-GW-011 müssen wir daher vor jedem Rollout eine isolierte Staging-Partition testen."}
{"ts": "152:28", "speaker": "I", "text": "Und wie genau überprüfen Sie in dieser Staging-Partition, dass keine Cross-Tenant-Leaks passieren?"}
{"ts": "152:37", "speaker": "E", "text": "Wir setzen ein Traffic-Mirroring auf, bei dem Requests synthetisch generiert werden. Dann laufen Policy-Checks aus POL-SEC-001. Zusätzlich lassen wir den Nimbus Observability Agent Alerts für Tenant-Mix-Events triggern, wie in SLA-ORI-02 gefordert."}
{"ts": "152:55", "speaker": "I", "text": "Gab es Fälle, in denen diese Tests etwas Kritisches gefunden haben?"}
{"ts": "153:04", "speaker": "E", "text": "Ja, Ticket GW-4821 beschreibt so einen Fall. Während eines Handshake-Tests fiel auf, dass das JIT-Access-Token vom Aegis IAM für zwei verschiedene Tenants identisch war. Das wurde noch vor dem Production-Rollout behoben."}
{"ts": "153:21", "speaker": "I", "text": "Interessant. Wie sind Sie da vorgegangen, um die Ursache zu finden?"}
{"ts": "153:29", "speaker": "E", "text": "Wir haben die IaC-Templates aus dem Commit mit der ID cf7a8 geprüft, dort einen falschen Secret-Ref in der Terraform-Variable gefunden. Danach wurde ein Hotfix gemäß RFC-ORI-092 eingespielt."}
{"ts": "153:44", "speaker": "I", "text": "Und welche Lessons Learned ziehen Sie daraus für künftige Deployments?"}
{"ts": "153:53", "speaker": "E", "text": "Wir haben eine zusätzliche IaC-Policy-Kontrolle implementiert, die Secrets-Referenzen gegen eine Whitelist prüft. Außerdem wird jetzt jeder mTLS-Handshake im Canary-Slot vor Blue/Green evaluiert, um den Blast Radius zu minimieren."}
{"ts": "154:09", "speaker": "I", "text": "Das heißt, Sie haben die Canary-Strategie doch noch punktuell integriert?"}
{"ts": "154:16", "speaker": "E", "text": "Genau, aber nur als Pre-Check. Die Hauptauslieferung erfolgt nach wie vor Blue/Green, weil die Umschaltzeit geringer ist und wir so SLA-ORI-02 besser einhalten können."}
{"ts": "154:28", "speaker": "I", "text": "Wie dokumentieren Sie diese Mischstrategie für Audit-Zwecke?"}
{"ts": "154:36", "speaker": "E", "text": "In Confluence gibt es eine Seite 'Deployment Patterns Orion', dort sind die Runbook-IDs, betroffenen RFCs und Lessons Learned verlinkt. Auditoren bekommen Lesezugriff auf diese Seite und die zugehörigen Pipeline-Logs."}
{"ts": "154:50", "speaker": "I", "text": "Gibt es Pläne, das noch stärker zu automatisieren?"}
{"ts": "154:57", "speaker": "E", "text": "Ja, wir prüfen gerade ein GitOps-basiertes System, das bei jeder Änderung an den IaC-Templates automatisch Compliance-Checks gegen POL-SEC-001 und die mTLS-Policy-Matrix fährt und das Ergebnis direkt im Merge-Request anzeigt."}
{"ts": "158:03", "speaker": "I", "text": "Sie hatten vorhin kurz Ticket GW-4821 erwähnt. Können Sie bitte nochmal genau schildern, wie Sie beim MTLS Handshake Fault vorgegangen sind?"}
{"ts": "158:08", "speaker": "E", "text": "Ja, klar. Das war ein Fall, bei dem in der Staging-Umgebung die Root CA in der mTLS-Policy-Matrix fehlte. Wir haben gem. Runbook RB-GW-011 Abschnitt 4.2 zunächst die Handshake-Logs in Nimbus TraceView gezogen und dann über den Aegis IAM Connector temporär einen Fallback-Key bereitgestellt."}
{"ts": "158:16", "speaker": "I", "text": "Und wie haben Sie verhindert, dass dieser Workaround in Produktion rutscht?"}
{"ts": "158:20", "speaker": "E", "text": "Wir haben im IaC-Template den Fallback-Key bewusst als ephemeral markiert, mit einer TTL von 30 Minuten. Zusätzlich gab es einen Guard in der CI/CD-Pipeline, der Builds mit diesem Flag in der prod-Stage blockiert."}
{"ts": "158:27", "speaker": "I", "text": "Wie lief dabei die Abstimmung mit den Teams des Aegis IAM?"}
{"ts": "158:31", "speaker": "E", "text": "Sehr eng. Wir nutzen für solche Fälle einen wöchentlichen RFC-Sync. Im konkreten Fall wurde RFC-ORI-77 ad hoc ergänzt, um den JIT-Access-Flow anzupassen. Das hat die Genehmigung innerhalb von zwei Stunden ermöglicht."}
{"ts": "158:39", "speaker": "I", "text": "Sie sprechen den JIT-Access-Flow an – wie stellen Sie sicher, dass er auch unter Last nicht die SLA-ORI-02 verletzt?"}
{"ts": "158:44", "speaker": "E", "text": "Wir haben in Nimbus Observability ein spezielles Panel, das mTLS-Handshake-Zeiten und Auth-Latenzen korreliert. Wenn die 95th-Percentile-Latenz > 200 ms geht, triggert ein Alert. Das ist direkt im SLA-ORI-02 hinterlegt."}
{"ts": "158:52", "speaker": "I", "text": "Gab es schon mal eine Überschreitung?"}
{"ts": "158:55", "speaker": "E", "text": "Einmal, bei einem Rolling Deployment in der Multi-Tenant-Umgebung, als wir versehentlich beide Gateways gleichzeitig neu gestartet haben. Da hatten wir kurzzeitig 350 ms, was den Alert ausgelöst hat, aber durch den schnellen Rollback begrenzt blieb."}
{"ts": "159:03", "speaker": "I", "text": "Welche Lessons Learned haben Sie daraus gezogen?"}
{"ts": "159:07", "speaker": "E", "text": "Wichtig war uns, im RB-GW-011 einen zusätzlichen Step einzubauen: vor dem zweiten Node-Restart prüfen wir jetzt im Nimbus-Dashboard die aktuellen Latenzen. Außerdem haben wir im IaC einen Mutex-Lock definiert, der gleichzeitige Restarts unterbindet."}
{"ts": "159:15", "speaker": "I", "text": "Das klingt nach einer Prozessänderung, die auch auditrelevant ist. Wie dokumentieren Sie das?"}
{"ts": "159:19", "speaker": "E", "text": "Wir pflegen solche Anpassungen in unserem internen Confluence unter der Kategorie 'Runbook Changes'. Jeder Eintrag referenziert das zugehörige Incident-Ticket und das RFC-Dokument. Für GW-4821 gibt es beispielsweise einen Eintrag mit allen Log-Snippets und den geänderten IaC-Snippets."}
{"ts": "159:27", "speaker": "I", "text": "Abschließend: sehen Sie bei dieser Kombination aus mTLS, JIT-Access und Blue/Green-Rollouts noch offene Risiken?"}
{"ts": "159:32", "speaker": "E", "text": "Das größte Restrisiko ist aus meiner Sicht die Komplexität der Abhängigkeiten. Wenn Aegis IAM eine Schema-Änderung ohne Vorwarnung einspielt, könnten Auth-Flows brechen. Deshalb haben wir jetzt im SLA-ORI-02 eine Klausel, die eine 48h-Vorabinfo für Breaking Changes vorschreibt, und wir spiegeln die kritischen Metriken in ein isoliertes Test-Cluster."}
{"ts": "160:03", "speaker": "I", "text": "Bevor wir ins nächste Thema einsteigen, können Sie mir bitte schildern, wie Sie im Orion Edge Gateway Incidents rund um Aegis IAM Anbindungen identifizieren?"}
{"ts": "160:09", "speaker": "E", "text": "Ja, wir haben im Build-Cluster ein Alerting, das direkt aus Nimbus Observability via RuleSet NIM-RS-017 Events triggert, wenn der JIT-Access-Flow länger als 1,2 Sekunden dauert oder 401/403 Codes häufen. Diese Alert-Events sind mit dem Incident Runbook RB-IAM-004 verlinkt."}
{"ts": "160:18", "speaker": "I", "text": "Und wenn so ein Alert kommt, was ist der erste Schritt?"}
{"ts": "160:22", "speaker": "E", "text": "Der On-Call Engineer prüft im Gateway-Log-Stream, ob es an der mTLS-Handshake-Phase liegt oder an einer Fehlkonfiguration im Aegis IAM Connector. Bei mTLS-Themen verweisen wir sofort auf die Checkliste aus RB-GW-011 Abschnitt 4.2."}
{"ts": "160:31", "speaker": "I", "text": "Gab es Fälle, wo die Observability-Daten nicht ausgereicht haben?"}
{"ts": "160:36", "speaker": "E", "text": "Ja, im Ticket GW-4821 hatten wir genau das. Nimbus zeigte nur erhöhte Latenz beim Token-Exchange, aber nicht die Ursache. Wir mussten manuell Correlation-IDs aus Gateway und IAM-Logs matchen."}
{"ts": "160:46", "speaker": "I", "text": "Wie wird so etwas in künftigen Deployments vermieden?"}
{"ts": "160:50", "speaker": "E", "text": "Wir haben in RFC-ORI-078 beschlossen, im IaC-Template für die Observability-Bridge zusätzlich einen Trace-Exporter zu aktivieren, der Aegis- und Gateway-Metriken in einem gemeinsamen Span darstellt."}
{"ts": "160:59", "speaker": "I", "text": "Klingt nach einer Multi-Hop-Integration zwischen Systemen. Welche Risiken sehen Sie dabei?"}
{"ts": "161:04", "speaker": "E", "text": "Das Hauptrisiko ist, dass ein Fehler in der Trace-Serialisierung den ganzen Deploy blockiert. Deshalb haben wir einen Feature-Flag 'trace_unified_export' vorgesehen, der in einem Blue/Green-Rollout nur auf der Green-Site aktiv ist."}
{"ts": "161:14", "speaker": "I", "text": "Und wie dokumentieren Sie diese Änderungen für Audits?"}
{"ts": "161:18", "speaker": "E", "text": "Im ChangeLog der RFCs und zusätzlich im Security-Appendix, wo wir auf die relevanten Runbooks und Lessons Learned verweisen. Bei GW-4821 zum Beispiel haben wir explizit notiert, wie der Blast Radius durch Segmentierung der Tenant-Routes begrenzt wurde."}
{"ts": "161:28", "speaker": "I", "text": "Haben Sie noch ein Beispiel für ein solches Lesson Learned?"}
{"ts": "161:33", "speaker": "E", "text": "Ja, nach einem Rolling Deployment in einem Multi-Tenant-Cluster (Incident GW-4799) haben wir gelernt, dass wir vorab die mTLS-Policy-Matrix gegen alle aktiven Tenants validieren müssen. Das ist jetzt ein fixer Step in der CI-Pipeline, referenziert in RB-GW-011 Abschnitt 3.5."}
{"ts": "161:44", "speaker": "I", "text": "Wie wirkt sich das auf die Latenz und SLA-ORI-02 aus?"}
{"ts": "161:48", "speaker": "E", "text": "Es kostet uns etwa 80ms zusätzliche Check-Zeit pro Tenant beim Deploy, aber das geschieht außerhalb des Request-Path. Im Betrieb bleibt die Latenz unter den 250ms, die SLA-ORI-02 vorgibt."}
{"ts": "161:39", "speaker": "I", "text": "Sie hatten vorhin die Lessons Learned aus GW-4821 kurz angesprochen. Können Sie nochmal konkret erklären, welche Anpassungen wir in der Aegis IAM Schnittstelle daraus abgeleitet haben?"}
{"ts": "161:44", "speaker": "E", "text": "Ja, klar. Nach der mTLS-Handshake-Störung haben wir in der Auth-Integration ein Pre-Validation Modul eingebaut, das vor dem eigentlichen Handshake eine Zertifikatskette gegen den Aegis PKI-Endpunkt prüft. Das ist inzwischen in den IaC-Definitionen im Terraform-Modul `orion_gateway_auth` verankert."}
{"ts": "161:53", "speaker": "I", "text": "Und das wird dann auch in der CI/CD-Pipeline automatisiert geprüft?"}
{"ts": "161:56", "speaker": "E", "text": "Exakt. Wir haben im Jenkinsfile einen Stage `auth_precheck` ergänzt, der das Runbook RB-GW-011 referenziert. Dort ist genau dokumentiert, welche mTLS-Policy-Matrix zu verwenden ist, und bei Abweichungen schlägt der Build fehl."}
{"ts": "162:05", "speaker": "I", "text": "Wie fließt Nimbus Observability da mit rein, um SLA-ORI-02 zu überwachen?"}
{"ts": "162:09", "speaker": "E", "text": "Nimbus liefert uns Latenz- und Fehlerquoten pro Tenant. Wir haben Dashboards mit Alert-Regeln gebaut, die den Abschnitt 'Gateway Auth Path' separat betrachten. Wenn dort die mTLS-Latenz 20% über dem Median liegt, triggert das einen SLA-Vorab-Alarm."}
{"ts": "162:19", "speaker": "I", "text": "Gab es da Koordinationsprobleme zwischen den RFCs für Auth und für Observability?"}
{"ts": "162:23", "speaker": "E", "text": "Ja, minimal. RFC-ORI-27 (Auth-Precheck) und RFC-ORI-29 (Observability-Granularität) hatten sich zeitlich überschnitten. Wir haben daher ein gemeinsames Change-Board-Meeting eingeschoben, um die Metrik-Namen und Tags abzustimmen."}
{"ts": "162:33", "speaker": "I", "text": "Stichwort Multi-Tenant-Rollouts: Welche Risiken sehen Sie da beim Rolling Deployment laut RB-GW-011?"}
{"ts": "162:37", "speaker": "E", "text": "Das größte Risiko ist, dass ein fehlerhaftes Zertifikats-Update nur einen Teil der Tenants trifft, was inkonsistente Auth-Erfahrungen erzeugt. RB-GW-011 empfiehlt daher, in der Staging-Phase immer mindestens zwei Tenants mit unterschiedlichen PKIs zu testen."}
{"ts": "162:47", "speaker": "I", "text": "Und wenn trotzdem ein Incident auftritt?"}
{"ts": "162:50", "speaker": "E", "text": "Dann ziehen wir den Incident-Plan aus IR-GW-005. Der sieht vor, dass wir sofort die betroffenen Tenant-Routen in der Routing-Tabelle deaktivieren und ein mTLS-Fallback-Profile aktivieren. Das minimiert den Blast Radius."}
{"ts": "162:59", "speaker": "I", "text": "Wie lange dauert es im Schnitt, diesen Fallback zu aktivieren?"}
{"ts": "163:02", "speaker": "E", "text": "Wir haben das gemessen: Im letzten Drill lag die Mean Time to Mitigate bei 3 Minuten 40 Sekunden. Das ist unter dem MTTR-Limit, das in SLA-ORI-02 Abschnitt 4 spezifiziert ist."}
{"ts": "163:10", "speaker": "I", "text": "Sie hatten erwähnt, dass das Pre-Validation Modul auch im Canary getestet wurde. Gab es da Unterschiede im Vergleich zum Blue/Green Rollout?"}
{"ts": "163:14", "speaker": "E", "text": "Beim Canary hatten wir die mTLS-Prüfung nur auf 10% des Traffics. Das hat uns geholfen, Performance-Einbußen früh zu sehen, allerdings war das Risiko höher, dass Fehler unentdeckt in den anderen 90% liefen. Blue/Green gibt uns da klarere Trennung, kostet aber mehr Ressourcen."}
{"ts": "163:39", "speaker": "I", "text": "Lassen Sie uns noch einmal auf die Entscheidung Blue/Green vs. Canary zurückkommen – wie haben Sie diese im Kontext der Multi-Tenant-Architektur abgewogen?"}
{"ts": "163:44", "speaker": "E", "text": "Wir haben in RB-GW-011 eine Matrix gepflegt, die sowohl die mTLS-Handshake-Dauer als auch den Impact pro Tenant simuliert. Canary hätte uns zwar feinere Granularität gegeben, aber bei 48 Tenants gleichzeitig wäre das Risiko von inkonsistenten Auth-Zuständen gegenüber Aegis IAM zu hoch gewesen."}
{"ts": "163:52", "speaker": "I", "text": "Das heißt, Sie haben Performance- und Konsistenzaspekte priorisiert?"}
{"ts": "163:55", "speaker": "E", "text": "Genau, SLA-ORI-02 verlangt <150ms für Gateway-Response unter Last. Die zusätzlichen Canary-Checks hätten das in unseren Stresstests um bis zu 40ms überschritten. Blue/Green erlaubt uns, einen kompletten Cluster mit neuen Policies zu starten und dann per Flip umzuschalten."}
{"ts": "164:03", "speaker": "I", "text": "Gab es dazu ein formales RFC-Dokument?"}
{"ts": "164:06", "speaker": "E", "text": "Ja, RFC-ORI-17. Darin haben wir auch die Lessons Learned aus GW-4821 einfließen lassen, insbesondere wie wir bei Handshake-Failures einen Rollback orchestrieren."}
{"ts": "164:12", "speaker": "I", "text": "Und wie dokumentieren Sie diese Abwägungen für Audits?"}
{"ts": "164:15", "speaker": "E", "text": "Wir nutzen das interne Decision-Log-System, jede Entscheidung ist mit dem zugehörigen Runbook und Ticket verlinkt. Bei Blue/Green ist z.B. die Referenz DEC-2024-08-14 hinterlegt."}
{"ts": "164:21", "speaker": "I", "text": "Welche Risiken bleiben trotz dieser Wahl bestehen?"}
{"ts": "164:24", "speaker": "E", "text": "Größtes Risiko ist der sogenannte Cold Start Lag, wenn der neue Green-Cluster zum ersten Mal mit Aegis IAM synchronisiert. Wir mitigieren das mit Pre-Warming-Skripten, aber 2–3 Sekunden können bei bestimmten API-Calls auftreten."}
{"ts": "164:32", "speaker": "I", "text": "Und wie wird das im Monitoring sichtbar?"}
{"ts": "164:35", "speaker": "E", "text": "Nimbus Observability hat ein Custom-Dashboard ORI-LAT-GW, das die Latenz pro Tenant und Endpoint ausweist. Wir haben Alarme konfiguriert, die bei >200ms in zwei aufeinanderfolgenden Messfenstern auslösen."}
{"ts": "164:42", "speaker": "I", "text": "Gab es in der Praxis schon einen Alarm während eines Blue/Green-Rollouts?"}
{"ts": "164:45", "speaker": "E", "text": "Einmal, beim Rollout in Staging. Ursache war eine vergessene mTLS-Zertifikatserneuerung im Green-Cluster. Das haben wir über das Pre-Rollout-Checklist-Update gefixt."}
{"ts": "164:51", "speaker": "I", "text": "Also ein klassischer Prozessfehler, der jetzt im Runbook steht?"}
{"ts": "164:54", "speaker": "E", "text": "Ja, Runbook RB-GW-011 wurde in Abschnitt 4.3 ergänzt: 'Verify mTLS Cert Expiry before switch'. Seitdem kein Wiederauftreten in Prod."}
{"ts": "165:15", "speaker": "I", "text": "Sie hatten eben die Blast Radius Minimierung erwähnt. Können Sie bitte noch tiefer auf die Lessons Learned aus den letzten Incidents eingehen, speziell wie diese in RB-GW-011 nachgezogen wurden?"}
{"ts": "165:28", "speaker": "E", "text": "Ja, klar. Wir haben im Runbook RB-GW-011 nach Ticket GW-4821 explizit eine neue Sektion eingefügt, die den Ablauf bei partiellen mTLS-Handshake-Fehlern beschreibt. Das beinhaltet jetzt auch ein automatisches Quarantaining des betroffenen Tenant-Routers, um lateral movement zu verhindern."}
{"ts": "165:45", "speaker": "I", "text": "War das eine reine technische Ergänzung oder gab es auch organisatorische Anpassungen?"}
{"ts": "165:53", "speaker": "E", "text": "Beides. Technisch haben wir im IaC-Template einen zusätzlichen Health-Check-Block verankert, organisatorisch mussten wir den On-Call-Plan anpassen, sodass Security-Engineers im First Response Slot involviert sind, nicht erst in Escalation Level 2."}
{"ts": "166:10", "speaker": "I", "text": "Wie wirkt sich das auf die SLA-ORI-02 Messungen aus?"}
{"ts": "166:17", "speaker": "E", "text": "Interessanterweise kaum negativ. Wir haben durch pre-emptive Checks in der Blue/Green Pipeline minimal längere Build-Zeiten, aber im Live-Traffic halten wir die Latenzgrenze von 120 ms zu 98 % ein."}
{"ts": "166:31", "speaker": "I", "text": "Gab es Gegenstimmen, die diese zusätzlichen Checks aus Performancegründen ablehnen wollten?"}
{"ts": "166:39", "speaker": "E", "text": "Ja, vor allem aus dem Payments-Team, die sehr empfindlich auf Latenzen reagieren. Wir haben dann Testläufe mit synthetischem Traffic repräsentativ für deren Patterns gefahren und konnten zeigen, dass der Impact <3 ms liegt."}
{"ts": "166:55", "speaker": "I", "text": "Wie haben Sie das im Audit-Log festgehalten?"}
{"ts": "167:02", "speaker": "E", "text": "In Confluence ist ein 'Decision Record' mit ID DR-ORI-27 angelegt, verlinkt auf die RFCs 1124 (Aegis IAM Anpassung) und 1130 (Nimbus Metrics Erweiterung). Dort steht die Messmethodik und der genehmigende CISO-Vertreter."}
{"ts": "167:19", "speaker": "I", "text": "Apropos Nimbus, haben Sie für die mTLS-Metriken eine spezielle Pipeline erstellt?"}
{"ts": "167:27", "speaker": "E", "text": "Ja, wir haben im Nimbus Observability Stack einen neuen Collector 'mtls-handshake-latency' implementiert, der aus den Envoy-Proxies der Gateways feeded. Dieser wird bei SLA-ORI-02 Ausreißern direkt ins Incident Management gepiped."}
{"ts": "167:45", "speaker": "I", "text": "Wie spielen diese Observability-Daten mit dem Rolling Deployment zusammen?"}
{"ts": "167:53", "speaker": "E", "text": "Während eines Rolling Deployments (RB-GW-011) nutzen wir die Daten als Gatekeeper: wenn die mTLS-Latenz in mehr als 2 von 5 Canary-Slots über 130 ms steigt, wird der Rollout pausiert und ein Automated Rollback getriggert."}
{"ts": "168:10", "speaker": "I", "text": "Das klingt robust. Sehen Sie noch Risiken, die nicht adressiert sind?"}
{"ts": "168:18", "speaker": "E", "text": "Ein Restrisiko ist immer das 'unknown unknown', z. B. bei gleichzeitigen Änderungen in Aegis IAM und im Gateway. Wir koordinieren zwar über den RFC-Kalender, aber wenn zwei Deployments zeitlich kollidieren, kann es zu unvorhergesehenen Auth-Timeouts kommen."}
{"ts": "169:15", "speaker": "I", "text": "Lassen Sie uns noch mal auf die Lessons Learned aus GW-4821 zurückkommen – wie haben Sie die Erkenntnisse konkret in RB-GW-011 eingepflegt?"}
{"ts": "169:26", "speaker": "E", "text": "Wir haben im Runbook einen zusätzlichen Abschnitt 'Handshake Recovery' ergänzt. Dort steht jetzt explizit, wie wir bei einer MTLS-Handshake-Störung in einer Multi-Tenant-Umgebung vorgehen, inklusive Timeout-Tuning und Priorisierung nach Tenant-Kritikalität."}
{"ts": "169:44", "speaker": "I", "text": "Gab es dazu auch Anpassungen in der CI/CD Pipeline?"}
{"ts": "169:50", "speaker": "E", "text": "Ja, wir haben in der Build-Stage einen automatisierten Test eingeführt, der die mTLS-Konfiguration gegen die Policy-Matrix aus POL-SEC-001 validiert. Das reduziert das Risiko, dass ein fehlerhaftes Zertifikat bis in Prod gelangt."}
{"ts": "170:07", "speaker": "I", "text": "Und wie stellen Sie sicher, dass das auch mit den Observability-Mechanismen von Nimbus harmoniert?"}
{"ts": "170:14", "speaker": "E", "text": "Wir haben die Alert-Rules in Nimbus so angepasst, dass sie die neuen Timeout- und Fehlercodes aus dem Runbook kennen. So vermeiden wir false positives und halten die SLA-ORI-02-Überwachung konsistent."}
{"ts": "170:30", "speaker": "I", "text": "Gab es bei der Umsetzung Konflikte mit laufenden RFCs, etwa im Aegis IAM Kontext?"}
{"ts": "170:37", "speaker": "E", "text": "Wir mussten tatsächlich RFC-IAM-114 und RFC-OBS-208 synchronisieren. Der IAM-Teil betraf JIT-Access-Flows, die beim mTLS-Handshake zusätzliche Claims auswerten, während OBS-208 die Log-Struktur in Nimbus erweiterte."}
{"ts": "170:56", "speaker": "I", "text": "Das klingt nach einem durchaus komplexen Abgleich. Haben Sie dafür ein dediziertes Koordinationsteam?"}
{"ts": "171:02", "speaker": "E", "text": "Wir haben ein virtuelles Tiger Team gebildet – mit je einem Vertreter aus Gateway, IAM und Observability. Die treffen sich zweimal pro Woche, um Änderungen abzugleichen."}
{"ts": "171:17", "speaker": "I", "text": "Wie beurteilen Sie rückblickend den Trade-off, den wir vorhin diskutiert haben, zwischen Latenz und Security-Checks?"}
{"ts": "171:24", "speaker": "E", "text": "Ehrlich gesagt: Die 5–7 ms zusätzliche Latenz sind im Kontext der gewonnenen Sicherheit vertretbar. Wir dokumentieren das im Architekturentscheidungs-Record ADR-GW-019, damit es im Audit nachvollziehbar bleibt."}
{"ts": "171:40", "speaker": "I", "text": "Wurde ADR-GW-019 auch mit den SLA-Verantwortlichen abgestimmt?"}
{"ts": "171:45", "speaker": "E", "text": "Ja, wir haben es im SLA-Board vorgestellt und die Messwerte aus der Nimbus-Überwachung präsentiert. Damit war klar, dass wir SLA-ORI-02 weiterhin einhalten."}
{"ts": "171:58", "speaker": "I", "text": "Letzte Frage: Würden Sie bei einem künftigen Projekt wieder Blue/Green gegenüber Canary bevorzugen?"}
{"ts": "172:05", "speaker": "E", "text": "In einem hochsensiblen Multi-Tenant-Setup wie Orion Edge Gateway definitiv. Der kontrollierte Switch im Blue/Green minimiert den Blast Radius und gibt uns saubere Rollback-Punkte – Canary ist in so einer Umgebung zu unberechenbar."}
{"ts": "177:15", "speaker": "I", "text": "Bevor wir abschließen, möchte ich noch verstehen, wie Sie die Lessons Learned aus GW-4821 formell in Ihre Deployment-Strategien zurückführen."}
{"ts": "177:22", "speaker": "E", "text": "Wir haben nach dem Incident ein Addendum zu RB-GW-011 erstellt, das explizit einen Pre-Deployment mTLS-Handshake-Test gegen unsere Staging-Cluster vorsieht. Das wurde dann auch in den IaC-Templates als Step hinterlegt."}
{"ts": "177:33", "speaker": "I", "text": "Gab es dabei Schnittstellenprobleme mit Aegis IAM oder Nimbus?"}
{"ts": "177:39", "speaker": "E", "text": "Ja, minimal. Die Testumgebung musste für Aegis JIT-Access freigeschaltet werden, damit die mTLS-Zertifikate aus dem Vault-Backend bezogen werden konnten. Für Nimbus haben wir zusätzlich ein temporäres Dashboard konfiguriert, um Handshake-Latenzen in Echtzeit zu sehen."}
{"ts": "177:53", "speaker": "I", "text": "Und wie dokumentieren Sie solche Addenda für Audit-Zwecke?"}
{"ts": "178:00", "speaker": "E", "text": "Wir pflegen eine Confluence-Seite pro Runbook-Version. Jede Änderung bekommt eine RFC-ID und eine Verknüpfung zu den relevanten Tickets wie GW-4821. Das Audit-Team hat Lesezugriff und wir führen vierteljährlich einen Review durch."}
{"ts": "178:14", "speaker": "I", "text": "Gab es bei der Umsetzung Performance-Einbußen im Hinblick auf SLA-ORI-02?"}
{"ts": "178:20", "speaker": "E", "text": "Kaum messbar. Der zusätzliche Pre-Handshake kostete im Schnitt 180ms, was innerhalb der 500ms Budgetgrenze von SLA-ORI-02 liegt. Wir haben das mit synthetischen Lasttests validiert."}
{"ts": "178:33", "speaker": "I", "text": "Wie gehen Sie mit der Gefahr um, dass Blue/Green-Deployments in der Multi-Tenant-Struktur dennoch unerwartete Seiteneffekte haben?"}
{"ts": "178:42", "speaker": "E", "text": "Wir nutzen Tenant-Isolation auf Netzwerkebene und führen bei Green-Instanzen Smoke-Tests mit repräsentativen Tenant-Daten durch. Zusätzlich gibt es ein Rollback-Fenster von 15 Minuten, das per Feature-Flag getriggert werden kann."}
{"ts": "178:57", "speaker": "I", "text": "Sind diese Smoke-Tests ebenfalls im IaC definiert?"}
{"ts": "179:02", "speaker": "E", "text": "Ja, als Teil des Deploy-Jobs in der CI/CD-Pipeline. Die Testskripte referenzieren RB-GW-015, das unsere Multi-Tenant-Validierungsroutine beschreibt."}
{"ts": "179:12", "speaker": "I", "text": "Gibt es einen Punkt, an dem Sie Canary wieder in Betracht ziehen würden?"}
{"ts": "179:18", "speaker": "E", "text": "Vielleicht bei Single-Tenant-Kunden mit sehr hohem Traffic, wo wir schrittweise ausrollen könnten, ohne andere zu beeinflussen. Aber für die Orion-Edge-Mandantenstruktur bleibt Blue/Green derzeit stabiler."}
{"ts": "179:31", "speaker": "I", "text": "Wie sichern Sie, dass diese Entscheidungen in der Wissensbasis nicht verloren gehen?"}
{"ts": "179:37", "speaker": "E", "text": "Neben Confluence pflegen wir ein internes Decision-Log-Repo im Git, in dem jede größere Architektur- oder Deployment-Entscheidung als ADR (Architecture Decision Record) mit Kontext, Alternativen und finaler Entscheidung abgelegt wird."}
{"ts": "178:15", "speaker": "I", "text": "Bei GW-4821 — können Sie bitte noch mal genau skizzieren, wie der mTLS-Handshake im Orion Edge Gateway damals fehlschlug?"}
{"ts": "178:20", "speaker": "E", "text": "Ja, das Problem war, dass in der Build-Phase der TLS-Kontext für einen Mandanten nicht ordnungsgemäß aus dem Secrets Vault geladen wurde. Dadurch kam es zum Certificate Mismatch beim Handshake, was sich besonders bei Requests mit hohem Parallelisierungsgrad bemerkbar machte."}
{"ts": "178:28", "speaker": "I", "text": "Und wie haben Sie das gemäß RB-GW-011 adressiert?"}
{"ts": "178:33", "speaker": "E", "text": "RB-GW-011 beschreibt einen Rolling Deployment Ablauf, bei dem zuerst eine Canary-Instanz mit gepatchtem mTLS-Loader hochgefahren wird. Wir haben zusätzlich einen Pre-Flight Check eingebaut, der die Zertifikate asynchron ausliest und mit der mTLS-Policy-Matrix validiert, bevor der Traffic umgeschwenkt wird."}
{"ts": "178:45", "speaker": "I", "text": "Das klingt nach enger Abstimmung. Wie passte das mit den parallelen RFCs für Aegis IAM und Nimbus Observability zusammen?"}
{"ts": "178:50", "speaker": "E", "text": "Wir haben in RFC-078 für Aegis IAM die JIT-Access Tokens so erweitert, dass sie während des Handshake-Prozesses validierbar sind. In RFC-081 für Nimbus haben wir zusätzliche mTLS-Metrics ins Tracing aufgenommen, damit SLA-ORI-02-Messpunkte automatisch ausgelöst werden, wenn Handshake-Latenzen über 200ms steigen."}
{"ts": "179:02", "speaker": "I", "text": "Gab es dabei Konflikte zwischen den Teams?"}
{"ts": "179:06", "speaker": "E", "text": "Ja, kurzfristig. Die IAM-Änderungen verlangten strengere Zertifikatsrotationen, was in Nimbus Alerts für vermeintlich 'abgelaufene' Zertifikate resultierte. Wir mussten eine gemeinsame Validierungsregel definieren, um False Positives zu vermeiden."}
{"ts": "179:15", "speaker": "I", "text": "Kommen wir zur Latenzfrage: Wie haben Sie den Trade-off zwischen zusätzlichem Security Check und SLA-ORI-02 eingeordnet?"}
{"ts": "179:20", "speaker": "E", "text": "Wir haben in einem Lasttest gezeigt, dass der Pre-Flight Check im Schnitt 8ms pro Request kostet. Damit blieben wir unter dem 250ms 95th Percentile Limit von SLA-ORI-02. Wir haben bewusst auf synchrone Überprüfungen verzichtet, um Spike-Latenzen zu vermeiden."}
{"ts": "179:32", "speaker": "I", "text": "Warum fiel die Wahl dann auf Blue/Green und nicht auf Canary?"}
{"ts": "179:36", "speaker": "E", "text": "Im Multi-Tenant-Kontext war das Risiko hoch, dass eine Canary nur eine Teilmenge der Mandanten abdeckt. Blue/Green erlaubt es uns, eine vollständige Umgebung parallel vorzubereiten und bei Erfolg den gesamten Traffic umzuleiten. Dadurch minimieren wir Inkonsistenzen zwischen Tenants."}
{"ts": "179:47", "speaker": "I", "text": "Gab es Bedenken hinsichtlich des Blast Radius bei Blue/Green?"}
{"ts": "179:51", "speaker": "E", "text": "Natürlich. Deshalb haben wir im Runbook einen Staged Switch integriert: erst 10% Traffic, dann 50%, erst bei stabilen mTLS-Metrics 100%. Das ist quasi ein abgesichertes Blue/Green."}
{"ts": "180:00", "speaker": "I", "text": "Wie haben Sie diese Entscheidungen für Audits dokumentiert?"}
{"ts": "180:05", "speaker": "E", "text": "Alle relevanten Sessions, Metriken und Testprotokolle wurden in unserem Confluence-Abschnitt 'ORI-Security-Deploy' hinterlegt, mit Verweisen auf RB-GW-011, die betroffenen RFCs und das Incident-Ticket GW-4821. So ist der Audit-Trail vollständig nachvollziehbar."}
{"ts": "180:51", "speaker": "I", "text": "Wir hatten vorhin schon kurz den Fix zu GW-4821 angerissen. Können Sie noch mal konkret erläutern, wie Sie dabei mit den Teams von Aegis IAM und Nimbus Observability koordiniert haben?"}
{"ts": "181:08", "speaker": "E", "text": "Ja, also wir haben direkt nach der ersten Alarmierung über Nimbus ein Incident-Bridge-Call gestartet. Parallel habe ich im Confluence das Runbook RB-GW-011 aufgerufen und die mTLS Recovery Steps mit den IAM-Kollegen durchgesprochen. Aegis hat dann in RFC-IAM-217 kurzfristig den JIT-Access für den Gateway-Cluster freigegeben."}
{"ts": "181:34", "speaker": "I", "text": "Gab es da zeitkritische Abhängigkeiten, die den Ablauf erschwert haben?"}
{"ts": "181:42", "speaker": "E", "text": "Definitiv. Die Observability-Dashboards aus Nimbus mussten wir erst auf das neue Zertifikatspaar umstellen, bevor wir die Handshakes neu initiieren konnten. Das war in RFC-NIM-142 dokumentiert, aber der Workaround, den wir aus einem älteren Incident-Postmortem kannten, hat uns etwa 15 Minuten gespart."}
{"ts": "182:05", "speaker": "I", "text": "Wie hat sich das auf die SLA-ORI-02 Einhaltung ausgewirkt?"}
{"ts": "182:13", "speaker": "E", "text": "Wir lagen knapp an der Grenze. Die Latenzspikes waren in den Nimbus-Traces klar sichtbar. Im SLA-Report für KW12 mussten wir eine Annotation setzen, dass die zusätzlichen Security Checks – also die vollständige mTLS Neuverhandlung – für den Ausschlag verantwortlich waren."}
{"ts": "182:39", "speaker": "I", "text": "Hatten Sie in dem Moment überlegt, temporär auf ein reduziertes Security-Level zu gehen, um die Latenz zu drücken?"}
{"ts": "182:47", "speaker": "E", "text": "Kurz, ja. Aber gemäß POL-SEC-001 und der internen Zero-Trust-Policy ist das nur mit CTO-Freigabe möglich. Da der Blast Radius in diesem Fall klar abgrenzbar war, haben wir uns entschieden, den vollen Handshake-Prozess durchzuziehen."}
