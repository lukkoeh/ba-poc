{"ts": "00:00", "speaker": "I", "text": "Können Sie kurz Ihre Hauptverantwortlichkeiten im Orion Edge Gateway während der Build-Phase schildern?"}
{"ts": "03:15", "speaker": "E", "text": "Ja, also ich bin Lead DevOps Engineer im P‑ORI Projekt, ähm, zuständig für die gesamte CI/CD Pipeline, das IaC-Framework und das Performance-Monitoring. Mein Hauptfokus ist, dass wir das Gateway mit den SLA-ORI-02 Vorgaben liefern – also p95 Latenz unter 120 Millisekunden – und dabei die Auth-Integration mit Aegis IAM sauber läuft."}
{"ts": "06:40", "speaker": "I", "text": "Wie haben Sie diese Latenz-Vorgabe konkret in Ihre Arbeitspakete integriert?"}
{"ts": "10:05", "speaker": "E", "text": "Wir haben in unseren Terraform-Modulen Default-Settings für Connection-Pools und Thread-Counts hinterlegt, die aus den Benchmarks in Ticket PERF‑221 stammen. Zusätzlich läuft in der Pipeline ein K6 Loadtest-Step, der bei Überschreitung der 120ms p95 sofort den Deploy-Job stoppt. This step is codified in our runbook RB-GW-011."}
{"ts": "13:50", "speaker": "I", "text": "Welche Tools setzen Sie zur Absicherung der Deployments ein?"}
{"ts": "17:10", "speaker": "E", "text": "Primär Terraform und Ansible für IaC, plus ein internes Policy-as-Code Modul namens SentinelEdge, das unsere Compliance-Checks automatisiert. Security Scans laufen mit ClairEdge im Container-Build, und wir haben einen GitLab Hook, der die Checks gegen die RBAC-Policies im Aegis IAM repliziert."}
{"ts": "20:45", "speaker": "I", "text": "Welche Automatisierungsschritte haben Sie in der Blue/Green Deployment Pipeline gemäß RB-GW-011 ergänzt?"}
{"ts": "24:00", "speaker": "E", "text": "Wir haben zusätzlich ein Pre‑Switch Validation Script eingebaut, das die Rate Limiting Configs in einer Staging-Zone mit synthetischem Traffic testet. Once the staging passes the latency and error budget thresholds defined in SLA-ORI-02 and SLA-ORI-04, the pipeline promotes the green environment live."}
{"ts": "28:15", "speaker": "I", "text": "Can you describe how rate limiting configurations are validated before production rollout?"}
{"ts": "32:40", "speaker": "E", "text": "Sure, we use a three-phase approach: First, unit tests on the config parser; second, integration tests against a mock IAM with mTLS enabled; third, live canary in a subset of API routes monitored by Nimbus Observability. Änderungen werden nur gemerged, wenn alle drei Phasen durch sind."}
{"ts": "36:55", "speaker": "I", "text": "Wie koppeln Sie das Gateway an Aegis IAM für mTLS und AuthN/AuthZ?"}
{"ts": "41:20", "speaker": "E", "text": "Wir nutzen einen Sidecar-Proxy, der die mTLS-Handshake-Logik implementiert und Tokens vom Aegis IAM zieht. Die Zertifikate werden über VaultEdge rotiert, und Policies in Aegis werden via API gepusht, sobald ein neues Gateway-Pod ausgerollt wird. Das Ganze ist im Runbook RB-IAM-042 dokumentiert."}
{"ts": "45:35", "speaker": "I", "text": "Can you walk me through a scenario where changes in Nimbus Observability impacted your gateway deployment?"}
{"ts": "50:10", "speaker": "E", "text": "Yes, mid‑April we had a schema change in Nimbus metrics ingestion (Ticket NMB‑934). Das führte dazu, dass unsere Latenz‑Dashboards falsche Percentiles anzeigten. Wir mussten in der Pipeline einen zusätzlichen Smoke-Test gegen die Raw Metrics API einbauen, bevor Deployments freigegeben wurden, um falsche grünes Licht zu vermeiden."}
{"ts": "54:25", "speaker": "I", "text": "Welche Monitoring-Hooks nutzen Sie, um API-Latenzen pro Mandant zu tracken?"}
{"ts": "60:00", "speaker": "E", "text": "Wir instrumentieren jeden Tenant-Request mit einem OpenTelemetry Trace‑ID, der in Nimbus Observability landet. Zusätzlich haben wir Prometheus-Exporter, die per Label pro Tenant aggregieren. Alerts triggern, wenn ein Tenant 20% über seinem p95‑Baseline liegt, und das wird im Incident-Runbook RB-MON-017 behandelt."}
{"ts": "90:00", "speaker": "I", "text": "Lassen Sie uns jetzt auf die Entscheidungen bei den Deployment-Strategien eingehen. Wie haben Sie zwischen Canary und Blue/Green gewählt?"}
{"ts": "90:06", "speaker": "E", "text": "Also, wir haben GW-4821 als Referenzticket genommen, das war ein Incident, wo das Canary-Deployment zu lange im 'shadow traffic' Modus hing. Based on that, we decided that for the SLA-ORI-02 critical path, Blue/Green gave us more predictable rollback times."}
{"ts": "90:18", "speaker": "I", "text": "Gab es dabei konkrete Messwerte oder nur qualitative Einschätzungen?"}
{"ts": "90:24", "speaker": "E", "text": "Wir hatten klare Metrics: im Canary-Fall lag der p95 bei 160 ms im Testcluster, whereas Blue/Green kept it around 110 ms under load from our synthetic clients defined in RB-GW-011."}
{"ts": "90:36", "speaker": "I", "text": "What were the main risks identified in the last RFC review for Orion Edge Gateway?"}
{"ts": "90:42", "speaker": "E", "text": "In RFC-ORI-27 haben wir drei Haupt-Risiken dokumentiert: erstens ein AuthN/AuthZ Drift zwischen Aegis IAM und lokalem mTLS Cache, zweitens die Gefahr von Überschreiten der Rate-Limits durch falsch konfigurierte Tenants, und drittens ein Observability Hook, der bei hoher Last dropped metrics verursachte."}
{"ts": "90:56", "speaker": "I", "text": "Wie haben Sie diese Risiken mitigiert?"}
{"ts": "91:02", "speaker": "E", "text": "Für den mTLS Cache haben wir ein tägliches Reconciliation-Job via Terraform + Ansible Playbook  gw-mtls-sync.yml implementiert. For rate limit misconfigs, we added a pre-prod validation stage in the CI pipeline. And for dropped metrics, we upgraded the Nimbus agent to v2.4 with backpressure handling."}
{"ts": "91:18", "speaker": "I", "text": "Welche Lessons Learned aus Incident Postmortems haben Ihre IaC-Module verändert?"}
{"ts": "91:24", "speaker": "E", "text": "Nach Incident INC-ORI-94 haben wir gelernt, dass statische Security Groups in unseren Terraform-Modulen zu starr waren. We refactored to use reusable modules with parameterized CIDR lists and added runbook RB-IAC-07 for emergency updates."}
{"ts": "91:38", "speaker": "I", "text": "Und wie stellen Sie sicher, dass diese Automatisierungen nachhaltig gewartet werden können?"}
{"ts": "91:44", "speaker": "E", "text": "Wir haben Code Ownership im Git-Repo klar geregelt, with CODEOWNERS file mapping to squads, und quartalsweise IaC-Reviews im CI enforced. Außerdem dokumentieren wir jede Änderung in der internen Confluence-Seite 'IaC-Sustainable'."}
{"ts": "91:56", "speaker": "I", "text": "Can you give an example of performance tuning that reduced latency sustainably?"}
{"ts": "92:02", "speaker": "E", "text": "Sure, wir haben die NGINX worker_connections dynamisch anhand der Pod CPU-Limits skaliert. That, combined with HTTP/2 multiplexing, brachte den p95 von 125 ms auf 108 ms im Dauerbetrieb runter."}
{"ts": "92:14", "speaker": "I", "text": "Welche KPIs nutzen Sie, um Fortschritte im Sinne von 'Sustainable Velocity' zu messen?"}
{"ts": "92:20", "speaker": "E", "text": "Wir tracken Change Lead Time, Deployment Frequency, und Error Rate pro Release. Zusätzlich schauen wir auf den Mean Time to Recovery, all aligned mit den Zielwerten aus SLA-ORI-02 und unserem internen DevOps Health Dashboard."}
{"ts": "98:00", "speaker": "I", "text": "Lassen Sie uns noch einmal auf die Wartbarkeit eingehen – wie stellen Sie sicher, dass Ihre Automatisierungen im Orion Edge Gateway nicht veralten?"}
{"ts": "98:06", "speaker": "E", "text": "Wir haben einen Pflegezyklus im Runbook RB-GW-021 definiert, der alle drei Sprints einen IaC-Code Review vorsieht. Außerdem nutzen wir Module aus unserem internen Registry, die versioniert und mit Deprecation Notices versehen werden, so we can plan refactors before breaking changes hit production."}
{"ts": "98:16", "speaker": "I", "text": "Gibt es da auch automatische Checks?"}
{"ts": "98:20", "speaker": "E", "text": "Ja, wir haben einen GitLab CI Stage namens 'Module-Audit', der prüft, ob verwendete Terraform-Provider noch supported sind. Zusätzlich laufen wöchentliche Security-Scans gegen die IaC-Templates, using a lightweight Checkov profile tailored for our RBAC model."}
{"ts": "98:32", "speaker": "I", "text": "Können Sie ein Beispiel geben, wie Sie Latenz nachhaltig optimiert haben?"}
{"ts": "98:38", "speaker": "E", "text": "Klar, wir haben in Sprint 14 das Redis-basiertes Rate-Limiting-Backend auf eine Cluster-Variante mit lokaler Sharding-Logik umgestellt. Dadurch konnten wir die durchschnittliche Response-Zeit um ~15ms senken und den p95-Wert von 118ms stabil unter SLA-ORI-02 halten. The change was low-risk because it was toggled via feature flags."}
{"ts": "98:52", "speaker": "I", "text": "Und diese Feature Flags, wie managen Sie die?"}
{"ts": "98:56", "speaker": "E", "text": "Die Flags liegen in unserem Config-Store 'HelixCfg', changes are promoted through the same Blue/Green pipeline as code. Wir haben ein Rollback-Runbook RB-GW-015, das dokumentiert, wie Flags sofort zurückgedreht werden können, falls Metriken wie error_rate{tenant} > 2% steigen."}
{"ts": "99:08", "speaker": "I", "text": "Welche KPIs nutzen Sie, um Ihre Sustainable Velocity zu messen?"}
{"ts": "99:12", "speaker": "E", "text": "Wir tracken Lead Time for Changes, Change Failure Rate und Mean Time to Recovery. Zusätzlich haben wir den KPI 'Automation Debt Ratio' eingeführt – das ist der Anteil manueller Tasks pro Release-Zyklus. Ziel ist <5% manuell, aktuell sind wir bei 3,8%."}
{"ts": "99:24", "speaker": "I", "text": "Gab es in letzter Zeit ein Performance-Tuning, das nicht wie geplant lief?"}
{"ts": "99:28", "speaker": "E", "text": "Ja, in Ticket GW-4972 hatten wir versucht, gRPC-Kompression zu erzwingen, expecting bandwidth savings. Allerdings stieg dadurch die Latenz um ~8ms, was uns nahe an die SLA-Grenze brachte. Wir haben das Feature per Flag deaktiviert und in der RFC-Review als 'Needs further benchmarking' markiert."}
{"ts": "99:40", "speaker": "I", "text": "Interessant. Wie fließen solche Learnings in die Dokumentation ein?"}
{"ts": "99:44", "speaker": "E", "text": "Wir haben ein Living Document im Confluence namens 'Orion Edge Gateway Playbook'. Jede Abweichung von geplanten Ergebnissen wird im Abschnitt 'Lessons Learned' mit Referenz auf Ticket und Metriken eingetragen. That way, future engineers can avoid repeating the same experiments without context."}
{"ts": "99:56", "speaker": "I", "text": "Zum Abschluss – wie priorisieren Sie technische Schulden vs. neue Features?"}
{"ts": "100:00", "speaker": "E", "text": "Wir haben einen festen Slot von 20% der Sprint-Kapazität für Tech-Debt eingeplant. Die Priorisierung erfolgt anhand eines Impact/Risk-Scores aus unserem internen Tool 'Prioritron', scoring both SLA impact and developer friction. New features müssen diesen Slot respektieren, unless there's a critical client commitment."}
{"ts": "102:00", "speaker": "I", "text": "Lassen Sie uns nochmal kurz auf die Integration mit Aegis IAM zurückkommen – besonders die mTLS-Handshake-Optimierungen. Welche Anpassungen haben Sie im Build-Sprint 12 vorgenommen?"}
{"ts": "102:18", "speaker": "E", "text": "Ja klar, im Sprint 12 haben wir den mTLS-Handshake von drei Round-Trips auf zwei reduziert, indem wir das Session-Resumption-Feature aus der Aegis 4.3 Library aktiviert haben. That reduced handshake latency by roughly 15ms per request, was ein signifikanter Schritt in Richtung SLA-ORI-02 war."}
{"ts": "102:44", "speaker": "I", "text": "Und wie haben Sie das in Ihrer Automatisierung verankert, damit es nicht in späteren Deployments verloren geht?"}
{"ts": "103:00", "speaker": "E", "text": "Wir haben in den IaC-Modulen von Terraform ein dedicated mTLS-Policy-Block erstellt. Zudem gibt es in der CI-Pipeline einen Integration-Test-Step, der gegen Aegis-Staging prüft, ob TLS-Resumption Header und Cipher Suites korrekt sind. That’s codified in runbook RB-IAM-007."}
{"ts": "103:26", "speaker": "I", "text": "Interessant. Und beim Thema Observability – wie binden Sie Nimbus Metriken so ein, dass Mandanten-spezifische Daten korrekt segmentiert werden?"}
{"ts": "103:44", "speaker": "E", "text": "Wir nutzen in der Gateway-Config den Mandanten-ID-Header als Label im Prometheus-Export, der von Nimbus Agent 6.2 aufgenommen wird. Then, in Grafana dashboards, we apply regex filters to ensure tenancy isolation. Ein Fehler in der Label-Konfiguration hatte vor drei Sprints zu einer Vermischung geführt – das haben wir mit PR #GW-5193 gefixt."}
{"ts": "104:16", "speaker": "I", "text": "Gab es da nicht auch eine Abhängigkeit zu einem Patch im Nimbus Collector?"}
{"ts": "104:28", "speaker": "E", "text": "Genau, das war der Multi-Hop-Effekt: Wir mussten erst das Collector-Plugin auf Version 2.8 bringen, sonst wurden die neuen Labels nicht akzeptiert. This required coordination mit dem Observability-Team, und wir haben das in Change Request CR-NIM-884 dokumentiert."}
{"ts": "104:56", "speaker": "I", "text": "Wie haben Sie diesen Change synchron mit Ihren Blue/Green-Rollouts orchestriert?"}
{"ts": "105:10", "speaker": "E", "text": "Wir haben ein gestaffeltes Vorgehen genutzt: Zuerst Green-Umgebung mit neuem Collector, parallel Traffic-Shaping via Envoy-Rules, dann Switch. This avoided label drop issues, und wir hatten nur ein 30s metrics gap."}
{"ts": "105:36", "speaker": "I", "text": "Das klingt nach einem sauber geplanten Ablauf. Welche Risiken haben Sie vorab noch abgesichert?"}
{"ts": "105:48", "speaker": "E", "text": "Vor allem das Risiko, dass ältere Clients ohne Mandanten-ID-Header Errors produzieren. Wir haben dafür in GW-Preprocessor ein Fallback eingebaut, der 'tenant=unknown' setzt. Plus, load tests with legacy clients to validate no SLA breach."}
{"ts": "106:14", "speaker": "I", "text": "How did you monitor that during the rollout to ensure no hidden latencies crept in?"}
{"ts": "106:26", "speaker": "E", "text": "Wir haben temporär p90 und p95 Latenzen per Mandant in einem separaten Dashboard angezeigt, with alert thresholds at 110ms. Zusätzlich ein Loki-Log-Stream für 'tenant=unknown' Events, um Patterns sofort zu sehen."}
{"ts": "106:50", "speaker": "I", "text": "Nach dem Rollout – gab es Lessons Learned, die Sie in künftige IaC-Module einfließen lassen?"}
{"ts": "107:06", "speaker": "E", "text": "Ja, wir haben den Mandanten-Label-Block als wiederverwendbares Terraform-Modul extrahiert. And we added a preflight check script, das sowohl mTLS-Resumption als auch Label-Konformität prüft, bevor `terraform apply` in Prod geht. Das ist jetzt Teil von RB-GW-015."}
{"ts": "120:00", "speaker": "I", "text": "Lassen Sie uns noch mal auf die Pipeline-Details eingehen. Wie verankern Sie denn die SLA-ORI-02 Überprüfung direkt in der CI/CD-Chain?"}
{"ts": "120:08", "speaker": "E", "text": "Wir haben dafür in der Jenkinsfile ein eigenes Stage 'perf-check' eingeführt, die nach dem Staging-Deploy mit synthetischen Lasttests prüft, ob p95 unter 120ms bleibt. Das Script nutzt k6 und schreibt die Ergebnisse ins Prometheus, sodass auch der Runbook-Eintrag RB-GW-015 automatisch aktualisiert wird."}
{"ts": "120:28", "speaker": "I", "text": "Interesting, und wie gehen Sie vor, wenn die Stage fehlschlägt?"}
{"ts": "120:33", "speaker": "E", "text": "Dann triggert ein Webhook einen Jira-Blocker-Ticket, z. B. GW-4932, und der Deployment-Job bricht ab. Wir haben gelernt, lieber einen Tag Delay zu akzeptieren als eine SLA-Verletzung in Prod."}
{"ts": "120:52", "speaker": "I", "text": "Sie hatten früher erwähnt, dass Security-Scans integriert sind. Wie kombinieren Sie die mit den Performance-Checks ohne Bottlenecks?"}
{"ts": "121:00", "speaker": "E", "text": "We run them in parallel stages – SAST, DAST und die perf-check Stage laufen as jobs on separate agents. Dadurch bleibt die Delivery-Rate im Schnitt bei 2 Deployments pro Tag, ohne dass wir Security opfern."}
{"ts": "121:18", "speaker": "I", "text": "Zurück zur Subsystem-Integration: Können Sie beschreiben, wie Änderungen im Nimbus Observability Ihr Gateway beeinflusst haben?"}
{"ts": "121:25", "speaker": "E", "text": "Ja, das war im März. Nimbus hat das Exportformat der Latenzmetriken geändert, was unseren Alertmanager-Silencer nicht mehr greifen ließ. Folge: Flut an false positives. Wir mussten das mTLS-Handshake-Logging temporär deaktivieren, um die Alert-Frequenz zu senken, bis wir die Parser im Modul 'gw-metrics-adapter' angepasst hatten."}
{"ts": "121:50", "speaker": "I", "text": "How did that interplay with Aegis IAM settings?"}
{"ts": "121:54", "speaker": "E", "text": "Well, since Aegis IAM's mTLS auth hooks feed into the same log pipeline, we had to coordinate a schema migration with both teams. It was a three-hop dependency: Gateway -> Metrics Adapter -> IAM hooks. We documented the sequence in RFC-ORI-14 including rollback scripts."}
{"ts": "122:16", "speaker": "I", "text": "Klingt nach hoher Abstimmungslast. Haben Sie dafür bestimmte Kommunikations-Patterns?"}
{"ts": "122:21", "speaker": "E", "text": "Ja, wir nutzen ein 'Change Control Standup' bei Multi-Hop-Änderungen, jeden Morgen 15 Minuten. Da sind Gateway, Observability und IAM-Vertreter zusammen, um genau solche Abhängigkeiten zu koordinieren."}
{"ts": "122:38", "speaker": "I", "text": "In Bezug auf Risikoabsicherung: Gab es zuletzt eine Entscheidung, bei der Sie bewusst Performance gegen Sicherheit abgewogen haben?"}
{"ts": "122:44", "speaker": "E", "text": "Ja, im Ticket GW-5011. Wir haben für einen Mandanten mit extremen Traffic-Spikes den Rate Limiter von 500 auf 800 rps erhöht, was leicht höhere CPU-Last brachte. Das Security-Team war einverstanden, weil die IAM-Token-Checks unverändert blieben, und wir hatten Evidence aus drei Lasttests, dass p95 immer noch <110ms bleibt."}
{"ts": "123:08", "speaker": "I", "text": "Und wie wurde das dokumentiert?"}
{"ts": "123:12", "speaker": "E", "text": "Im Runbook RB-GW-019 unter 'Rate Limiter Exceptions', plus ein Post-Change Review mit Lessons Learned, um zu verhindern, dass solche Ausnahmen unbemerkt bleiben."}
{"ts": "128:00", "speaker": "I", "text": "Können Sie uns bitte genauer schildern, wie Sie die Rate Limiting Configs vor dem Production Rollout validieren? Ich erinnere mich, Sie hatten da einen speziellen Validierungs-Job."}
{"ts": "128:05", "speaker": "E", "text": "Ja, genau. Wir nutzen dafür den Runbook-Eintrag RB-GW-021, der beschreibt, wie wir in der Staging-Umgebung synthetische Lasttests fahren. Wir kombinieren `k6` Scripts mit unseren eigenen mTLS-geschützten Test-Clients. So können wir die p95 Latenz und die Enforcement-Logik prüfen, bevor überhaupt eine Prod-Pipeline triggered wird."}
{"ts": "128:16", "speaker": "I", "text": "And how do you make sure those synthetic loads reflect real multi-tenant patterns?"}
{"ts": "128:20", "speaker": "E", "text": "We replay anonymized traffic samples from the last 30 days, segmented per tenant category. In Deutsch gesagt: wir mappen die Volumina und Burst-Patterns aus den Observability-Daten des Nimbus-Stacks, um sie realistisch nachzubilden."}
{"ts": "128:33", "speaker": "I", "text": "Sie sprachen Nimbus Observability an – gab es jüngst einen Fall, wo Änderungen dort Ihr Deployment beeinflusst haben?"}
{"ts": "128:37", "speaker": "E", "text": "Ja, das war Mitte letzten Monats. Das Nimbus-Team hat den Export-Intervall für Latenzmetriken von 15s auf 5s reduziert. Dadurch stieg unser Telemetrie-Throughput, und unser mTLS-Sidecar im Orion Gateway bekam plötzlich 20% mehr Traffic. Wir mussten in IaC Modul `gw_telemetry.tf` die Ressourcenlimits anpassen, sonst hätte es Throttling gegeben."}
{"ts": "128:52", "speaker": "I", "text": "Interesting. Did you coordinate that via a formal change request?"}
{"ts": "128:55", "speaker": "E", "text": "Ja, wir haben ein CR im internen Change-Board, ID CR-NIM-447, eingereicht und als Cross-System Risk markiert. Das half, die Stakeholder von IAM und Observability frühzeitig zu involvieren."}
{"ts": "129:07", "speaker": "I", "text": "Wie koppeln Sie denn aktuell das Orion Gateway an Aegis IAM für mTLS und AuthN/AuthZ, gerade nach diesen Telemetrie-Anpassungen?"}
{"ts": "129:12", "speaker": "E", "text": "Wir haben im Gateway einen Envoy-basierten mTLS-Cluster konfiguriert. Die Zertifikate kommen on-demand vom Aegis IAM über einen gRPC-Endpoint. Zusätzlich validieren wir AuthZ-Token synchron gegen den Aegis PDP. Nach den Telemetrie-Änderungen mussten wir das Circuit-Breaking etwas lockern, um keine unnötigen 503er zu erzeugen."}
{"ts": "129:27", "speaker": "I", "text": "Hat das Auswirkungen auf die SLA-ORI-02 Vorgabe gehabt?"}
{"ts": "129:31", "speaker": "E", "text": "Kurzzeitig ja. Wir hatten eine p95 Latenz von 130 ms für ca. 15 Minuten, was wir sofort im Nimbus-Dashboard sahen. Mit einer Hotfix-Anpassung in `auth_cluster.yaml` konnten wir wieder unter 120 ms kommen. Die Anpassung war in Ticket GW-4932 dokumentiert."}
{"ts": "129:45", "speaker": "I", "text": "In terms of automation, how did you integrate that fix without slowing down delivery?"}
{"ts": "129:49", "speaker": "E", "text": "Wir haben den Hotfix über unsere Blue/Green-Pipeline (RB-GW-011) ausgerollt, mit einem temporären Override der Canary-Step-Skips. That way, we kept full regression tests parallel to the prod rollout, no downtime."}
{"ts": "130:01", "speaker": "I", "text": "Gab es Lessons Learned daraus für zukünftige Multi-Hop Changes?"}
{"ts": "130:05", "speaker": "E", "text": "Absolut. Wir haben in den IaC-Runbooks jetzt einen Abschnitt 'Cross-Service Impact Checks' ergänzt, der automatisiert prüft, ob Observability- oder IAM-Konfigurationen geändert wurden. So vermeiden wir, dass wir wie bei CR-NIM-447 erst reaktiv handeln müssen."}
{"ts": "130:00", "speaker": "I", "text": "Sie hatten vorhin kurz erwähnt, dass das Aegis IAM für mTLS-Einbindung genutzt wird. Können Sie mir bitte genauer erklären, wie Sie die Zertifikats-Rotation dort automatisiert haben?"}
{"ts": "130:15", "speaker": "E", "text": "Ja, klar… also wir haben in unserem IaC-Modul `iac-orion-iam-mtls` einen Terraform-Provider, der über die Aegis API neue Zertifikatspaare generiert. Das wird über einen CronJob in der CI-Pipeline getriggert, und ein Pre-Deployment Hook prüft via Runbook RB-IAM-022, ob das neue Zertifikat auf allen Gateway-Pods geladen ist, bevor der alte Key revoked wird."}
{"ts": "130:44", "speaker": "I", "text": "Verstehe. How do you ensure that this rotation doesn’t cause downtime for active client sessions?"}
{"ts": "131:00", "speaker": "E", "text": "We actually run both certs in parallel during a grace period defined in `mtlsRotationWindow` config. Active sessions finish with the old cert, while new handshakes are on the new one. Das haben wir in einem Chaos-Test validiert, dokumentiert im Ticket SEC-GW-143."}
{"ts": "131:28", "speaker": "I", "text": "Interessant, und wie binden Sie diese Zertifikatsprüfung ins Monitoring ein?"}
{"ts": "131:42", "speaker": "E", "text": "Wir haben einen Prometheus-Exporter im Sidecar, der die Ablaufdaten der mTLS-Zertifikate ausliest. Ein Alert in Alertmanager löst bei < 7 Tagen Restlaufzeit aus. Gleichzeitig schreibt er ein Event ins Nimbus Observability Event-Stream, damit das Support-Team frühzeitig reagieren kann."}
{"ts": "132:10", "speaker": "I", "text": "Speaking of Nimbus, können Sie ein Beispiel geben, wo sich Änderungen dort direkt auf Ihre Gateway-Deployments ausgewirkt haben?"}
{"ts": "132:25", "speaker": "E", "text": "Ja, im April gab es ein Update des Nimbus-SDKs, das die Latenz-Metrik `api_p95_ms` von Millisekunden auf Mikrosekunden umgestellt hat. Unsere SLA-Check-Skripte für SLA-ORI-02 haben dadurch falsche Werte ausgeworfen, was fast einen Rollout-Stop verursacht hätte. Wir mussten kurzfristig in GW-4932 die Parser-Logik anpassen und neu deployen, inklusive Regressionstests."}
{"ts": "132:58", "speaker": "I", "text": "Wie haben Sie diese Regressionstests organisiert, um sicherzugehen, dass alle Metriken korrekt interpretiert werden?"}
{"ts": "133:14", "speaker": "E", "text": "Wir haben ein Synthetic-Test-Cluster, das gezielt API-Calls mit bekannten Antwortzeiten erzeugt. Die Auswertung läuft dann durch dasselbe Observability-Setup wie in Prod. So konnten wir sicherstellen, dass der neue Mikrosekunden-Parser wieder unter 120ms p95 ausgibt, wie in SLA-ORI-02 gefordert."}
{"ts": "133:40", "speaker": "I", "text": "Switching gears: Welche Lessons Learned aus dem Incident-Postmortem im Mai haben Ihre Automatisierung beeinflusst?"}
{"ts": "133:55", "speaker": "E", "text": "Das war der Vorfall mit falsch konfiguriertem Rate-Limiting, ID INC-GW-557. Wir haben daraus gelernt, dass wir vor Prod-Rollout eine Stage mit Live-Traffic-Replay brauchen. Deshalb haben wir das Modul `rl-validation` in die Blue/Green-Pipeline RB-GW-011 integriert. Es simuliert die Top 50 API-Methoden pro Mandant und vergleicht die Responses."}
{"ts": "134:26", "speaker": "I", "text": "Gab es dabei Trade-offs hinsichtlich Delivery-Speed?"}
{"ts": "134:38", "speaker": "E", "text": "Ja, die Validierung verlängert die Pipeline um ca. 8 Minuten. Aber wir haben in RFC-0582 dokumentiert, dass der Gewinn an Sicherheit und SLA-Compliance den Delay rechtfertigt. Außerdem läuft das nur bei Konfig-Änderungen, nicht bei allen Releases."}
{"ts": "135:02", "speaker": "I", "text": "Und wie messen Sie, ob diese Maßnahmen langfristig ihre Wirkung zeigen, also im Sinne von Sustainable Velocity?"}
{"ts": "135:18", "speaker": "E", "text": "Wir tracken KPIs wie 'Mean Time to Detect Config Errors' und den Prozentsatz der Deployments, die ohne Hotfix auskommen. Seit Einführung des `rl-validation`-Steps ist MTTD von 2h auf 15min gesunken, und Hotfix-Quote von 12% auf 3%."}
{"ts": "138:00", "speaker": "I", "text": "Wie stellen Sie sicher, dass Ihre Terraform-Module für das Orion Edge Gateway auch bei Änderungen im Aegis IAM nicht brechen?"}
{"ts": "138:05", "speaker": "E", "text": "Wir haben in der Build-Phase ein Contract Testing eingeführt, ähm, das basiert auf den Schnittstellen-Spezifikationen aus dem Aegis IAM Runbook RB-IAM-07. Zusätzlich laufen nightly Integration Tests in einer Staging-Umgebung, wo mTLS-Handshake und AuthN/AuthZ-Flows simuliert werden."}
{"ts": "138:15", "speaker": "I", "text": "Do you coordinate those tests with the Nimbus Observability team?"}
{"ts": "138:20", "speaker": "E", "text": "Yes, genau, wir haben einen gemeinsamen Jenkins Job, der nach erfolgreichem IAM-Test automatisch die Observability Hooks triggert. Dadurch sehen wir sofort, wenn sich zum Beispiel das Latenz-Metrik-Format ändert."}
{"ts": "138:32", "speaker": "I", "text": "Sie hatten mal erwähnt, dass bei einer Änderung in Nimbus ein unerwarteter Spike in den Latenzen auftrat. Können Sie das kurz schildern?"}
{"ts": "138:38", "speaker": "E", "text": "Ja, das war Ticket OBS-221. Nimbus hat das Sampling-Intervall von 1s auf 100ms reduziert, und unser Gateway hat plötzlich 5x mehr Metriken gesendet. Das hat die p95 Latenz kurzfristig über 200ms gedrückt. Wir haben dann im IaC ein Konfig-Limit für Metrik-Frequency eingeführt."}
{"ts": "138:52", "speaker": "I", "text": "Interessant. How did you validate that fix before going live?"}
{"ts": "138:56", "speaker": "E", "text": "We spun up a shadow environment in the Blue cluster, injected the higher metric rate, und haben mit K6 die API-Last simuliert. Die Latenzen blieben stabil unter 115ms, also SLA-ORI-02 compliant."}
{"ts": "139:08", "speaker": "I", "text": "Gibt es hier eine SOP oder ein Runbook für solche cross-system Tests?"}
{"ts": "139:12", "speaker": "E", "text": "Ja, Runbook RB-GW-017 beschreibt die Schritte: IAM- und Observability-Mock konfigurieren, Gateway-Config via Terraform Apply in Staging pushen, dann Synthetic Load fahren und Metriken gegen die SLA-Thresholds vergleichen."}
{"ts": "139:24", "speaker": "I", "text": "And in terms of decision-making, was this fix treated as a hotfix or part of normal sprint delivery?"}
{"ts": "139:29", "speaker": "E", "text": "Das lief als Hotfix unter Change-ID CHG-5598. Wir haben im RFC-Board kurzfristig abgestimmt, weil ein Kunde im Mandanten-Cluster T8 bereits SLA-Verletzungen gemeldet hatte."}
{"ts": "139:40", "speaker": "I", "text": "Gab es Bedenken bezüglich des Risikos, diesen Hotfix so schnell einzuspielen?"}
{"ts": "139:44", "speaker": "E", "text": "Ja, wir hatten die Diskussion, ob wir den Fix erst im Canary ausrollen. Aber aufgrund der klaren Reproduktion im Staging und der Dringlichkeit haben wir Blue/Green parallelisiert, also Blue mit Fix, Green als Rollback-Option. Evidence aus GW-4821 hat uns gezeigt, dass das stabil ist."}
{"ts": "139:58", "speaker": "I", "text": "Wie haben Sie die Lessons Learned daraus in Ihre nachhaltigen Automatisierungs-Strategien einfließen lassen?"}
{"ts": "140:00", "speaker": "E", "text": "Wir haben eine neue Stage in der CI/CD Pipeline hinzugefügt: 'Cross-System Impact Test'. Das prüft automatisch nach jedem Merge, ob Änderungen an IAM, Gateway oder Observability die SLA-KPIs gefährden. Außerdem wurde das Runbook RB-GW-017 um Troubleshooting-Hinweise ergänzt, um schneller reagieren zu können."}
{"ts": "140:00", "speaker": "I", "text": "Lassen Sie uns noch tiefer in die Pipeline schauen. In RB-GW-011 hatten Sie ja schon Blue/Green definiert. Welche zusätzlichen Automatisierungsjobs haben Sie seitdem ergänzt?"}
{"ts": "140:15", "speaker": "E", "text": "Wir haben zwei Stages ergänzt: eine pre-prod Security-Scan Stage mit SAST und DAST, und eine mTLS handshake validation, scripted via Terraform provisioners. The idea was to catch cert mismatches before cutover."}
{"ts": "140:38", "speaker": "I", "text": "Wie integrieren Sie diese Security-Scans, ohne die Deployment-Geschwindigkeit zu beeinträchtigen?"}
{"ts": "140:52", "speaker": "E", "text": "Wir parallelisieren die Scans, splitten den Traffic in ephemeral test slots. Das Runbook RB-SEC-044 beschreibt genau, wie wir Scan-Container mit auto-expire nach 15 Minuten nutzen, um die CI/CD nicht zu blockieren."}
{"ts": "141:14", "speaker": "I", "text": "Can you describe how you validate rate limiting configs before production rollout?"}
{"ts": "141:27", "speaker": "E", "text": "Sure—wir haben ein Synthetic Load Modul in der Staging-Umgebung, das per Tenant unterschiedliche Burst Patterns simuliert. Wir vergleichen die p95 Latenz gegen SLA-ORI-02 und loggen Abweichungen in Nimbus Observability."}
{"ts": "141:52", "speaker": "I", "text": "Wie koppeln Sie das Orion Gateway an Aegis IAM für mTLS und AuthN/AuthZ?"}
{"ts": "142:06", "speaker": "E", "text": "Das Gateway lädt beim Deploy das aktuelle Trust Bundle aus dem Aegis Secret Store. mTLS wird über Envoy Sidecars enforced, und AuthZ-Regeln kommen via gRPC vom IAM Policy Service. Changes triggern automatische ConfigMap Updates."}
{"ts": "142:31", "speaker": "I", "text": "Can you walk me through a scenario where Nimbus Observability changes impacted your gateway deployment?"}
{"ts": "142:45", "speaker": "E", "text": "Ja, im März hat Nimbus den Schema-Endpoint für Latenzmetriken geändert. Our IaC healthcheck modules failed, blocking the rollout pipeline. We hotpatched the parser, updated RB-OBS-009, and added schema validation in pre-deploy."}
{"ts": "143:12", "speaker": "I", "text": "Welche Monitoring-Hooks nutzen Sie, um API-Latenzen pro Mandant zu tracken?"}
{"ts": "143:25", "speaker": "E", "text": "Wir injizieren pro Tenant einen Prometheus counter und histogram metric via Gateway plugin. That allows slicing by tenant_id in Grafana dashboards and cross-referencing with rate limit events."}
{"ts": "143:46", "speaker": "I", "text": "Gab es eine besondere Herausforderung bei der Kombination dieser Hooks mit den IAM Policies?"}
{"ts": "144:00", "speaker": "E", "text": "Ja, die Hooks mussten tenant-spezifische Labels setzen, ohne PII zu loggen. Wir haben ein Hashverfahren dokumentiert in RFC-GW-015, approved by Security Council, um Mandanten IDs anonymisiert zu korrelieren."}
{"ts": "144:22", "speaker": "I", "text": "Können Sie abschließend den Mehrwert dieser Multi-Hop Integration zwischen Gateway, IAM und Observability beschreiben?"}
{"ts": "144:36", "speaker": "E", "text": "Sie erhöht die Transparenz enorm. IAM regelt den Zugriff, Gateway enforced Policies, und Observability liefert die Evidence in near real-time. This closed loop let us catch policy misconfigurations within minutes instead of hours."}
{"ts": "146:00", "speaker": "I", "text": "Lassen Sie uns noch einmal auf die SLA-ORI-02 Vorgabe zurückkommen. Wie haben Sie konkret die p95 Latency < 120ms in Ihren jüngsten Pipeline-Anpassungen verankert?"}
{"ts": "146:05", "speaker": "E", "text": "Wir haben dafür im Jenkinsfile einen zusätzlichen Stage 'latency-check' eingebaut, der auf dem Staging-Cluster mit synthetischen Lastprofilen aus Runbook RB-LAT-07 testet. Jede Build-Promotion wird blockiert, wenn p95 > 118ms ist, um ein kleines Sicherheitsfenster zu haben."}
{"ts": "146:15", "speaker": "I", "text": "Okay, und diese Loadtests, laufen die parallel zu Security-Scans oder sequenziell?"}
{"ts": "146:20", "speaker": "E", "text": "Parallel, um die Delivery-Rate nicht zu drosseln. We isolated performance tests on a dedicated node pool so they don't starve the SAST/DAST jobs of resources."}
{"ts": "146:30", "speaker": "I", "text": "Verstehe. Beim Thema Rate Limiting — wie stellen Sie sicher, dass die Konfiguration vor dem Rollout in Prod korrekt ist?"}
{"ts": "146:35", "speaker": "E", "text": "Wir validieren über ein Integrationstest-Set aus Ticket GW-5123, das mTLS-gesicherte Calls gegen eine Shadow-Instanz schickt. Die Testfälle prüfen Limits pro Mandant und ob die HTTP 429 Responses wie im Spec ORI-RL-04 formatiert sind."}
{"ts": "146:45", "speaker": "I", "text": "Wie koppeln Sie das Orion Gateway aktuell mit dem Aegis IAM, speziell für mTLS und AuthN/AuthZ?"}
{"ts": "146:50", "speaker": "E", "text": "Da gibt es eine mTLS-Handshake-Phase, die im Sidecar-Container läuft. The certs are rotated via Vault every 24h, und die AuthZ-Entscheidungen kommen über einen gRPC-Call an den Aegis PDP. Änderungen daran werden in RFC-ORI-22 dokumentiert."}
{"ts": "147:00", "speaker": "I", "text": "Gab es zuletzt ein Beispiel, wo Nimbus Observability Änderungen Ihre Deployments beeinflusst haben?"}
{"ts": "147:05", "speaker": "E", "text": "Ja, im März wurde die Export-Schnittstelle von Prometheus nach OpenTelemetry geändert. That broke our latency dashboards until we patched the Helm chart values per Runbook RB-OBS-09."}
{"ts": "147:15", "speaker": "I", "text": "Welche Monitoring-Hooks nutzen Sie, um API-Latenzen pro Mandant zu tracken?"}
{"ts": "147:20", "speaker": "E", "text": "Wir haben ein Label 'tenant_id' in jedem Prometheus-Histogramm, und zusätzlich sendet ein Loki-Log-Exporter korrelierende Trace-IDs. That allows cross-checking between logs and metrics for anomaly detection."}
{"ts": "147:30", "speaker": "I", "text": "Letzte Frage für dieses Segment: Welche Lessons Learned aus Incident Postmortems haben Ihre IaC-Module zuletzt beeinflusst?"}
{"ts": "147:35", "speaker": "E", "text": "Nach Incident INC-472 haben wir ein Terraform-Modul so erweitert, dass Security Group Changes nur nach 4-Augen-Prinzip und Ticket-Referenz, z.B. GW-4930, deployed werden. We also added pre-apply hooks that simulate network ACL changes."}
{"ts": "147:45", "speaker": "I", "text": "Und wie stellen Sie sicher, dass diese Automatisierungen langfristig wartbar bleiben?"}
{"ts": "147:50", "speaker": "E", "text": "Wir pflegen für jedes Modul ein README mit Usage-Beispielen, und ein 'owner'-Label im Repo. Plus, quarterly refactoring sessions, um deprecated APIs zu entfernen und die Codequalität hoch zu halten."}
{"ts": "148:00", "speaker": "I", "text": "Könnten Sie mir noch etwas zu den Validierungsmechanismen vor einem Production Rollout erzählen? Especially regarding rate limiting in the API gateway."}
{"ts": "148:05", "speaker": "E", "text": "Klar, wir nutzen ein zweistufiges Verfahren: Zuerst wird die Config in einer Staging-Umgebung gegen synthetische Lastprofile aus dem Runbook RB-GW-073 getestet. Dann erfolgt ein Shadow Deployment, bei dem die neuen Rate-Limits live mitlaufen, aber keinen Traffic blocken. That allows us to capture anomalies without impacting users."}
{"ts": "148:14", "speaker": "I", "text": "Verstehe. Und wie fließen Security-Scans in diesen Ablauf ein, ohne dass die Delivery-Rate leidet?"}
{"ts": "148:19", "speaker": "E", "text": "Wir haben im CI-Job 'sec-scan-gw' eine Parallelisierung implementiert. Die OWASP ZAP Scans laufen parallel zu den Static Code Analysis Steps. Außerdem nutzen wir cached dependency scans, um nur geänderte Artefakte neu zu prüfen. This reduces scan time from ~15 to 7 minutes."}
{"ts": "148:28", "speaker": "I", "text": "Wie koppeln Sie denn das Orion Gateway an Aegis IAM für mTLS und AuthN/AuthZ, gerade bei Multi-Tenant Szenarien?"}
{"ts": "148:34", "speaker": "E", "text": "Wir injizieren über Terraform-Module die Client-Zertifikate aus dem Aegis PKI Store in die Gateway-Pods. Für AuthN/AuthZ nutzen wir dann ein OPA-Policy-Plugin, das direkt Aegis IAM APIs anspricht. In Multi-Tenant Fällen hängt die Policy-Decision-URL vom Mandanten ab, was wir über ein Mapping in Consul lösen."}
{"ts": "148:44", "speaker": "I", "text": "Gab es mal eine Situation, in der Änderungen im Nimbus Observability System Einfluss auf Ihr Deployment hatten?"}
{"ts": "148:50", "speaker": "E", "text": "Ja, im Ticket OBS-219 haben sie das Schema für Latenzmetriken geändert. Our gateway latency exporter failed silently, wodurch wir p95-Werte nicht mehr korrekt reportet haben. Das führte zu einem SLA-Violations-Alarm, obwohl die echten Werte im Rahmen lagen. Wir haben danach einen Contract-Test zwischen Nimbus API und unserem Exporter eingeführt."}
{"ts": "148:59", "speaker": "I", "text": "Welche Monitoring-Hooks setzen Sie, um API-Latenzen pro Mandant zu tracken?"}
{"ts": "149:04", "speaker": "E", "text": "Wir nutzen ein Prometheus-Middleware-Plugin im Gateway, das den Mandanten aus dem JWT extrahiert. Then it labels all latency histograms with that tenant ID. Zusätzlich haben wir ein Alert-Rule-Template, das aus SLA-ORI-02 die Schwellenwerte liest."}
{"ts": "149:13", "speaker": "I", "text": "Interessant. Können Sie ein Beispiel für eine Performance-Optimierung nennen, die nachhaltig wirkt?"}
{"ts": "149:18", "speaker": "E", "text": "Wir haben den JSON-Parser in der Auth-Middleware von einer generischen Bibliothek auf einen streaming-basierten Parser umgestellt, der weniger Garbage erzeugt. This reduced GC pauses, und die p95-Latenz sank dauerhaft um ca. 18ms, gemessen über drei Release-Zyklen."}
{"ts": "149:27", "speaker": "I", "text": "Wie stellen Sie sicher, dass Ihre Automatisierungen nachhaltig gewartet werden können?"}
{"ts": "149:32", "speaker": "E", "text": "Wir dokumentieren alle CI/CD-Pipelines im internen Confluence und versehen IaC-Module mit Unit- und Integrationstests. Zudem haben wir einen Quarterly Automation Review, bei dem wir veraltete Patterns refactoren. Maintaining a clear module ownership map is key."}
{"ts": "149:41", "speaker": "I", "text": "Welche KPIs nutzen Sie, um 'Sustainable Velocity' zu messen?"}
{"ts": "149:46", "speaker": "E", "text": "Wir betrachten den Change Failure Rate, die durchschnittliche Cycle Time und den SLA-Compliance-Score. If all three stay within target ranges über mindestens zwei Quartale, sehen wir das als Indikator für nachhaltige Geschwindigkeit."}
{"ts": "149:36", "speaker": "I", "text": "Bevor wir zu den finalen Lessons Learned kommen: wie haben Sie die Monitoring-Hooks so erweitert, dass sie auch bei Mandantenwechseln stabil bleiben?"}
{"ts": "149:40", "speaker": "E", "text": "Wir haben einen Mandanten-Kontext-Interceptor in die Gateway-Pipeline eingebaut, der vor jedem Upstream-Call den Tenant-ID Header injected. Zusätzlich, äh, nutzen wir in Prometheus ein Label `tenant_id`, damit die Zeitreihen getrennt bleiben."}
{"ts": "149:48", "speaker": "I", "text": "Und das greift nahtlos mit Aegis IAM zusammen?"}
{"ts": "149:52", "speaker": "E", "text": "Yes, weil der Interceptor auch die mTLS Session Attributes aus Aegis IAM ausliest und gegen die Policy Engine matched. Dadurch vermeiden wir, dass falsche Tenant-Daten ins Monitoring laufen."}
{"ts": "149:59", "speaker": "I", "text": "Spannend. Gab es mal einen Fall, wo eine Änderung in Nimbus Observability dieses Setup gebrochen hat?"}
{"ts": "150:04", "speaker": "E", "text": "Ja, im Ticket OBS-1924. Nimbus hat den Default-Scrape-Timeout von 5 auf 3 Sekunden reduziert. Dadurch sind bei hoher Last einige `tenant_id`-metriken gedroppt, was unser SLA-ORI-02 Verletzungs-Alarm ausgelöst hat."}
{"ts": "150:12", "speaker": "I", "text": "Wie haben Sie darauf reagiert?"}
{"ts": "150:15", "speaker": "E", "text": "Wir haben laut Runbook RB-MON-07 sofort den Scrape Timeout override auf 6 Sekunden gesetzt und parallel im IaC Modul `nimbus_scrape.tf` den neuen Wert als Default gepinnt. Danach Regression-Tests in Stage-Blue gefahren."}
{"ts": "150:24", "speaker": "I", "text": "Das zeigt ja eine enge Verzahnung von Gateway, IAM und Observability — klassisches multi-hop dependency handling."}
{"ts": "150:28", "speaker": "E", "text": "Genau, und wir dokumentieren diese Abhängigkeiten in der `dependency-map.yaml` im Repo. Das hat uns auch bei der RFC-079 Entscheidung geholfen, ob wir den Observability-Stack entkoppeln."}
{"ts": "150:35", "speaker": "I", "text": "Kommen wir zu einer späten Entscheidung: Bei GW-4821 hatten Sie Canary verworfen. Gab es parallel Risiken bei der Blue/Green-Variante?"}
{"ts": "150:40", "speaker": "E", "text": "Ja, Risk-ID RSK-BG-07: Bei hoher Rate-Limiting-Konfiguration bestand die Gefahr, dass der Blue-Cluster die Request-Tokens zu schnell verbraucht. Wir haben das mitigiert, indem wir laut RFC-085 die Token-Buckets pro Cluster isoliert haben."}
{"ts": "150:50", "speaker": "I", "text": "Haben Sie Evidence gesammelt?"}
{"ts": "150:53", "speaker": "E", "text": "Wir haben Load-Tests mit 10k RPS gefahren, Messung in Grafana unter Dashboard GW-LAT-02. Latency p95 blieb bei 112 ms, also unter SLA-ORI-02. Evidence im Confluence-Page `BG-Risk-Mitigation` verlinkt."}
{"ts": "151:00", "speaker": "I", "text": "Und diese Lessons fließen jetzt wie in Ihre IaC-Module ein?"}
{"ts": "151:04", "speaker": "E", "text": "Wir haben die Terraform-Module so angepasst, dass Rate-Limit-Parameter als variables exposed werden. Damit kann das SRE-Team bei Bedarf ohne Code-Change per Pipeline-Parametrisierung reagieren."}
{"ts": "151:12", "speaker": "I", "text": "Lassen Sie uns nochmal auf die Integration mit Aegis IAM eingehen – wie genau handhaben Sie mTLS Handshakes im Orion Gateway?"}
{"ts": "151:17", "speaker": "E", "text": "Wir haben dafür im IaC-Modul `gw_tls_config.tf` die Zertifikat-Chains aus dem Aegis PKI-Cluster referenziert. Das Gateway validiert den Client-Cert-Chain gegen den CA-Store, der per Ansible-Job `job-iam-sync` alle 6h gezogen wird. Zusätzlich enforce ich in der NGINX-Lua-Layer, dass die SAN-Einträge mit dem Mandanten-UUID matchen."}
{"ts": "151:27", "speaker": "I", "text": "And how do you verify that before rollout?"}
{"ts": "151:32", "speaker": "E", "text": "We run a pre-prod smoke test suite, `mTLS-VAL-04`, that spins up ephemeral clients using test certs. Dabei prüfen wir nicht nur handshake success, sondern auch die Latenz added by TLS termination – to keep it within SLA-ORI-02."}
{"ts": "151:43", "speaker": "I", "text": "Sie hatten mal erwähnt, dass Änderungen in Nimbus Observability Ihr Deployment beeinflusst haben. Können Sie das ausführen?"}
{"ts": "151:49", "speaker": "E", "text": "Ja, im Ticket OBS-221 haben die Kollegen das Exporter-Format von JSON auf Protobuf umgestellt. Mein Gateway-Modul `gw_metrics_adapter` konnte die neuen protobuf payloads initially nicht parsen, was dazu führte, dass unsere Latenz-Histogramme leer waren. Wir mussten kurzfristig die Parser-Library updaten und parallel eine Fallback-JSON-Route im Sidecar aktivieren."}
{"ts": "151:59", "speaker": "I", "text": "War das in einer Build- oder in einer Runtime-Phase?"}
{"ts": "152:04", "speaker": "E", "text": "Das fiel leider erst im Staging-Runtime auf. Deshalb haben wir jetzt in der CI-Stage `pre_metrics_check` einen Contract-Test gegen Nimbus eingebaut, der Protobuf-Deserialisierung prüft, bevor wir Blue/Green umschalten."}
{"ts": "152:13", "speaker": "I", "text": "Speaking of Blue/Green, how do you balance speed and safety when introducing security scans?"}
{"ts": "152:19", "speaker": "E", "text": "Wir haben die SAST-Scans in die Build-Phase integriert, aber parallelisiert mit den Unit-Tests. For DAST, we run them selectively: only on modules changed in a PR, using the diff-based scope from RB-GW-011. So the pipeline stays under 12 minutes."}
{"ts": "152:29", "speaker": "I", "text": "Gab es dafür eine formale Freigabe?"}
{"ts": "152:33", "speaker": "E", "text": "Ja, das ist im RFC-079 dokumentiert, approved by our SecOps und DevOps Leads. Wir haben als Evidenz die Durchlaufzeiten aus 20 Pipeline-Runs angehängt."}
{"ts": "152:40", "speaker": "I", "text": "Wenn Sie an die Lessons Learned aus Incident GW-4972 denken – was haben Sie daraus abgeleitet?"}
{"ts": "152:46", "speaker": "E", "text": "Das war der Fall, wo ein fehlerhafter Rate-Limit-Config Deploy im Peak-Traffic zu 429er-Spikes führte. Wir haben daraufhin ein Validierungs-Script `rl_conf_guard.py` geschrieben, das Grenzwerte gegen die historischen p95-Werte der Mandanten vergleicht, bevor es ins Prod rollt."}
{"ts": "152:56", "speaker": "I", "text": "Und wie messen Sie den Erfolg solcher Maßnahmen langfristig?"}
{"ts": "153:02", "speaker": "E", "text": "Wir tracken KPIs wie mean time to rollback, p95-Latenz pro Mandant und die Anzahl der Change-Induced Incidents. Wenn die unter den Benchmarks aus SLA-ORI-02 bleiben, sehen wir das als sustainable velocity Indikator."}
{"ts": "152:48", "speaker": "I", "text": "Lassen Sie uns noch etwas tiefer auf die Multi-Hop-Abhängigkeiten eingehen. Wie stellen Sie sicher, dass Änderungen im Orion Gateway nicht unbemerkt das Aegis IAM brechen?"}
{"ts": "152:53", "speaker": "E", "text": "Wir haben da so einen mehrstufigen Validierungsprozess. Zuerst laufen in der CI-Stage unsere mTLS-Handshake-Tests gegen ein simuliertes Aegis IAM. Then, in staging, we enable full AuthN/AuthZ flows with real certificates for a subset of tenants."}
{"ts": "152:59", "speaker": "I", "text": "Nutzen Sie dafür einen speziellen Runbook-Eintrag?"}
{"ts": "153:02", "speaker": "E", "text": "Ja, das ist im Runbook RB-IAM-031 dokumentiert. Darin steht auch, welche Test-User und welche Key-Pairs wir verwenden dürfen, um die SLA-ORI-02 Latenzgrenze nicht zu verletzen."}
{"ts": "153:08", "speaker": "I", "text": "And how about when Nimbus Observability changes its schema? How do you prevent breaking the dashboard hooks?"}
{"ts": "153:13", "speaker": "E", "text": "Wir haben gelernt, nach Incident INC-OBS-447 ein Schema-Contract-File zu pflegen. In der Gateway-Pipeline wird bei jedem Build das Contract gegen das aktuelle Nimbus-API geprüft."}
{"ts": "153:19", "speaker": "I", "text": "Interessant. Und diese Prüfung läuft vor oder nach den Rate Limiting Validierungen?"}
{"ts": "153:23", "speaker": "E", "text": "Vorher. Because if the metrics sink fails, rate limiting metrics per tenant would be meaningless. Wir wollen sicherstellen, dass die Basis-Metriken stimmen, bevor wir Load-Tests fahren."}
{"ts": "153:30", "speaker": "I", "text": "Gibt es dazu Automation in Ihrer Blue/Green-Pipeline?"}
{"ts": "153:34", "speaker": "E", "text": "Ja, Stage 'pre-green-verify' führt die Schema-Checks, mTLS-Tests und auch Security-Scans aus. The idea is to catch multi-hop issues before traffic shift."}
{"ts": "153:41", "speaker": "I", "text": "Wie schnell erkennen Sie Abweichungen in der Latenz pro Mandant?"}
{"ts": "153:45", "speaker": "E", "text": "Dank der Observability-Hooks bekommen wir binnen 60 Sekunden eine Alert, wenn p95 > 120ms. Wir nutzen dynamische Thresholds pro Tenant-Profil."}
{"ts": "153:51", "speaker": "I", "text": "Have there been cases where tenant-specific thresholds prevented a false positive?"}
{"ts": "153:55", "speaker": "E", "text": "Yes, for instance with tenant ALPHA-33 during a scheduled load test—they usually operate at 80% of the SLA cap, so static thresholds would have paged us unnecessarily."}
{"ts": "154:01", "speaker": "I", "text": "Das heißt, Ihr Alerting ist kontextspezifisch implementiert?"}
{"ts": "154:04", "speaker": "E", "text": "Genau. Wir haben das in Ticket OBS-GW-219 festgehalten und in den Alertmanager-Regeln verankert, um Multi-Hop-Effekte zwischen Gateway, IAM und Observability zu berücksichtigen."}
{"ts": "154:24", "speaker": "I", "text": "Bevor wir zum Abschluss kommen, wollte ich noch auf die Observability Hooks eingehen – wie haben Sie die Mandanten-Latenzen im Orion Gateway letztlich im Dashboard sichtbar gemacht?"}
{"ts": "154:32", "speaker": "E", "text": "Wir haben in der Build-Phase zusätzlich zu den Standard-Prometheus-Exports einen Mandanten-Header-Parser in den Sidecar integriert. That parser enriches the latency metrics with the tenant_id label, und dann pusht er sie an Nimbus Observability. In Runbook RB-OBS-019 steht genau, wie die Labels zu konfigurieren sind."}
{"ts": "154:48", "speaker": "I", "text": "Hat das irgendwelche Änderungen am IAM-Setup erfordert?"}
{"ts": "154:53", "speaker": "E", "text": "Ja, minimal. We had to add a claim passthrough in Aegis IAM so that mTLS-established sessions also carry the tenant_id claim. Sonst hätten wir im Gateway keine eindeutige Zuordnung gehabt."}
{"ts": "155:06", "speaker": "I", "text": "Und wie testen Sie, dass diese Claims korrekt durchgereicht werden?"}
{"ts": "155:11", "speaker": "E", "text": "Wir nutzen ein kleines Go-Testtool, tenant-checker, das über Staging gegen das Gateway feuert. It validates both the rate limits and the claim presence. Die Tests sind Teil der CI, siehe Job 'gw-claims-verify' in Pipeline YAML."}
{"ts": "155:26", "speaker": "I", "text": "Können Sie ein Beispiel geben, wie sich eine Änderung in Nimbus Observability auf den Gateway-Releaseplan ausgewirkt hat?"}
{"ts": "155:33", "speaker": "E", "text": "Klar, als Nimbus die protobuf-Schema-Version für MetricPayload geändert hat (Ticket OBS-772), mussten wir im Parser Code anpassen. Without that, metrics ingestion would have failed silently. Wir haben den Release um zwei Tage verschoben, um mit OBS-Team gemeinsam ein kompatibles Schema zu testen."}
{"ts": "155:51", "speaker": "I", "text": "Gab es für solche Änderungen einen festgelegten Kommunikationsweg?"}
{"ts": "155:56", "speaker": "E", "text": "Ja, in RFC-Process ORI-RFC-07 ist definiert: any upstream schema change requires a 48h notice in the shared #orion-integration channel. Die Praxis zeigt aber, dass wir manchmal auch ad hoc reagieren müssen."}
{"ts": "156:10", "speaker": "I", "text": "Wie haben Sie in solchen Ad-hoc-Fällen das Risiko bewertet?"}
{"ts": "156:15", "speaker": "E", "text": "Wir haben eine Quick Risk Assessment Checklist aus Postmortem PM-ORI-05 übernommen. It scores changes on impact, reversibility, and monitoring coverage. Bei OBS-772 hatten wir high impact, high reversibility, gute Monitoring-Abdeckung – daher moderate Gesamtrisiko-Bewertung."}
{"ts": "156:32", "speaker": "I", "text": "Und wie fließt so etwas in Ihre IaC-Module ein?"}
{"ts": "156:37", "speaker": "E", "text": "Nach dem Vorfall haben wir ein Terraform-Modul update für den Sidecar-ConfigMap-Generator geschrieben, der Schema-Version als Variable akzeptiert. That way, wir können Schema-Bumps schneller parametrieren ohne Code-Build."}
{"ts": "156:50", "speaker": "I", "text": "Gab es auch Lessons Learned in Bezug auf Blue/Green vs. Canary in diesem Kontext?"}
{"ts": "156:56", "speaker": "E", "text": "Definitiv. For schema-sensitive components, Canary gave us early warning in 5% traffic slice. Aber für Gateway-Core-Rollouts bleiben wir bei Blue/Green gemäß GW-4821, um SLA-ORI-02 nicht zu gefährden."}
{"ts": "156:48", "speaker": "I", "text": "Bevor wir zum Abschluss kommen, könnten Sie bitte noch einmal erläutern, wie Sie die Lessons Learned aus dem letzten Incident Postmortem konkret in die IaC-Module integriert haben?"}
{"ts": "156:54", "speaker": "E", "text": "Ja, klar. In der Postmortem-Analyse zu Incident GW-5110 haben wir festgestellt, dass unser Terraform-Modul für die API-Gateway-Subnetzgruppen keine Fallback-Routen definierte. We then created a conditional block in the module that provisions a secondary route table when primary health checks fail."}
{"ts": "157:02", "speaker": "I", "text": "Und wie stellen Sie sicher, dass diese Fallback-Routen nicht aus Versehen im Normalbetrieb aktiv werden?"}
{"ts": "157:07", "speaker": "E", "text": "Da greifen wir auf die Monitoring-Hooks aus dem Runbook RB-GW-015 zurück. They query the health endpoint every 5 seconds, and only if two consecutive failures occur, the Lambda trigger updates the route association."}
{"ts": "157:15", "speaker": "I", "text": "Klingt robust. Haben Sie diese Änderung auch in Ihren Canary-Umgebungen getestet, bevor Sie sie live gesetzt haben?"}
{"ts": "157:20", "speaker": "E", "text": "Ja, wir haben das in der Stage 'canary-eu-central' getestet. We simulated a failure by disabling the primary ENI, observed the route switch, and validated that p95 latency stayed under SLA-ORI-02 threshold."}
{"ts": "157:28", "speaker": "I", "text": "Gab es dabei unerwartete Nebeneffekte?"}
{"ts": "157:32", "speaker": "E", "text": "Nur minimale. Der erste Health-Check hat sich wegen DNS-Caching um 1–2 Sekunden verzögert. We documented this in ticket GW-5342 and adjusted TTL settings accordingly."}
{"ts": "157:40", "speaker": "I", "text": "Wie fließen solche Tickets langfristig in Ihre Sustainable Velocity KPIs ein?"}
{"ts": "157:45", "speaker": "E", "text": "Wir tracken 'Mean Time To Mitigation' und 'Config Drift Incidents'. By reducing DNS-related delays, we improved MTTR by 8%, which shows up in our quarterly KPI dashboard."}
{"ts": "157:54", "speaker": "I", "text": "Haben Sie im Hinblick auf Nachhaltigkeit auch technische Schuld adressiert?"}
{"ts": "157:59", "speaker": "E", "text": "Ja, wir haben veraltete Bash-Skripte in Python-Modules refaktoriert. This reduced onboarding time for new engineers and eliminated undocumented environment variables."}
{"ts": "158:07", "speaker": "I", "text": "Und wie dokumentieren Sie diese Verbesserungen?"}
{"ts": "158:11", "speaker": "E", "text": "Wir pflegen ein Changelog im Git-Repo 'orion-infra' und verlinken es in Confluence unter 'Sustainable Velocity Log'. Every entry references the related ticket IDs."}
{"ts": "158:19", "speaker": "I", "text": "Zum Abschluss: Welche Maßnahme aus den letzten drei Monaten hatte den größten Impact auf die Gateway-Stabilität?"}
{"ts": "158:24", "speaker": "E", "text": "Definitiv die Einführung des mTLS-Rekeying-Playbooks RB-GW-022. It preemptively rotates client certs every 14 days, avoiding auth-related outages we saw earlier in the year."}
{"ts": "158:24", "speaker": "I", "text": "Im letzten Teil haben Sie die Canary-Strategie schon angeschnitten. Können Sie bitte noch mal konkret auf die Monitoring-Hooks eingehen, die Sie in der Build-Phase an das Orion Gateway angebunden haben?"}
{"ts": "158:32", "speaker": "E", "text": "Ja, klar. Wir haben in RB-MON-017 definiert, dass jeder Release Candidate automatisch einen Hook zu Nimbus Observability bekommt. Das sind im Wesentlichen Prometheus-Exporter mit mTLS, die per Terraform-Modul gw-monitor.tf in unsere Stage- und Prod-Cluster deployt werden."}
{"ts": "158:46", "speaker": "I", "text": "And how do you ensure that those exporters don't impact the SLA-ORI-02 latency target?"}
{"ts": "158:52", "speaker": "E", "text": "Wir haben Load-Tests mit JMeter Scripts aus dem Runbook RB-LT-004 gefahren und die Exporter auf einer separaten Sidecar-Container-Basis laufen lassen. So vermeiden wir, dass die Main Gateway Pods durch Metrikabfragen gebremst werden."}
{"ts": "159:06", "speaker": "I", "text": "Das heißt, Sie haben die Sidecars auch im IaC berücksichtigt?"}
{"ts": "159:10", "speaker": "E", "text": "Genau, wir nutzen Helm-Charts mit Values Overrides für die Sidecar-Definition. Und über das GitOps-Repo gateway-deploy haben wir ArgoCD so konfiguriert, dass diese Hooks nur auf bestimmten Branches aktiv sind."}
{"ts": "159:24", "speaker": "I", "text": "Can you give me an example of a multi-hop dependency issue you faced when integrating Aegis IAM and Nimbus Observability?"}
{"ts": "159:32", "speaker": "E", "text": "Ja, das war im Ticket INT-392. Wir hatten mTLS Zertifikate vom Aegis IAM, die alle 24h rotiert werden. Nimbus hat die Zertifikatsänderung nicht sofort übernommen, dadurch sind die AuthN-Metriken ins Leere gelaufen. Wir mussten dann einen Hook bauen, der bei Cert-Rotation ein Forced Reload im Observability-Agent triggert."}
{"ts": "159:48", "speaker": "I", "text": "Das klingt nach einem klassischen Race Condition Problem."}
{"ts": "159:51", "speaker": "E", "text": "Exactly, und wir haben das als Runbook-Step RB-IAM-REL-002 aufgenommen, um es in künftigen Deployments zu berücksichtigen."}
{"ts": "160:00", "speaker": "I", "text": "Wie haben Sie diese Änderung getestet, ohne Prod zu gefährden?"}
{"ts": "160:04", "speaker": "E", "text": "Wir haben in einer Blue/Green Umgebung mit Shadow Traffic gearbeitet. Das heißt, der Green Stack bekam die realen Zertifikats-Rotationen per Test-CA, und wir haben die Reaktionen im Observability-Log geprüft, bevor wir den Stack switchten."}
{"ts": "160:18", "speaker": "I", "text": "Did that influence your decision-making framework for handling other cross-system changes?"}
{"ts": "160:24", "speaker": "E", "text": "Ja, wir haben daraus gelernt, dass wir bei Multi-Hop Dependencies immer einen Synchronisations-Trigger einbauen. In RFC-ORI-27 steht jetzt explizit, dass jede wichtige Event-Kette einen dedizierten Health-Check-Pfad haben muss."}
{"ts": "160:38", "speaker": "I", "text": "Gab es dabei Risiken, die Sie in den letzten RFC Reviews gesondert adressiert haben?"}
{"ts": "160:44", "speaker": "E", "text": "Ja, das größte Risiko war, dass ein Trigger fälschlicherweise auslöst und dadurch unnötige Reloads verursacht. Wir haben das mitigiert, indem wir eine 3-fache Validierungsschicht implementiert haben: Zertifikat-Hash, Ablaufdatum und OCSP-Status müssen sich alle ändern, bevor der Hook feuert."}
{"ts": "160:00", "speaker": "I", "text": "Wenn wir auf die Monitoring-Hooks zurückkommen – können Sie erläutern, wie diese Hooks genau die Mandanten-Latenzen im Orion Gateway erfassen?"}
{"ts": "160:05", "speaker": "E", "text": "Ja, wir haben in der Build-Phase Module in Go geschrieben, die per gRPC Stats von den Edge Nodes sammeln und via Prometheus Pushgateway forwarden. For multi-tenant tagging, we enrich the metrics with `tenant_id` labels, as per RB-MON-07, so that p95 per Mandant im Grafana-Board sichtbar ist."}
{"ts": "160:18", "speaker": "I", "text": "Und wie ist der Zusammenhang mit dem Aegis IAM dabei, gerade wenn mTLS-Konfigurationen geändert werden?"}
{"ts": "160:24", "speaker": "E", "text": "Da gibt es eine Abhängigkeit – that's the multi-hop part. Wenn Aegis IAM ein neues Root CA-Chain ausrollt, müssen unsere mTLS-Clients am Gateway neu provisioniert werden. Wir triggern dann im IaC-Modul `gw_tls.tf` ein Re-Apply, und der Monitoring-Hook prüft, ob AuthN Latenzen steigen. That link spans Gateway, IAM, and Observability."}
{"ts": "160:40", "speaker": "I", "text": "Haben Sie dafür einen automatisierten Test in der CI/CD Pipeline?"}
{"ts": "160:44", "speaker": "E", "text": "Genau, im Stage `SEC-VALIDATE` führen wir mit einem mTLS-Testclient gegen die Staging-Endpoints eine handshake-time measurement durch. If the handshake exceeds 50ms, the pipeline fails as per SLA-ORI-02 pre-check."}
{"ts": "160:57", "speaker": "I", "text": "Wie gehen Sie vor, wenn der Observability-Stack wie Nimbus ein Breaking Change bringt?"}
{"ts": "161:02", "speaker": "E", "text": "Wir haben das zweimal erlebt – Nimbus 3.4 hat das Labelsystem geändert. Wir mussten dann im Runbook RB-OBS-21 ein Mapping-Script deployen, um alte Labelnamen auf neue zu mappen, so dass das Gateway-Exporterschema stabil blieb. Without that, dashboards would have broken instantly."}
{"ts": "161:17", "speaker": "I", "text": "Speaking of stability, how did you decide on Blue/Green over Canary in the GW-4821 case?"}
{"ts": "161:22", "speaker": "E", "text": "Wir hatten im Ticket GW-4821 klar die Risikoanalyse dokumentiert: Canary hätte bei uns in der Edge-Zone 3 Probleme mit fragmentierter Session-State-Verwaltung gehabt. Blue/Green allowed us to switch entire tenant segments atomically, avoiding partial failures. The evidence came from load test logs in `/perf/gw4821/edge3.log`."}
{"ts": "161:39", "speaker": "I", "text": "Gab es dabei Risiken, die Sie gesondert mitigiert haben?"}
{"ts": "161:43", "speaker": "E", "text": "Ja, das Haupt-Risiko war, dass der Green-Cluster hinter dem Blue eine andere Security-Policy hatte. Wir haben daher vor dem Switch einen Policy-Diff-Check laufen lassen, basierend auf dem RFC-Risk-Table RFCT-ORI-22. Any drift triggered a rollback."}
{"ts": "161:56", "speaker": "I", "text": "Können Sie ein Beispiel für ein IaC-Update nennen, das aus einem Postmortem entstanden ist?"}
{"ts": "162:01", "speaker": "E", "text": "Nach Incident INC-2023-44, wo eine falsche Rate-Limit-Config live ging, haben wir in `gw_rate.tf` ein Schema-Validation-Module ergänzt. That was influenced directly by the postmortem's root cause: missing type checks in Terraform variables."}
{"ts": "162:14", "speaker": "I", "text": "Und wie sichern Sie, dass diese Automatisierung nachhaltig bleibt?"}
{"ts": "162:19", "speaker": "E", "text": "Wir pflegen einen wöchentlichen Automation-Health-Check. Dabei prüfen wir Code-Ownership in Git, laufen Unit-Tests gegen die IaC-Module und reviewen Open Tickets mit Tag `auto-maintenance`. This ensures the scripts don't silently rot over time."}
{"ts": "161:35", "speaker": "I", "text": "Lassen Sie uns nochmal auf die Lessons Learned eingehen. In den Postmortems, äh, gab es ja ein paar IaC-Module, die Sie geändert haben – können Sie mir ein konkretes Beispiel geben?"}
{"ts": "161:39", "speaker": "E", "text": "Ja, klar. Zum Beispiel das Terraform-Modul für die API Gateway Routing Tables. After Incident INC-GW-773 haben wir die default timeout Werte von 5s auf 8s erhöht und gleichzeitig einen Healthcheck-Parameter ergänzt, der aus Runbook RB-GW-015 stammt. Das hat die Resilienz bei hohen Latenzen verbessert."}
{"ts": "161:47", "speaker": "I", "text": "Und wie haben Sie sichergestellt, dass diese Änderung nicht die SLA-ORI-02 verletzt?"}
{"ts": "161:51", "speaker": "E", "text": "We did a pre-deployment test in our staging cluster with synthetic load generated via JMeter scripts aus unserem CI-Job 'gw-latency-check'. Dabei haben wir p95 unter 110ms gehalten, also unter der 120ms Vorgabe."}
{"ts": "161:58", "speaker": "I", "text": "Im RFC-Review hat das Team auch Risiken dokumentiert – können Sie eines nennen, das besonders relevant war?"}
{"ts": "162:03", "speaker": "E", "text": "Ein zentrales Risiko war die Abhängigkeit von der Nimbus Observability API für mTLS-Zertifikatsprüfungen. Falls deren Schema sich ändert, könnte unser Auth-Handshake brechen. Wir haben in RFC-ORI-223 festgelegt, dass ein Contract-Test in der CI-Pipeline läuft, der exakt dieses Schema validiert."}
{"ts": "162:11", "speaker": "I", "text": "Haben Sie dafür spezielle Monitoring Hooks eingerichtet?"}
{"ts": "162:14", "speaker": "E", "text": "Ja, wir nutzen Prometheus Exporter, die pro Mandant die Latenzverteilung aus dem Gateway mappen. Zusätzlich gibt’s ein Loki-Log-Label 'tenant_id', sodass wir in Grafana Drill-downs machen können. This way, we can correlate spikes mit bestimmten Mandanten."}
{"ts": "162:22", "speaker": "I", "text": "Wie fließt das in Ihre kontinuierliche Verbesserung ein?"}
{"ts": "162:26", "speaker": "E", "text": "Wir haben ein wöchentliches KPI-Review, wo sustainable velocity Metriken wie 'Change Lead Time' und 'Error Budget Burn' betrachtet werden. Any deviation triggers a retro, und da passen wir entweder IaC-Module oder Pipeline-Checks an."}
{"ts": "162:34", "speaker": "I", "text": "Gab es jüngst ein Beispiel für Performance-Tuning, das nachhaltig gewirkt hat?"}
{"ts": "162:38", "speaker": "E", "text": "Ja, wir haben den Nginx-Layer im Gateway so umkonfiguriert, dass wir 'reuseport' und 'epoll' aktiviert haben. Das war initial ein Test in BRANCH 'feat/syscall-opt', documented in Ticket GW-4952, und hat unter Last die CPU-Usage um 15% gesenkt."}
{"ts": "162:46", "speaker": "I", "text": "Wie gehen Sie dabei mit der Wartbarkeit um?"}
{"ts": "162:49", "speaker": "E", "text": "Wir pflegen alle Tuning-Parameter in einer zentralen Ansible Role 'gateway-perf', versioniert im gleichen Repo wie die App. Each change muss durch Code Review, und wir haben eine README.md mit Kontext und Benchmarks, damit das Wissen langfristig erhalten bleibt."}
{"ts": "162:57", "speaker": "I", "text": "Zum Abschluss – würden Sie sagen, Blue/Green bleibt auch künftig Ihr bevorzugtes Deployment-Pattern?"}
{"ts": "163:01", "speaker": "E", "text": "Ja, solange wir den Traffic-Switch unter 200ms halten können und keine stateful Dependencies blockieren. Canary war nützlich in Experimenten, aber Blue/Green hat uns bei Orion Edge Gateway im Build-Phase mehr Kontrolle und schnellere Rollbacks gegeben, wie wir in GW-4821 dokumentiert haben."}
{"ts": "163:35", "speaker": "I", "text": "Zum Thema nachhaltige Automatisierung: wie stellen Sie sicher, dass Ihre Terraform-Module für das Gateway auch in zwei Jahren noch wartbar sind?"}
{"ts": "163:40", "speaker": "E", "text": "Ja, also wir haben 'nen internen Guideline-Doc, nennen wir es mal IaC-Runbook-ORI, Version 2.3, da sind Version-Pinning, Modulstruktur und Naming-Conventions festgelegt. Und, äh, wir machen alle sechs Monate ein Refactoring-Sprint, um veraltete Provider auszutauschen."}
{"ts": "163:54", "speaker": "I", "text": "And in terms of CI checks, do you enforce those guidelines automatically?"}
{"ts": "164:00", "speaker": "E", "text": "Yes, absolutely. Wir haben in der GitLab-CI einen Linter-Job, der die Module gegen das Runbook prüft. Failt der, geht kein Merge durch. Zusätzlich ein InSpec-Test, der live in der Staging-Cloud Provisionierungen gegen unsere Policy prüft."}
{"ts": "164:15", "speaker": "I", "text": "Können Sie ein Beispiel geben, wo diese Checks ein Problem früh erkannt haben?"}
{"ts": "164:20", "speaker": "E", "text": "Ja, Ticket GW-5132 war so eins. Da hat ein Kollege aus Versehen einen Rate-Limit-Block ohne mTLS-Requirement konfiguriert. Der Linter hat die missing attribute policy verletzt, Merge wurde blockiert."}
{"ts": "164:34", "speaker": "I", "text": "Speaking of rate limits, how do you validate configurations before they hit production now, after that incident?"}
{"ts": "164:41", "speaker": "E", "text": "We built a synthetic traffic generator in Staging. Auf Basis der Config aus der MR wird eine Test-Suite gefahren, die sowohl p95 Latenz als auch Error-Rates misst. Wenn SLA-ORI-02 in 3 Runs nicht passt, geht’s zurück in Dev."}
{"ts": "164:56", "speaker": "I", "text": "Interessant. Und wie tracken Sie über Zeit, ob diese Prozesse die Sustainable Velocity verbessern?"}
{"ts": "165:02", "speaker": "E", "text": "Wir haben drei KPIs: Merge Lead Time, Deployment Frequency und Latency Stability Index. Letzterer ist ein interner Wert aus Nimbus Observability, der die Schwankung pro Mandant misst."}
{"ts": "165:15", "speaker": "I", "text": "Can you share a performance tuning change that had a lasting impact?"}
{"ts": "165:21", "speaker": "E", "text": "Sure. Wir haben im April die Gateway-Threadpool-Size dynamisch an CPU-Kerne angepasst (GW-5274). Das ging als RFC rein, nach Tests sahen wir 18% weniger Latenzspitzen bei Lastwechseln. Seitdem stabil."}
{"ts": "165:36", "speaker": "I", "text": "Gab es dabei Risiken, die Sie besonders adressieren mussten?"}
{"ts": "165:41", "speaker": "E", "text": "Ja, risk ID R-ORI-77: mögliche Thread-Exhaustion bei Memory-Leak. Wir haben deshalb ein Watchdog-Script per Ansible ausgerollt, das JVM-Heap und Thread-Count monitored und bei Schwellenwerten neu startet."}
{"ts": "165:56", "speaker": "I", "text": "Und wie dokumentieren Sie solche Lessons Learned für zukünftige Builds?"}
{"ts": "166:02", "speaker": "E", "text": "Wir pflegen ein Confluence-Space 'Orion Build Patterns'. Jede Änderung mit Ticket-ID, Screenshot aus Nimbus, und Link zum Postmortem wird dort festgehalten. Das fließt auch in IaC-Module ein."}
{"ts": "165:31", "speaker": "I", "text": "Im Zusammenhang mit der Observability-Änderung aus Ticket OBS-229 — wie haben Sie sichergestellt, dass die Gateway-Metriken weiterhin konsistent blieben?"}
{"ts": "165:36", "speaker": "E", "text": "Wir haben einen Shadow-Metrics-Stream aufgebaut, der parallel zu Nimbus lief. Dadurch konnten wir old vs. new vergleichen, bevor wir den Switch im Runbook RB-OBS-014 finalisiert haben."}
{"ts": "165:42", "speaker": "I", "text": "Did you have to adjust any alert thresholds in Prometheus after that migration?"}
{"ts": "165:46", "speaker": "E", "text": "Yes, we reduced the p95 latency alert from 130 ms to 120 ms to align with SLA-ORI-02, and added a per-tenant dimension to catch burst anomalies earlier."}
{"ts": "165:53", "speaker": "I", "text": "Gab es da Konflikte mit den IAM-Zertifikatserneuerungen? Ich meine, mTLS-Handshake kann ja Latenzen pushen."}
{"ts": "165:58", "speaker": "E", "text": "Genau, bei der Rotation in Aegis IAM kam es zu Spikes. Wir haben im Deployment-Hook ein Pre-Warm implementiert, das neue Zertifikate im Hintergrund cached, bevor der Traffic geswitcht wird."}
{"ts": "166:05", "speaker": "I", "text": "How was this pre-warm mechanism tested before going live?"}
{"ts": "166:09", "speaker": "E", "text": "We simulated certificate expiry in staging using toxiproxy to inject handshake delays, then validated via the synthetic client in RB-GW-022."}
{"ts": "166:16", "speaker": "I", "text": "Sie erwähnten mal, dass Rate-Limiting-Konfigurationen in einem separaten Validierungs-Job laufen. Können Sie den Ablauf skizzieren?"}
{"ts": "166:21", "speaker": "E", "text": "Klar, der Job lädt die geplanten Konfigurationen, fährt sie gegen einen Replay-Cluster und checkt die Error-Rates. Wir nutzen da ein YAML-Schema (schema-ratelimit-v3) und rejecten bei >0,5% 429-Fehlern im Replay."}
{"ts": "166:29", "speaker": "I", "text": "Did you encounter any false positives during that replay validation?"}
{"ts": "166:33", "speaker": "E", "text": "Only once, when a tenant had a burst pattern not represented in our replay dataset. We updated the dataset generator to include randomized burst sequences."}
{"ts": "166:40", "speaker": "I", "text": "Im letzten RFC-Review, welche Hauptrisiken wurden im Zusammenhang mit diesen Multi-Hop-Abhängigkeiten benannt?"}
{"ts": "166:45", "speaker": "E", "text": "Ein Risiko war, dass ein Delay im Observability-Export die Auto-Scaling-Entscheidungen verzögert. Wir haben deshalb einen lokalen Fallback-Metrics-Cache im Gateway implementiert, dokumentiert in RFC-ORI-17."}
{"ts": "166:53", "speaker": "I", "text": "And how did you verify that this fallback wouldn't create drift in scaling decisions?"}
{"ts": "166:58", "speaker": "E", "text": "We ran paired load tests with and without fallback over a 48h window; difference in scaling trigger time was under 3 seconds, which is within our tolerance per SLA-ORI-05."}
{"ts": "166:51", "speaker": "I", "text": "Noch mal zu den Pipeline-Änderungen – welche Anpassungen haben Sie in der RB-GW-011 konkret seit letzter Sprint-Review umgesetzt?"}
{"ts": "166:55", "speaker": "E", "text": "Wir haben im YAML-Template den Security-Scan-Step vor den Canary-Stage verschoben, um bei Findings früher abbrechen zu können. Außerdem wurde der Terraform-Plan-Check mit tfsec erweitert. Das war zwar ein kleiner Mehraufwand, aber die Fehlerrate in prod-pre hat sich um 18% reduziert."}
{"ts": "167:04", "speaker": "I", "text": "Und wie haben Sie das getestet, ohne die Delivery-Rate zu beeinträchtigen?"}
{"ts": "167:09", "speaker": "E", "text": "Wir haben temporär einen Parallel-Job eingeführt, der die Security-Scans gegen eine staging-Umgebung fährt. In den Runbook-Einträgen RB-SCAN-017 steht explizit, dass bei Idle-Time unter 5 Minuten kein Delivery-Slot verpasst wird."}
{"ts": "167:17", "speaker": "I", "text": "Wie stellen Sie sicher, dass Rate-Limiting-Configs valide sind, bevor Sie in Produktion gehen?"}
{"ts": "167:22", "speaker": "E", "text": "Wir nutzen ein internes Tool 'throttle-tester', das gegen Mock-Services Anfragen generiert. Die Limits aus der ConfigMap werden in einer pre-prod Namespace injiziert, und dann messen wir p95-Latenzen. Die SLA-ORI-02 Checks laufen mit."}
{"ts": "167:31", "speaker": "I", "text": "Gab es dabei mal Abweichungen, die kritisch waren?"}
{"ts": "167:36", "speaker": "E", "text": "Ja, Ticket GW-5194. Da hatte Aegis IAM ein mTLS-Zertifikat mit falscher CN ausgestellt. Das führte zu Retries und erhöhte Latenz. Wir haben daraufhin im CI einen CN-Validator eingebaut."}
{"ts": "167:45", "speaker": "I", "text": "Das klingt nach einer Multi-Hop-Abhängigkeit. Können Sie den Ablauf zwischen Gateway, IAM und Observability beschreiben?"}
{"ts": "167:50", "speaker": "E", "text": "Klar, die API-Requests kommen ins Orion Gateway, dort greift die mTLS-Handshake-Logik, die direkt auf Aegis IAM zugreift. IAM gibt JWTs zurück, die im Gateway validiert werden. Parallel pusht das Gateway Metriken zu Nimbus Observability, wo wir pro Tenant Dashboards haben."}
{"ts": "167:59", "speaker": "I", "text": "Und was passiert, wenn im Observability-System eine Schema-Änderung kommt?"}
{"ts": "168:04", "speaker": "E", "text": "Das hatten wir mit Schema v2. Nimbus hat das 'latency_bucket' Feld umbenannt. Unsere Alert-Rules sind gebrochen. Seitdem fahren wir einen Contract-Test gegen das Observability-API, bevor wir Gateways deployen."}
{"ts": "168:12", "speaker": "I", "text": "Wie dokumentieren Sie solche Learnings?"}
{"ts": "168:16", "speaker": "E", "text": "In den RFC-Docs und im zentralen Runbook Confluence Space. Für GW-5194 gibt's einen Abschnitt 'Cross-System Contract Tests' mit Checklisten für Jenkins Pipelines."}
{"ts": "168:23", "speaker": "I", "text": "Wenn Sie jetzt zurückblicken: Würden Sie anders entscheiden bei Canary vs Blue/Green?"}
{"ts": "168:28", "speaker": "E", "text": "Mit den neuen Contract-Tests hätten wir Canary evtl. länger laufen lassen können. Aber Blue/Green bleibt für uns die sicherere Wahl, weil wir im Ausfall-Fall sofort swappen können. Die Evidenz aus GW-4821, insbesondere die MTTR-Statistiken, spricht klar dafür."}
{"ts": "169:31", "speaker": "I", "text": "Können Sie mir noch genauer schildern, wie die Kopplung des Orion Gateways an Aegis IAM für mTLS in der Build-Phase umgesetzt wurde?"}
{"ts": "169:38", "speaker": "E", "text": "Ja, klar, also… wir haben in der `RB-GW-011` Pipeline ein Pre-Stage eingebaut, das automatisch das mTLS-Zertifikatspaar aus dem Aegis Vault zieht. Then we run a handshake test against a staging IAM endpoint before allowing the build to proceed."}
{"ts": "169:50", "speaker": "I", "text": "Und wie sichern Sie, dass AuthN und AuthZ nicht in Konflikt geraten, gerade bei Multi-Tenant Szenarien?"}
{"ts": "169:57", "speaker": "E", "text": "Wir haben eine kombinierte Policy-Validierung implementiert. The IaC module applies tenant-specific AuthZ rules fetched via API from Aegis, and a test suite runs synthetic calls per tenant to verify both authentication and authorization logic."}
{"ts": "170:09", "speaker": "I", "text": "Can you walk me through how Nimbus Observability changes impacted your last gateway deployment?"}
{"ts": "170:15", "speaker": "E", "text": "Klar, vor zwei Sprints hat Nimbus ein neues Metrics-Schema für Latenzen eingeführt. That broke our parsing in the deployment health checks. We had to patch the Helm chart to map new metric labels before rollout could continue."}
{"ts": "170:28", "speaker": "I", "text": "Gab es dafür eine dokumentierte Abhängigkeit im Runbook?"}
{"ts": "170:33", "speaker": "E", "text": "Ja, im Runbook `GW-OBS-07` steht jetzt ein Abschnitt ‚Nimbus Schema Changes‘, und wir haben einen wöchentlichen Pull des Schema-Files in die Testumgebung eingebaut."}
