{"ts": "00:00", "speaker": "I", "text": "Können Sie bitte, äh, kurz die Hauptziele der Hera QA Platform beschreiben, damit wir sicherstellen, dass wir denselben Kontext haben?"}
{"ts": "02:15", "speaker": "E", "text": "Gerne. Die Hera QA Platform soll alle Testpipelines bei Novereon Systems unter einer Oberfläche vereinen. Ziel ist, die Ausführung zu orchestrieren, flaky Tests automatisiert zu erkennen und priorisiert zu behandeln. Wir wollen damit laut Projektauftrag P-HER nicht nur Effizienz, sondern auch die Vorhersagbarkeit verbessern."}
{"ts": "05:05", "speaker": "I", "text": "Und wie sieht Ihre Rolle als QA Lead in der Build-Phase konkret aus?"}
{"ts": "07:20", "speaker": "E", "text": "Ich bin verantwortlich für die Definition der Teststrategien, die Anbindung der Testframeworks an die Orchestrierungsengine und die Einhaltung interner Policies wie POL-QA-014. Zusätzlich koordiniere ich mit Dev- und SRE-Teams, um die Testumgebung stabil zu halten."}
{"ts": "10:10", "speaker": "I", "text": "Welche besonderen Herausforderungen sehen Sie in der Testorchestrierung für dieses Projekt?"}
{"ts": "13:00", "speaker": "E", "text": "Die größte Herausforderung ist die Heterogenität der Testtypen. Wir haben API-, UI-, Performance- sowie Security-Tests in verschiedenen Sprachen. Die Orchestrierung muss die Abhängigkeiten erkennen und gemäß Runbook RB-QA-051 auch Security-Checks früh einbinden."}
{"ts": "17:30", "speaker": "I", "text": "Wie priorisieren Sie Testfälle basierend auf Risiko und Auswirkung, gemäß Ihrer Strategie?"}
{"ts": "20:15", "speaker": "E", "text": "Wir nutzen eine Risikomatrix aus POL-QA-014. Kritische Pfade im Code, z.B. Payment-Module oder Authentifizierungskomponenten, werden mit hoher Priorität getestet. Dazu verknüpfen wir Impact-Analysen aus den Build-Logs mit den Test-Suites."}
{"ts": "24:00", "speaker": "I", "text": "Inwiefern berücksichtigen Sie Sicherheitsaspekte in Ihrer Teststrategie?"}
{"ts": "27:45", "speaker": "E", "text": "Security-Aspekte fließen in jede Teststufe ein. Wir binden automatisierte Pen-Tests ein, definieren Negativtests für Auth-Flows und prüfen Abweichungen sofort gegen die Vorgaben aus RB-QA-051."}
{"ts": "32:00", "speaker": "I", "text": "Wie stellen Sie sicher, dass Traceability von Anforderungen bis zu Testfällen gegeben ist?"}
{"ts": "35:40", "speaker": "E", "text": "Wir nutzen ein internes Traceability-Tool, das alle Anforderungen aus dem ALM-System mit Test-IDs verknüpft. Bei Hera werden diese IDs automatisch in die Orchestrierungsreports übernommen, sodass wir lückenlos nachweisen können, welcher Test welche Anforderung abdeckt."}
{"ts": "40:00", "speaker": "I", "text": "Wie binden Sie Sicherheits-Runbooks wie RB-QA-051 in Ihre Testpläne ein?"}
{"ts": "43:30", "speaker": "E", "text": "RB-QA-051 definiert, wann und wie Security-Tests auszuführen sind, inklusive Eskalationspfaden. In unseren Testplänen markieren wir diese Schritte als Mandatory Gates. Die Orchestrierung stoppt bei Nichtbestehen und erstellt automatisch ein Ticket im SecOps-System."}
{"ts": "50:00", "speaker": "I", "text": "Gibt es Abhängigkeiten zu anderen Projekten wie Aegis IAM oder Poseidon Networking?"}
{"ts": "54:00", "speaker": "E", "text": "Ja, Hera ist auf Aegis IAM angewiesen, um Authentifizierungstests realistisch durchzuführen, und auf Poseidon Networking für Last- und Failover-Tests. Änderungen dort müssen wir einkalkulieren, um unsere Testpläne anzupassen."}
{"ts": "90:00", "speaker": "I", "text": "Lassen Sie uns etwas tiefer gehen: Wie genau priorisieren Sie Testfälle basierend auf Risiko und Auswirkung, gerade im Kontext der Hera QA Platform?"}
{"ts": "90:08", "speaker": "E", "text": "Wir nutzen eine gewichtete Risikomatrix gemäss POL-QA-014, wobei wir Eintrittswahrscheinlichkeit und Schadenshöhe multiplizieren. Für Hera bedeutet das z. B., dass Schnittstellen zu Aegis IAM höher priorisiert werden, da ein Auth-Failure den gesamten Testlauf blockieren kann."}
{"ts": "90:22", "speaker": "I", "text": "Und wie fliessen Sicherheitsaspekte in diese Matrix ein?"}
{"ts": "90:26", "speaker": "E", "text": "Sicherheitsaspekte haben bei uns einen Mindestfaktor. Selbst wenn die Eintrittswahrscheinlichkeit gering ist, setzen wir den Schadensfaktor auf Maximum, wenn es um kritische Policies aus RB-QA-051 geht. Das zwingt uns, solche Fälle immer früh im Zyklus zu testen."}
{"ts": "90:40", "speaker": "I", "text": "Wie stellen Sie Traceability von Anforderungen bis zu Testfällen sicher?"}
{"ts": "90:44", "speaker": "E", "text": "Wir mappen jede User Story in Jira auf einen Testfall in unserem Orchestrator. Zusätzlich verlinken wir dort den relevanten Abschnitt aus dem Security-Runbook. Bei Hera nutzen wir das Mapping-Tool 'TraceLinker', das automatisch prüft, ob eine Anforderung ohne Testfall existiert."}
{"ts": "90:58", "speaker": "I", "text": "Gibt es Abhängigkeiten zu Poseidon Networking, die Ihre Tests beeinflussen?"}
{"ts": "91:03", "speaker": "E", "text": "Ja, insbesondere bei End-to-End-Tests. Die Netzwerk-Latenzprofile von Poseidon beeinflussen unsere Retry-Logik. Deshalb haben wir in Ticket QA-3421 eine Anpassung dokumentiert, um Timeouts dynamisch an den Poseidon-SLOs zu orientieren."}
{"ts": "91:18", "speaker": "I", "text": "Welche SLOs sind für QA in diesem Projekt relevant?"}
{"ts": "91:22", "speaker": "E", "text": "Primär der 'Test Completion SLO' von 95% aller geplanten Tests pro Build in unter 45 Minuten. Wir messen das automatisiert via den CI-Pipelines und reporten im QA-Dashboard."}
{"ts": "91:35", "speaker": "I", "text": "Wie kommunizieren Sie mit dem Security-Team, wenn Sie Schwachstellen finden?"}
{"ts": "91:39", "speaker": "E", "text": "Wir nutzen ein dediziertes Slack-Channel und öffnen parallel ein SecTicket im internen Tracker. Für kritische Findings gemäss RB-QA-051 gilt eine 4-Stunden-Reaktionszeit. Wir hatten z. B. letzte Woche bei Testfall HERA-SEC-17 so einen Fall."}
{"ts": "91:55", "speaker": "I", "text": "Gab es Lessons Learned aus anderen Projekten, die Sie hier anwenden?"}
{"ts": "92:00", "speaker": "E", "text": "Aus dem Projekt Orion Build haben wir gelernt, dass flaky Tests oft in Setup-Routinen auftreten. Für Hera führen wir daher vor jedem Release Cycle einen 'Flaky Audit' durch, dokumentiert in Runbook QA-RB-019."}
{"ts": "92:14", "speaker": "I", "text": "Sie haben vorhin erwähnt, dass Sie Timeouts dynamisch anpassen. Können Sie das genauer erklären?"}
{"ts": "92:19", "speaker": "E", "text": "Klar, wir ziehen die aktuellen Latenzwerte aus Poseidon’s Monitoring API, berechnen daraus einen adaptiven Timeout-Wert und injizieren den in die Orchestrator-Konfiguration. So vermeiden wir unnötige Testabbrüche und halten trotzdem die SLOs ein."}
{"ts": "98:00", "speaker": "I", "text": "Lassen Sie uns nun auf konkrete Entscheidungen zu sprechen kommen – gab es im Projekt Hera QA Situationen, in denen Sie bewusst Testabdeckung reduziert haben, um einen Termin zu halten?"}
{"ts": "98:15", "speaker": "E", "text": "Ja, das war der Fall beim Sprint 14, als wir das neue Orchestrierungsmodul deployen mussten. Wir haben uns entschieden, lediglich die High-Risk-Szenarien gemäss POL-QA-014 zu fahren – Low-Risk-Regressionstests wurden verschoben. Das Risiko haben wir im Ticket QA-HER-442 dokumentiert und mit der Release-Note verknüpft."}
{"ts": "98:40", "speaker": "I", "text": "Wie haben Sie dieses Risiko gegenüber Stakeholdern begründet?"}
{"ts": "98:52", "speaker": "E", "text": "Wir haben anhand der Flaky-Test-Analytics gezeigt, dass die betroffenen Low-Risk-Tests in den letzten fünf Läufen stabil waren. Außerdem gab es ein SLA-Druckelement: Das vereinbarte SLO von 95 % Testlauf-Abdeckung für kritische Pfade war erfüllt, was wir als Hauptargument nutzten."}
{"ts": "99:20", "speaker": "I", "text": "Gab es technische Gegenstimmen im Team?"}
{"ts": "99:31", "speaker": "E", "text": "Ja, die SRE-Kollegen haben Bedenken wegen potenzieller Drift in den Testumgebungen geäußert. Wir haben das mitigiert, indem wir im Runbook RB-QA-051 einen sofortigen Post-Release-Testplan ergänzt haben, der innerhalb von 24 Stunden nach Go-Live alle offenen Szenarien prüft."}
{"ts": "99:58", "speaker": "I", "text": "Können Sie ein Beispiel eines solchen Post-Release-Fundes nennen?"}
{"ts": "100:10", "speaker": "E", "text": "Nach Release von Sprint 14 fanden wir einen Minor-Bug in der Testdaten-Synchronisation. Das war in Ticket BUG-HER-233 protokolliert. Wir konnten ihn binnen 3 Stunden fixen, ohne SLA-Verletzung."}
{"ts": "100:35", "speaker": "I", "text": "Wie fließen solche Learnings wieder in die Strategie ein?"}
{"ts": "100:47", "speaker": "E", "text": "Wir haben eine Lessons-Learned-Sektion im Confluence-Bereich der Hera QA Platform, in der solche Fälle eingetragen werden. Daraus entstehen Anpassungen an unsere Priorisierungs-Checkliste und teilweise an RFCs, z.B. RFC-1770 wurde nach diesem Bug bezüglich Testdatenvalidierung erweitert."}
{"ts": "101:15", "speaker": "I", "text": "Haben Sie auch schon einmal den umgekehrten Trade-off erlebt – also länger getestet und einen Release verschoben?"}
{"ts": "101:27", "speaker": "E", "text": "Ja, beim Security-Patch im Zusammenhang mit Aegis IAM. Die Abhängigkeit war kritisch, und die Security-Runbooks verlangten vollständige Regression aller Authentifizierungs-Workflows. Wir haben das Release um zwei Tage verschoben, um die 100 % Abdeckung zu erreichen. Stakeholder-Approval dazu war durch das Risk Board im Ticket RISK-HER-118 dokumentiert."}
{"ts": "101:55", "speaker": "I", "text": "Wie hat sich diese Entscheidung auf das Verhältnis zu den Produktverantwortlichen ausgewirkt?"}
{"ts": "102:06", "speaker": "E", "text": "Positiv, weil wir transparent kommuniziert haben. Die Produktowner sahen, dass wir proaktiv Risiken minimieren, was langfristig Vertrauen schafft. Kurzfristig gab es natürlich Frustration über die Verzögerung."}
{"ts": "102:28", "speaker": "I", "text": "Zum Schluss: Welche impliziten Heuristiken nutzen Sie, wenn Sie zwischen Testtiefe und Time-to-Market entscheiden müssen?"}
{"ts": "102:40", "speaker": "E", "text": "Ich schaue immer auf drei Faktoren: 1) Kritikalität der betroffenen Funktion im SLO-Kontext, 2) Historie von Defects in diesem Bereich, und 3) Aufwand für einen Hotfix im Worst Case. Wenn der Hotfix-Aufwand gering ist und SLO nicht gefährdet wird, tendiere ich zu schnellerem Release. Diese Logik ist nicht formal im Runbook, aber intern etabliert."}
{"ts": "114:00", "speaker": "I", "text": "Sie haben vorhin erwähnt, dass Sie bei Hera QA in einer Sprintphase gezielt weniger getestet haben, um den Release-Termin zu halten. Können Sie das bitte noch einmal konkretisieren?"}
{"ts": "114:05", "speaker": "E", "text": "Ja, das war im Build-Sprint 14. Wir hatten eine kritische Abhängigkeit zu einem neuen Feature im Aegis IAM Connector. Laut Ticket QA-7841 fehlten uns Integrationstests, aber aufgrund des Go-Live-Fensters laut Release-Kalender mussten wir auf vollständige End-to-End-Tests verzichten."}
{"ts": "114:14", "speaker": "I", "text": "Wie haben Sie dieses Risiko dokumentiert? Gab es ein formales Verfahren?"}
{"ts": "114:18", "speaker": "E", "text": "Wir haben das Risiko im QA-Risk-Log unter der ID RSK-HER-09 festgehalten und in RFC-1770 als 'Known Deviation' markiert. Zusätzlich wurde im Runbook RB-QA-051 ein temporärer Workaround für die Authentifizierungsschicht beschrieben."}
{"ts": "114:28", "speaker": "I", "text": "Und wie haben Sie das gegenüber dem Security-Team vertreten? Immerhin betrifft es ja IAM."}
{"ts": "114:32", "speaker": "E", "text": "Wir haben eine Ausnahmegenehmigung über das Security Change Advisory Board eingeholt. Das Meeting-Protokoll SEC-CAB-2023-11-15 dokumentiert, dass wir für zwei Wochen mit erhöhter Monitoring-Frequenz in den Login-Logs arbeiten."}
{"ts": "114:42", "speaker": "I", "text": "Gab es messbare Auswirkungen auf Ihre SLOs in dieser Zeit?"}
{"ts": "114:46", "speaker": "E", "text": "Nein, die SLO 99,5% Testpassrate blieb stabil. Allerdings stieg die mittlere Bearbeitungszeit für Incidents (MTTR) um ca. 12%, weil wir zwei kleinere Regressionen im Auth-Flow hatten."}
{"ts": "114:55", "speaker": "I", "text": "War das aus Ihrer Sicht gerechtfertigt?"}
{"ts": "114:58", "speaker": "E", "text": "Aus Projektperspektive ja, weil wir den vertraglich zugesicherten Launch-Termin halten konnten und die Regressionen durch Hotfix QA-HF-332 und -333 in weniger als 24 Stunden behoben wurden."}
{"ts": "115:05", "speaker": "I", "text": "Gab es intern Kritik an der Entscheidung?"}
{"ts": "115:08", "speaker": "E", "text": "Ja, das Platform-Team hat angemerkt, dass wir damit einen 'precedent' schaffen könnten. Deshalb haben wir in der Lessons Learned Session LLS-HER-05 einen klaren Katalog definiert, wann solche Trade-offs zulässig sind."}
{"ts": "115:17", "speaker": "I", "text": "Können Sie ein Beispiel aus diesem Katalog nennen?"}
{"ts": "115:20", "speaker": "E", "text": "Ein Punkt ist: nur wenn die betroffene Funktionalität durch isolierte Monitoring- und Rollback-Mechanismen abgesichert ist, wie in Runbook RB-QA-060 beschrieben. Ohne diese Guards keine Abstriche bei der Testtiefe."}
{"ts": "115:28", "speaker": "I", "text": "Letzte Frage dazu: Haben Sie den Kunden über die temporäre Risikoerhöhung informiert?"}
{"ts": "115:32", "speaker": "E", "text": "Ja, in der Release Note 1.4.0 gab es einen Abschnitt 'Known Limitations', und wir haben im wöchentlichen Steering Committee Call explizit darauf hingewiesen, mit Verweis auf Ticket QA-7841 und RFC-1770."}
{"ts": "116:00", "speaker": "I", "text": "Sie hatten eben erwähnt, dass Sie sich auf RFC-1770 bezogen haben, um die Testabdeckung zu reduzieren. Können Sie genauer ausführen, wie Sie das Risiko quantifiziert haben?"}
{"ts": "116:10", "speaker": "E", "text": "Ja, wir haben dazu eine Risikomatrix aus POL-QA-014 angewendet, die sowohl Eintrittswahrscheinlichkeit als auch Auswirkung bewertet. Konkret haben wir die Module im Hera-Orchestrator, die nur intern verwendet werden, in eine niedrigere Kategorie gestuft."}
{"ts": "116:28", "speaker": "I", "text": "Und wie haben Sie sichergestellt, dass diese Entscheidung nicht die Sicherheit verletzt, gerade in Bezug auf RB-QA-051?"}
{"ts": "116:39", "speaker": "E", "text": "Wir haben alle sicherheitsrelevanten Tests aus den Runbooks priorisiert ausgeführt. RB-QA-051 spezifiziert z. B. für Authentifizierungsprozesse zwingende Penetrationstests. Diese sind nicht gekürzt worden."}
{"ts": "116:55", "speaker": "I", "text": "Gab es dabei Abhängigkeiten zu Aegis IAM, die berücksichtigt werden mussten?"}
{"ts": "117:05", "speaker": "E", "text": "Ja, absolut. Die Session-Token-Validierung in Hera hängt direkt von den Aegis IAM APIs ab. Deshalb haben wir mit dem IAM-Team abgesprochen, dass ihre API-Änderungen im Staging vorgezogen getestet werden, bevor wir in unseren orchestrierten Regression-Run gehen."}
{"ts": "117:23", "speaker": "I", "text": "Wie haben Sie diese cross-team Koordination dokumentiert?"}
{"ts": "117:33", "speaker": "E", "text": "Das ging über Ticket QA-HERA-482 im internen Tracker. Dort haben wir alle Abhängigkeiten, Testfenster und Ansprechpartner gelistet. Das Ticket ist mit den relevanten SLO-Dashboards verlinkt."}
{"ts": "117:49", "speaker": "I", "text": "SLO-Dashboards – welche Metriken waren für diese Entscheidung maßgeblich?"}
{"ts": "118:00", "speaker": "E", "text": "Wir haben 'Critical Test Pass Rate' und 'Mean Time to Detect' als Schlüsselmetriken genommen. Beide mussten laut SLA-QA-022 innerhalb vordefinierter Schwellen bleiben, auch wenn wir die Testtiefe in weniger kritischen Bereichen reduziert haben."}
{"ts": "118:17", "speaker": "I", "text": "Gab es einen Moment, wo Sie befürchtet haben, dass dieser Ansatz scheitern könnte?"}
{"ts": "118:27", "speaker": "E", "text": "Ja, als im Smoke-Test einer nicht sicherheitskritischen Komponente ein Race Condition Bug auftrat. Wir mussten abwägen: zurück in die volle Testtiefe oder fixen und weiter. Wir haben uns für Letzteres entschieden, mit dokumentiertem Restrisiko."}
{"ts": "118:44", "speaker": "I", "text": "Wie haben Sie das Restrisiko dokumentiert?"}
{"ts": "118:54", "speaker": "E", "text": "Über einen Risk Acceptance Record im QA-Repository, referenziert als RAR-HERA-019. Darin steht die Begründung, die betroffenen Module, potenzielle Auswirkungen und der genehmigende Stakeholder."}
{"ts": "119:08", "speaker": "I", "text": "Wurde dieser Record später auditiert?"}
{"ts": "119:20", "speaker": "E", "text": "Ja, im quartalsweisen QA-Audit durch das Compliance-Team. Ergebnis: Vorgehen war im Rahmen der Policies, aber Empfehlung, in der nächsten Build-Phase eine automatisierte Race-Detection einzuführen."}
{"ts": "122:00", "speaker": "I", "text": "Lassen Sie uns kurz auf die interdisziplinären Schnittstellen eingehen: Wie stellen Sie sicher, dass QA, SRE und das Security-Team dieselben Prioritäten verfolgen?"}
{"ts": "122:04", "speaker": "E", "text": "Wir nutzen wöchentliche Alignment-Calls und ein gemeinsames Kanban-Board nach dem Muster aus Runbook RB-QA-032. Darin sind QA-Tasks nach SLO-Relevanz markiert, sodass SRE und Security sofort sehen, was kritisch ist."}
{"ts": "122:09", "speaker": "I", "text": "Und wie messen Sie diese SLOs konkret im QA-Kontext?"}
{"ts": "122:12", "speaker": "E", "text": "Für die Hera QA Platform gilt ein Mean Time to Detection von unter 15 Minuten für kritische Testfehler. Das tracken wir via das interne Monitoring-Modul 'Aletheia', das sowohl Test-Logs als auch Security-Events korreliert."}
{"ts": "122:17", "speaker": "I", "text": "Gab es hier Überschneidungen mit Aegis IAM oder Poseidon Networking?"}
{"ts": "122:21", "speaker": "E", "text": "Ja, insbesondere bei Authentifizierungs-Tests. Aegis IAM liefert Tokens, die unsere Security-Test-Suites konsumieren. Poseidon Networking beeinflusst Latenztests, was wiederum unsere Performance-SLOs tangiert – das ist ein klassisches Multi-Hop-Problem."}
{"ts": "122:27", "speaker": "I", "text": "Wie gehen Sie vor, wenn ein sicherheitskritischer Test innerhalb dieser Kette fehlschlägt?"}
{"ts": "122:31", "speaker": "E", "text": "Wir triggern sofort das Incident Playbook aus RB-QA-051, Stufe 'Rot'. Das löst ein Cross-Team War-Room aus, in dem SRE den Infrastrukturzustand checkt und Security die IAM-Logs analysiert. QA liefert die reproduzierbaren Steps aus dem Testfall."}
{"ts": "122:37", "speaker": "I", "text": "Welche Lessons Learned aus anderen Projekten haben Sie hier übernommen?"}
{"ts": "122:41", "speaker": "E", "text": "Aus Projekt 'Lynx DataHub' haben wir gelernt, dass Testdaten-Isolation absolut entscheidend ist. Deshalb isolieren wir Test-Namespaces strikt – eine Abweichung hatte damals zu sieben Fehlalarmen pro Woche geführt."}
{"ts": "122:46", "speaker": "I", "text": "Kommen wir zu einer Entscheidung: Gab es bei Hera eine Situation, bei der Sie weniger getestet haben, um eine Deadline zu halten?"}
{"ts": "122:50", "speaker": "E", "text": "Ja, im Sprint 14. Laut RFC-1770 haben wir UI-Regressions-Tests von 100% auf 60% Coverage reduziert, um den neuen Orchestrator-Endpunkt pünktlich auszuliefern. Das Risiko wurde in Ticket QA-4129 dokumentiert."}
{"ts": "122:56", "speaker": "I", "text": "Wie haben Sie dieses Risiko begründet?"}
{"ts": "122:59", "speaker": "E", "text": "Wir hatten Metriken, dass UI-Bugs in ähnlichen Modulen historisch <1% der kritischen Defekte ausmachten. Zudem gab es automatisierte Smoke-Tests, die die wichtigsten Pfade abdeckten. Die Entscheidung wurde vom PM und Security abgenickt."}
{"ts": "123:04", "speaker": "I", "text": "Gab es nachträglich Probleme durch diese Entscheidung?"}
{"ts": "123:08", "speaker": "E", "text": "Nur einen Minor-Bug im UI, der in Patch 14.1 gefixt wurde. Alles in allem hat sich der Trade-off gelohnt, da wir das Go-Live-Datum halten konnten, ohne Sicherheits-SLOs zu verletzen."}
{"ts": "124:00", "speaker": "I", "text": "Sie hatten vorhin von einer bewussten Reduktion der Testtiefe gesprochen. Mich interessiert jetzt – wie haben Sie das konkret mit dem Security-Team abgestimmt, gerade im Kontext von RB-QA-051?"}
{"ts": "124:08", "speaker": "E", "text": "Wir haben dazu ein Ad-hoc-Meeting einberufen, basierend auf Ticket QA-HER-482. Dort waren Vertreter von Security, SRE und QA anwesend. Laut RB-QA-051 mussten wir sicherstellen, dass alle kritischen Authentifizierungs-Pfade aus Aegis IAM trotzdem vollständig getestet bleiben."}
{"ts": "124:16", "speaker": "I", "text": "Heißt das, Sie haben eine Teilmenge der Test-Suites priorisiert?"}
{"ts": "124:23", "speaker": "E", "text": "Genau. Wir haben in Zeile 54 des Runbooks eine Tabelle, die die Risikoklasse A beschreibt. Diese Testfälle durften nicht entfallen. Wir haben nur bei Klasse C und teilweise B gekürzt, wenn die Abdeckung durch automatisierte Regressionstests schon hoch war."}
{"ts": "124:31", "speaker": "I", "text": "Gab es dazu einen formalen Waiver-Prozess?"}
{"ts": "124:39", "speaker": "E", "text": "Ja, wir haben nach POL-QA-014 einen Waiver Request erstellt, WF-REQ-77, und diesen über das interne Confluence-Formular eingereicht. Das Approval kam innerhalb von 24 Stunden vom QA Governance Board."}
{"ts": "124:47", "speaker": "I", "text": "Und wie haben Sie in dieser Zeit die SLOs überwacht? Gab es Abweichungen?"}
{"ts": "124:56", "speaker": "E", "text": "Wir haben unser SLO für Testausführungszeit (max. 6 Stunden für den Full Regression Run) mit Prometheus-Metriken überwacht. In der reduzierten Testtiefe lagen wir bei 4,2 Stunden, was unter dem Ziel war. Keine SLO-Verletzung."}
{"ts": "125:04", "speaker": "I", "text": "Aber gab es im Nachgang unentdeckte Defects, die auf die Kürzung zurückzuführen waren?"}
{"ts": "125:12", "speaker": "E", "text": "Ein Fall, ja. Ticket BUG-HER-921, ein Edge-Case im Reporting-Modul. War Risikoklasse B, fiel in die gekürzte Menge. Der Fix war in zwei Tagen implementiert, keine Produktionsauswirkung, aber ein Lerneffekt."}
{"ts": "125:20", "speaker": "I", "text": "Wurde das in Ihre Lessons Learned übernommen?"}
{"ts": "125:28", "speaker": "E", "text": "Ja, im Post-Mortem PM-HER-07 haben wir ergänzt, dass bei Modulen mit komplexer Datenaggregation auch niedrigere Risikoklassen nicht automatisch gestrichen werden sollten."}
{"ts": "125:36", "speaker": "I", "text": "Wie sieht es mit Abhängigkeiten zu Poseidon Networking aus – hat das Ihre Entscheidung beeinflusst?"}
{"ts": "125:44", "speaker": "E", "text": "Indirekt. Poseidon liefert die Netzwerk-Mocks für unsere Tests. Wir mussten sicherstellen, dass deren Update auf v3.4 nicht durch unsere Kürzungen ungetestet blieb. Deshalb blieben alle entsprechenden Schnittstellen-Tests unangetastet."}
{"ts": "125:52", "speaker": "I", "text": "Könnten Sie mir ein Beispiel geben, wo Sie diesen Trade-off dokumentiert haben?"}
{"ts": "126:00", "speaker": "E", "text": "Ja, in RFC-1770 Abschnitt 5.3 ist explizit beschrieben, welche Testmodule entfallen sind und wie wir das Risiko bewertet haben: Impact Score < 3, Mitigation durch Monitoring und schnelle Hotfix-Pipeline."}
{"ts": "126:00", "speaker": "I", "text": "Sie hatten vorhin die Reduktion der Testtiefe angesprochen. Mich würde interessieren: Wie haben Sie das konkret dokumentiert, damit es im Audit nachvollziehbar bleibt?"}
{"ts": "126:05", "speaker": "E", "text": "Wir haben jede Abweichung in unserem QA-Decision-Log festgehalten, das ist Teil von Confluence, Abschnitt QA-HERA-DEC-2024. Zusätzlich haben wir Ticket QA-3421 eröffnet, um den Bezug zu RFC-1822 herzustellen, wo die Deadline-bedingte Änderung der Testabdeckung freigegeben wurde."}
{"ts": "126:15", "speaker": "I", "text": "Und wie stellen Sie sicher, dass solche Entscheidungen nicht zu einem blinden Fleck in der Sicherheitsprüfung führen?"}
{"ts": "126:21", "speaker": "E", "text": "Wir gleichen jede Reduktion gegen die Sicherheits-Runbooks ab, konkret RB-QA-051 und RB-SEC-014. Wenn ein kritischer Bereich betroffen ist, muss der Security Lead ein Override in unserem JIRA-Workflow geben, sonst wird der Merge-Request geblockt."}
{"ts": "126:33", "speaker": "I", "text": "Gab es im Hera-Projekt eine Situation, wo das Override tatsächlich verweigert wurde?"}
{"ts": "126:38", "speaker": "E", "text": "Ja, im Sprint 14. Da wollten wir einen Teil der API-Auth-Tests auslassen, um einen Release-Kandidaten rechtzeitig zu liefern. Der Security Lead hat auf Grundlage der Abhängigkeit zum Aegis IAM Projekt abgelehnt, weil die Authentifizierungsmodule gerade ein Update aus Poseidon Networking erhalten hatten."}
{"ts": "126:54", "speaker": "I", "text": "Das heißt, Sie mussten die volle Testtiefe in diesem Bereich doch fahren?"}
{"ts": "127:00", "speaker": "E", "text": "Genau. Wir haben dann einen zusätzlichen Test-Cluster aufgesetzt und mittels parallelisiertem Orchestrator-Lauf die Ausführungszeit halbiert. Das war zwar ressourcenintensiv, hat aber das SLO von maximal 48 Stunden QA-Zyklus eingehalten."}
{"ts": "127:12", "speaker": "I", "text": "Wie bewerten Sie im Nachhinein diesen Trade-off zwischen Ressourcenverbrauch und Qualitätssicherung?"}
{"ts": "127:18", "speaker": "E", "text": "Aus QA-Sicht war es richtig. Wir haben zwar kurzfristig mehr Compute-Kosten generiert, aber gemäß unserem Risiko-Score-Modell (POL-QA-014 Anhang C) war das Risiko eines Auth-Breaks deutlich höher als die Mehrkosten."}
{"ts": "127:31", "speaker": "I", "text": "Spiegelt sich das auch in den Lessons Learned wider?"}
{"ts": "127:36", "speaker": "E", "text": "Ja, in LL-HERA-2024-05 haben wir vermerkt, dass Schnittstellen-Updates aus anderen Projekten immer eine Überprüfung der Testreduktionspläne erfordern. Das ist jetzt ein fester QA-Gate-Schritt."}
{"ts": "127:46", "speaker": "I", "text": "Gab es nach diesem Vorfall Änderungen in Ihren SLAs oder SLOs?"}
{"ts": "127:51", "speaker": "E", "text": "Die SLA blieb gleich, aber wir haben das interne SLO für sicherheitsrelevante Regressionstests von 72 auf 48 Stunden verschärft, um mehr Puffer vor Release zu haben."}
{"ts": "128:01", "speaker": "I", "text": "Abschließend: Würden Sie diese Herangehensweise auch auf weniger kritische Module anwenden?"}
{"ts": "128:06", "speaker": "E", "text": "Nein, für Low-Risk-Module halten wir an der flexiblen Testtiefe fest, um Time-to-Market nicht unnötig zu verlängern. Aber bei sicherheitskritischen Pfaden gilt jetzt praktisch eine Null-Toleranz gegenüber Reduktionsplänen ohne volle Kompensation."}
{"ts": "128:00", "speaker": "I", "text": "Sie hatten vorhin die Abhängigkeit zur Poseidon Networking API nur kurz erwähnt. Können Sie das bitte noch einmal genauer erläutern, vor allem im Hinblick auf die Testorchestrierung?"}
{"ts": "128:05", "speaker": "E", "text": "Ja, klar. Die Hera QA Platform triggert für bestimmte Lasttests direkte Calls gegen die Poseidon Networking API. Das bedeutet, wir müssen in unseren Orchestrierungs-Jobs sicherstellen, dass die Poseidon Dev-Cluster verfügbar sind und die API-Schemas nicht breaking changes enthalten. Im Build-Phase-Setup haben wir diese Abhängigkeit im Runbook RB-QA-044 dokumentiert."}
{"ts": "128:15", "speaker": "I", "text": "Und was passiert, wenn während eines dieser Lasttests die API-Version plötzlich wechselt?"}
{"ts": "128:20", "speaker": "E", "text": "Dann greift unser Fallback: wir haben in der Jenkins-Pipeline einen Schema-Validator, der gegen die zuletzt freigegebene OpenAPI-Definition testet. Fällt der Vergleich durch, wird der Test-Job mit einem 'dependency failure' markiert, und wir öffnen automatisch ein Ticket in JIRA unter dem Label P-HER-NET. Das ist inzwischen Routine, weil wir die Lessons Learned aus Projekt Aegis IAM übernommen haben."}
{"ts": "128:35", "speaker": "I", "text": "Das klingt nach einem klaren Multi-Hop zwischen QA und Networking. Wie stellen Sie sicher, dass Sicherheitsaspekte nicht untergehen, wenn so viele Schnittstellen im Spiel sind?"}
{"ts": "128:42", "speaker": "E", "text": "Wir binden die Security-Policies aus RB-QA-051 direkt in die Testpläne ein. Zum Beispiel prüfen wir bei API-Integrationstests nicht nur Funktionalität, sondern auch, ob TLS-Zertifikate gültig sind und ob die Endpunkte HSTS-Header setzen. Diese Prüfungen laufen als separate Stage, und deren Status fließt in unseren QA-SLO-Bericht ein."}
{"ts": "128:58", "speaker": "I", "text": "Gab es Fälle, wo Sicherheitsprüfungen bewusst reduziert wurden, um einen Release nicht zu blockieren?"}
{"ts": "129:04", "speaker": "E", "text": "Ja, im Sprint 42 hatten wir eine enge Deadline für ein Demo-Release. Da haben wir – dokumentiert in RFC-1822 – entschieden, die erweiterten Pen-Tests zu verschieben. Das Risiko wurde als 'medium' eingestuft, weil es sich um eine interne Demo handelte. Wir haben das abgesichert, indem wir sofort danach in Sprint 43 die vollständigen Tests nachgezogen."}
{"ts": "129:20", "speaker": "I", "text": "Wie reagieren Sie, wenn ein sicherheitskritischer Test fehlschlägt, besonders in einem Build-Context?"}
{"ts": "129:25", "speaker": "E", "text": "Protokollgemäß stoppen wir den Build, setzen das Ticket auf 'Blocker' und informieren das Security-Team via unserem Slack-Bridge. Parallel wird in der Runbook-Sektion 'Incident QA-Sec-Stop' geprüft, welche Workarounds zulässig sind. In einem Fall mit Ticket HER-SEC-219 mussten wir die betroffene Komponente komplett zurückrollen."}
{"ts": "129:42", "speaker": "I", "text": "Sie erwähnten QA-relevante SLOs. Können Sie ein Beispiel nennen und wie Sie das messen?"}
{"ts": "129:47", "speaker": "E", "text": "Ein zentrales SLO ist die 'Test Execution Pass Rate' von mindestens 95 % für kritische Pfade pro Build. Wir messen das über unseren internen QA-Dashboard-Server, der die Pipeline-Resultate aggregiert. Wird der Wert unterschritten, triggert das automatisch eine Root-Cause-Analyse gemäß POL-QA-014."}
{"ts": "129:59", "speaker": "I", "text": "Gab es eine Situation, in der Sie aufgrund eines Trade-offs zwischen Testtiefe und Time-to-Market Kritik erhielten?"}
{"ts": "130:04", "speaker": "E", "text": "Ja, beim Milestone M3. Wir hatten nur 48 Stunden bis zum vertraglich fixierten Review-Termin. In RFC-1770 haben wir dokumentiert, dass wir auf die Ausführung aller Low-Risk-Tests verzichtet haben. Einige Stakeholder hielten das für riskant, aber die Risikoanalyse (Anhang B des RFC) zeigte, dass die betroffenen Module isoliert sind und keine kritischen Pfade berühren."}
{"ts": "130:20", "speaker": "I", "text": "Im Nachhinein betrachtet – würden Sie heute denselben Trade-off eingehen?"}
{"ts": "130:26", "speaker": "E", "text": "Mit den jetzt vorhandenen Automatisierungen wahrscheinlich nicht. Wir haben seither die Testdauer um 35 % reduziert, ohne die Tiefe zu opfern, indem wir parallelisierte Container-Runner eingeführt haben. Damals war es aber die einzige realistische Option, um die Time-to-Market-SLOs einzuhalten."}
{"ts": "130:00", "speaker": "I", "text": "Bevor wir zum Abschluss kommen, würde ich gern noch verstehen, wie Sie in der Build-Phase mit dem Platform-Team koordinieren, wenn sich Abhängigkeiten verschieben."}
{"ts": "130:20", "speaker": "E", "text": "Wir haben da einen wöchentlichen Sync mit dem Platform-Team, der in unserem internen Converge-Board als Event PT-SYNC-07 hinterlegt ist. Wenn z. B. ein Service-Endpoint in Poseidon Networking umbenannt wird, aktualisieren wir die Test-Orchestration-Skripte innerhalb von 24 Stunden nach Bekanntgabe."}
{"ts": "130:45", "speaker": "I", "text": "Und wie fließt das in Ihre Risikobewertung ein?"}
{"ts": "131:02", "speaker": "E", "text": "Änderungen an Abhängigkeits-Services bekommen automatisch einen Risikoscore nach POL-QA-014. Ein Endpoint-Change in einem Auth-Flow, der über Aegis IAM läuft, wird z. B. mit 'hoch' bewertet und bekommt Priorität 1 in der Testpipeline."}
{"ts": "131:25", "speaker": "I", "text": "Sie hatten vorhin RB-QA-051 erwähnt. Können Sie konkret erklären, wie Sie diesen Runbook-Abschnitt in Ihre Testpläne einweben?"}
{"ts": "131:44", "speaker": "E", "text": "Klar. RB-QA-051 Abschnitt 3.4 beschreibt z. B. das Verhalten bei Session-Fixation-Angriffen. Unsere automatisierten Tests nutzen die in RB-QA-051 dokumentierten Angriffsvektoren, und wir taggen diese Tests mit 'SEC-HIGH', sodass sie in jeder CI-Runde mitlaufen, selbst wenn wir andere Bereiche skippen."}
{"ts": "132:10", "speaker": "I", "text": "Gab es in den letzten Sprints sicherheitskritische Funde, die Ihre SLOs beeinflusst haben?"}
{"ts": "132:32", "speaker": "E", "text": "Ja, in Sprint 18 hatten wir einen Fail im Testfall SEC-TC-449 zu Token Expiration. Das führte zu einem SLA-Risiko, weil laut SLA-QA-007 Sicherheitsfixes binnen 72 Stunden in Staging sein müssen. Wir haben das über Ticket HERA-SEC-212 getrackt und mit dem Security-Team innerhalb von 36 Stunden gefixt."}
{"ts": "132:58", "speaker": "I", "text": "Wie lief da die Kommunikation?"}
{"ts": "133:15", "speaker": "E", "text": "Wir nutzen das Incident-Channel-Protokoll ICP-QA-02. Das heißt, ich poste den Fail mit Log-Auszug und Link zur betroffenen Anforderung in den #sec-incidents-Channel, tagge den Security-Leiter, und wir stimmen uns dann im War Room Call ab."}
{"ts": "133:40", "speaker": "I", "text": "War Room klingt intensiv. Gibt es da eine Art Lessons Learned-Template?"}
{"ts": "133:56", "speaker": "E", "text": "Ja, nach jedem War Room erstellen wir ein LL-Dokument nach Template LL-QA-05. Darin dokumentieren wir Root Cause, betroffene SLOs, und mögliche Automation-Gaps. Bei SEC-TC-449 haben wir z. B. festgehalten, dass unser Token-Renewal-Simulator zu selten läuft."}
{"ts": "134:22", "speaker": "I", "text": "Und haben Sie daraufhin die Testtiefe verändert?"}
{"ts": "134:38", "speaker": "E", "text": "Genau. Wir haben den Simulator in den Nightly-Build integriert, obwohl das die Build-Dauer um ca. 12 Minuten verlängert. Das war ein bewusster Trade-off: Mehr Sicherheit vs. längere Feedback-Zeit."}
{"ts": "135:02", "speaker": "I", "text": "Wie haben Sie diesen Trade-off abgesichert?"}
{"ts": "135:20", "speaker": "E", "text": "Wir haben RFC-1770 als Entscheidungsgrundlage genutzt. Darin ist dokumentiert, dass bei sicherheitsrelevanten Flows die Testtiefe Vorrang vor Time-to-Market hat, solange die Verzögerung unter 15 Minuten bleibt. Das wurde vom Steering Committee am 14. März abgenickt."}
{"ts": "148:00", "speaker": "I", "text": "Lassen Sie uns noch einmal konkret auf die SLO-Metriken eingehen: Welche Kennzahlen überwachen Sie aktuell für die QA innerhalb der Hera-Platform?"}
{"ts": "148:05", "speaker": "E", "text": "Wir tracken vor allem die Build-zu-Deploy-Zeit, die Fehlerrate in der Integrationsstufe und die Mean Time to Detect für kritische Defekte. Zusätzlich haben wir ein internes SLA von maximal 4 Stunden für die Analyse sicherheitsrelevanter Fehlermeldungen."}
{"ts": "148:12", "speaker": "I", "text": "Und wie werden diese Metriken erhoben – automatisiert oder manuell?"}
{"ts": "148:17", "speaker": "E", "text": "Das ist größtenteils automatisiert. Wir nutzen das interne Monitoring-Framework 'NovaPulse', das Hooks in die Testorchestrierung integriert. Nur bei sicherheitskritischen Fällen, die etwa aus RB-QA-051-Checks resultieren, gibt es eine manuelle Validierungsschicht."}
{"ts": "148:25", "speaker": "I", "text": "Sie erwähnten RB-QA-051. Können Sie beschreiben, wie das Runbook konkret in die täglichen QA-Abläufe eingebettet ist?"}
{"ts": "148:31", "speaker": "E", "text": "Ja, wir haben in unserem Testplan für jede User-Story einen Abschnitt 'SecRun', der auf RB-QA-051 verweist. Das Laufzeitverhalten der Testfälle wird gegen bekannte Angriffsmuster aus dem Runbook gespiegelt, und bei Abweichungen wird automatisch ein Ticket in JIRA-QA-Sec geöffnet."}
{"ts": "148:40", "speaker": "I", "text": "Gab es schon Fälle, in denen diese automatische Erkennung Fehlalarme geliefert hat?"}
{"ts": "148:45", "speaker": "E", "text": "Ja, zwei Mal in den letzten vier Wochen. Beide Male betraf es den Aegis IAM Connector. Wir haben daraufhin eine Korrektur in den Heuristiken vorgenommen, die im HeuristicProfile v2.3 dokumentiert ist."}
{"ts": "148:54", "speaker": "I", "text": "Stichwort Aegis IAM – wie koordinieren Sie bei solchen Funden mit dem Platform-Team?"}
{"ts": "149:00", "speaker": "E", "text": "Wir haben ein wöchentliches Cross-Team-Meeting, und bei kritischen Findings geht sofort ein Alert an den Platform-OnCall-Kanal. Zusätzlich referenzieren wir in den Tickets die entsprechenden API-Schnittstellen, um die Nachvollziehbarkeit zu sichern."}
{"ts": "149:09", "speaker": "I", "text": "Gab es dabei schon Kommunikationsprobleme, zum Beispiel durch unterschiedliche Terminologien?"}
{"ts": "149:14", "speaker": "E", "text": "Absolut. Die Security spricht oft in CVE-IDs, während wir in QA eher mit internen Defect-IDs arbeiten. Wir haben daraufhin ein Mapping-Dokument erstellt, das in Confluence liegt, um diese Lücke zu schließen."}
{"ts": "149:22", "speaker": "I", "text": "Kommen wir zum Thema Lessons Learned: Welche Erkenntnisse aus vorigen Projekten, etwa Poseidon Networking, konnten Sie hier anwenden?"}
{"ts": "149:28", "speaker": "E", "text": "Aus Poseidon haben wir gelernt, dass frühe Einbindung des SRE-Teams in die Testplanung die Stabilität deutlich verbessert. Deshalb haben wir hier schon in Sprint 1 gemeinsame Review-Sessions für Testfälle und deren Infrastrukturabhängigkeiten eingeführt."}
{"ts": "149:37", "speaker": "I", "text": "Und abschließend: Wie bewerten Sie das Restrisiko, wenn Sie aus Zeitgründen Testtiefe reduzieren?"}
{"ts": "149:42", "speaker": "E", "text": "Wir dokumentieren das im QA-Risikoregister unter Verweis auf RFC-1770 und das entsprechende JIRA-Ticket. Die Entscheidung wird gemeinsam mit Product Owner und Security Lead getroffen, wobei wir die Eintrittswahrscheinlichkeit und die Auswirkung nach POL-QA-014 klassifizieren."}
{"ts": "149:36", "speaker": "I", "text": "Kommen wir nochmal zu den Lessons Learned aus anderen Projekten – gab es einen spezifischen Vorfall in Aegis IAM, der Ihre Herangehensweise in Hera beeinflusst hat?"}
{"ts": "149:42", "speaker": "E", "text": "Ja, in Aegis IAM hatten wir einen Integrations-Bug, der durch fehlende Schnittstellen-Tests zwischen Auth- und Provisioning-Services nicht aufgefallen war. In Hera haben wir deshalb die Testorchestrierung so erweitert, dass Cross-Service-Tests in der Nightly Pipeline Pflicht sind."}
{"ts": "149:51", "speaker": "I", "text": "Und wie stellen Sie sicher, dass diese Cross-Service-Tests auch bei Änderungen in Poseidon Networking aktuell bleiben?"}
{"ts": "149:56", "speaker": "E", "text": "Wir haben einen Dependency-Monitor implementiert, der aus den Poseidon-Build-Logs Änderungen an API-Schemas erkennt. Ein Trigger im QA-Orchestrator stößt dann automatisch die relevanten Regression-Tests an, basierend auf den Mappings in Testplan-Dokument TP-HER-023."}
{"ts": "150:07", "speaker": "I", "text": "Wie messen Sie den Erfolg dieser automatischen Trigger?"}
{"ts": "150:11", "speaker": "E", "text": "Wir tracken zwei KPIs: die Mean Detection Time (MDT) für Schema-Inkompatibilitäten und den Anteil der durch Trigger gefundenen Fehler. Beide Werte sind im QA-SLO-Dashboard unter SLO-QA-02 hinterlegt."}
{"ts": "150:20", "speaker": "I", "text": "Gab es Fehlalarme?"}
{"ts": "150:23", "speaker": "E", "text": "Ja, anfangs 12 % False Positives, weil der Parser in Build-Logs auch Kommentarzeilen als Schema-Änderung interpretierte. Das haben wir mit einem Regex-Filter im Runbook RB-QA-061 korrigiert."}
{"ts": "150:33", "speaker": "I", "text": "Wenn ein sicherheitskritischer Test aus RB-QA-051 fehlschlägt, wie kommunizieren Sie das?"}
{"ts": "150:37", "speaker": "E", "text": "Wir öffnen sofort ein SEC-Ticket im Tracker, versehen mit der Kennung des fehlgeschlagenen Testfalls und verlinken die zugehörige Anforderung. Parallel geht eine Slack-Alert-Message ins SecOps-Channel – das ist in Abschnitt 4.2 des Runbooks dokumentiert."}
{"ts": "150:48", "speaker": "I", "text": "Und wie priorisieren Sie die Behebung, wenn mehrere Tickets offen sind?"}
{"ts": "150:52", "speaker": "E", "text": "Nach den Kriterien aus POL-QA-014: Risikoauswirkung, Eintrittswahrscheinlichkeit, und SLA-Verpflichtung. Ein RB-QA-051-Fehler mit Auswirkung auf Kundendaten hat automatisch Priorität 1 mit 24h-Fix-SLA."}
{"ts": "151:02", "speaker": "I", "text": "In Bezug auf Trade-offs – gab es jüngst eine Situation in Hera, wo Sie Tests verschoben haben?"}
{"ts": "151:07", "speaker": "E", "text": "Ja, im Sprint 14. Wir haben die vollständige Performance-Test-Suite um zwei Tage nach Release verschoben, um ein kritisches Feature für das Stakeholder-Meeting einzuhalten. Das Risiko wurde im Ticket QA-RISK-118 dokumentiert und durch Monitoring-Maßnahmen nach Go-Live mitigiert."}
{"ts": "151:18", "speaker": "I", "text": "Gab es Einwände vom SRE-Team?"}
{"ts": "151:22", "speaker": "E", "text": "Ja, sie haben auf mögliche SLO-Verletzungen hingewiesen. Wir haben deshalb im RFC-1785 einen Fallback-Plan mit Traffic-Shaping und Canary-Releases beschrieben, um Latenzspitzen zu erkennen und zu begrenzen."}
{"ts": "151:06", "speaker": "I", "text": "Lassen Sie uns jetzt noch mal konkret in die Lessons Learned aus anderen Projekten einsteigen. Gab es etwas aus Poseidon Networking, das Sie direkt in Hera übernommen haben?"}
{"ts": "151:15", "speaker": "E", "text": "Ja, absolut. In Poseidon hatten wir ein sehr striktes Vorgehen bei der Testdatenisolation. Diese Methodik — inspiriert aus dem Runbook RB-QA-041 — haben wir in Hera direkt angewandt, um Konflikte in parallelen Testausführungen zu minimieren."}
{"ts": "151:26", "speaker": "I", "text": "Und wie wirkt sich das auf die Einhaltung der SLOs aus?"}
{"ts": "151:31", "speaker": "E", "text": "Es reduziert die Fehlerrate in Testpipelines um knapp 12 %, was wiederum die Mean Time to Detect für kritische Bugs senkt. Das ist direkt relevant für unser QA-SLO von MTTD ≤ 30 Minuten."}
{"ts": "151:44", "speaker": "I", "text": "Gab es eine Situation, in der Sie bei dieser Isolation Kompromisse eingehen mussten?"}
{"ts": "151:50", "speaker": "E", "text": "Ja, beim Sprint 18. Wir haben damals temporär auf vollständige Isolation verzichtet, um einen kritischen Regressionstest schneller durchzubekommen. Das war in Ticket QA-572 dokumentiert, mit explizitem Risiko-Flag."}
{"ts": "152:03", "speaker": "I", "text": "War das eine bewusste Entscheidung im Sinne von Time-to-Market vs. Testtiefe?"}
{"ts": "152:08", "speaker": "E", "text": "Genau. Wir haben das Risiko als mittel eingestuft, weil die betroffenen Module bereits durch Security in Aegis IAM gehärtet waren. Entsprechend war die Eintrittswahrscheinlichkeit gering."}
{"ts": "152:20", "speaker": "I", "text": "Wie war die Kommunikation mit dem Security-Team in so einem Fall?"}
{"ts": "152:25", "speaker": "E", "text": "Wir haben sofort einen kurzen Abstimmungscall einberufen. Nach RB-QA-051 Abschnitt 5.2 ist das Pflicht, wenn sicherheitsrelevante Tests ausgelassen oder modifiziert werden."}
{"ts": "152:37", "speaker": "I", "text": "Hat das SRE-Team hier ebenfalls eine Rolle gespielt?"}
{"ts": "152:42", "speaker": "E", "text": "Ja, sie haben die Produktions-Telemetrie im Blick behalten, um Anomalien sofort zu melden. Das war Teil der abgestuften Rollout-Strategie, die in RFC-1822 beschrieben ist."}
{"ts": "152:54", "speaker": "I", "text": "Wenn wir auf die Build-Phase schauen, ist das ja ein Balanceakt zwischen Geschwindigkeit und Qualität. Wie dokumentieren Sie diese Trade-offs?"}
{"ts": "153:01", "speaker": "E", "text": "Wir führen ein Decision Log, in dem jeder Verzicht oder jede Verkürzung von Tests mit Ticket-ID, Begründung, Risikoanalyse und Genehmigung festgehalten wird. Das wird wöchentlich im QA-Review geprüft."}
{"ts": "153:13", "speaker": "I", "text": "Gab es schon mal eine Rücknahme einer solchen Entscheidung aufgrund neuer Erkenntnisse?"}
{"ts": "153:18", "speaker": "E", "text": "Ja, bei QA-601. Neue Logdaten aus der SRE-Überwachung zeigten doch eine Anfälligkeit, sodass wir den ausgelassenen Lasttest nachträglich ausgeführt haben. Das hat uns einen potenziellen Produktionsausfall erspart."}
{"ts": "153:06", "speaker": "I", "text": "Sie hatten vorhin erwähnt, dass die Integration mit Poseidon Networking nicht trivial war. Können Sie das bitte noch einmal im Detail ausführen?"}
{"ts": "153:11", "speaker": "E", "text": "Ja, klar. Wir mussten in der Hera QA Platform einige Mock-Schnittstellen zu Poseidon aufbauen, um Latenz- und Paketverlust-Szenarien nachzustellen. Das betraf vor allem die Orchestrierungskomponente, die in unseren Build-Pipelines als Service Container läuft."}
{"ts": "153:17", "speaker": "I", "text": "Und wie haben Sie sichergestellt, dass diese Mocks wirklich realistische Bedingungen abbilden?"}
{"ts": "153:22", "speaker": "E", "text": "Wir haben dazu die Runbooks RB-NET-019 und RB-QA-051 kombiniert. RB-NET-019 gibt uns historische Latenzdaten aus Poseidon, und RB-QA-051 beschreibt die sicherheitsrelevanten Testbedingungen. So konnten wir sowohl Performance- als auch Security-Aspekte in einen Testflow einflechten."}
{"ts": "153:30", "speaker": "I", "text": "Gab es da Abhängigkeiten zu Aegis IAM?"}
{"ts": "153:35", "speaker": "E", "text": "Ja, indirekt. Die Authentifizierung unserer Test-Agents gegenüber Poseidon lief über Aegis IAM. Das heißt, wenn wir Security-Policies in RB-QA-051 prüfen, müssen wir auch die IAM-Token-Lebenszeit aus den Aegis-Logs berücksichtigen. Das war ein typischer Multi-Hop-Check, weil Performance-Probleme auch durch ablaufende Tokens entstehen konnten."}
{"ts": "153:44", "speaker": "I", "text": "Interessant. Und wie haben Sie diese Multi-Hop-Abhängigkeiten im Testreport ausgewiesen?"}
{"ts": "153:49", "speaker": "E", "text": "Wir haben im Testreport ein eigenes Feld 'Cross-System Trace' eingeführt, das die Ticket-IDs aus beiden Bereichen listet, z. B. T-POS-443 für ein Poseidon-Update und T-IAM-221 für einen Token-Refresh-Bug. So kann man bei einem Fehlschlag sofort sehen, ob die Ursache netzwerk- oder auth-basiert ist."}
{"ts": "153:57", "speaker": "I", "text": "Kommen wir zu Entscheidungen unter Zeitdruck: Gab es in der Build-Phase Situationen, wo Sie bewusst weniger getestet haben?"}
{"ts": "154:02", "speaker": "E", "text": "Ja, beim Release 0.9.5 haben wir auf vollständige Regressionstests verzichtet, um die Deadline für den internen Pilot zu halten. Wir haben das Risiko mit Verweis auf RFC-1770 dokumentiert und nur die hochpriorisierten Szenarien nach POL-QA-014 ausgeführt."}
{"ts": "154:10", "speaker": "I", "text": "Wie wurde das Risiko eingeschätzt und akzeptiert?"}
{"ts": "154:15", "speaker": "E", "text": "Ich habe in Ticket QA-RISK-092 einen Impact-Score von 2/5 vermerkt, basierend auf der Eintrittswahrscheinlichkeit und den potenziellen Auswirkungen laut SLA-Dokument QA-SLA-003. Die Freigabe kam nach Abstimmung mit dem Product Owner und dem SRE Lead."}
{"ts": "154:23", "speaker": "I", "text": "Gab es im Nachhinein Probleme, die auf diese Entscheidung zurückzuführen sind?"}
{"ts": "154:28", "speaker": "E", "text": "Wir hatten einen Minor Bug in der UI-Validierung, Ticket QA-BUG-511, der in einem vollständigen Regressionstest aufgefallen wäre. Der Fix war innerhalb von zwei Tagen implementiert, und da es keinen SLO-Verstoß gab, blieb der Impact gering."}
{"ts": "154:36", "speaker": "I", "text": "Würden Sie rückblickend dieselbe Entscheidung treffen?"}
{"ts": "154:41", "speaker": "E", "text": "Ja, unter denselben Bedingungen schon. Wir hatten klare Belege, ein dokumentiertes Risiko und einen Plan für schnelles Bugfixing. Entscheidend war, dass wir die Transparenz gegenüber allen Stakeholdern gewahrt haben."}
{"ts": "154:26", "speaker": "I", "text": "Sie hatten vorhin erwähnt, dass Sie bei sicherheitskritischen Testfehlern sofort reagieren. Können Sie ein aktuelles Beispiel aus der Build-Phase der Hera QA Platform nennen, wo das passiert ist?"}
{"ts": "154:31", "speaker": "E", "text": "Ja, letzte Woche im Nightly Run hat ein Test aus dem Paket SEC-Auth-04 gegen das Aegis IAM Subsystem versagt. Der Test prüft die Durchsetzung von MFA bei API-Zugriffen. Laut Runbook RB-QA-051 mussten wir innerhalb von vier Stunden reagieren, also haben wir einen Hotfix-Branch erstellt und den Test in einer isolierten Staging-Umgebung erneut ausgeführt."}
{"ts": "154:42", "speaker": "I", "text": "Und wie haben Sie sichergestellt, dass dieser Hotfix nicht zu Regressionen in anderen Modulen führt?"}
{"ts": "154:47", "speaker": "E", "text": "Wir haben sofort die automatisierte Regression Suite für alle Module mit IAM-Integration durchlaufen lassen, insbesondere jene, die in der Abhängigkeitsmatrix aus Ticket QA-DEP-332 aufgeführt sind. Das umfasste auch das Poseidon Networking Modul, da dessen API-Gateway ebenfalls IAM-Tokens validiert."}
{"ts": "154:58", "speaker": "I", "text": "Gab es da Koordinationsbedarf mit dem Platform Team?"}
{"ts": "155:02", "speaker": "E", "text": "Ja, wir haben via internen Slack-Channel #plat-sec sofort einen Deployment Freeze für die betroffenen Services beantragt, um die SLO für Authentifizierungs-Latenz nicht zu verletzen. Das Platform Team hat uns dann temporäre Canary Slots zur Verfügung gestellt."}
{"ts": "155:12", "speaker": "I", "text": "Hatten Sie für diesen Fall vorher schon eine RFC dokumentiert?"}
{"ts": "155:16", "speaker": "E", "text": "Tatsächlich, RFC-1822 behandelt genau den Ablauf bei sicherheitskritischen Testfails im Build. Darin steht u.a., dass QA Lead und Security Lead binnen 30 Minuten ein Incident-Huddle starten müssen. Das haben wir umgesetzt, inklusive der Checkliste aus RB-QA-051."}
{"ts": "155:27", "speaker": "I", "text": "Gab es im Incident-Huddle Diskussionen über Anpassungen der Testorchestrierung?"}
{"ts": "155:31", "speaker": "E", "text": "Ja, wir haben entschieden, den MFA-Test künftig in zwei Varianten zu fahren: einmal mit synthetischen Benutzern aus der QA-Domain und einmal mit realistischen Testidentitäten aus dem Aegis Sandbox Tenant. Das wird in POL-QA-014 als 'Dual Context Execution' empfohlen, um False Positives zu minimieren."}
{"ts": "155:43", "speaker": "I", "text": "Klingt nach zusätzlichem Aufwand. Wie haben Sie das mit den Deadlines vereinbart?"}
{"ts": "155:48", "speaker": "E", "text": "Wir haben im Sprint Planning einen Trade-off gemacht: Zwei Low-Risk UI-Tests aus dem Hera Dashboard Paket wurden temporär depriorisiert. Das wurde in Jira im Sprint-Scope-Dokument vermerkt und mit Ticket QA-SCOPE-557 belegt."}
{"ts": "155:59", "speaker": "I", "text": "Wurde dieser Trade-off vom Product Owner sofort akzeptiert?"}
{"ts": "156:03", "speaker": "E", "text": "Nicht sofort, wir mussten anhand von Metriken aus dem letzten Incident-Report zeigen, dass ein MFA-Bypass-Risiko eine deutlich höhere Auswirkung auf unsere SLA hätte als zwei verspätete UI-Features. Die Berechnung stützte sich auf die Risikopriorisierungsmatrix in POL-QA-014."}
{"ts": "156:15", "speaker": "I", "text": "Letzte Frage dazu: Haben Sie Lessons Learned dokumentiert?"}
{"ts": "156:19", "speaker": "E", "text": "Ja, im Confluence-Bereich 'Hera QA Incidents' gibt es jetzt eine Seite LL-SEC-MFA-2024, wo wir den Ablauf, die getroffenen Kommunikationsschritte mit SRE, Platform und Security sowie die Anpassungen an der Testorchestrierung dokumentiert haben. Das dient künftigen Builds als Referenz."}
{"ts": "156:02", "speaker": "I", "text": "Sie haben die Integration der Security-Runbooks schon umrissen. Mich würde noch interessieren: Wie verknüpfen Sie diese mit den automatisierten Regressionstests im Hera-Build?"}
{"ts": "156:10", "speaker": "E", "text": "Wir referenzieren in den Test-Suites direkte Calls zu den Checks aus RB-QA-051, sodass bei jedem Build-Snapshot automatisch die Security-Gates laufen. Die Testautomation ruft die entsprechenden YAML-Definitionen ab, die im selben Repo wie die Hera QA Platform liegen."}
{"ts": "156:23", "speaker": "I", "text": "Und wie reagieren Sie, wenn diese Gates rot werden, aber der Release-Train schon vorbereitet ist?"}
{"ts": "156:30", "speaker": "E", "text": "Da gibt es ein Eskalationsschema: zunächst ein Blocker-Ticket im JIRA-Board mit Security-Label. Parallel informiere ich den Security-Lead und den Build-Manager – wir haben dafür in RUN-QA-SEC-04 einen Ablaufplan, der festlegt, dass keine Deployments ohne Freigabe erfolgen."}
{"ts": "156:44", "speaker": "I", "text": "Sie hatten mal gesagt, dass Hera auch Abhängigkeiten zu Aegis IAM hat. Können Sie die technische Verbindung etwas genauer schildern?"}
{"ts": "156:53", "speaker": "E", "text": "Ja, das ist unser Multi-Hop-Link: Die Authentifizierung in den Testumgebungen läuft über Aegis IAM. Das bedeutet, dass wir für jede Test-Session Token generieren, die wiederum von Poseidon Networking validiert werden. Fällt eins der Systeme aus, kann unsere gesamte Testorchestrierung ins Leere laufen."}
{"ts": "157:09", "speaker": "I", "text": "Das heißt, Ihr QA-Team muss auch deren Verfügbarkeit monitoren?"}
{"ts": "157:15", "speaker": "E", "text": "Genau, wir haben SLO-Checks eingebaut, die per API-Healthchecks sowohl Aegis als auch Poseidon prüfen. Wenn die Latenz > 200 ms oder der Error-Rate > 1% ist, flaggen wir den Testlauf als potenziell verfälscht."}
{"ts": "157:28", "speaker": "I", "text": "Gab es schon mal den Fall, dass Sie wegen so einer Abhängigkeit ein Release verschieben mussten?"}
{"ts": "157:34", "speaker": "E", "text": "Ja, im Ticket QA-INC-882 vom März. Poseidon hatte ein Routing-Update eingespielt, das die Auth-Flows verzögert hat. Wir haben daraufhin ein Freeze-Fenster von 48 h eingelegt, um die Regressionsergebnisse nicht zu verfälschen."}
{"ts": "157:49", "speaker": "I", "text": "Wie bewerten Sie solche Verzögerungen im Hinblick auf die Projektziele?"}
{"ts": "157:55", "speaker": "E", "text": "Das ist immer ein Trade-off: Wir riskieren Time-to-Market, aber gemäß RFC-1770 Abschnitt 5.2 ist Datenintegrität in QA-Läufen höher zu gewichten als Geschwindigkeit. Wir dokumentieren das und schließen die Entscheidung im Go/No-Go-Log ab."}
{"ts": "158:09", "speaker": "I", "text": "Haben Sie in solchen Situationen auch Ausnahmen zugelassen?"}
{"ts": "158:15", "speaker": "E", "text": "Einmal, ja: Bei Release 0.9.7 haben wir die kritischen Tests priorisiert und nicht-kritische Szenarien temporär ausgesetzt, um die Deadline zu halten. Das Risiko wurde in QA-RISK-REP-014 bewertet und von der Projektleitung akzeptiert."}
{"ts": "158:29", "speaker": "I", "text": "Wenn Sie heute zurückblicken: Würden Sie diesen Trade-off wieder so entscheiden?"}
{"ts": "158:36", "speaker": "E", "text": "Ja, weil wir durch gezieltes Monitoring und Hotfix-Pläne sichergestellt haben, dass eventuelle Lücken schnell geschlossen werden konnten. Alle relevanten Stakeholder waren informiert, und kein Endkunde hat einen Defekt bemerkt."}
{"ts": "157:38", "speaker": "I", "text": "Sie hatten vorhin die Verbindung zwischen den Testartefakten und den Runbooks erwähnt. Mich interessiert jetzt: Wie stellen Sie sicher, dass bei einer API-Änderung im Hera-Backend die Testorchestrierung automatisch die relevanten Sicherheits-Checks aus RB-QA-051 zieht?"}
{"ts": "157:44", "speaker": "E", "text": "Wir nutzen dafür die interne Hook-Mechanik im Orchestrator-Modul. Jede Änderung im API-Schema triggert ein Pre-Merge-Event, das unsere Security-Test-Suite referenziert. Diese Suite ist direkt mit den Kapiteln 3 und 4 aus RB-QA-051 verknüpft. Das Mapping wird in der CI-Konfig gepflegt, so dass keine manuellen Lücken entstehen."}
{"ts": "157:55", "speaker": "I", "text": "Und wie gehen Sie damit um, wenn gleichzeitig ein anderes Projekt wie Aegis IAM ein Update bringt, das ebenfalls Schnittstellen berührt?"}
{"ts": "158:01", "speaker": "E", "text": "Da greifen wir auf das Cross-Project Dependency Board zu. Für Aegis IAM haben wir eine Abhängigkeitstabelle, die Endpunkte markiert, die Hera nutzt. Änderungen dort lösen bei uns automatisch eine zusätzliche Laufzeit der betroffenen Integrationstests aus. Diese Abhängigkeit wurde in Ticket QA-HER-432 dokumentiert und mit dem Aegis-Team abgestimmt."}
{"ts": "158:15", "speaker": "I", "text": "Gibt es dabei typische Latenzprobleme, wenn zwei Pipelines parallel laufen?"}
{"ts": "158:20", "speaker": "E", "text": "Ja, das passiert. Wir haben dafür einen Semaphore-Mechanismus implementiert, der den Testlauf von Hera pausiert, bis die Aegis-Pipeline die relevanten Artefakte bereitstellt. Das ist zwar ein kleiner Zeitverlust, verhindert aber inkonsistente Testergebnisse."}
{"ts": "158:32", "speaker": "I", "text": "Könnten Sie kurz erklären, wie das mit den SLOs zusammenhängt?"}
{"ts": "158:36", "speaker": "E", "text": "Sicher. Unser QA-SLO definiert, dass kritische Regressionen innerhalb von maximal 4 Stunden nach Commit erkannt werden müssen. Wenn wir Abhängigkeiten wie zu Aegis haben, fließt das in unsere SLO-Berechnung ein – wir loggen die Wartezeit explizit, um sie von der eigentlichen Testlaufzeit zu trennen."}
{"ts": "158:49", "speaker": "I", "text": "Das klingt nach einer recht ausgefeilten Metrik. Gab es dazu formale Abstimmungen?"}
{"ts": "158:53", "speaker": "E", "text": "Ja, wir haben das in RFC-1821 festgehalten, der die Anpassung der SLO-Messung bei Cross-Team-Abhängigkeiten beschreibt. Dieser RFC wurde von QA, SRE und Platform gemeinsam verabschiedet."}
{"ts": "159:03", "speaker": "I", "text": "Kommen wir zu den Trade-offs: Gab es einen Moment in der Build-Phase, wo Sie bewusst auf bestimmte Performance-Tests verzichtet haben?"}
{"ts": "159:08", "speaker": "E", "text": "Ja, im Sprint 14. Wir hatten eine harte Deadline für die Beta-Demo. Die Lasttests für den neuen Report-Generator wurden auf Post-Beta verschoben. Das Risiko wurde in Ticket QA-HER-517 dokumentiert, inklusive einer Notfall-Maßnahme: Falls in der Beta Performance-Probleme auftreten, ziehen wir sofort das Lasttest-Profil aus RUN-PERF-009 nach."}
{"ts": "159:22", "speaker": "I", "text": "Gab es dafür Rückendeckung vom Management?"}
{"ts": "159:25", "speaker": "E", "text": "Ja, wir haben das Risiko im Steering Committee vorgestellt, mit Verweis auf die niedrige Nutzerzahl in der Beta. Das Commitee hat zugestimmt, weil der Zeitgewinn für das Marketing-Event kritischer war."}
{"ts": "159:35", "speaker": "I", "text": "Und rückblickend – würden Sie es wieder so entscheiden?"}
{"ts": "159:39", "speaker": "E", "text": "Mit den damaligen Daten ja. Wir hatten keine negativen Performance-Funde in der Beta, und konnten die verschobenen Tests im nächsten Sprint nachholen. Aber ich habe gelernt, die Entscheidung noch stärker mit quantitativen Risikomodellen zu untermauern, nicht nur mit Erfahrungswerten."}
{"ts": "159:38", "speaker": "I", "text": "Wir waren vorhin bei den Lessons Learned aus anderen Projekten stehen geblieben. Können Sie bitte etwas konkreter schildern, wie Sie aus dem Aegis IAM Projekt Erkenntnisse für Hera ableiten konnten?"}
{"ts": "159:42", "speaker": "E", "text": "Ja, im Aegis IAM gab es ähnliche Schnittstellenprobleme zwischen Authentifizierung und Testumgebung. Wir haben damals einen Pre-Integration-Check entwickelt, dokumentiert in Ticket QA-4421, der auch bei Hera vor jedem Nightly-Build läuft, um fehlerhafte Token-Generierung früh zu erkennen."}
{"ts": "159:48", "speaker": "I", "text": "Und wie wirkt sich dieser Pre-Integration-Check auf Ihre SLOs aus?"}
{"ts": "159:53", "speaker": "E", "text": "Er reduziert die Build-Ausfälle um etwa 18 %, was direkt die Verfügbarkeit der QA-Umgebung verbessert. Unser SLO für Test-Environment-Uptime liegt bei 99,3 %, und dieser Check hilft, unter POL-QA-014 Abschnitt 3.2, diesen Wert konsistent zu halten."}
{"ts": "159:59", "speaker": "I", "text": "Klingt gut. Gab es auch technische Abhängigkeiten zu Poseidon Networking, die in der Teststrategie berücksichtigt werden mussten?"}
{"ts": "160:04", "speaker": "E", "text": "Absolut. Poseidon liefert die Service-Mesh-Konfiguration. Wir mussten in unseren Testplänen einen Netzwerkausfall-Simulator einbinden, dokumentiert in Runbook RB-QA-062, um Timeouts und Fallbacks zu prüfen. Ohne diesen Schritt hätten wir eine Lücke in der Risikodeckung gehabt."}
{"ts": "160:10", "speaker": "I", "text": "Wie koordinieren Sie solche Simulationsläufe mit dem SRE-Team?"}
{"ts": "160:15", "speaker": "E", "text": "Wir haben wöchentliche Chaos-Testing-Slots im QA-Kalender. SRE erhält vorab eine Simulationsmatrix aus unserem Jira-Board, z. B. QA-SIM-057, und gibt grünes Licht. Das ist in der internen SRE-QA-Schnittstellenrichtlinie festgelegt."}
{"ts": "160:21", "speaker": "I", "text": "Wie reagieren Sie, wenn bei solchen Simulationen kritische Sicherheits-Tests scheitern?"}
{"ts": "160:26", "speaker": "E", "text": "Dann greift RB-QA-051 Abschnitt 5: Der Build wird sofort gestoppt, Security bekommt eine PagerDuty-Notification, und wir erstellen ein Incident-Ticket im Security-Track, z. B. SEC-INC-203. Erst nach 'Security Sign-Off' dürfen wir weiter."}
{"ts": "160:33", "speaker": "I", "text": "Hatten Sie in Hera schon so einen Fall?"}
{"ts": "160:37", "speaker": "E", "text": "Ja, vor drei Wochen. Ein TLS-Zertifikat war in der Staging-Umgebung abgelaufen. Das wurde durch unseren automatisierten Check erkannt, Build gestoppt, Ticket SEC-INC-198 eröffnet. Wir konnten innerhalb von 4 Stunden die Zertifikate erneuern."}
{"ts": "160:44", "speaker": "I", "text": "Wie haben Sie in diesem Fall den Trade-off zwischen Fixzeit und laufenden Tests bewertet?"}
{"ts": "160:50", "speaker": "E", "text": "Wir haben auf Basis von RFC-1770 entschieden, laufende Regressionstests zu pausieren, um Zertifikats-Fixes zu priorisieren. Risikoanalyse zeigte, dass die Unterbrechung von 6 Stunden weniger kritisch war als ein potenzieller Sicherheitseinbruch."}
{"ts": "160:57", "speaker": "I", "text": "Gab es dazu formale Dokumentation?"}
{"ts": "161:02", "speaker": "E", "text": "Ja, die Entscheidung ist im Change-Log CHG-2024-044 festgehalten, mit Verweis auf die Risiko-Matrix aus POL-QA-014 und dem Security-Runbook RB-QA-051. Diese Dokumentation ist Teil unseres Audit-Trails für Hera."}
{"ts": "161:08", "speaker": "I", "text": "In der letzten Antwort haben Sie kurz die Abhängigkeiten zu Poseidon Networking erwähnt. Können Sie das bitte noch einmal detailliert erläutern, insbesondere wie sich Netzwerklatenzen auf Ihre Testorchestrierung auswirken?"}
{"ts": "161:13", "speaker": "E", "text": "Ja, also bei Poseidon Networking handelt es sich um ein internes Projekt, das unser internes SDN steuert. Wenn dort Latenzen >120ms auftreten, schlägt der Integrationstest SUITE-NET-014 in der Hera QA Platform fehl. Wir haben deshalb im Orchestrator einen Pre-Flight-Check implementiert, der Metriken aus dem Poseidon Prometheus-Endpunkt abfragt, bevor wir überhaupt die Testläufe starten."}
{"ts": "161:24", "speaker": "I", "text": "Und wie verknüpfen Sie diese Pre-Flight-Checks mit den SLOs, die Sie vorhin angesprochen haben?"}
{"ts": "161:28", "speaker": "E", "text": "Wir haben für QA ein internes SLO definiert: 95% aller orchestrierten Testläufe sollen ohne externe Latenzfehler durchlaufen. Der Pre-Flight-Check ist direkt im QA-SLO-Dashboard angebunden. Wenn der Check fehlschlägt, wird der Lauf in der SLO-Messung gar nicht gezählt, um die Metrik nicht zu verfälschen."}
{"ts": "161:39", "speaker": "I", "text": "Interessant, aber heißt das nicht, Sie blenden potenziell relevante Fehler aus?"}
{"ts": "161:43", "speaker": "E", "text": "Das ist ein Trade-off, klar. Wir dokumentieren solche Ausblendungen im Ticket-System (z. B. QA-EXCL-221) und führen monatlich mit dem Platform-Team eine 'Root Cause Review' durch. Falls sich zeigt, dass die Latenz durch unsere eigenen Komponenten verursacht wird, werden diese Runs rückwirkend in die SLO-Berechnung einbezogen."}
{"ts": "161:55", "speaker": "I", "text": "Wie gehen Sie vor, wenn während einer kritischen Release-Phase so eine Latenz auftritt?"}
{"ts": "161:59", "speaker": "E", "text": "Dann greifen wir auf Runbook RB-QA-051 Abschnitt 4.3 zurück. Dort ist beschrieben, wie wir über einen Fallback-Testpfad die wichtigsten Smoke- und Security-Tests isoliert fahren, ohne auf externe Netzwerkabhängigkeiten zu warten. Das verkürzt die Zeit bis zur Freigabe um bis zu 40 Minuten."}
{"ts": "162:09", "speaker": "I", "text": "Gab es einen konkreten Vorfall, wo Sie das anwenden mussten?"}
{"ts": "162:13", "speaker": "E", "text": "Ja, im Build-Sprint 22 hatten wir Ticket INC-POSE-042. Poseidon hatte ein Firmware-Update ausgerollt, das einen Memory Leak verursachte. Die Latenz stieg auf 300 ms. Wir haben sofort auf den Fallback umgestellt und konnten die Hera QA Platform trotzdem für das Merge-Fenster qualifizieren."}
{"ts": "162:25", "speaker": "I", "text": "Wie haben Sie das Risiko gegenüber dem Management kommuniziert?"}
{"ts": "162:29", "speaker": "E", "text": "Wir haben einen Risk Acceptance Report erstellt, basierend auf RFC-1770, Abschnitt 2.1, der die reduzierte Testabdeckung dokumentiert. Zusätzlich haben wir im Steering Committee Meeting die potenziellen Auswirkungen auf die User Journeys vorgestellt und die Abnahme protokollieren lassen."}
{"ts": "162:40", "speaker": "I", "text": "Das klingt sehr prozessgetrieben. Wie stellen Sie sicher, dass diese Prozesse nicht zu viel Zeit kosten?"}
{"ts": "162:44", "speaker": "E", "text": "Wir haben im QA-Playbook definiert, dass alle Entscheidungen zu Test-Trade-offs in weniger als 45 Minuten getroffen werden müssen, inklusive Dokumentation. Dafür nutzen wir Templates aus Confluence und vorgefertigte Checklisten, die auf den Runbooks basieren."}
{"ts": "162:54", "speaker": "I", "text": "Letzte Frage zu diesem Themenblock: Sehen Sie in Zukunft Möglichkeiten, diese Fallback-Strategien zu automatisieren?"}
{"ts": "162:58", "speaker": "E", "text": "Definitiv. Wir planen in P-HER-OPS-Backlog Item QA-AUTO-113, die Entscheidungskriterien aus RB-QA-051 maschinenlesbar zu machen und in den Orchestrator zu integrieren. Damit könnte der Wechsel auf Fallback-Tests ohne menschliches Eingreifen erfolgen, sofern die SLAs dies zulassen."}
{"ts": "162:48", "speaker": "I", "text": "Sie hatten vorhin erwähnt, dass wir bei Hera QA auch cross-project Dependencies berücksichtigen mussten. Können Sie ein aktuelles Beispiel aus der Build-Phase geben, das besondere Aufmerksamkeit verlangte?"}
{"ts": "162:54", "speaker": "E", "text": "Ja, konkret ging es um die Schnittstelle zum Aegis IAM Modul. Wir hatten im letzten Sprint eine Änderung im Authentifizierungs-Flow, die in Ticket QA-482 dokumentiert wurde. Das erforderte sowohl Anpassungen in unseren Test-Suites als auch eine Abstimmung mit dem Security-Team, um sicherzustellen, dass die RB-QA-051 Schritte für Credential Handling eingehalten werden."}
{"ts": "163:07", "speaker": "I", "text": "Wie sind Sie da methodisch vorgegangen, um diese Abhängigkeit sauber abzudecken?"}
{"ts": "163:12", "speaker": "E", "text": "Wir haben zunächst im Traceability-Matrix-Tool eine neue Verknüpfung der IAM-Anforderungen zu spezifischen Testfällen angelegt. Dann haben wir gemäss POL-QA-014 eine Risikoanalyse gemacht: hoher Impact bei Auth-Failures, daher Priorität 1. Parallel hat das SRE-Team für die Test-Umgebungen einen temporären Token-Service deployt, um die End-to-End-Flows nachstellen zu können."}
{"ts": "163:26", "speaker": "I", "text": "Gab es dabei besondere Herausforderungen bei der Testorchestrierung?"}
{"ts": "163:31", "speaker": "E", "text": "Ja, die grösste war die Synchronisation der Testläufe über drei Pipelines hinweg. Die Hera QA Platform musste die Ergebnisse aus dem IAM-Testcluster und dem Haupt-Cluster aggregieren. Wir haben dafür das Orchestrierungsskript ORCH-02 angepasst, um die result.xml Files zeitlich zusammenzuführen und Flaky-Test-Analysen erst nach vollständigem Eingang aller Teilergebnisse zu starten."}
{"ts": "163:47", "speaker": "I", "text": "Und wie wurde die Sicherheit während dieser Anpassung gewährleistet?"}
{"ts": "163:51", "speaker": "E", "text": "Durch ein Security-Gate im CI, das auf RB-QA-051 basiert. Jeder Build, der die neue Orchestrierung nutzte, musste den Credential-Leak-Scan bestehen. Zusätzlich haben wir ein temporäres Audit-Log aktiviert, um Anomalien im Token-Handling direkt an das Security-Team zu melden."}
{"ts": "164:04", "speaker": "I", "text": "Gab es Kommunikationsprobleme zwischen QA und Security in diesem Prozess?"}
{"ts": "164:09", "speaker": "E", "text": "Nicht wirklich Probleme, eher Timing-Themen. Security arbeitet mit einem wöchentlichen Review-Zyklus, QA braucht oft innerhalb von Stunden Feedback. Wir haben daher einen ad-hoc Slack-Channel eingerichtet und in Runbook RB-QA-051 ergänzt, dass kritische Findings sofort in diesen Channel gepostet werden."}
{"ts": "164:22", "speaker": "I", "text": "Wenn jetzt bei so einem Cross-Dependency-Test ein sicherheitskritischer Test fehlschlägt, wie entscheiden Sie, ob der Build blockiert wird?"}
{"ts": "164:28", "speaker": "E", "text": "Wir folgen da der Severity-Matrix aus POL-QA-014 Anhang C. Severity 1 bei Auth-Bypass oder Datenleak blockiert den Build sofort. Alles darunter wird als Warning markiert, aber nicht ausgeliefert, bis es verifiziert ist. Das ist auch in RFC-1822 dokumentiert, die wir für Hera erstellt haben."}
{"ts": "164:41", "speaker": "I", "text": "Gab es in letzter Zeit einen Fall, wo Sie einen Trade-off eingehen mussten, um eine Deadline zu halten?"}
{"ts": "164:46", "speaker": "E", "text": "Ja, beim Release Sprint 12. Wir hatten einen Performance-Test mit langer Laufzeit, der Flaky-Warnungen ausgab. Um das geplante Go-Live nicht zu gefährden, haben wir entschieden, nur den kritischen 20%-Subset dieser Tests zu fahren. Das Risiko wurde im Ticket QA-499 dokumentiert, mit Verweis auf die Ergebnisse der letzten drei stabilen Läufe als Begründung."}
{"ts": "164:59", "speaker": "I", "text": "Und wie haben Sie dieses Risiko gegenüber dem Management transparent gemacht?"}
{"ts": "165:04", "speaker": "E", "text": "Wir haben im wöchentlichen QA-Report ein eigenes Kapitel 'Deferred Tests' eingeführt, mit Risikoanalyse, Impact-Beschreibung und Rückfallplan. Das Management konnte so nachvollziehen, dass wir Time-to-Market priorisiert haben, aber mit klar dokumentierten Kontrollen und Post-Release-Tests, wie in RFC-1770 empfohlen."}
{"ts": "164:28", "speaker": "I", "text": "Sie hatten vorhin von der engeren Zusammenarbeit mit dem Platform-Team gesprochen. Können Sie das bitte noch konkretisieren, wie das bei Hera QA in der Build-Phase aussieht?"}
{"ts": "164:34", "speaker": "E", "text": "Ja, also wir haben wöchentliche Syncs mit dem Platform-Team, bei denen wir die aktuellen Testumgebungen gegen den Stand der Deployment-Pipelines abgleichen. Da geht es z. B. um die Versionsstände der Container-Images, die laut Runbook RB-PL-033 immer synchron zu unseren Testfällen sein müssen."}
{"ts": "164:46", "speaker": "I", "text": "Und wie stellen Sie sicher, dass diese Synchronität tatsächlich gegeben ist? Gibt es da automatisierte Checks?"}
{"ts": "164:52", "speaker": "E", "text": "Genau, wir haben ein kleines Python-Skript, das bei jedem Nightly-Build die Image-Hashes mit dem Stand im Testfall-Repository vergleicht. Wenn's Abweichungen gibt, geht automatisch ein Ticket ins Board, Typ QA-SYNC, das innerhalb von 24 h laut SLA-PL-04 gelöst werden muss."}
{"ts": "165:05", "speaker": "I", "text": "Gab es schon mal kritische Abweichungen, die den Testplan gefährdet haben?"}
{"ts": "165:09", "speaker": "E", "text": "Ja, im März hatten wir eine Situation, wo die Container-Version 2.4.7 im Staging lief, unsere Tests aber noch gegen 2.4.5 spezifiziert waren. Das hat dazu geführt, dass drei sicherheitsrelevante Tests aus RB-QA-051 unerwartet fehlschlugen."}
{"ts": "165:22", "speaker": "I", "text": "Wie haben Sie darauf reagiert? Wurde der Build gestoppt?"}
{"ts": "165:26", "speaker": "E", "text": "Wir haben zunächst den Build in der QA-Stage eingefroren, dann gemeinsam mit SRE die Logs analysiert. Gemäß Incident-Runbook IR-SEC-019 haben wir einen Hotfix-Testplan erstellt, um gezielt die Änderungen in 2.4.7 nachzutesten, bevor wir den Rest fortgesetzt haben."}
{"ts": "165:40", "speaker": "I", "text": "Das klingt nach einem definierten Prozess. Gab es Diskussionen über den Trade-off zwischen dem Zeitverlust und der Sicherheit?"}
{"ts": "165:46", "speaker": "E", "text": "Absolut. In der Retrospektive gab es Stimmen, die gesagt haben, wir hätten die nicht sicherheitskritischen Tests weiterlaufen lassen können, um Zeit zu sparen. Ich habe mich aber auf RFC-1770 berufen, Abschnitt 4.2, wo klar steht, dass bei unbekannten Versionen ein vollständiger Freeze erfolgen muss."}
{"ts": "165:59", "speaker": "I", "text": "Wurden daraus Anpassungen an den Prozessen abgeleitet?"}
{"ts": "166:03", "speaker": "E", "text": "Ja, wir haben eine Vorab-Benachrichtigungspflicht eingeführt. Das Platform-Team muss jetzt mindestens 48 h vor geplanter Versionserhöhung ein QA-Notify-Ticket erstellen. Das gibt uns die Möglichkeit, Testpläne proaktiv anzupassen."}
{"ts": "166:13", "speaker": "I", "text": "Wie messen Sie den Erfolg dieser Maßnahme?"}
{"ts": "166:16", "speaker": "E", "text": "Wir tracken die Metrik 'Ungeplante Testunterbrechungen pro Monat'. Vor der Änderung lagen wir bei im Schnitt 3,2 pro Monat, seit der Einführung sind wir auf 0,8 gesunken. Das erfüllt das interne SLO-QA-002."}
{"ts": "166:27", "speaker": "I", "text": "Letzte Frage zu diesem Punkt: Sehen Sie irgendwelche Risiken, dass diese Regelung in der heißen Projektphase umgangen wird?"}
{"ts": "166:32", "speaker": "E", "text": "Das Risiko besteht immer, besonders wenn der Release-Druck steigt. Deshalb haben wir in den QA-Review-Checklisten einen Pflichtpunkt eingefügt, der prüft, ob ein QA-Notify vorlag. Verstöße werden im Lessons-Learned-Dokument vermerkt und mit dem Steering Committee besprochen."}
{"ts": "165:28", "speaker": "I", "text": "Sie haben vorhin die Integration von RB-QA-051 beschrieben. Mich interessiert jetzt, wie Sie diese Runbooks konkret mit den SRE-Checklisten verknüpfen."}
{"ts": "165:33", "speaker": "E", "text": "Wir mappen die einzelnen Sicherheitsprüfpunkte aus RB-QA-051 direkt auf die SRE-Checkliste aus SR-OPS-023. Das bedeutet, dass jeder sicherheitsrelevante Testfall bei der Übergabe an das SRE-Team bereits ein Abhaken der entsprechenden Checklisten-Punkte triggert."}
{"ts": "165:38", "speaker": "I", "text": "Und wie stellen Sie sicher, dass das im Build-Phase-Druck nicht untergeht?"}
{"ts": "165:43", "speaker": "E", "text": "Wir haben dafür ein automatisiertes Gate im CI/CD-Workflow. Wenn ein sicherheitskritischer Punkt nicht erledigt ist, schlägt der Build fehl. Das ist in unseren internen Policies unter QA-POL-022 festgehalten."}
{"ts": "165:49", "speaker": "I", "text": "Gab es da schon Kollisionen mit den Release-Deadlines?"}
{"ts": "165:54", "speaker": "E", "text": "Ja, es gab im Ticket QA-2145 einen Fall, wo ein fehlgeschlagener AuthN-Test das Deployment um zwei Tage verzögert hat. Wir haben das bewusst in Kauf genommen, weil das Risiko eines Missbrauchs zu hoch war."}
{"ts": "165:59", "speaker": "I", "text": "Wie haben die anderen Teams darauf reagiert?"}
{"ts": "166:04", "speaker": "E", "text": "Das Platform-Team war zunächst unzufrieden, aber nachdem wir den Exploit-PoC aus dem Security-Test gezeigt haben, war klar, dass die Verzögerung gerechtfertigt war."}
{"ts": "166:10", "speaker": "I", "text": "Können Sie ein Beispiel nennen, wie Sie Lessons Learned aus dem Aegis IAM Projekt hier anwenden konnten?"}
{"ts": "166:15", "speaker": "E", "text": "Aus Aegis IAM haben wir die Praxis übernommen, kritische Pfade frühzeitig mit Chaos-Tests zu belasten. Das haben wir jetzt für die Login- und Token-Refresh-Mechanismen der Hera QA Platform ebenfalls eingeführt."}
{"ts": "166:21", "speaker": "I", "text": "Spannend. Haben Sie dafür ein spezifisches Runbook erstellt?"}
{"ts": "166:26", "speaker": "E", "text": "Ja, RB-QA-078 beschreibt genau diese Chaos-Tests, inklusive der Abbruchkriterien und Recovery-Strategien, die wir im Incident-Runbook IR-PLT-004 hinterlegt haben."}
{"ts": "166:32", "speaker": "I", "text": "Wenn Sie das alles zusammenfassen: Welche SLOs sind für Sie in der QA-Phase jetzt am kritischsten?"}
{"ts": "166:37", "speaker": "E", "text": "Für uns sind die SLOs zu Testausführungszeit (< 4h für den vollständigen Regressionstest) und Fehlerbehebungszeit bei Blockern (< 24h) entscheidend. Diese sind in SLA-QA-002 mit den Stakeholdern vereinbart."}
{"ts": "166:43", "speaker": "I", "text": "Gab es in letzter Zeit Abweichungen?"}
{"ts": "166:48", "speaker": "E", "text": "Einmal, im Kontext von Ticket QA-2299, haben wir die 4-Stunden-Marke überschritten, weil wir zusätzliche Security-Scans auf Anweisung des CISO-Teams einfügen mussten. Das haben wir im Post-Mortem dokumentiert und als Ausnahme deklariert."}
{"ts": "166:28", "speaker": "I", "text": "Bevor wir jetzt zum Abschluss kommen, möchte ich noch genauer verstehen, wie Sie konkret mit dem Platform-Team in der Build-Phase der Hera QA Platform zusammenarbeiten."}
{"ts": "166:36", "speaker": "E", "text": "Wir haben wöchentliche Sync-Meetings mit dem Platform-Team, in denen wir die Testumgebungen gegen die neuesten Container-Builds prüfen. Dabei achten wir darauf, dass die Orchestrierung der Tests in der Kubernetes-basierten Staging-Umgebung konsistent ist. Änderungen an den Helm-Charts werden über ein gemeinsames RFC-Board abgestimmt."}
{"ts": "166:49", "speaker": "I", "text": "Gab es in letzter Zeit einen Fall, wo diese Abstimmung besonders kritisch war?"}
{"ts": "166:54", "speaker": "E", "text": "Ja, letzte Woche hat das Platform-Team das Node-Pool-Scaling angepasst. Unser Testorchestrator lief dadurch auf älteren Kernel-Versionen in einem Pool, was zwei sicherheitskritische Tests fehlschlagen ließ. Wir mussten sofort das RB-QA-051 Runbook ziehen und die Regression isolieren, bevor wir die Builds wieder freigaben."}
{"ts": "167:08", "speaker": "I", "text": "Wie haben Sie das Risiko in diesem Fall bewertet?"}
{"ts": "167:13", "speaker": "E", "text": "Wir haben die Ticketnummer T-HER-2942 im Incident-Tracker eröffnet, die Auswirkungen anhand der Security-Klassifizierung aus POL-QA-014 auf Stufe 'high' gesetzt und den Rollout per Change Freeze eingefroren. Parallel haben wir mit den SREs das SLA-Dokument konsultiert, um sicherzustellen, dass keine produktionsnahen SLOs verletzt werden."}
{"ts": "167:27", "speaker": "I", "text": "Hat das Auswirkungen auf die geplante Lieferzeit gehabt?"}
{"ts": "167:32", "speaker": "E", "text": "Ja, wir haben bewusst einen Tag Delay in Kauf genommen. Das ist ein klassischer Trade-off: Time-to-Market vs. Security Compliance. In RFC-1770 hatten wir bereits festgehalten, dass wir bei sicherheitskritischen Findings keine Abstriche machen."}
