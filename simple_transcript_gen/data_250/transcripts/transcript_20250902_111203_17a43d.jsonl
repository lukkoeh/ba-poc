{"ts": "00:00", "speaker": "I", "text": "Können Sie mir bitte kurz den aktuellen Stand von Hera QA Platform beschreiben?"}
{"ts": "05:15", "speaker": "E", "text": "Ja, gern. Wir sind aktuell in der Build-Phase, etwa 70% der Kernmodule sind implementiert. Das Orchestrierungsmodul für die Testläufe läuft bereits in einer internen Staging-Umgebung. Hauptziel ist es, alle Testpipelines aus den verschiedenen Produktteams unter einem Dach zusammenzuführen und flaky tests automatisiert zu identifizieren und zu isolieren. Das ist ein Kernpunkt der Unternehmensstrategie für konsistente QA-Prozesse."}
{"ts": "10:42", "speaker": "I", "text": "Welche Hauptziele verfolgen Sie konkret in dieser Phase?"}
{"ts": "15:30", "speaker": "E", "text": "Zum einen die technische Basis für eine einheitliche Orchestration schaffen, also verbindliche Schnittstellen und Workflows definieren. Zum anderen wollen wir mit Modulen wie dem 'Flake Analyzer' die Wiederholungsrate instabiler Tests um mindestens 40% senken. Wir haben das in OKR-QA-2024Q2 festgeschrieben, mit klaren KPIs im SLA-Dokument QA-SLA-017."}
{"ts": "20:10", "speaker": "I", "text": "Wie setzen Sie dabei die Policy POL-QA-014 konkret um?"}
{"ts": "25:00", "speaker": "E", "text": "Die Policy schreibt vor, dass Tests riskobasiert priorisiert werden. In Hera QA Platform nutzen wir dafür ein Scoring-Modell, das Anwendungs-Impact, Änderungshäufigkeit und Defect-Historie kombiniert. Dieses Modell ist in unserem Runbook RB-QA-P-HER-03 dokumentiert. Ein Beispiel: Bei kritischen Payment-Komponenten wird die Testpriorität automatisch um zwei Stufen angehoben, selbst bei kleinen Codeänderungen."}
{"ts": "30:45", "speaker": "I", "text": "Und wie gehen Sie mit bekannten flaky tests um?"}
{"ts": "35:20", "speaker": "E", "text": "Die werden zunächst markiert und in einen Quarantäne-Workflow verschoben. Dort laufen sie isoliert mehrfach gegen verschiedene Umgebungen. Wenn sie weiterhin instabil sind, erstellen wir automatisch ein Ticket im System TCK-HER-FT, das direkt an das verantwortliche Team geht. So verhindern wir, dass flaky tests die Haupt-Pipeline blockieren."}
{"ts": "40:05", "speaker": "I", "text": "Welche Tools sorgen für die End-to-End-Traceability?"}
{"ts": "45:00", "speaker": "E", "text": "Wir setzen auf ein internes Tool namens LinkTrace, das Anforderungen aus unserem Requirement-Management mit Testfällen und Defect-IDs aus dem Bugtracker verknüpft. Änderungen an einer Anforderung erzeugen automatisch einen Impact-Report für die betroffenen Tests. Das ist besonders wichtig bei Subsystemen, die über mehrere Teams verteilt sind."}
{"ts": "50:15", "speaker": "I", "text": "Können Sie ein Beispiel geben, wie eine Änderung in einem Upstream-Service die Testplanung beeinflusst?"}
{"ts": "55:40", "speaker": "E", "text": "Klar, nehmen wir den Auth-Service aus Projekt Helios Datalake: Wenn dort ein neues Token-Format eingeführt wird, erkennt LinkTrace die Abhängigkeit zu unseren Login-Tests im Hera QA Platform. Das Orchestrierungsmodul plant dann automatisch Regressionstests für alle betroffenen User Journeys ein. Hier fließen auch Observability-Daten aus Nimbus ein, die uns zeigen, wie oft die betroffenen APIs in Produktion aufgerufen werden."}
{"ts": "60:25", "speaker": "I", "text": "Gab es große Trade-offs bei der Testarchitektur?"}
{"ts": "65:55", "speaker": "E", "text": "Ja, zum Beispiel haben wir uns gegen vollumfängliche Service-Virtualisierung entschieden, um die Time-to-Market nicht zu gefährden. Das steht so in RFC-HER-ARCH-022. Stattdessen simulieren wir nur kritische Schnittstellen und testen den Rest gegen echte Staging-Services. Das reduziert zwar die Abdeckung um ca. 8%, spart aber pro Release-Zyklus im Schnitt zwei Tage."}
{"ts": "72:40", "speaker": "I", "text": "Wie dokumentieren Sie solche Entscheidungen?"}
{"ts": "80:00", "speaker": "E", "text": "Alle Trade-offs und Risikoeinschätzungen landen in unserem Confluence-Archiv unter dem Hera-Runbook-Bereich. Dort referenzieren wir auch die zugehörigen Tickets und RFCs. Zusätzlich erstellen wir bei kritischen Punkten einen 'Risk Acceptance Report' wie RAR-HER-005, der von QA-Lead und Product Owner gegengezeichnet wird."}
{"ts": "90:00", "speaker": "I", "text": "Zum Abschluss würde ich gern noch ein wenig tiefer auf die Lessons Learned eingehen. Welche Erkenntnisse haben Sie speziell im Umgang mit den flaky tests gewonnen, die Sie in der Build-Phase gesammelt haben?"}
{"ts": "90:35", "speaker": "E", "text": "Also, eine wesentliche Erkenntnis ist, dass wir nicht nur die Testcases selbst betrachten dürfen, sondern das gesamte Orchestrierungsumfeld. Wir haben festgestellt, dass flaky tests oft aus Umgebungsvariabilität resultieren – z.B. schwankende Antwortzeiten in den Staging-APIs. Daraufhin haben wir im Runbook RB-HER-022 eine Checkliste für Stabilitätsprüfungen vor dem Teststart ergänzt."}
{"ts": "91:10", "speaker": "I", "text": "Haben diese Checklisten einen messbaren Effekt auf Ihre KPIs gehabt?"}
{"ts": "91:30", "speaker": "E", "text": "Ja, tatsächlich. Unsere Flaky-Quote, die wir als 'FTI' – Flaky Test Index – in der wöchentlichen QA-Metrik erfassen, ist um ca. 18 % gesunken. Das war innerhalb von zwei Sprints nach Einführung der Checkliste sichtbar. Wir haben das in Jira-Ticket QA-5472 dokumentiert und im Quarterly Quality Report festgehalten."}
{"ts": "92:05", "speaker": "I", "text": "Gab es daneben auch Lerneffekte im Bereich Traceability, die Sie in künftigen Phasen nutzen wollen?"}
{"ts": "92:25", "speaker": "E", "text": "Absolut. Wir haben gelernt, dass die Verknüpfung zwischen Anforderungen, Testfällen und Defects in unserem Traceability-Tool 'NoverLink' zu starr war. In der nächsten Phase wollen wir flexiblere Mapping-Regeln zulassen, sodass wir schneller reagieren können, wenn sich z. B. in einem Upstream-Service eine API ändert. Das wurde im RFC-HER-019 vorgeschlagen."}
{"ts": "93:00", "speaker": "I", "text": "Interessant. Haben Sie in diesem RFC auch Risiken oder mögliche negative Nebeneffekte beschrieben?"}
{"ts": "93:20", "speaker": "E", "text": "Ja, wir haben darin explizit das Risiko genannt, dass zu flexible Mappings zu Inkonsistenzen führen könnten, wenn z. B. Teams unterschiedliche Interpretationen einer Anforderung haben. Zur Risikominderung soll ein Validierungs-Job in der Orchestrierungspipeline eingeführt werden, der solche Diskrepanzen vor Merge erkennt."}
{"ts": "93:55", "speaker": "I", "text": "Und wie wollen Sie diesen Validierungs-Job technisch umsetzen?"}
{"ts": "94:15", "speaker": "E", "text": "Wir planen, ein Python-Skript zu nutzen, das die NoverLink-API abfragt und die requirement-to-test-Mappings gegen ein zentrales Schema validiert. Dieser Job wird als pre-merge Hook in unserem Git-basierte CI integriert, basierend auf dem Orchestrator-Modul HER-ORCH-07."}
{"ts": "94:50", "speaker": "I", "text": "Klingt durchdacht. Gab es weitere Metriken außer dem FTI, die Sie für Verbesserungen herangezogen haben?"}
{"ts": "95:05", "speaker": "E", "text": "Ja, wir verfolgen auch den MTTR – Mean Time to Resolution – für Testfailures. Durch engere Integration mit Nimbus Observability konnten wir den MTTR von 14 Stunden auf 9 Stunden senken, weil Logs und Metriken aus der Produktionsumgebung direkt im QA-Dashboard verfügbar sind."}
{"ts": "95:40", "speaker": "I", "text": "Wie haben die Teams auf diese Dashboard-Integration reagiert?"}
{"ts": "96:00", "speaker": "E", "text": "Sehr positiv, weil sie sofort sehen können, ob ein Fehler durch einen echten Code-Bug oder durch eine Infrastruktur-Anomalie verursacht wurde. Das hat uns geholfen, Prioritäten schneller zu setzen und unnötige Hotfixes zu vermeiden."}
{"ts": "96:25", "speaker": "I", "text": "Wenn Sie jetzt auf die Build-Phase zurückblicken – was würden Sie in der nächsten Projektphase anders machen?"}
{"ts": "96:45", "speaker": "E", "text": "Ich würde früher in cross-funktionale Workshops investieren, um Abhängigkeiten zu anderen Projekten wie Helios und Nimbus schon vor der Testplanung zu identifizieren. Außerdem wollen wir die Risk-Based Testing-Methodik aus POL-QA-014 stärker automatisieren, um subjektive Gewichtungen zu reduzieren."}
{"ts": "106:00", "speaker": "I", "text": "Wenn wir jetzt in Richtung Lessons Learned schauen – was würden Sie sagen, sind die drei wichtigsten Erkenntnisse aus der Build-Phase von Hera QA Platform?"}
{"ts": "106:20", "speaker": "E", "text": "Erstens: Die frühzeitige Einbindung der Testdaten-Generierung in die CI/CD-Pipeline hat die Stabilität massiv erhöht. Zweitens: Unser Risiko-Score-Modell aus POL-QA-014 musste dynamischer werden, weil sich Abhängigkeiten zwischen Modulen wie Hera-Core und Subsystem Triton-API schneller änderten als initial angenommen. Drittens: Die enge Verzahnung mit Observability-Metriken aus Nimbus hat uns geholfen, Performance-Regressionen früher zu erkennen."}
{"ts": "106:48", "speaker": "I", "text": "Gab es auch negative Überraschungen oder Punkte, die Sie so nicht erwartet hätten?"}
{"ts": "107:05", "speaker": "E", "text": "Ja, zum Beispiel die Anzahl an sogenannten 'silent failures' in den Flaky-Test-Analysen. Da mussten wir nachsteuern, indem wir einen zusätzlichen Alert-Mechanismus in Runbook RB-HER-017 definiert haben, der auf ungewöhnliche Muster bei Test-Dauer und CPU-Auslastung reagiert."}
{"ts": "107:27", "speaker": "I", "text": "Können Sie konkrete Metriken oder KPIs nennen, die Sie jetzt standardmäßig verfolgen?"}
{"ts": "107:42", "speaker": "E", "text": "Wir tracken u.a. den MTTR für Test-Failures, den Anteil automatisiert klassifizierter Defects (> 78 % im letzten Sprint), und die Coverage der Business-Critical User Journeys. Zusätzlich messen wir die ‚Flake Rate‘ pro Test-Suite und Subsystem-Impact-Score, der via Traceability-Matrix aus dem Tool QLink berechnet wird."}
{"ts": "108:09", "speaker": "I", "text": "Wie fließen diese KPIs in Ihre Entscheidungsprozesse für die nächste Phase ein?"}
{"ts": "108:25", "speaker": "E", "text": "Sie sind Teil des Quality-Gates in RFC-HER-044. Wenn z. B. die Flake Rate über 5 % steigt, ist laut SLA-QA-02 ein zusätzlicher Stabilisierungssprint verpflichtend. Das haben wir einmal im Build schon gemacht, um eine kritische Auslieferung nicht zu gefährden."}
{"ts": "108:48", "speaker": "I", "text": "Gibt es Prozesse, die Sie basierend auf den Erfahrungen verschärfen oder lockern wollen?"}
{"ts": "109:04", "speaker": "E", "text": "Wir wollen die Abnahme-Kriterien verschärfen, was die Traceability angeht. Das bedeutet, kein Test ohne verknüpfte Requirement-ID darf mehr in den Regression-Run. Gleichzeitig lockern wir temporär die Pflicht, jede Exploratory-Session zu dokumentieren, um die Geschwindigkeit in der nächsten Integrationswelle zu halten."}
{"ts": "109:31", "speaker": "I", "text": "Welche Rolle spielt dabei das Zusammenspiel mit den Teams anderer Projekte, etwa Helios Datalake?"}
{"ts": "109:47", "speaker": "E", "text": "Sehr wichtig – wir haben aus Ticket HLD-INT-209 gelernt, dass Schema-Änderungen im Datalake direkte Auswirkungen auf unsere Test-Datenpipelines haben. Deshalb gibt es jetzt ein Cross-Project Change Board, das Änderungen mit mehr als Impact-Level 2 vorab kommuniziert."}
{"ts": "110:12", "speaker": "I", "text": "Wie stellen Sie sicher, dass solche Lessons Learned auch langfristig erhalten bleiben?"}
{"ts": "110:27", "speaker": "E", "text": "Wir pflegen ein internes Confluence-Portal 'Hera QA Knowledge Base'. Dort gibt es eine Section 'Retrospectives', in der wir pro Sprint die wichtigsten Learnings, verlinkte Runbooks, relevante RFCs und betroffene Tickets dokumentieren. Das ist seit Retrospektive R-HER-008 Pflicht."}
{"ts": "110:49", "speaker": "I", "text": "Wenn Sie einen Wunsch frei hätten – was würden Sie in der kommenden Projektphase grundlegend ändern?"}
{"ts": "111:00", "speaker": "E", "text": "Ich würde die Testorchestrierung stärker event-getrieben machen und tiefer in die Build-Pipeline integrieren. Das würde es erlauben, auf Änderungen in Upstream-Services, die via Nimbus Observability Events gemeldet werden, nahezu in Echtzeit neue Tests zu planen. Damit könnten wir die Reaktionszeit auf kritische Änderungen von derzeit ~6 Stunden auf unter 1 Stunde senken."}
{"ts": "114:00", "speaker": "I", "text": "Kommen wir nun zu den Lessons Learned – welche Erkenntnisse haben Sie aus der bisherigen Build‑Phase von Hera QA Platform gezogen?"}
{"ts": "114:05", "speaker": "E", "text": "Eine zentrale Erkenntnis ist, dass unsere ursprüngliche Annahme zur Stabilität der Testumgebungen zu optimistisch war. Wir haben gelernt, dass wir im Runbook RB‑QA‑022 eine klare Routine für das tägliche Smoke‑Testing der Infrastruktur fest verankern mussten, um Environment Drifts frühzeitig zu erkennen."}
{"ts": "114:15", "speaker": "I", "text": "Wie hat sich das konkret auf den Projektverlauf ausgewirkt?"}
{"ts": "114:20", "speaker": "E", "text": "Dadurch konnten wir die Anzahl der Build‑Abbrüche wegen Infrastrukturfehlern um rund 35 % reduzieren. Vorher hatten wir im Ticketing‑System JIRA‑NSG pro Woche drei bis vier CRIT‑Tickets dieser Art, jetzt meist nur noch eins."}
{"ts": "114:30", "speaker": "I", "text": "Gibt es weitere Learnings, die Sie erwähnenswert finden?"}
{"ts": "114:34", "speaker": "E", "text": "Ja, wir haben gelernt, dass unsere Flaky‑Test‑Erkennung aus der Analytics‑Komponente sensibler abgestimmt werden musste. Initial hatten wir zu viele False Positives. In RFC‑HERA‑071 haben wir dann den Threshold von 0,75 auf 0,85 angepasst, was die Entwicklerakzeptanz gesteigert hat."}
{"ts": "114:45", "speaker": "I", "text": "Welche KPIs nutzen Sie, um diese Verbesserungen zu messen?"}
{"ts": "114:49", "speaker": "E", "text": "Wir tracken drei primäre KPIs: den Median der Testausführungszeit, die Flaky‑Test‑Rate und die Mean Time to Detect (MTTD) kritischer Defekte. Die Flaky‑Rate konnten wir von 12 % auf unter 5 % senken, MTTD von 14 auf 9 Stunden."}
{"ts": "115:00", "speaker": "I", "text": "Gab es auch qualitative Metriken, die Sie berücksichtigen?"}
{"ts": "115:04", "speaker": "E", "text": "Ja, wir führen Entwickler‑Surveys durch, um die wahrgenommene Testzuverlässigkeit zu messen. Auch haben wir interne Post‑Mortems nach POL‑INC‑005 standardisiert, die qualitative Ursachen wie 'Requirement Misalignment' erfassen."}
{"ts": "115:15", "speaker": "I", "text": "Wenn Sie auf die Build‑Phase zurückblicken: Was würden Sie in der nächsten Phase anders machen?"}
{"ts": "115:20", "speaker": "E", "text": "Ich würde frühzeitiger mit den Teams der Upstream‑Services gemeinsame Testdatenpools definieren. In der Build‑Phase haben wir zu oft ad‑hoc synthetische Daten erstellt, die in der Integrationsumgebung nicht alle Edge Cases abgedeckt haben."}
{"ts": "115:30", "speaker": "I", "text": "Würde das auch die Traceability verbessern?"}
{"ts": "115:34", "speaker": "E", "text": "Definitiv. Gemeinsame Datenpools lassen sich in unserem Traceability‑Tool TLink einfacher an Requirements binden. So sehen wir schneller, welche Anforderung mit welchen Testdaten und Testfällen verknüpft ist."}
{"ts": "115:45", "speaker": "I", "text": "Gibt es Risiken, die Sie jetzt klarer sehen als zu Projektbeginn?"}
{"ts": "115:50", "speaker": "E", "text": "Ja, das größte Risiko bleibt die Abhängigkeit von Helios Datalake Latenzen. Wenn deren SLA von 200 ms überschritten wird, geraten unsere orchestrierten Tests ins Wanken. Wir haben das in Runbook RB‑HERA‑LAT‑001 als kritischen Watchpoint dokumentiert und mit dem Operations‑Team abgestimmt."}
{"ts": "118:00", "speaker": "I", "text": "Welche Lessons Learned haben Sie bis jetzt aus der Build-Phase der Hera QA Platform gezogen?"}
{"ts": "118:07", "speaker": "E", "text": "Eine wichtige Erkenntnis ist, dass wir die Gewichtung zwischen automatisierten Regressionstests und explorativem Testen zu Beginn unterschätzt haben. In Runbook RB-HER-023 haben wir dokumentiert, dass 15 % mehr exploratory sessions die Erkennungsrate von Integrationsfehlern deutlich erhöht haben."}
{"ts": "118:18", "speaker": "I", "text": "Gab es auch Metriken oder KPIs, die Sie besonders beeinflusst haben?"}
{"ts": "118:24", "speaker": "E", "text": "Ja, wir tracken aktuell den 'Flaky Test Index' (FTI) und die Mean Time to Detect (MTTD) von Defects. Seit Einführung des FTI-Monitorings im Mai ist der Wert von 0,27 auf 0,14 gefallen, was wir in Ticket QA-5473 als Meilenstein festgehalten haben."}
{"ts": "118:37", "speaker": "I", "text": "Wie wirken sich diese KPIs auf Ihre täglichen Entscheidungen im QA-Team aus?"}
{"ts": "118:43", "speaker": "E", "text": "Wir nutzen sie als Trigger in der Testorchestrierung: wenn der FTI einen Schwellwert überschreitet, verschieben wir Ressourcen temporär von Low-Risk-Features zu High-Risk-Komponenten. Das ist auch in der Policy POL-QA-014, Abschnitt 6.2, verankert."}
{"ts": "118:56", "speaker": "I", "text": "Gab es Herausforderungen bei der Umsetzung dieser Policy?"}
{"ts": "119:02", "speaker": "E", "text": "Ja, insbesondere bei cross-funktionalen Teams. Manche Entwickler-Streams waren nicht darauf vorbereitet, kurzfristig Testressourcen abzugeben. Wir haben das in RFC-HER-45 adressiert, indem wir einen wöchentlichen Sync eingeführt haben."}
{"ts": "119:15", "speaker": "I", "text": "Welche weiteren Verbesserungen planen Sie für die nächste Projektphase?"}
{"ts": "119:21", "speaker": "E", "text": "Wir wollen ein Predictive Analytics Modul einführen, das Observability-Daten aus Nimbus direkt in die Testpriorisierung einspeist. Laut unserem Proof-of-Concept aus Sprint 19 könnten wir damit MTTD nochmals um 12 % senken."}
{"ts": "119:34", "speaker": "I", "text": "Können Sie ein Beispiel geben, wie Observability-Daten das konkret beeinflussen würden?"}
{"ts": "119:40", "speaker": "E", "text": "Wenn Nimbus z. B. im Produktionssystem eine Latenzerhöhung in Service S-Auth registriert, würde Hera automatisch Regressionstests für Auth-Module priorisieren. Das Mapping ist in Mapping-Tabelle MT-HER-07 definiert."}
{"ts": "119:53", "speaker": "I", "text": "Wie stellen Sie sicher, dass solche Änderungen gut dokumentiert werden?"}
{"ts": "119:59", "speaker": "E", "text": "Jede Anpassung wird als Change Request im QA-Change-Log erfasst. Zusätzlich erstellen wir eine Kurzfassung im Runbook, um auch neuen Teammitgliedern den Kontext zu geben. Beispiel: CR-HER-118 hat den neuen FTI-Threshold dokumentiert."}
{"ts": "120:12", "speaker": "I", "text": "Gibt es aus Ihrer Sicht noch 'weiche' Faktoren, die man nicht in KPIs messen kann?"}
{"ts": "120:18", "speaker": "E", "text": "Definitiv. Team-Morale und die Bereitschaft, Wissen zu teilen, sind schwer messbar, haben aber direkten Einfluss. Wir haben deshalb ein internes QA-Forum etabliert, was laut unserer internen Umfrage UA-2024-Q2 die Zufriedenheit um 18 % gesteigert hat."}
{"ts": "125:00", "speaker": "I", "text": "Zum Abschluss würde ich gern auf die Lessons Learned eingehen. Welche wesentlichen Erkenntnisse haben Sie aus der Build-Phase gezogen?"}
{"ts": "125:20", "speaker": "E", "text": "Wir haben vor allem gelernt, dass die initiale Annahme, Flaky Tests ließen sich rein durch Retries stabilisieren, zu optimistisch war. In Runbook RB-HER-FT-03 haben wir dokumentiert, dass Stabilisierung eher durch Refactoring und präzisere Mocks erreicht wird."}
{"ts": "125:45", "speaker": "I", "text": "Gab es dabei KPIs, die den Fortschritt oder auch die Probleme messbar gemacht haben?"}
{"ts": "126:05", "speaker": "E", "text": "Ja, wir haben die Defect Escape Rate von anfänglich 8% auf 4,7% gesenkt. Parallel sank die Flaky Test Rate laut wöchentlichem QA-Report HER-QA-52 von 12% auf 5%. Diese Metriken waren für uns die Leitplanken."}
{"ts": "126:35", "speaker": "I", "text": "Interessant. Und wie flossen diese Kennzahlen in Entscheidungen für die Testplanung ein?"}
{"ts": "126:55", "speaker": "E", "text": "Wir haben bei hoher Flaky Rate bestimmte Test Suites temporär aus der CI-Pipeline entfernt, um die Build-Zeiten unter unserem SLA-Build-015 zu halten. Das wurde jeweils in Tickets wie HER-PLN-112 dokumentiert."}
{"ts": "127:20", "speaker": "I", "text": "Welche Verbesserungen planen Sie in der nächsten Projektphase konkret?"}
{"ts": "127:40", "speaker": "E", "text": "Wir wollen ein automatisches Tagging in der Orchestrierung einführen, das Tests mit niedriger Vertrauenswürdigkeit markiert. Außerdem planen wir, die Traceability-Matrix aus Conreq auf Änderungen im Helios Datalake zu erweitern."}
{"ts": "128:05", "speaker": "I", "text": "Wie genau soll das Tagging technisch umgesetzt werden?"}
{"ts": "128:25", "speaker": "E", "text": "Über einen zusätzlichen Schritt im Jenkinsfile, der die Ergebnisse mit der Flaky-Historie aus dem Hera-Analytics-Service vergleicht. Diese Logik ist als Proof-of-Concept im Branch feat/test-tagging hinterlegt."}
{"ts": "128:50", "speaker": "I", "text": "Gibt es Risiken, dass ein falsches Tagging zu übersehen von relevanten Defects führt?"}
{"ts": "129:10", "speaker": "E", "text": "Ja, das Risiko besteht. Wir mitigieren das durch einen manuellen Review-Prozess für alle als 'low trust' markierten Tests, wie in RFC-HER-021 beschrieben. Dieser Schritt ist im aktuellen Zeitplan eingepreist."}
{"ts": "129:35", "speaker": "I", "text": "Haben Sie auch qualitative Lessons Learned, also Dinge, die sich nicht direkt in Zahlen ausdrücken lassen?"}
{"ts": "129:55", "speaker": "E", "text": "Definitiv. Die enge Kommunikation mit den Upstream-Teams war entscheidend, um Regressions früh zu erkennen. Der wöchentliche Sync mit Nimbus Observability brachte ungeschriebene Anforderungen ans Licht, die sonst untergegangen wären."}
{"ts": "130:20", "speaker": "I", "text": "Was würden Sie in der Zusammenarbeit mit diesen Teams künftig anders machen?"}
{"ts": "130:40", "speaker": "E", "text": "Wir wollen die Observability-Daten direkt in unser Dashboard integrieren, damit Korrelationen zwischen Produktionsanomalien und Testfehlschlägen in Echtzeit sichtbar werden. Das soll laut unserem nächsten Sprintziel HER-SPR-24 als MVP umgesetzt werden."}
{"ts": "143:00", "speaker": "I", "text": "Sie hatten vorhin ja schon den Zusammenhang zwischen unserer Orchestrierung und den Observability-Daten gestreift. Könnten Sie das bitte nochmal konkreter anhand eines Beispiels erklären?"}
{"ts": "143:05", "speaker": "E", "text": "Ja, klar. Also, wir haben im Hera QA Platform Build die Metriken aus dem Nimbus Observability Stream direkt in unsere Priorisierungspipeline integriert. Wenn z. B. ein Anstieg der Latenzen im Upstream-Service „Aurora API“ gemeldet wird, triggert das automatisch eine Anpassung der Test-Suite in der nächtlichen Orchestrierung. Das basiert auf Runbook QA-OBS-443, wo genau beschrieben ist, wie solche Events gemappt werden."}
{"ts": "143:14", "speaker": "I", "text": "Das heißt, Sie reagieren dynamisch auf Produktionsdaten?"}
{"ts": "143:19", "speaker": "E", "text": "Genau. Wir nutzen dafür den Risk-Based Testing Ansatz aus Policy POL-QA-014. Das heißt, wenn ein Produktionssignal einen Bereich als risikoreich markiert, erhöhen wir dort die Testtiefe – selbst wenn der Sprint-Plan etwas anderes vorsieht."}
{"ts": "143:28", "speaker": "I", "text": "Und wie wirkt sich das auf Ihre SLA-Ziele aus?"}
{"ts": "143:33", "speaker": "E", "text": "Wir haben eine SLA für kritische Regressionen von maximal 4 Stunden bis zur Erkennung. Durch die Integration von Observability-Daten konnten wir im letzten Quartal den Schnitt auf 2 Stunden senken. Das Ticket QA-MET-882 fasst die Messungen zusammen."}
{"ts": "143:42", "speaker": "I", "text": "Interessant. Gab es auch Fälle, wo falsche Signale zu unnötigen Tests geführt haben?"}
{"ts": "143:47", "speaker": "E", "text": "Ja, zwei Mal im letzten Sprint. Da war ein Spike in den Logs, der aber durch einen geplanten Lasttest im Helios Datalake verursacht wurde. Unser Heuristik-Filter, der in Runbook QA-FLT-219 beschrieben ist, hat das nicht erkannt. Wir passen den Filter jetzt an, um solche false positives zu vermeiden."}
{"ts": "143:56", "speaker": "I", "text": "Können Sie den Trade-off beschreiben, den Sie hier eingehen?"}
{"ts": "144:01", "speaker": "E", "text": "Klar. Mehr Filterung reduziert unnötige Testläufe und spart Ressourcen, aber es birgt das Risiko, echte Anomalien zu übersehen. Wir haben uns entschieden, etwas konservativer zu filtern, dokumentiert in RFC-QA-77, um die Defect Escape Rate nicht zu verschlechtern."}
{"ts": "144:10", "speaker": "I", "text": "Wie fließt diese Entscheidung in die nächste Projektphase ein?"}
{"ts": "144:15", "speaker": "E", "text": "Wir planen in der nächsten Phase, den Filter adaptiv zu gestalten, basierend auf historischen Flaky Test Rates und Produktionsmetriken. Das ist Teil der geplanten Prozessverbesserungen, die wir aus den Lessons Learned ableiten."}
{"ts": "144:24", "speaker": "I", "text": "Gibt es dazu schon Prototypen?"}
{"ts": "144:29", "speaker": "E", "text": "Ein Proof-of-Concept läuft gerade in einer isolierten QA-Stage-Umgebung. Wir füttern den Filter mit simulierten Alerts aus Aurora API und prüfen, ob die Orchestrierung gemäß den Policies reagiert. Ergebnisse dokumentieren wir im internen Wiki-Artikel QA-POC-Filter-2024."}
{"ts": "144:38", "speaker": "I", "text": "Wie messen Sie den Erfolg dieser Änderung?"}
{"ts": "144:43", "speaker": "E", "text": "Primär über zwei KPIs: die Reduktion der unnötigen Testausführungen um mindestens 15 % und das Halten der Defect Escape Rate unter 0,8 %. Zusätzlich beobachten wir die durchschnittliche Ausführungszeit pro Build, um sicherzustellen, dass Time-to-Market Ziele nicht leiden."}
{"ts": "145:00", "speaker": "I", "text": "Wir hatten ja vorhin schon über die Defect Escape Rate gesprochen. Mich würde interessieren, wie Sie aktuell diese Kennzahl im Tagesgeschäft verwenden, um Entscheidungen in der Orchestrierung zu treffen."}
{"ts": "145:05", "speaker": "E", "text": "Ja, also wir werten die Defect Escape Rate täglich in unserem QA-Dashboard aus, das an die Hera QA Platform angebunden ist. Wenn der Wert über 0,8 % steigt, wird automatisch ein Ticket im internen System RQ-457 erstellt, und wir priorisieren dann Regressionstests in den nächsten Orchestrierungszyklen."}
{"ts": "145:14", "speaker": "I", "text": "Und wie läuft diese Priorisierung technisch ab? Gibt es da fixe Runbooks oder ist es eher ad-hoc?"}
{"ts": "145:19", "speaker": "E", "text": "Wir haben ein Runbook RB-HER-023, in dem genau beschrieben ist, wie der CI/CD-Pipeline-Manager die Test-Suites entsprechend der Risk-Based Testing Policy POL-QA-014 neu reihen muss. Das ist nicht ad-hoc, sondern regelbasiert, mit Schwellenwerten und Gewichtungen pro Komponente."}
{"ts": "145:28", "speaker": "I", "text": "Können Sie ein Beispiel geben, wie eine solche Gewichtung aussieht?"}
{"ts": "145:33", "speaker": "E", "text": "Klar, zum Beispiel hat das Payment-Subsystem eine Gewichtung von 1,5, weil ein Defect dort hohe geschäftliche Auswirkungen hätte. Das wird durch die Traceability-Matrix im Tool QLink abgebildet, sodass bei Änderungen am Payment-Service automatisch 50 % mehr Tests in dieser Domäne orchestriert werden."}
{"ts": "145:45", "speaker": "I", "text": "Verstehe. Und wie gehen Sie mit den berüchtigten flaky tests um, die ja in der Vergangenheit oft Verzögerungen verursacht haben?"}
{"ts": "145:51", "speaker": "E", "text": "Wir labeln solche Tests in unserem Test-Repo mit @flaky und hinterlegen in einem separaten YAML-Config die Retry-Strategie. Außerdem gibt es ein Quarantäne-Protokoll nach SOP-QA-009: Tests, die dreimal in Folge inkonsistente Ergebnisse liefern, werden isoliert, um den Orchestrierungsfluss nicht zu blockieren."}
{"ts": "146:02", "speaker": "I", "text": "Interessant. Gab es zuletzt einen Fall, wo diese Quarantäne entscheidend war?"}
{"ts": "146:07", "speaker": "E", "text": "Ja, vor zwei Wochen im Build-Cluster B7. Da hat ein flaky Test im Notification-Service 40 % der Pipeline-Läufe blockiert. Durch die Quarantäne konnten wir in weniger als einer Stunde wieder auf 95 % Durchsatz kommen, was unser SLA von 90 % klar erfüllt."}
{"ts": "146:17", "speaker": "I", "text": "Das klingt nach einem effizienten Mechanismus. Wie dokumentieren Sie solche Vorfälle?"}
{"ts": "146:22", "speaker": "E", "text": "Wir führen ein Incident-Log in Confluence unter HER-QA-Incidents. Jeder Eintrag enthält das Jira-Ticket, die betroffenen Test-Suites, die Root-Cause-Analyse und den Link zum Runbook-Abschnitt, der angepasst wurde. Das fließt dann in unsere Lessons Learned ein."}
{"ts": "146:33", "speaker": "I", "text": "Wenn Sie an die nächste Projektphase denken, welche Prozessverbesserungen haben Sie schon konkret geplant?"}
{"ts": "146:38", "speaker": "E", "text": "Wir wollen die Retry-Strategien dynamischer machen, basierend auf Observability-Daten aus Nimbus. Außerdem planen wir, die Traceability-Matrix um Produktions-Usage-Patterns aus dem Helios Datalake zu erweitern, um Testfälle präziser zu priorisieren."}
{"ts": "146:49", "speaker": "I", "text": "Das heißt, Sie würden Live-Daten stärker in die Testplanung einbeziehen?"}
{"ts": "146:54", "speaker": "E", "text": "Genau. Bisher war das eher eine manuelle Bewertung. In der nächsten Phase wollen wir, dass der Orchestrator automatisch erkennt, wenn ein Feature in Produktion plötzlich stark genutzt wird, und die Testabdeckung dafür temporär erhöht. Das reduziert das Risiko, dass kritische Defects entkommen."}
{"ts": "147:00", "speaker": "I", "text": "Lassen Sie uns gerne auf die konkreten Entscheidungen eingehen, die Sie in der Build-Phase getroffen haben. Welche Trade-offs waren dabei am schwersten zu akzeptieren?"}
{"ts": "147:06", "speaker": "E", "text": "Schwierig war definitiv der Verzicht auf vollständige Regression Suites bei jedem Nightly Build. Wir haben im RFC-QA-221 dokumentiert, dass wir stattdessen eine risikobasierte Auswahl fahren, um die Build-Zeit unter 90 Minuten zu halten."}
{"ts": "147:14", "speaker": "I", "text": "Gab es hierzu interne Diskussionen oder sogar formale Change Advisory Boards?"}
{"ts": "147:19", "speaker": "E", "text": "Ja, wir hatten zwei CAB-Sitzungen, bei denen die Release-Manager und QA-Leads die Defect Escape Rate der letzten drei Sprints betrachtet haben. Laut unserem SLA-QA-05 mussten wir unter 2% bleiben, das war die Leitlinie."}
{"ts": "147:28", "speaker": "I", "text": "Und wie haben Sie die Risiken, die aus diesem Trade-off resultieren, mitigiert?"}
{"ts": "147:34", "speaker": "E", "text": "Wir haben im Runbook RB-HER-017 einen Prozess verankert, der bei bestimmten kritischen Codebereichen automatisch eine erweiterte Testauswahl triggert. Zusätzlich nutzen wir Observability-Alerts aus dem Projekt Nimbus, um verdächtige Patterns früh zu erkennen."}
{"ts": "147:44", "speaker": "I", "text": "Können Sie ein Beispiel für so einen Alert nennen, der tatsächlich einen Fehler vor dem Release verhindert hat?"}
{"ts": "147:50", "speaker": "E", "text": "Letzten Monat hat ein Latency-Spike im Helios Datalake-Stream zu einem Alert geführt, Ticket QA-INC-482. Wir haben daraufhin eine gezielte Testreihe für die betroffenen ETL-Jobs durchgeführt und einen Concurrency-Bug gefunden."}
{"ts": "147:59", "speaker": "I", "text": "Das heißt, hier kam die Multi-Projekt-Integration direkt zum Tragen."}
{"ts": "148:03", "speaker": "E", "text": "Genau. Ohne die Verknüpfung zwischen Hera QA Platform und Nimbus Observability hätten wir den Zusammenhang zwischen Streaming-Latenz und Datenvalidierungsfehlern nicht so schnell erkannt."}
{"ts": "148:11", "speaker": "I", "text": "Wie dokumentieren Sie solche Lessons Learned, damit sie teamübergreifend nutzbar sind?"}
{"ts": "148:16", "speaker": "E", "text": "Wir pflegen eine Confluence-Seite 'Hera Cross-Impact Cases', auf der wir pro Fall die Metriken, die Alerts und die daraus abgeleiteten Testanpassungen festhalten. Das ist Teil von unserem Knowledge Base Artikel KB-HER-044."}
{"ts": "148:25", "speaker": "I", "text": "Und fließt das auch in die künftige Testfall-Priorisierung ein?"}
{"ts": "148:29", "speaker": "E", "text": "Ja, wir haben die Priorisierungslogik in der Orchestrierung angepasst. Wenn ein Service in den letzten 60 Tagen in einem Cross-Impact Case aufgetreten ist, erhält er automatisch eine höhere Test-Priority laut Policy POL-QA-014."}
{"ts": "148:38", "speaker": "I", "text": "Zum Abschluss: Welche Risiken sehen Sie für die nächste Projektphase, trotz dieser Maßnahmen?"}
{"ts": "148:44", "speaker": "E", "text": "Das größte Risiko ist aktuell die steigende Flaky Test Rate in den UI-Tests. Selbst mit Retry-Strategien aus Runbook RB-HER-009 haben wir 4,3% erreicht, was über unserem Zielwert liegt. Das kann die Defect Detection verzögern."}
{"ts": "149:00", "speaker": "I", "text": "Sie hatten vorhin schon RFC-QA-221 angesprochen. Können Sie bitte näher erläutern, wie diese Entscheidung in der Praxis umgesetzt wurde?"}
{"ts": "149:05", "speaker": "E", "text": "Ja, gern. In RFC-QA-221 haben wir festgelegt, dass für die Build-Phase von Hera QA Platform eine Reduktion der Testabdeckung um 12 % akzeptabel ist, solange kritische Pfade durch automatisierte Smoke-Tests abgedeckt bleiben. Wir haben dazu in Runbook RB-HER-07 genau beschrieben, welche Test-Suites priorisiert werden."}
{"ts": "149:18", "speaker": "I", "text": "Und wie stellen Sie sicher, dass diese Priorisierung nicht zu Qualitätsverlusten führt?"}
{"ts": "149:23", "speaker": "E", "text": "Wir monitoren die Fehlerraten in den nightly builds sehr eng. Wenn in mehr als zwei aufeinanderfolgenden nächtlichen Runs ein kritischer Defekt auftaucht, wird die Abdeckung temporär wieder erhöht. Diese Schwelle ist auch in SLA-QA-03 dokumentiert."}
{"ts": "149:37", "speaker": "I", "text": "Gibt es ein konkretes Beispiel, wo Sie diese Schwelle erreicht haben?"}
{"ts": "149:42", "speaker": "E", "text": "Ja, im Ticket QA-BUG-542 hatten wir eine Regression im Payment-Connector. Nach zwei fehlerhaften nightly Runs haben wir sofort die vollständige Regression-Suite für diesen Bereich wieder aktiviert."}
{"ts": "149:55", "speaker": "I", "text": "Wie schnell konnten Sie in diesem Fall reagieren?"}
{"ts": "150:00", "speaker": "E", "text": "Innerhalb von sechs Stunden nach dem zweiten fehlgeschlagenen Build. Das ging, weil die Orchestrierung in Hera QA Platform so konzipiert ist, dass Test-Suites per Konfiguration in Orchestrator-Config-JSON umgeschaltet werden können."}
{"ts": "150:14", "speaker": "I", "text": "Das klingt sehr effizient. Gab es dabei technische Hürden?"}
{"ts": "150:19", "speaker": "E", "text": "Ein Problem war, dass der Config-Reload nicht sofort auf allen Subsystemen greift. Wir mussten dafür einen Hotfix in Service HER-Orch-02 deployen, um die Propagation zu beschleunigen."}
{"ts": "150:33", "speaker": "I", "text": "Wie dokumentieren Sie solche Hotfixes für die Nachvollziehbarkeit?"}
{"ts": "150:38", "speaker": "E", "text": "Jeder Hotfix bekommt ein eigenes Change-Log im Confluence-Space QA-HER, verlinkt mit dem Jira-Issue. Außerdem aktualisieren wir die betroffenen Runbooks, in diesem Fall RB-HER-07 und RB-HER-Infra-03."}
{"ts": "150:52", "speaker": "I", "text": "Und wie fließen diese Erfahrungen in die Lessons Learned ein?"}
{"ts": "150:57", "speaker": "E", "text": "Wir halten sie im Quartalsreview fest. Dort bewerten wir, ob der Trade-off aus RFC-QA-221 weiterhin sinnvoll ist oder angepasst werden muss. Manchmal verschieben wir die Grenzen, wenn die Datenlage das nahelegt."}
{"ts": "151:10", "speaker": "I", "text": "Gab es schon Anpassungen an RFC-QA-221 basierend auf solchen Reviews?"}
{"ts": "151:15", "speaker": "E", "text": "Ja, im letzten Review haben wir die erlaubte Reduktion auf 10 % gesenkt, weil die Fehlerquote in kritischen Pfaden leicht anstieg. Das ist in RFC-QA-221-v2 dokumentiert und seitdem in Kraft."}
{"ts": "151:00", "speaker": "I", "text": "Sie hatten vorhin die RFC-QA-221 erwähnt. Mich würde interessieren, wie Sie diese Entscheidung damals intern kommuniziert haben, gerade im Hinblick auf die Build-Phase."}
{"ts": "151:05", "speaker": "E", "text": "Ja, ähm, wir haben das in unserem wöchentlichen QA-Guild-Meeting vorgestellt und parallel im Confluence-Space 'Hera Decisions' dokumentiert. Dort gibt es ein Template, das sowohl die Risikoanalyse nach POL-QA-014 als auch die Auswirkung auf Time-to-Market beschreibt."}
{"ts": "151:15", "speaker": "I", "text": "Gab es dazu auch formale Abnahmen oder war das eher ein informeller Konsens?"}
{"ts": "151:20", "speaker": "E", "text": "Formal, ja. Wir haben im Jira-Ticket DEC-HER-048 alle Stakeholder gelistet, die mit \\\"Approved\\\" kommentieren mussten. Erst danach durften wir die Änderung in die Testorchestrierung aufnehmen."}
{"ts": "151:30", "speaker": "I", "text": "Inwiefern hat das die Planung der nächsten Sprints beeinflusst?"}
{"ts": "151:35", "speaker": "E", "text": "Signifikant. Durch die reduzierte Abdeckung in weniger kritischen Modulen konnten wir zwei Sprints früher ein Feature-Set für das Helios-Interface liefern. Das wurde durch Observability-Daten gestützt, die ein geringes Incident-Risiko zeigten."}
{"ts": "151:45", "speaker": "I", "text": "Haben Sie das auch in Ihren Runbooks verankert, falls ähnliche Situationen auftreten?"}
{"ts": "151:50", "speaker": "E", "text": "Ja, Runbook RB-HER-017 enthält jetzt einen Abschnitt 'Abdeckungs-Trade-off-Checkliste'. Da steht z. B., dass wir bei einer Incident-Rate unter 0,5 % in vergleichbaren Bereichen eine Abdeckung <80 % temporär akzeptieren dürfen."}
{"ts": "152:00", "speaker": "I", "text": "Gab es auch Risiken, die Sie eventuell unterschätzt haben?"}
{"ts": "152:05", "speaker": "E", "text": "Ehrlich gesagt ja. Ein Downstream-Service aus Nimbus Observability hatte eine versteckte API-Änderung, die wir durch die geringere Testtiefe erst spät bemerkten. Das kostete uns einen Hotfix."}
{"ts": "152:15", "speaker": "I", "text": "Wie haben Sie darauf reagiert, um solche Spätentdeckungen zu vermeiden?"}
{"ts": "152:20", "speaker": "E", "text": "Wir haben einen zusätzlichen Canary-Testlayer eingeführt, der nightly gegen alle bekannten Downstream-Endpunkte läuft. Das ist jetzt im SLA-QA-05 als verpflichtend markiert."}
{"ts": "152:30", "speaker": "I", "text": "Interessant. Und wie stellen Sie sicher, dass diese Canary-Tests nicht selbst flaky werden?"}
{"ts": "152:35", "speaker": "E", "text": "Wir nutzen die gleiche Flaky-Detection-Engine, die auch im Hera-Core läuft. Tests, die dreimal in Folge instabil sind, werden automatisch in den Quarantäne-Status verschoben und erhalten das Label 'CAN-FLAKY'."}
{"ts": "152:45", "speaker": "I", "text": "Abschließend: Sehen Sie diese Entscheidung aus RFC-QA-221 eher als Ausnahmefall oder könnte das zur Regel werden?"}
{"ts": "152:50", "speaker": "E", "text": "Es bleibt eine Ausnahme. Wir haben klare Kriterien, wann solche Trade-offs zulässig sind, und die Lessons Learned daraus sind jetzt Teil unseres Onboarding-Kurses für neue QA-Ingenieure."}
{"ts": "153:00", "speaker": "I", "text": "Sie hatten vorhin RFC-QA-221 erwähnt. Können Sie bitte konkret schildern, welche Entscheidung darin dokumentiert wurde?"}
{"ts": "153:15", "speaker": "E", "text": "Ja, in RFC-QA-221 haben wir festgehalten, dass wir für das Hera QA Platform Build zunächst nur 80 % der geplanten Integrationstests implementieren. Die restlichen 20 % wurden bewusst verschoben, um das Go-Live-Fenster einzuhalten. Wir haben das Risiko quantifiziert und in Runbook-RISK-047 dokumentiert."}
{"ts": "153:38", "speaker": "I", "text": "Wie haben Sie das Risiko quantifiziert? Gab es da ein bestimmtes Bewertungsmodell?"}
{"ts": "153:52", "speaker": "E", "text": "Wir haben die Risk-Based Testing Methodik aus POL-QA-014 angewendet. Das heißt: Eintrittswahrscheinlichkeit × Auswirkungsgrad, skaliert auf unsere SLA-Matrix. Beispielsweise: ein fehlender Test für den Payment-Adapter wurde als mittelhohes Risiko (Score 12) eingestuft, weil wir Observability-Daten aus Nimbus hatten, die zeigten, dass diese Schnittstelle stabil läuft."}
{"ts": "154:22", "speaker": "I", "text": "Und wie haben Sie diese Observability-Daten konkret in die Priorisierung eingebunden?"}
{"ts": "154:37", "speaker": "E", "text": "Wir haben in unserem Hera Orchestrator ein Modul, das Metriken wie MTTR und Error Rate aus Nimbus APIs zieht. Diese fließen in das Priorisierungstool ein, das über eine gEDA-Formel die Testreihenfolge bestimmt. Ohne diese Daten hätten wir wahrscheinlich andere Testfälle priorisiert."}
{"ts": "154:59", "speaker": "I", "text": "Gab es im Zuge dieser Entscheidung auch Rückmeldungen aus anderen Projekten, etwa Helios Datalake?"}
{"ts": "155:13", "speaker": "E", "text": "Ja, Helios hat uns z. B. Log-Cluster-Analysen geliefert, die halfen, Anomalien in den Testumgebungen zu erkennen. Das war wichtig für die End-to-End-Traceability: wir konnten einen Defect aus Hera direkt mit einem Log-Pattern aus Helios verknüpfen und so schneller beheben."}
{"ts": "155:37", "speaker": "I", "text": "Welche nicht-technischen Faktoren spielten bei der Abwägung zwischen Abdeckung und Time-to-Market eine Rolle?"}
{"ts": "155:52", "speaker": "E", "text": "Vor allem vertragliche Meilensteine. Unser SLA-QA-2023 schreibt vor, dass neue Features spätestens 4 Wochen vor Release im Staging sein müssen. Außerdem gab es internen Druck vom Vertrieb, da ein Pilotkunde den Starttermin öffentlich kommuniziert hatte."}
{"ts": "156:18", "speaker": "I", "text": "Wie stellen Sie sicher, dass die verschobenen Tests nicht untergehen?"}
{"ts": "156:32", "speaker": "E", "text": "Wir haben für jeden verschobenen Testfall ein Ticket im JIRA-Board QA-BACKLOG angelegt, inklusive Risiko-Score und Verweis auf RFC-QA-221. Zusätzlich ist in Runbook-RISK-047 ein Abschnitt \"Deferred Tests\" mit Verantwortlichen und Deadlines."}
{"ts": "156:54", "speaker": "I", "text": "Gab es im Nachgang schon Folgen aus dieser Entscheidung, positiv oder negativ?"}
{"ts": "157:08", "speaker": "E", "text": "Positiv: Wir haben den Build-Phase-Milestone pünktlich erreicht. Negativ: Ein Defekt im weniger getesteten Reporting-Modul wurde erst im UAT entdeckt. Laut Incident INC-8742 war der Fix aber innerhalb von 36 Stunden im Testsystem."}
{"ts": "157:33", "speaker": "I", "text": "Wurden aus INC-8742 Lessons Learned abgeleitet?"}
{"ts": "157:48", "speaker": "E", "text": "Ja, wir haben in der Retrospektive beschlossen, dass Module mit historisch hoher Defektdichte – auch wenn aktuell stabil – nie komplett aus der Testabdeckung herausfallen dürfen. Das ist jetzt als Zusatzregel in POL-QA-014-Appendix-B verankert."}
{"ts": "159:00", "speaker": "I", "text": "Sie hatten vorhin RFC-QA-221 erwähnt – könnten Sie mir bitte genauer erklären, wie diese Entscheidung in Ihrem Runbook festgehalten wurde?"}
{"ts": "159:05", "speaker": "E", "text": "Ja, klar. Im Runbook RB-HER-OPS-07 haben wir das als eigenen Abschnitt 'Architekturentscheidungen' hinterlegt. Dort sind die Abwägungen aus RFC-QA-221 gelistet, inklusive der Metriken aus dem Observability-Stream, die uns dazu gebracht haben, bestimmte Testpfade zu de-priorisieren."}
{"ts": "159:12", "speaker": "I", "text": "Gab es bei der Umsetzung dieser Entscheidung konkrete Risiken, die Sie in Kauf genommen haben?"}
{"ts": "159:17", "speaker": "E", "text": "Ja, wir sind bewusst das Risiko eingegangen, bei selten auftretenden Edge-Cases im Payment-Modul weniger automatische Tests laufen zu lassen, um die Build-Pipeline um ca. 12 Minuten zu verkürzen. Das haben wir im Risk Log RSK-HER-41 mit einer mittleren Eintrittswahrscheinlichkeit dokumentiert."}
{"ts": "159:25", "speaker": "I", "text": "Und wie überwachen Sie diese Risiken aktuell, um schnell reagieren zu können?"}
{"ts": "159:30", "speaker": "E", "text": "Wir nutzen einen wöchentlichen Review der SLA-Dashboards. Wenn die Fehlerrate im Payment-Modul über 0,3 % steigt, triggert das ein Incident-Ticket im JIRA-Board HER-QA, was wiederum eine Reaktivierung der zuvor de-priorisierten Testfälle auslöst."}
{"ts": "159:38", "speaker": "I", "text": "Spielen dabei die Daten aus dem Helios Datalake noch eine Rolle?"}
{"ts": "159:43", "speaker": "E", "text": "Ja, absolut. Wir ziehen stündliche Aggregationen aus Helios, um Trends in den Live-Daten früh zu erkennen. Diese fließen direkt in unsere Testfall-Priorisierung ein, vor allem wenn sie auf Muster hindeuten, die unsere synthetischen Tests bisher nicht abdecken."}
{"ts": "159:51", "speaker": "I", "text": "Haben Sie ein Beispiel für so ein Muster, das bisher nicht abgedeckt war?"}
{"ts": "159:56", "speaker": "E", "text": "Ja, ein gutes Beispiel war die Sequenz von Bulk-Updates im Inventory-Service, die zu einem kurzzeitigen Deadlock geführt hat. Das trat in Produktion auf, wurde im Helios Datalake als Anomalie markiert, und wir haben dann einen neuen Testfall HER-TC-982 erstellt, um genau dieses Szenario abzudecken."}
{"ts": "160:04", "speaker": "I", "text": "Wie lange hat es vom ersten Auftreten bis zur Abdeckung durch einen Testfall gedauert?"}
{"ts": "160:09", "speaker": "E", "text": "Ungefähr 36 Stunden. Wir haben eine Fast-Track-Prozedur im Runbook RB-HER-QA-03, die es erlaubt, kritische Produktionsfehler innerhalb von zwei Tagen in die Test-Suite aufzunehmen."}
{"ts": "160:16", "speaker": "I", "text": "Beeinflussen solche kurzfristigen Ergänzungen nicht die Stabilität der Build-Pipeline?"}
{"ts": "160:21", "speaker": "E", "text": "Doch, kurzfristig schon. Wir haben dafür einen separaten 'Quarantäne-Branch' in der Orchestrierung, in dem neue Tests 3–5 Zyklen laufen, bevor sie in den Haupt-Workflow integriert werden. Das minimiert das Risiko, dass instabile Tests die gesamte Pipeline blockieren."}
{"ts": "160:29", "speaker": "I", "text": "Das klingt nach einem ausbalancierten Vorgehen. Gibt es Kennzahlen, die zeigen, ob sich dieser Prozess lohnt?"}
{"ts": "160:34", "speaker": "E", "text": "Ja, laut KPI-Dashboard Q4/23 haben wir die Zahl der Build-Abbrüche durch neu eingeführte Tests um 42 % reduziert. Gleichzeitig konnten wir die mittlere Reaktionszeit auf Produktionsvorfälle von 4 Tagen auf 1,8 Tage senken."}
{"ts": "161:00", "speaker": "I", "text": "Sie hatten vorhin RFC-QA-221 erwähnt. Können Sie bitte genauer erklären, wie diese Entscheidung die Struktur der Testarchitektur beeinflusst hat?"}
{"ts": "161:05", "speaker": "E", "text": "Ja, sicher. RFC-QA-221 war im Prinzip der formale Beschluss, die Testausführung in Hera QA Platform stärker zu parallelisieren, auch wenn wir wussten, dass das in manchen Subsystemen die Log-Korrelation erschwert. Wir haben im Runbook RB-HER-07 festgehalten, wie wir diese Parallelisierungsgrade konfigurieren und in kritischen Fällen wieder zurückfahren können."}
{"ts": "161:15", "speaker": "I", "text": "Gab es dadurch konkrete Risiken, die Sie in Kauf genommen haben?"}
{"ts": "161:20", "speaker": "E", "text": "Ja, das Hauptrisiko war, dass bei Fehlern in stark verteilten Testläufen die Root-Cause-Analyse länger dauert. Wir haben dafür ein Interim-SLA für die Fehleranalyse eingeführt: maximal 6 Stunden bis zur ersten Ursachenhypothese. Das ist in SLA-QA-HER-02 dokumentiert."}
{"ts": "161:30", "speaker": "I", "text": "Und wie stellen Sie sicher, dass dieses SLA eingehalten wird?"}
{"ts": "161:36", "speaker": "E", "text": "Wir haben ein Alerting in unserem internen Tool OrbiMon konfiguriert, das einen Jira-Ticket-Workflow triggert, wenn der Analyse-Status nach 5 Stunden nicht auf 'Hypothese erstellt' steht. Ticket-Typ ist HER-ANALYSE, und unser Runbook beschreibt die Eskalationsstufen."}
{"ts": "161:46", "speaker": "I", "text": "Interessant. Waren dafür Anpassungen an der Observability-Schnittstelle nötig?"}
{"ts": "161:51", "speaker": "E", "text": "Ja, wir mussten den Event-Stream aus Nimbus Observability um ein Feld 'testExecutionGroup' erweitern, um die Zuordnung bei parallelen Runs zu erleichtern. Das ging als Change-Request CR-NIM-482 durch, mit Abnahme durch beide Teams."}
{"ts": "162:00", "speaker": "I", "text": "Hat diese Erweiterung auch andere Projekte beeinflusst?"}
{"ts": "162:05", "speaker": "E", "text": "Ja, Helios Datalake nutzt dieselben Event-Schemas für historische Analysen. Dort mussten die ETL-Jobs angepasst werden, um das neue Feld zu ignorieren oder korrekt zu verarbeiten. War zwar eine kleine Änderung, aber ohne Koordination hätten wir Inkonsistenzen riskiert."}
{"ts": "162:15", "speaker": "I", "text": "Gab es in diesem Zusammenhang Lessons Learned, die Sie festgehalten haben?"}
{"ts": "162:20", "speaker": "E", "text": "Definitiv. Wir haben in unserem Confluence-Bereich eine Seite 'Cross-Project Schema Changes' angelegt, die als Checkliste dient, bevor Felder in Observability-Events geändert werden. Das hätte uns bei einem früheren Incident, ID HER-INC-037, viel Zeit gespart."}
{"ts": "162:30", "speaker": "I", "text": "Wie priorisieren Sie solche Infrastruktur-Änderungen im Vergleich zu Feature-Entwicklung?"}
{"ts": "162:35", "speaker": "E", "text": "Wir nutzen ein duales Backlog: eines für Feature Stories, eines für technische Plattform-Themen. Mit dem Policy-Dokument POL-QA-014 als Referenz haben wir ein Minimum an technischer Schuld definiert, das nicht überschritten werden darf, sonst werden Features blockiert."}
{"ts": "162:45", "speaker": "I", "text": "Gab es einen Fall, wo Sie Features blockiert haben?"}
{"ts": "162:50", "speaker": "E", "text": "Ja, im März haben wir die Einführung eines neuen Test-Dashboards um zwei Sprints verschoben, weil die Traceability zwischen Anforderungen und Testfällen nicht den Vorgaben aus POL-QA-014 entsprach. Das war unpopulär, aber die Compliance-Prüfung durch QA-Audit-Team hatte Priorität."}
{"ts": "163:00", "speaker": "I", "text": "Sie hatten vorhin die Observability-Daten aus Nimbus schon angerissen. Mich würde interessieren, wie genau diese Daten in Hera einfließen."}
{"ts": "163:05", "speaker": "E", "text": "Ja, also wir ziehen Metriken wie Error Rates und Latenzen über den Observability-Connector, der in Runbook RB-HER-OBS-07 beschrieben ist. Diese Metriken fließen dann direkt in unseren Risk-Scoring-Algorithmus ein."}
{"ts": "163:14", "speaker": "I", "text": "Und beeinflusst das auch die Priorisierung der Testausführung?"}
{"ts": "163:18", "speaker": "E", "text": "Genau, wenn im Live-System ein Anstieg der Latenz im Payment-Subsystem registriert wird, erhöht Hera automatisch die Gewichtung entsprechender End-to-End-Tests. Das ist in Ticket QA-HER-451 dokumentiert."}
{"ts": "163:27", "speaker": "I", "text": "Gab es da auch mal Fehlalarme, also Fälle, wo die Observability-Daten zu viel Lärm erzeugt haben?"}
{"ts": "163:33", "speaker": "E", "text": "Ja, ein Beispiel im März: Der Upstream-Service für Customer-Profile hatte einen geplanten Load-Test, den Nimbus als Anomalie meldete. Hera hat daraufhin Tests verschoben, obwohl es kein echtes Incident war."}
{"ts": "163:45", "speaker": "I", "text": "Wie haben Sie das mitigiert?"}
{"ts": "163:49", "speaker": "E", "text": "Wir haben in RFC-QA-238 festgelegt, dass Observability-Events erst nach einer 5-Minuten-Persistenz und Cross-Check mit Deployment-Logs in Hera-Trigger umgewandelt werden."}
{"ts": "163:59", "speaker": "I", "text": "Das heißt, Sie korrelieren Metriken mit CI/CD-Events?"}
{"ts": "164:03", "speaker": "E", "text": "Ja, exakt. Das kommt aus der Lesson Learned in Sprint 14, wo wir gemerkt haben, dass isolierte Metriken oft falsche Priorisierungen erzeugen. Die Korrelation ist jetzt fester Bestandteil im Orchestrierungsmodul."}
{"ts": "164:14", "speaker": "I", "text": "Wie wirkt sich eine Änderung in einem Upstream-Service konkret auf Ihre Testplanung aus, z. B. bei Schnittstellenänderungen?"}
{"ts": "164:20", "speaker": "E", "text": "Wenn der API-Schema-Validator im Hera-Preflight feststellt, dass sich ein Feldtyp geändert hat, wird automatisch ein Impact-Tree berechnet. Das zeigt uns, welche Testpakete auszuführen sind – das war z. B. im Helios Datalake Update vom April der Fall."}
{"ts": "164:33", "speaker": "I", "text": "Und diese Impact-Trees – sind die auch für externe Projekte sichtbar?"}
{"ts": "164:37", "speaker": "E", "text": "Nur für verknüpfte Projekte mit SLA-QA-05. Helios und Nimbus sind da drin, kleinere interne Tools nicht."}
{"ts": "164:44", "speaker": "I", "text": "Abschließend noch zu den dokumentierten Trade-offs: Können Sie mir ein Beispiel geben, wo Sie bewusst Abdeckung reduziert haben?"}
{"ts": "164:50", "speaker": "E", "text": "Klar, in RFC-QA-221 haben wir entschieden, bei der Release 3.2 die Low-Risk-GUI-Tests für das Admin-Panel um 40 % zu reduzieren, um zwei Wochen früher live zu gehen. Das Risiko wurde mit QA-Risk-Formular RF-17 bewertet und von der Projektleitung akzeptiert."}
{"ts": "164:00", "speaker": "I", "text": "Sie haben vorhin die Observability-Integration angesprochen – könnten Sie mir mal ein konkretes Beispiel aus der letzten Sprintplanung nennen?"}
{"ts": "164:05", "speaker": "E", "text": "Ja, klar. Letzte Woche haben wir im Runbook RB-OBS-09 festgehalten, dass der Upstream-Service 'Orion Auth' ungewöhnlich hohe Latenzen hatte. Diese Metriken aus Nimbus Observability sind dann direkt in die Priorisierung der Hera Regression Suites eingeflossen."}
{"ts": "164:14", "speaker": "I", "text": "Das heißt, Sie haben die Tests in der Plattform dynamisch umgebaut?"}
{"ts": "164:18", "speaker": "E", "text": "Genau. Im Test-Orchestrator haben wir die Authentifizierungsflows ganz nach oben gezogen. Laut Policy POL-QA-014 dürfen wir bei kritischen SLA-Verletzungen sofortige Smoke-Tests einschieben."}
{"ts": "164:26", "speaker": "I", "text": "Und wie lange dauert es von der Observability-Erkennung bis zur Testanpassung?"}
{"ts": "164:31", "speaker": "E", "text": "In der Build-Phase sind es aktuell etwa 15 Minuten, weil wir noch manuell bestätigen. In der Run-Phase wollen wir das mit den Triggern aus Ticket QA-TRG-512 automatisieren."}
{"ts": "164:40", "speaker": "I", "text": "Gab es dabei Stolpersteine oder false positives?"}
{"ts": "164:44", "speaker": "E", "text": "Ja, bei einem Release von Helios Datalake. Die Observability-Daten sahen wie ein Problem aus, aber es war ein geplanter Re-Index. Wir haben das jetzt im Runbook RB-OBS-Exceptions dokumentiert."}
{"ts": "164:53", "speaker": "I", "text": "Sie erwähnten vorhin die Trade-offs aus RFC-QA-221 – können Sie das auf diesen Fall anwenden?"}
{"ts": "164:58", "speaker": "E", "text": "Ja, RFC-QA-221 beschreibt, dass wir bei Time-to-Market-Priorität die Testtiefe bei nicht-betroffenen Modulen reduzieren. Hier haben wir das Risiko akzeptiert, um den Fix für 'Orion Auth' sofort zu validieren."}
{"ts": "165:07", "speaker": "I", "text": "Wie halten Sie diese Risikoentscheidung fest?"}
{"ts": "165:11", "speaker": "E", "text": "In unserem Confluence-Abschnitt 'Risk Log' mit Verweis auf das Jira-Ticket QA-RISK-88. Dort steht der Impact, die getroffenen Annahmen und die geplante Nachtestung drin."}
{"ts": "165:19", "speaker": "I", "text": "Und gab es schon mal Folgen, weil Sie so eine Abdeckung reduziert haben?"}
{"ts": "165:23", "speaker": "E", "text": "Einmal, ja – beim Modul 'Hera Analytics'. Wir hatten einen Minor-Bug in Produktion, der erst im Post-Release-Test auffiel. War aber innerhalb des akzeptierten Risiko-Scores von 3 laut SLA-QA-02."}
{"ts": "165:32", "speaker": "I", "text": "Würden Sie sagen, das lohnt sich trotzdem?"}
{"ts": "165:36", "speaker": "E", "text": "Für kritische Fixes ja. Die Daten aus den letzten drei Zyklen zeigen, dass wir im Schnitt 12 Stunden schneller live gehen konnten, ohne dass der Defect-Leakage KPI über 0,5 % gestiegen ist."}
{"ts": "166:00", "speaker": "I", "text": "Bevor wir zum Abschluss kommen, würde ich gern noch verstehen, wie genau Sie die Lessons Learned aus den bisherigen Sprints festhalten."}
{"ts": "166:05", "speaker": "E", "text": "Also, wir führen am Ende jedes zweiwöchigen Sprints ein Retro-Dokument in Confluence, das an Runbook RB-QA-005 angehängt wird. Darin listen wir nicht nur die offensichtlichen Fehler, sondern auch implizite Patterns, die wir in den Testdaten gesehen haben."}
{"ts": "166:13", "speaker": "I", "text": "Können Sie ein Beispiel für so ein implizites Pattern geben?"}
{"ts": "166:18", "speaker": "E", "text": "Ja, zum Beispiel haben wir festgestellt, dass Build-Pipelines montags zwischen 9 und 10 Uhr 15 % häufiger abbrechen, meist wegen API-Timeouts im Staging-Cluster. Das stand nirgends in einem SLA, ist aber für unsere Testplanung inzwischen fest eingeplant."}
{"ts": "166:28", "speaker": "I", "text": "Wie fließt so etwas in Ihre zukünftige Planung ein?"}
{"ts": "166:33", "speaker": "E", "text": "Wir verschieben kritische Regression-Suites auf Nachmittage oder nutzen den sogenannten 'Quiet Window' laut Runbook RB-DEP-012. Those windows are defined to avoid peak load periods and reduce flaky test noise."}
{"ts": "166:44", "speaker": "I", "text": "Gab es KPIs, die besonders aussagekräftig waren für diese Optimierungen?"}
{"ts": "166:49", "speaker": "E", "text": "Ja, die 'Flakiness Rate' pro Suite und die Mean Time to Detect (MTTD) bei kritischen Bugs. Wir haben gesehen, dass eine Verschiebung um 4 Stunden die MTTD im Schnitt um 18 % verbessert."}
{"ts": "166:59", "speaker": "I", "text": "Und wie dokumentieren Sie diese Änderungen für Stakeholder, die nicht tief in den QA-Prozessen stecken?"}
{"ts": "167:03", "speaker": "E", "text": "Wir erstellen ein Quartals-Update im QA-Newsletter und referenzieren darin Tickets wie T-QA-7842, wo die Änderung an der Orchestrierungslogik beschrieben ist. Zusätzlich gibt’s eine Executive Summary in leicht verständlicher Sprache."}
{"ts": "167:13", "speaker": "I", "text": "Welche Risiken sehen Sie, wenn diese impliziten Regeln nicht beachtet werden?"}
{"ts": "167:18", "speaker": "E", "text": "Das Risiko ist, dass Tests in Lastspitzen laufen, was zu einer Häufung von False Positives führt. This can erode trust in the platform outputs and slow down release approvals."}
{"ts": "167:28", "speaker": "I", "text": "Gibt es ein konkretes Beispiel, wo das schon passiert ist?"}
{"ts": "167:33", "speaker": "E", "text": "Ja, im März-Lauf 2024, als wir die Release-Candidate-Suite versehentlich während eines Helios Datalake-Maintenance-Fensters gestartet haben. Ergebnis: 23 von 120 Tests sind fehlgeschlagen, ohne dass Code geändert wurde."}
{"ts": "167:45", "speaker": "I", "text": "Wie haben Sie darauf reagiert?"}
{"ts": "167:49", "speaker": "E", "text": "Wir haben sofort ein Post-Mortem erstellt (DOC-QA-PM-019) und in RFC-QA-238 festgelegt, dass Orchestrierung künftig Observability-Signale zu Maintenance direkt abfragt, bevor eine Suite gestartet wird."}
{"ts": "167:00", "speaker": "I", "text": "Wir hatten ja vorhin über die Observability-Daten gesprochen. Mich würde jetzt interessieren – wie gehen Sie konkret vor, wenn ein Risk-Assessment während des laufenden Sprints eine neue Priorisierung erfordert?"}
{"ts": "167:20", "speaker": "E", "text": "Das läuft bei uns über den Runbook-Eintrag RB-HER-PRIO-05. Darin ist festgelegt, dass wir bei einer Änderung im Risk-Score über 15 % innerhalb von 24 Stunden eine sofortige Testfall-Neupriorisierung im Orchestrator auslösen. Die Policy POL-QA-014 gibt uns hier den Rahmen, und der Orchestrator injiziert dann die neuen Prioritäten direkt in die laufenden Test-Pipelines."}
{"ts": "167:45", "speaker": "I", "text": "Und diese Anpassungen wirken sich ja vermutlich auch auf die Abfolge der Cross-Service-Tests aus, oder?"}
{"ts": "168:05", "speaker": "E", "text": "Genau. Wir haben da einen Dependency-Graph im System, der aus den Helios Datalake-Metadaten generiert wird. Wenn ein kritischer Upstream-Service wie z. B. das User-Profile-Modul einen höheren Risk-Score hat, verschiebt sich die Testsequenz so, dass dessen Integrationspfade zuerst geprüft werden. Das ist im Multi-Tenant-Setup besonders wichtig, weil ein Fehler dort viele Mandanten gleichzeitig betreffen würde."}
{"ts": "168:35", "speaker": "I", "text": "Sie erwähnten gerade den Multi-Tenant-Aspekt – welche besonderen Risiken ergeben sich daraus für die Hera QA Platform?"}
{"ts": "168:55", "speaker": "E", "text": "Ein Hauptrisiko ist, dass ein Tenant-spezifischer Bug durch gemeinsam genutzte Komponenten propagiert wird. In Ticket QA-HER-482 haben wir so einen Fall dokumentiert, wo ein fehlerhaftes Feature-Flag nur bei einem Mandanten aktiv war, aber die Test-Pipeline den Flag-Status nicht isoliert hatte. Das führte zu falschen Positivmeldungen in den Regressionstests."}
{"ts": "169:25", "speaker": "I", "text": "Wie haben Sie diesen Fehler dann im Test-Framework adressiert?"}
{"ts": "169:45", "speaker": "E", "text": "Wir haben daraufhin im RFC-QA-312 die Mandanten-Isolation in den Testumgebungen vorgeschrieben. Das heißt, jede Testausführung bekommt jetzt ein dediziertes Tenant-Context-Setup, was in der Orchestrierung als eigener Namespace durchgezogen wird. Zusätzlich checken wir die Feature-Flag-Konfiguration gegen die in Helios gespeicherten Soll-Werte."}
{"ts": "170:15", "speaker": "I", "text": "Welche Rolle spielt dabei Nimbus Observability jetzt noch? Ziehen Sie Live-Daten für die Isolation?"}
{"ts": "170:35", "speaker": "E", "text": "Ja, partiell. Wir nutzen den Nimbus-Stream für Feature-Flag-Events, um Abweichungen zwischen Test- und Produktionsumgebungen früh zu erkennen. Das ist aber ein Trade-off, den wir in RFC-QA-221 schon dokumentiert haben, weil Live-Daten in Tests sowohl realistische Szenarien ermöglichen als auch Flakiness erhöhen können."}
{"ts": "171:00", "speaker": "I", "text": "Diese Flakiness-Problematik – gab es jüngst wieder einen Vorfall, der das verdeutlicht?"}
{"ts": "171:20", "speaker": "E", "text": "Ja, im März hatten wir QA-HER-539. Da hat ein geplanter Schema-Change im Upstream-Service während einer Testausführung eine Serie von Integrationstests fehlschlagen lassen. Der Orchestrator hat das als 'flaky' erkannt, weil die Metriken aus Nimbus gleichzeitig keine Production-Errors angezeigt haben. Wir mussten dann den Testlauf unterbrechen und die Schema-Migrations-Tests separat fahren."}
{"ts": "171:50", "speaker": "I", "text": "Das klingt nach einer bewussten Entscheidung, hier auf Time-to-Market zu achten. Wie balancieren Sie diese Abwägung?"}
{"ts": "172:10", "speaker": "E", "text": "Wir dokumentieren solche Entscheidungen immer in einem DEC-Log. Für diesen Fall hieß der Eintrag DEC-HER-2023-03-15. Dort steht, dass wir die nicht betroffenen Features wie geplant ausrollen, um den Sprint-Plan zu halten, und die betroffenen Schema-Pfade im nächsten Maintenance-Window nachziehen. Das erlaubt uns, Risiken gezielt zu isolieren statt den ganzen Release zu blockieren."}
{"ts": "172:40", "speaker": "I", "text": "Würden Sie sagen, dass sich diese Strategie bewährt hat?"}
{"ts": "173:00", "speaker": "E", "text": "Ja, in den letzten drei Quartalen konnten wir so die durchschnittliche Verzögerung pro Release von 2,4 Tagen auf unter einen Tag senken, ohne einen Anstieg kritischer Defects im Post-Release-Window zu verzeichnen. Die KPIs in unserem Quality-Dashboard, speziell MTTR und Defect Leakage Rate, bestätigen das bisher."}
{"ts": "174:00", "speaker": "I", "text": "Sie hatten vorhin RFC-QA-221 erwähnt. Können Sie bitte noch einmal ausführen, welche konkreten Risiken dort adressiert wurden, gerade in Bezug auf die Hera QA Platform?"}
{"ts": "174:12", "speaker": "E", "text": "Ja, gern. In RFC-QA-221 haben wir das Risiko bewertet, dass durch verkürzte Testzyklen im Build-Fenster kritische Regressionen durchrutschen könnten. Wir haben deshalb im Runbook RB-HER-07 eine Eskalationskette definiert, um bei detektierten Sev-1-Defects innerhalb von vier Stunden reagieren zu können."}
{"ts": "174:31", "speaker": "I", "text": "Das klingt nach einem straffen Zeitplan. Gab es dabei ein Abwägen gegen die Testabdeckung?"}
{"ts": "174:40", "speaker": "E", "text": "Definitiv. Wir haben in der Build-Phase die Abdeckung bei Low-Risk-Modulen temporär auf 65 % reduziert, um die kritischen Pfade – etwa die Orchestrierungs-Engine und die Traceability-Mappings – mit 95 % zu sichern."}
{"ts": "174:58", "speaker": "I", "text": "Wie wird diese Entscheidung dokumentiert, abgesehen vom RFC?"}
{"ts": "175:05", "speaker": "E", "text": "Neben dem RFC pflegen wir ein Decision Log im Confluence-Space HER-QA, verlinkt mit den entsprechenden JIRA-Tickets wie HER-7821. Dort steht auch, welche SLAs temporär angepasst wurden."}
{"ts": "175:22", "speaker": "I", "text": "Können Sie ein Beispiel für eine solche SLA-Anpassung nennen?"}
{"ts": "175:30", "speaker": "E", "text": "Sicher. Für die Build-Phase haben wir den SLA für das Beheben von Medium-Severity Bugs von 48 auf 72 Stunden verlängert, um die Testautomation nicht zu unterbrechen. Das war in SLA-Dokument SLA-HER-03 festgehalten."}
{"ts": "175:50", "speaker": "I", "text": "Gab es dazu kritisches Feedback aus anderen Projekten, etwa Helios Datalake?"}
{"ts": "176:00", "speaker": "E", "text": "Ja, Helios-Teams äußerten Bedenken, weil Abhängigkeiten zu deren ETL-Tests bestehen. Wir haben daraufhin im Ticket HEL-HER-115 eine temporäre Synchronisation der Deploy-Fenster vereinbart."}
{"ts": "176:18", "speaker": "I", "text": "Wie stellen Sie sicher, dass solche temporären Absprachen nicht untergehen?"}
{"ts": "176:27", "speaker": "E", "text": "Wir führen einen Abschnitt 'Temporary Agreements' im Runbook RB-HER-Coord ein, der vor jedem Sprint Planning aktualisiert wird. Dort sind auch Ablaufdaten vermerkt."}
{"ts": "176:44", "speaker": "I", "text": "Zum Abschluss: Welche Lessons Learned ziehen Sie aus dieser Phase?"}
{"ts": "176:52", "speaker": "E", "text": "Wir haben gelernt, dass eine enge Dokumentation von Trade-offs die Akzeptanz erhöht. Außerdem, dass Observability-Metriken wie Error Budget Consumption helfen, Prioritäten anzupassen, ohne lange Abstimmungsschleifen."}
{"ts": "177:08", "speaker": "I", "text": "Würden Sie in der nächsten Phase wieder ähnliche Abwägungen treffen?"}
{"ts": "177:16", "speaker": "E", "text": "Nur selektiv. Wir planen, für Low-Risk-Module gezieltere Smoke-Tests zu implementieren, um Abdeckungseinbußen kleiner zu halten. Das wird in der kommenden RFC-QA-237 spezifiziert."}
{"ts": "180:00", "speaker": "I", "text": "Zum Abschluss würde ich gern nochmal auf die dokumentierten Risiken zurückkommen, speziell jene, die Sie in RFC-QA-221 vermerkt haben."}
{"ts": "180:20", "speaker": "E", "text": "Ja, darin haben wir klar benannt, dass wir bei der Hera QA Platform bewusst eine reduzierte Regression-Suite in Kauf genommen haben, um das Build-Fenster von 9 auf 5 Stunden zu drücken."}
{"ts": "180:45", "speaker": "I", "text": "Wurde dieses Risiko in irgendeiner Form durch zusätzliche Monitoring-Maßnahmen abgefedert?"}
{"ts": "181:05", "speaker": "E", "text": "Genau, wir haben im Runbook RB-HERA-OPS-07 festgehalten, dass kritische Pfade nach Deployment automatisiert über den Nimbus Observability Stream überwacht werden, mit SLA-basierten Alerts innerhalb von 90 Sekunden."}
{"ts": "181:30", "speaker": "I", "text": "Gab es schon Fälle, wo diese Alerts tatsächlich einen Defekt früher entdeckt haben als klassische Tests?"}
{"ts": "181:48", "speaker": "E", "text": "Ja, Ticket QA-INC-5423 beschreibt so einen Fall: Ein Upstream-API-Feld wurde umbenannt, was in unseren reduzierten Tests nicht abgedeckt war, aber die Latenz-Metrik im Live-Monitoring sprang sofort an."}
{"ts": "182:15", "speaker": "I", "text": "Interessant. Wie gehen Sie in so einem Incident dann vor, dokumentationsseitig?"}
{"ts": "182:33", "speaker": "E", "text": "Wir aktualisieren sowohl das Runbook als auch die Testfall-Mapping-Tabelle. Im konkreten Fall haben wir einen neuen Smoke-Test für das betroffene Feld erstellt, verlinkt über Trace-ID T-HERA-9987."}
{"ts": "182:58", "speaker": "I", "text": "Und wie priorisieren Sie, ob ein neuer Smoke-Test oder ein vollständiger Regression-Test ergänzt wird?"}
{"ts": "183:16", "speaker": "E", "text": "Das folgt unserer internen Heuristik aus POL-QA-014: Wenn der Defekt in einem hochfrequent genutzten Pfad liegt und die Ausfallkosten > 10k€ pro Stunde liegen, geht er sofort in die Smoke-Suite."}
{"ts": "183:40", "speaker": "I", "text": "Könnte es sein, dass diese schnelle Ergänzung wiederum das Build-Fenster wieder verlängert?"}
{"ts": "184:00", "speaker": "E", "text": "Ja, das ist der Trade-off. Wir haben in RFC-QA-224 festgehalten, dass die Smoke-Suite eine harte Obergrenze von 45 Minuten haben darf, sonst müssen wir Tests auf Wochenend-Builds verschieben."}
{"ts": "184:25", "speaker": "I", "text": "Verstehe, also ein ständiges Austarieren zwischen Abdeckung und Zeitbudget."}
{"ts": "184:38", "speaker": "E", "text": "Genau, und dabei hilft uns auch ein Scorecard-System, das jede Testfalländerung mit einem Impact-Score versieht, damit wir objektiver entscheiden können."}
{"ts": "185:00", "speaker": "I", "text": "Wie fließt diese Scorecard in die Lessons Learned ein, die Sie für die nächste Projektphase ziehen?"}
{"ts": "185:18", "speaker": "E", "text": "Wir sehen darin Trends, z. B. dass viele High-Impact-Tests aus Observability-Alerts generiert werden. Für die nächste Phase planen wir, diese Generierung halbautomatisch zu machen."}
{"ts": "188:00", "speaker": "I", "text": "Könnten Sie bitte noch einmal konkret beschreiben, wie genau Sie die Daten aus Nimbus Observability in der Hera QA Platform nutzen?"}
{"ts": "188:15", "speaker": "E", "text": "Ja, klar. Wir ziehen in der Build-Phase Metriken wie Response-Zeiten und Error-Rates direkt über die OBC-API, also die Observability Core API, und legen sie dann als Parameter in unseren Test-Orchestrator. So können wir beispielsweise End-to-End-Tests gezielt gegen Services fahren, die in den letzten 24 Stunden in den P90- und P99-Latenzen auffällig waren."}
{"ts": "188:36", "speaker": "I", "text": "Und diese Auswahl passiert automatisiert, oder müssen Sie da manuell eingreifen?"}
{"ts": "188:44", "speaker": "E", "text": "Automatisiert zu etwa 80 %. Wir haben im Runbook RB-HER-07 beschrieben, welche Schwellenwerte das Orchestrierungsmodul triggert. Wenn z. B. die Error-Rate von Service X über 1,2 % steigt, wird automatisch ein fokussierter Regressionstestplan erstellt."}
{"ts": "189:05", "speaker": "I", "text": "Gab es Situationen, in denen diese Automatisierung fehlschlug?"}
{"ts": "189:15", "speaker": "E", "text": "Ja, in Ticket QA-INC-482 hatten wir den Fall, dass fehlerhafte Metrikdaten aus Nimbus zu einer Überlast von Testumgebungen führten. Wir haben danach einen manuellen Review-Step eingeführt, der bei extremer Abweichung eine Bestätigung durch den Test Lead verlangt."}
{"ts": "189:37", "speaker": "I", "text": "Wie wirkt sich das auf Ihre Time-to-Market-Ziele aus?"}
{"ts": "189:46", "speaker": "E", "text": "Minimal, weil dieser Review nur bei 3–5 % der Runs nötig ist. Die restlichen 95 % laufen weiter vollautomatisch. Das war auch ein Trade-off, den wir in RFC-QA-221 abgewogen und dokumentiert haben: leicht höhere Latenz in Ausnahmefällen gegen Stabilität der Testumgebung."}
{"ts": "190:10", "speaker": "I", "text": "Können Sie noch auf ein Multi-Service-Szenario eingehen, bei dem eine Änderung upstream mehrere Testpläne beeinflusst hat?"}
{"ts": "190:20", "speaker": "E", "text": "Klar. Beim Deployment von Helios Datalake v4.2 hat sich das JSON-Schema für den Event-Stream geändert. Das hat nicht nur die Tests im Hera-Projekt für das Data-Ingest-Modul betroffen, sondern auch zwölf End-to-End-Flows, die auf diesen Stream hören. Wir mussten also über die Traceability-Matrix TCM-HER-11 automatisch alle abhängigen Testfälle markieren und neu einplanen."}
{"ts": "190:47", "speaker": "I", "text": "Wie schnell konnten Sie da reagieren?"}
{"ts": "190:54", "speaker": "E", "text": "Innerhalb von 4 Stunden nach Erkennen der Schemaänderung. Das SLA für kritische Testfallanpassungen liegt laut POL-QA-014 bei maximal 6 Stunden, also waren wir deutlich drunter."}
{"ts": "191:10", "speaker": "I", "text": "Sie erwähnten vorhin die Priorisierung nach Risiko – hat sich dieses Prinzip hier bewährt?"}
{"ts": "191:18", "speaker": "E", "text": "Ja, absolut. Wir haben zuerst die Flows mit höchster Geschäftsrelevanz angepasst, um kritische Datenverarbeitungen nicht zu gefährden. Niedriger priorisierte Tests, z. B. für Reporting-Features, wurden erst am Folgetag aktualisiert."}
{"ts": "191:36", "speaker": "I", "text": "Gibt es auf Basis dieser Erfahrungen geplante Anpassungen an der Orchestrierung?"}
{"ts": "191:45", "speaker": "E", "text": "Wir planen, im nächsten Sprint die Orchestrierung so zu erweitern, dass Schema-Änderungen aus Helios-Deployments proaktiv über einen Webhook an Hera gemeldet werden. Das würde den manuellen Erkennungsaufwand komplett eliminieren und unsere SLA-Zeiten weiter verbessern."}
{"ts": "195:00", "speaker": "I", "text": "Könnten Sie mir bitte ein konkretes Beispiel geben, wie Observability-Daten aus Nimbus Ihre Testentscheidungen beeinflusst haben?"}
{"ts": "195:15", "speaker": "E", "text": "Ja, zum Beispiel hatten wir im April einen Anstieg der Latenzen im Payment-Microservice. Die Logs und Metriken aus Nimbus haben uns gezeigt, dass sich dies nur unter bestimmten Lastmustern zeigte. Daraufhin haben wir in Hera einen gezielten Lasttest mit diesen Mustern orchestriert."}
{"ts": "195:40", "speaker": "I", "text": "Interessant, und wie haben Sie das in der Testplanung abgebildet?"}
{"ts": "195:55", "speaker": "E", "text": "Wir haben einen neuen Testfall in der Suite 'Perf-Payment-Pattern' angelegt, mit Referenz auf Ticket QA-5632. Im Runbook RB-HERA-17 ist dokumentiert, wie wir die Observability-Daten exportieren und in die Testdaten-Generierung einspeisen."}
{"ts": "196:20", "speaker": "I", "text": "Gab es auch Fälle, wo Änderungen im Helios Datalake Ihre Tests beeinflusst haben?"}
{"ts": "196:35", "speaker": "E", "text": "Ja, im Juni wurde in Helios das Schema des Event-Streams 'OrderCreated' geändert. Unsere Traceability-Matrix hat sofort mehrere abhängige Tests in Hera markiert. Wir mussten die Mapper-Komponente im Testdaten-Injector anpassen."}
{"ts": "196:58", "speaker": "I", "text": "Wie schnell konnten Sie darauf reagieren?"}
{"ts": "197:12", "speaker": "E", "text": "Durch den orchestrierten CI-Trigger: Innerhalb von 4 Stunden hatten wir die neuen Feldnamen in den Testfällen aktualisiert. Unser SLA für kritische Upstream-Änderungen liegt bei 8 Stunden, also waren wir deutlich schneller."}
{"ts": "197:35", "speaker": "I", "text": "Sie hatten RFC-QA-221 erwähnt. Können Sie den größten Trade-off daraus nochmal zusammenfassen?"}
{"ts": "197:50", "speaker": "E", "text": "Klar, RFC-QA-221 beschreibt unsere Entscheidung, dynamische Testumgebungen nur für Hochrisiko-Komponenten zu nutzen. Wir verzichten bewusst auf volle Testabdeckung in Low-Risk-Bereichen, um Build-Zeiten um 35% zu reduzieren."}
{"ts": "198:15", "speaker": "I", "text": "Gab es dafür konkrete Risiken, die Sie akzeptiert haben?"}
{"ts": "198:28", "speaker": "E", "text": "Ja, wir nehmen in Kauf, dass in seltenen Fällen ein Low-Risk-Service mit einem Minor-Bug in Produktion geht. Laut unserer Risikoanalyse POL-QA-014 ist das vertretbar, solange der MTTR unter 2 Stunden bleibt."}
{"ts": "198:50", "speaker": "I", "text": "Und wie dokumentieren Sie solche Entscheidungen für das Team?"}
{"ts": "199:05", "speaker": "E", "text": "Neben dem RFC legen wir im Confluence-Bereich 'Hera QA Decisions' pro Fall eine Kurzbeschreibung mit Impact-Analyse ab. Ein Beispiel: Decision-Log-Eintrag DL-2023-07-14 mit den Metriken zu Build-Zeit und entfallenem Coverage."}
{"ts": "199:28", "speaker": "I", "text": "Sehen Sie Anzeichen, dass dieser Trade-off in der nächsten Phase angepasst werden muss?"}
{"ts": "199:43", "speaker": "E", "text": "Wir beobachten aktuell eine leichte Zunahme von Minor-Bugs in Low-Risk-Services. Falls der Trend anhält, könnte in der nächsten Phase eine moderate Coverage-Erhöhung sinnvoll sein, wie schon in unserem Lessons-Learned-Dokument LL-HERA-05 angedeutet."}
{"ts": "204:00", "speaker": "I", "text": "Zum Abschluss möchte ich nochmal auf die SLA-Verpflichtungen eingehen. Wie stellen Sie sicher, dass die Hera QA Platform diese auch in Spitzenlastzeiten erfüllt?"}
{"ts": "204:15", "speaker": "E", "text": "Wir haben im Runbook RB-HER-OPS-032 genau definiert, wie wir bei Lastspitzen vorgehen. Das umfasst automatische Skalierung der Test-Executors und eine Priorisierung kritischer Test-Suiten, basierend auf ihrer Risikoeinstufung laut POL-QA-014."}
{"ts": "204:36", "speaker": "I", "text": "Und wie wird das in der Praxis getriggert? Gibt es dafür automatisierte Schwellenwerte?"}
{"ts": "204:50", "speaker": "E", "text": "Ja, wir nutzen Metriken aus dem internen Monitoring-Service Orbis. Sobald die Queue-Länge für Testjobs einen Wert von 250 überschreitet, löst ein Alert aus, Ticket-Typ 'HER-AL-ScaleUp', und Kubernetes skaliert die Worker-Pods hoch."}
{"ts": "205:12", "speaker": "I", "text": "Gab es Situationen, in denen diese Skalierung nicht rechtzeitig gegriffen hat?"}
{"ts": "205:26", "speaker": "E", "text": "Einmal, im Dezember, während eines simultanen Upstream-Deployments im Helios Datalake. Da hatten wir eine Verzögerung von knapp 8 Minuten, weil der Scale-Up-Webhook wegen einer Namespacelimitierung blockiert war. Das haben wir danach in RFC-HER-078 dokumentiert."}
{"ts": "205:52", "speaker": "I", "text": "Das klingt nach einem klaren Schnittpunkt zwischen Plattform- und Infrastrukturthemen. Wie adressieren Sie solche Abhängigkeiten künftig?"}
{"ts": "206:08", "speaker": "E", "text": "Wir haben nach diesem Vorfall in unser Release-Gating zusätzliche Checks eingebaut, die den Namespace-Quota-Status abfragen. Außerdem ist nun ein manueller Override im Runbook beschrieben, falls die Automatisierung versagt."}
