{"ts": "00:00", "speaker": "I", "text": "Können Sie mir kurz den aktuellen Build-Status des Orion Edge Gateway schildern und auch, äh, wie weit sind wir noch vom Feature Freeze entfernt?"}
{"ts": "04:15", "speaker": "E", "text": "Ja, also derzeit sind wir bei etwa 85 % der geplanten Features; die Core API Gateway Komponente läuft stabil in unserer Staging-Umgebung. The remaining parts are mainly the advanced rate limiting module and the final auth integration tests."}
{"ts": "08:40", "speaker": "I", "text": "Welche Kernaufgaben haben Sie im Rahmen der API Gateway Implementierung übernommen?"}
{"ts": "13:05", "speaker": "E", "text": "Ich war primär für die Definition der Kong-basierten Gateway-Konfiguration zuständig, inklusive der Custom Plugins für mTLS und JWT. I also coordinated the integration with the Aegis IAM for token introspection."}
{"ts": "17:40", "speaker": "I", "text": "How does your work tie into the SLA-ORI-02 p95 Latency unter 120 ms target?"}
{"ts": "22:00", "speaker": "E", "text": "We measure latency in our synthetic load tests; ich habe gezielt die Plugin-Chain optimiert, so dass nur noch zwei Auth-Filter sequentiell laufen. That reduced p95 from ~150 ms down to 112 ms on average."}
{"ts": "26:30", "speaker": "I", "text": "Welche IaC-Tools setzen Sie für die Gateway-Infrastruktur ein und warum?"}
{"ts": "31:05", "speaker": "E", "text": "Wir verwenden Terraform für die Cloud-Ressourcen und Ansible für die Gateway-Node-Konfiguration. Terraform gives us reproducible infra, Ansible lets us push config changes quickly to blue/green clusters."}
{"ts": "35:25", "speaker": "I", "text": "Can you walk me through your blue/green deployment process as per RB-GW-011?"}
{"ts": "40:00", "speaker": "E", "text": "Sure, RB-GW-011 beschreibt, dass wir zuerst das Green Cluster mit der neuen Config hochfahren, volle Canary Tests fahren, dann Traffic via DNS umschwenken. Danach beobachten wir 15 Minuten die Metriken, bevor Blue abgeschaltet wird."}
{"ts": "44:35", "speaker": "I", "text": "Wie stellen Sie sicher, dass Änderungen im Auth-Integrationsteil nicht die Rate-Limits verletzen?"}
{"ts": "49:15", "speaker": "E", "text": "Wir haben im CI-Pipeline einen Lasttestschritt, der Auth-Requests mit simulierten Bursts schickt. The scripts read the configured limits from the same config repo, so mismatches are caught early."}
{"ts": "53:45", "speaker": "I", "text": "Mit welchen anderen Projekten wie Aegis IAM oder Nimbus Observability gibt es, äh, kritische Abhängigkeiten?"}
{"ts": "58:25", "speaker": "E", "text": "Aegis IAM liefert uns die Access Tokens, without it the gateway can't authorize. Nimbus Observability integriert direkt mit unseren Prometheus Exportern, um SLA-ORI-02 Metriken zentral zu erfassen."}
{"ts": "62:50", "speaker": "I", "text": "How do you propagate mTLS handshake fixes from GW-4821 into production without breaching SLAs?"}
{"ts": "67:30", "speaker": "E", "text": "We treat mTLS as a hotfix category; gemäß RB-GW-011 wird ein Patch im Green Cluster deployed, parallel läuft Load-Verification. Then we do a rolling DNS cut-over during our low-traffic window to avoid p95 spikes."}
{"ts": "90:00", "speaker": "I", "text": "Sie hatten vorhin den mTLS-Fix GW-4821 erwähnt. Können Sie bitte genauer erklären, wie Sie den in die Produktionskette bringen, ohne das SLA-ORI-02 zu verletzen?"}
{"ts": "90:09", "speaker": "E", "text": "Ja, also wir nutzen dafür einen gestaffelten Rollout in drei Waves, kombiniert mit Canary-Nodes. First Wave geht nur auf zwei Edge-Knoten im Staging-Cluster, danach messen wir die Latenz mit Nimbus Observability Hooks – wenn p95 unter 115 ms bleibt, pushen wir Wave 2. Auf diese Weise vermeiden wir SLA-Breaches."}
{"ts": "90:22", "speaker": "I", "text": "Und wie stimmen Sie das mit dem Security-Team für POL-SEC-001 Least Privilege ab?"}
{"ts": "90:30", "speaker": "E", "text": "Wir haben einen festen Review-Slot jeden Dienstag. Dort checken wir die Role-Bindings aus dem Aegis IAM gegen POL-SEC-001. Any exceptions müssen in Ticket SEC-2043 dokumentiert werden, inklusive Begründung und Ablaufdatum."}
{"ts": "90:44", "speaker": "I", "text": "Gab es denn schon mal einen Fall, wo Sie RB-GW-011 unter starkem Zeitdruck einsetzen mussten?"}
{"ts": "90:51", "speaker": "E", "text": "Ja, im März, Incident INC-GW-771. Rate Limiter Module hat falsche Quoten ausgeliefert. Laut RB-GW-011 mussten wir sofort auf das Blue-Fleet Deployment zurückschwenken. Das ging innerhalb von 4 Minuten, aber nur, weil wir die IaC-Statefiles aktuell hatten."}
{"ts": "91:04", "speaker": "I", "text": "When the runbook doesn't quite fit the failure, what heuristics do you apply?"}
{"ts": "91:11", "speaker": "E", "text": "Rule of thumb: contain impact first, then diagnose. Also, I check if any recent commits touched the auth or rate-limiting code paths — those are high-risk. If nothing obvious, we apply a safe config rollback."}
{"ts": "91:24", "speaker": "I", "text": "Welche Lessons Learned haben Sie aus dem letzten Major Incident gezogen?"}
{"ts": "91:30", "speaker": "E", "text": "Dass unser Observability-Alert zu spät kam, weil das Sampling zu niedrig war. Wir haben daraufhin RFC-OBS-219 aus Nimbus übernommen, Sampling Rate auf 20 % erhöht und die Alerts in Grafana EdgeDash angepasst."}
{"ts": "91:44", "speaker": "I", "text": "Wie messen Sie aktuell in der Build-Phase die Einhaltung des p95 Latenz-SLOs?"}
{"ts": "91:50", "speaker": "E", "text": "Wir fahren synthetische Lasttests über k6-Skripte in der CI-Pipeline, mit Thresholds direkt an SLA-ORI-02 gebunden. Ergebnisse werden in Build-Artifact Latenz-Report abgelegt, ID per Commit-Hash."}
{"ts": "92:03", "speaker": "I", "text": "Have you tried request sampling strategies like RFC-1114 from Nimbus Observability?"}
{"ts": "92:10", "speaker": "E", "text": "Yes, partially. We implemented adaptive sampling: bei hoher Error-Rate werden mehr Requests geloggt. Das reduziert Overhead in Normalbetrieb und gibt uns im Störfall bessere Daten."}
{"ts": "92:22", "speaker": "I", "text": "Welche Trade-offs mussten Sie zwischen Sicherheit und Latenz eingehen?"}
{"ts": "92:28", "speaker": "E", "text": "Wir haben z. B. beim mTLS-Handshake die Schlüsselgröße von 4096 auf 3072 bit reduziert. Das war ein Kompromiss aus Security-Team-Sicht vertretbar, brachte aber 8 ms Latenzgewinn pro Request laut PERF-GW-007."}
{"ts": "98:00", "speaker": "I", "text": "Kommen wir jetzt zu den Incidents – können Sie einen konkreten Fall beschreiben, in dem Sie RB-GW-011 unter starkem Zeitdruck anwenden mussten?"}
{"ts": "98:07", "speaker": "E", "text": "Ja, das war beim Vorfall GW-INC-237 letzten Monat. Wir hatten plötzliche Latenzspikes über 300 ms, und laut SLA-ORI-02 durften wir nicht über 120 ms p95 gehen. Also habe ich direkt das Blue/Green-Prozedere aus RB-GW-011 gestartet, um den fehlerhaften Build gegen die vorherige stabile Version auszutauschen."}
{"ts": "98:21", "speaker": "I", "text": "And when the runbook didn’t cover the exact failure mode, how did you proceed?"}
{"ts": "98:27", "speaker": "E", "text": "We applied an unwritten heuristic – wir checken zuerst die Upstream-Dependencies wie Aegis IAM Token-Lifetime und Nimbus Observability sampling rates. Wenn beide normal sind, dann gehen wir tiefer ins mTLS Handshake Debugging, using the GW-4821 patch notes as a reference."}
{"ts": "98:44", "speaker": "I", "text": "Interessant. Welche Lessons Learned haben Sie aus diesem Major Incident gezogen?"}
{"ts": "98:48", "speaker": "E", "text": "Zum einen, dass wir im IaC-Template sofort Fallback-Pfade definieren müssen, um Latenzspitzen schneller zu mitigieren. Zum anderen, dass unsere Observability-Alerts feiner abgestuft werden müssen – wir haben danach ein Draft-RFC-212 für adaptive Alert Thresholds erstellt."}
{"ts": "99:05", "speaker": "I", "text": "Wie messen Sie aktuell in der Build-Phase die Einhaltung des p95 Latenz-SLOs?"}
{"ts": "99:09", "speaker": "E", "text": "Wir nutzen eine Kombination aus synthetischen Tests in der Staging-Umgebung und Live-Traffic-Replays. Die Metriken laufen in Nimbus Observability, und wir haben ein spezielles Dashboard 'GW-SLO-Perf' angelegt, das im 5-Sekunden-Takt refreshed wird."}
{"ts": "99:24", "speaker": "I", "text": "Have you experimented with request sampling strategies similar to RFC-1114 from Nimbus Observability?"}
{"ts": "99:30", "speaker": "E", "text": "Yes, wir haben ein Sampling auf 1% Low-Traffic-Endpunkte gefahren, um Latenzanomalien früh zu erkennen. Das hat allerdings den Overhead erhöht, daher mussten wir in Ticket GW-OPT-56 einen Trade-off dokumentieren: weniger Sampling in Peak-Zeiten, um die CPU-Load zu senken."}
{"ts": "99:47", "speaker": "I", "text": "Welche Trade-offs mussten Sie allgemein zwischen Sicherheit und Latenz eingehen?"}
{"ts": "99:51", "speaker": "E", "text": "Wir haben etwa beim mTLS-Handshake die Cipher-Suite leicht angepasst – von TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 auf eine Suite mit etwas schnellerer Handshake-Zeit. Dokumentiert in RFC-GW-SEC-09, mit Abweichung von POL-SEC-001 begründet und vom Security-Team freigegeben."}
{"ts": "100:08", "speaker": "I", "text": "Welche größten Risiken sehen Sie für die Go-Live-Phase?"}
{"ts": "100:12", "speaker": "E", "text": "Hauptsächlich eine mögliche Unterdimensionierung der Rate-Limit-Komponente, sollte Traffic von Partnerdiensten höher ausfallen als prognostiziert. Außerdem Risiken bei der Synchronisierung von Aegis IAM Token-Revocations in Echtzeit."}
{"ts": "100:25", "speaker": "I", "text": "Can you reference any tickets or RFCs that influenced a major architectural change?"}
{"ts": "100:30", "speaker": "E", "text": "Sure – Ticket GW-ARCH-72 führte zu einer Umstellung auf ein Sidecar-basiertes Auth-Modul, nachdem RFC-ORION-07 gezeigt hat, dass Inline-Auth den Throughput um 15% reduziert. Diese Entscheidung wurde im Architektur-Logbuch AL-ORI-2024-03 dokumentiert."}
{"ts": "102:00", "speaker": "I", "text": "Lassen Sie uns nochmal auf RB-GW-011 zurückkommen. Wie haben Sie das im letzten Incident umgesetzt, wo der Auth-Cache plötzlich kollabierte?"}
{"ts": "102:20", "speaker": "E", "text": "Ja, das war der Fall am 14.03., Ticket INC-GW-7754. We followed the blue/green process steps in RB-GW-011, Abschnitt 3.2, und mussten improvisieren, weil die Cache-Wiederherstellung länger dauerte als im Runbook angenommen."}
{"ts": "102:45", "speaker": "I", "text": "Sie sagten improvisieren – welche Heuristiken kamen da ins Spiel, die nicht dokumentiert waren?"}
{"ts": "103:02", "speaker": "E", "text": "Wir haben ein inoffizielles Muster, 'gradual drain', bei dem wir 10% des Traffics zurück auf das grüne Cluster leiten, um zu testen. That’s not in RB-GW-011 yet, but it helped keep p95 latency under 125ms in that scenario."}
{"ts": "103:28", "speaker": "I", "text": "Und wie messen Sie die Latenz in so einer Live-Situation?"}
{"ts": "103:41", "speaker": "E", "text": "Wir nutzen ein kombiniertes Dashboard aus Nimbus Observability mit einem speziellen p95-Widget, plus CLI-Snippets aus Tool 'lat_snap'. In Build-Phase tracken wir jede 30s-Periode, um SLA-ORI-02 zu verifizieren."}
{"ts": "104:05", "speaker": "I", "text": "Have you tried any request sampling strategies, maybe like RFC-1114 describes?"}
{"ts": "104:18", "speaker": "E", "text": "Ja, wir haben RFC-1114 als Basis genommen, aber angepasst: nur 5% der Requests werden deep-traced, um Overhead zu minimieren. This was a trade-off between observability detail and latency impact."}
{"ts": "104:39", "speaker": "I", "text": "Gab es einen Moment, wo Sicherheit und Latenz wirklich in Konflikt standen?"}
{"ts": "104:52", "speaker": "E", "text": "Definitiv – beim mTLS Handshake Patch GW-4821. Wir mussten entscheiden: sofort deployen und +15ms Latenz riskieren oder verzögern. Wir haben mit Security und Ops abgestimmt und laut RFC-GW-SEC-09 den Fix gestaffelt ausgerollt."}
{"ts": "105:20", "speaker": "I", "text": "Welche Evidenz haben Sie dokumentiert, um diese Entscheidung audit-ready zu machen?"}
{"ts": "105:34", "speaker": "E", "text": "Wir haben das in DEC-GW-2022-09 erfasst, mit Metrics-Screenshots, Slack-Threads und dem Approval-Log des Security Leads. This way, we meet POL-AUD-004 requirements."}
{"ts": "105:55", "speaker": "I", "text": "Wie fließen solche Lessons Learned dann zurück ins Runbook?"}
{"ts": "106:08", "speaker": "E", "text": "Nach jedem Major Incident erstellen wir ein Runbook-Update-Ticket, z. B. RBUP-GW-77, und planen es ins nächste Sprint. Gradual drain kommt jetzt in RB-GW-011 Abschnitt 4.4."}
{"ts": "106:28", "speaker": "I", "text": "Gibt es noch offene Risiken für Go-Live aus Ihrer Sicht?"}
{"ts": "106:42", "speaker": "E", "text": "Ja, das größte Risiko ist die Cross-Region Replication Latenz bei Peak Load. We’re monitoring via Nimbus alerts, und wir haben ein Fallback per Feature Flag vorbereitet, siehe TKT-GW-9011."}
{"ts": "118:00", "speaker": "I", "text": "Lassen Sie uns noch etwas tiefer in die Lessons Learned aus dem letzten Major Incident eintauchen. Gab es bestimmte Änderungen an RB-GW-011, die Sie direkt danach eingepflegt haben?"}
{"ts": "118:06", "speaker": "E", "text": "Ja, wir haben im Runbook den Abschnitt zu mTLS-Reconnects erweitert. Vorher stand da nur ein generischer Retry-Loop, jetzt verweisen wir konkret auf das Fix-Skript aus Ticket GW-4821 und definieren Timeout-Werte, um nicht das SLA-ORI-02 zu reißen."}
{"ts": "118:14", "speaker": "I", "text": "Und wie stellen Sie sicher, dass diese Anpassungen auch im CI/CD-Prozess landen und nicht nur lokal dokumentiert sind?"}
{"ts": "118:20", "speaker": "E", "text": "We push them into the IaC repo as part of the 'ops' module, so during pipeline execution, the latest runbook artefacts are bundled into the deployment image. Außerdem gibt es ein Checkscript, das vor Go-Live prüft, ob die Runbook-Version mit der in der Pipeline übereinstimmt."}
{"ts": "118:28", "speaker": "I", "text": "Könnten Sie ein Beispiel geben, wie diese Runbook-Integration half, ein Problem schneller zu lösen?"}
{"ts": "118:34", "speaker": "E", "text": "During the last blue/green swap, node G-17 didn't pick up the new auth cert. Dank der neuen Runbook-Section konnten wir sofort das GW-4821-Skript ausführen und den Node innerhalb von drei Minuten wieder ins Cluster bringen."}
{"ts": "118:42", "speaker": "I", "text": "Sie erwähnten vorhin den Trade-off zwischen Security und Latenz – hat sich daran seit dem letzten Tuning etwas geändert?"}
{"ts": "118:48", "speaker": "E", "text": "Minimal. Wir haben in RFC-ORIGW-09 dokumentiert, dass wir für interne Service-zu-Service Calls weaker cipher suites zulassen, um unter 120ms p95 zu bleiben, aber nur, wenn POL-SEC-001 Kriterien wie Least Privilege erfüllt sind."}
{"ts": "118:56", "speaker": "I", "text": "Wie evaluieren Sie laufend, ob diese schwächeren Cipher Suites nicht plötzlich ein Risiko darstellen?"}
{"ts": "119:02", "speaker": "E", "text": "Wir fahren wöchentliche Security-Scans über das Nimbus Observability Modul, mit einem speziellen Check für Cipher Strength. Falls das Rating unter 'B' fällt, triggert das automatisch ein Jira Ticket vom Typ SEC-ALERT."}
{"ts": "119:10", "speaker": "I", "text": "Interesting. Und wie binden Sie das Observability-Team in solche Entscheidungen ein?"}
{"ts": "119:16", "speaker": "E", "text": "Wir haben einen festen Sync alle zwei Wochen. Dort bringen wir Performance Charts, SLA Violations und Security Findings zusammen. Das Observability-Team prüft dann, ob Sampling-Strategien aus RFC-1114 angepasst werden müssen, um Anomalien schneller zu sehen."}
{"ts": "119:24", "speaker": "I", "text": "Gab es dabei schon einmal einen Konflikt zwischen den Teams?"}
{"ts": "119:30", "speaker": "E", "text": "Ja, im März. Das Observability-Team wollte die Sampling-Rate von 10% auf 25% erhöhen, um eine Auth-Latenzanomalie zu untersuchen. Wir mussten aber ablehnen, da das in Peak-Zeiten die Latenz um ~8ms erhöht hätte, was uns gefährlich nah an das SLA-ORI-02 Limit bringt."}
{"ts": "119:40", "speaker": "I", "text": "Wie wurde der Konflikt gelöst?"}
{"ts": "119:46", "speaker": "E", "text": "We agreed on a conditional sampling bump: nur bei Detektion bestimmter Error Codes (5xx im Auth-Pfad) wird temporär auf 25% erhöht. That kept latency safe most of the time, yet gave them the granularity during incidents."}
{"ts": "120:00", "speaker": "I", "text": "Lassen Sie uns noch mal auf die Abhängigkeiten eingehen – speziell, wie Sie die mTLS-Handshake-Fixes aus GW-4821 in Prod gebracht haben, ohne SLAs zu verletzen."}
{"ts": "120:12", "speaker": "E", "text": "Ja, das war tricky. Wir haben damals einen Canary-Release gemacht, parallel mit einem Shadow-Traffic-Setup. That allowed us to validate the fix under real load while isolating risk."}
{"ts": "120:28", "speaker": "I", "text": "Und wie haben Sie den Shadow-Traffic technisch umgesetzt?"}
{"ts": "120:39", "speaker": "E", "text": "Wir haben in Terraform ein zusätzliches Target Group Binding definiert, in dem wir den Traffic dupliziert haben. Using Envoy's tap filter feature, konnten wir SSL handshakes trace-en."}
{"ts": "120:55", "speaker": "I", "text": "Interessant. War das in RB-GW-011 dokumentiert oder eher ein Ad-hoc-Ansatz?"}
{"ts": "121:05", "speaker": "E", "text": "Teilweise dokumentiert – die Canary-Pattern sind drin, aber das Shadowing war ein improvisierter Workaround. We've since added it to RB-GW-015 for handshake issues."}
{"ts": "121:20", "speaker": "I", "text": "Gab es dabei Konflikte mit Aegis IAM Policies, z. B. POL-SEC-001?"}
{"ts": "121:31", "speaker": "E", "text": "Ja, weil Shadow-Traffic auch Auth-Tokens mitführt. We had to mask sensitive headers in-flight, mittels Lua-Script im Envoy, to still comply with least privilege."}
{"ts": "121:49", "speaker": "I", "text": "Haben Sie diese Header-Maskierung getestet gegen die Rate-Limits?"}
{"ts": "122:00", "speaker": "E", "text": "Genau, wir haben synthetic load runs gefahren. The masking added ~3ms per request, well within SLA-ORI-02 budget."}
{"ts": "122:14", "speaker": "I", "text": "Klingt, als hätten Sie hier ein gutes Multi-Hop-Testing zwischen Gateway, IAM und Observability hinbekommen."}
{"ts": "122:25", "speaker": "E", "text": "Ja, war koordinativ aufwendig. We scheduled joint test windows with Nimbus Observability to ensure metrics propagation was intact despite header changes."}
{"ts": "122:42", "speaker": "I", "text": "Gab es Erkenntnisse, wie Sie die Tests in Zukunft optimieren würden?"}
{"ts": "122:53", "speaker": "E", "text": "Wir planen, das Shadowing permanent als Feature Flag in CI/CD zu halten. That way, enabling it for a hotfix won't require infra changes."}
{"ts": "123:08", "speaker": "I", "text": "Und wie dokumentieren Sie solche Entscheidungen für die Audit-Readiness?"}
{"ts": "123:20", "speaker": "E", "text": "Wir erstellen ein DEC-Record in Confluence, mit Verweis auf Ticket GW-4821 und das ergänzende RFC-1203. That satisfies our internal compliance checklist."}
{"ts": "128:00", "speaker": "I", "text": "Bevor wir abschließen, können Sie mir bitte noch schildern, wie Sie im Build-Phase-Status die Ergebnisse aus den p95 Latenz-Tests in Ihre täglichen Stand-ups einbringen?"}
{"ts": "128:15", "speaker": "E", "text": "Ja, also wir haben jeden Morgen ein kurzes Slot, da bringe ich die neuesten Metriken aus Nimbus Observability rein. I usually highlight whether we're trending towards or away from the SLA-ORI-02 target. Die Daten stammen direkt aus dem Canary-Cluster, damit wir keine Produktionslast simulieren müssen."}
{"ts": "128:40", "speaker": "I", "text": "Und wie verknüpfen Sie das mit den Security-Anforderungen, etwa mTLS Handshakes oder POL-SEC-001 Least Privilege?"}
{"ts": "128:55", "speaker": "E", "text": "Das ist tricky. Wir haben im Build Cluster einen eigenen mTLS Testpfad, der die gleichen Cipher Suites wie prod nutzt. By doing that, we ensure that handshake timings are realistic, und wir prüfen parallel, ob die Service Accounts nur die minimalen Berechtigungen haben."}
{"ts": "129:20", "speaker": "I", "text": "Gab es da schon mal Konflikte zwischen Performance und diesen Sicherheits-Checks?"}
{"ts": "129:32", "speaker": "E", "text": "Ja, mehrfach. Ein Beispiel: Ticket SEC-GW-7742 dokumentiert, dass ein strengeres TLS-Profil die Latenz im 95. Perzentil um fast 18 ms erhöht hat. Wir mussten also mit dem Security-Team abstimmen, ob wir laut Ausnahmeprotokoll AP-SEC-05 temporär eine schwächere Cipher Suite nutzen, bis die Hardwarebeschleunigung ausgerollt war."}
{"ts": "129:58", "speaker": "I", "text": "Interessant. How do you document these temporary deviations for audit readiness?"}
{"ts": "130:10", "speaker": "E", "text": "Wir nutzen dafür unser internes ADR-Template (Architectural Decision Record). Each ADR references the relevant ticket, die polnischen Policy IDs und die Gültigkeitsdauer. Das geht alles in Confluence und wird bei den monatlichen Audit-Preps reviewt."}
{"ts": "130:35", "speaker": "I", "text": "Wie sieht es mit Lessons Learned aus dem letzten Major Incident aus, speziell für das Orion Edge Gateway?"}
{"ts": "130:48", "speaker": "E", "text": "Das letzte Major Incident, MI-ORI-202, war ein Ausfall der Rate-Limiter-Komponente durch einen fehlerhaften Redis-Failover. Wir haben daraus gelernt, in RB-GW-011 explizit einen Schritt für manuelles Umschalten auf den Fallback-Algorithmus 'leaky bucket' aufzunehmen. That reduced recovery time by 40% in drills."}
{"ts": "131:15", "speaker": "I", "text": "Haben Sie auch ungeschriebene Heuristiken ergänzt?"}
{"ts": "131:26", "speaker": "E", "text": "Ja, eine ist: wenn der Observability-Stream plötzlich 'flatlines', immer zuerst die Exporter-Configs checken before touching the gateway code. Das hat uns schon mal eine unnötige rollback wave erspart."}
{"ts": "131:48", "speaker": "I", "text": "Wie gehen Sie mit Risiken um, die kurz vor Go-Live erkannt werden, aber nicht mehr vollständig mitigiert werden können?"}
{"ts": "132:00", "speaker": "E", "text": "Wir führen eine Risk Acceptance Form ein, die von PM, Security und Operations signiert werden muss. For example, bei RSK-ORI-55 wussten wir, dass ein bestimmter Auth-Flow unter hoher Last suboptimal performt. Wir haben das dokumentiert, mit Workaround beschrieben und Go-Live nicht verschoben."}
{"ts": "132:25", "speaker": "I", "text": "Und welche Tools nutzen Sie, um diese Risiken transparent zu halten?"}
{"ts": "132:36", "speaker": "E", "text": "Wir taggen sie in Jira mit dem Label 'go-live-risk', verknüpfen mit ADRs und den zugehörigen RFCs. That way, im Post-Mortem oder bei Audits hat man sofort die ganze Kette von Entscheidung und Evidenz vorliegen."}
{"ts": "136:00", "speaker": "I", "text": "Lassen Sie uns jetzt auf die Lessons Learned vom letzten Major Incident eingehen. Wie haben Sie RB-GW-011 konkret angewendet?"}
{"ts": "136:05", "speaker": "E", "text": "Ja, also beim Incident vom 3. März hatten wir plötzlich einen massiven Spike in der Auth-Latenz. RB-GW-011 sieht ja das sofortige Umschalten auf den Standby-Cluster vor, mit Blue/Green Identifikation. Wir haben innerhalb von 4 Minuten umgeschaltet und die p95 Latenz fiel wieder unter 120 ms."}
{"ts": "136:13", "speaker": "I", "text": "Und was haben Sie gemacht, als das Runbook nicht alle Failure Modes abgedeckt hat?"}
{"ts": "136:18", "speaker": "E", "text": "Da musste ich auf meine heuristics zurückgreifen — for example, checking the mTLS cert expiry dates manually using our internal gw-cli tool, which isn’t in RB-GW-011. Das hat uns geholfen, einen schleichenden Handshake-Degradation zu erkennen."}
{"ts": "136:27", "speaker": "I", "text": "Wie fließen solche Erkenntnisse zurück ins Runbook?"}
{"ts": "136:31", "speaker": "E", "text": "Wir haben direkt ein Update-PR im Runbook-Repo erstellt, Ticket OPS-GW-778 verlinkt. Dort habe ich einen neuen Abschnitt 'mTLS Zertifikatprüfung' ergänzt, basierend auf diesem Incident."}
{"ts": "136:40", "speaker": "I", "text": "Kommen wir zur Performanceoptimierung: How did you tweak the system to sustain the SLA-ORI-02 target even under load?"}
{"ts": "136:46", "speaker": "E", "text": "Wir haben adaptive rate limiting eingeführt, basierend auf Request-Kategorien. For example, low-priority API calls get throttled earlier. Plus, wir haben den JSON-Parsing-Pfad mit einem Streaming-Parser ersetzt, was laut RFC-1122 aus der Nimbus Observability-Pipeline empfohlen wurde."}
{"ts": "136:57", "speaker": "I", "text": "Gab es dabei Trade-offs zwischen Sicherheit und Latenz?"}
{"ts": "137:01", "speaker": "E", "text": "Ja, ein konkretes Beispiel: Wir haben bei internen Service-zu-Gateway Calls auf einen leichteren Cipher-Suite gewechselt. Das spart ca. 5 ms pro Request, aber wir mussten das im SEC-RFC-45 dokumentieren und eine Ausnahme zu POL-SEC-001 einholen."}
{"ts": "137:12", "speaker": "I", "text": "Wie wurde diese Ausnahme genehmigt?"}
{"ts": "137:16", "speaker": "E", "text": "Über ein Architektur-Review mit dem Security-Team, Referenz TCK-SEC-992. Dort haben wir Benchmarks und Risikoanalyse präsentiert. Approval kam mit der Auflage, dass wir mTLS Session Lifetimes halbieren."}
{"ts": "137:26", "speaker": "I", "text": "Interessant. Können Sie noch ein weiteres Beispiel nennen, wo Sie bewusst gegen eine Policy entschieden haben?"}
{"ts": "137:31", "speaker": "E", "text": "During a peak traffic test, wir haben temporär den Auth-Cache TTL von 60s auf 180s erhöht. Policy POL-AUTH-003 erlaubt max. 120s, aber wir hatten die Genehmigung im Ticket PERF-2121, da dies die Latenzspikes im p95 um 15 ms reduziert hat."}
{"ts": "137:42", "speaker": "I", "text": "Wie stellen Sie sicher, dass solche Abweichungen audit-ready dokumentiert sind?"}
{"ts": "137:46", "speaker": "E", "text": "Wir pflegen ein Confluence-Log 'Deviation Register', verlinkt zu allen Jira-Tickets und RFC-Dokumenten. Jeder Eintrag enthält Datum, Grund, Impact und Approval-IDs. Das erleichtert Audits enorm."}
{"ts": "137:36", "speaker": "I", "text": "Lassen Sie uns noch kurz auf die Schnittstellen zum Nimbus Observability eingehen – wie genau haben Sie da die Event-Streams für das Gateway angebunden?"}
{"ts": "137:46", "speaker": "E", "text": "Also, wir haben über die interne EventBridge-Implementierung gearbeitet, mit einem dedizierten mTLS Channel zu Nimbus. That way we ensure both security and data integrity, und wir konnten die Streams so filtern, dass nur Gateway-relevante Metriken wie `edge.latency.p95` oder `auth.rate_limit.hit` übertragen werden."}
{"ts": "137:58", "speaker": "I", "text": "Und wie stellen Sie sicher, dass Änderungen im Auth-Integrationsteil nicht die Rate-Limits verletzen?"}
{"ts": "138:05", "speaker": "E", "text": "Wir haben dafür ein Pre-Deploy-Skript in der CI-Pipeline, das die aktuellen Limits aus der ConfigMap liest und testweise eine Auth-Library mit 5000 Requests gegen ein Staging-Cluster schickt. If the measured p95 goes beyond 110ms, the pipeline fails. Das ist inspiriert von den Checks in RB-GW-011, aber erweitert um Auth-spezifische KPIs."}
{"ts": "138:21", "speaker": "I", "text": "Können Sie ein Beispiel geben, wo Sie so einen Check ausgelöst haben?"}
{"ts": "138:28", "speaker": "E", "text": "Ja, Ticket GW-5273. Wir hatten eine neue JWT-Parsing-Library eingebaut, die unbemerkt bei langen Claims einem JSON-Parser Fallback nutzte. Das erhöhte die Latenz um ~25ms. The CI caught it, wir haben revert gemacht und im RFC-1282 dann festgehalten, dass Libraries mit dynamischer Parsing-Strategie in unserem Kontext nicht zulässig sind."}
{"ts": "138:46", "speaker": "I", "text": "Wie stimmen Sie sich mit dem Security-Team ab, um POL-SEC-001 Least Privilege einzuhalten?"}
{"ts": "138:54", "speaker": "E", "text": "Wir haben ein zweiwöchentliches Review-Meeting, in dem wir die aktuellen RoleBindings aus dem Cluster gegen das POL-SEC-001 Profil prüfen. Any deviation gets a JIRA task, z. B. SEC-441, wo wir einem Service-Account fälschlich Zugriff auf die Admin-API gegeben hatten. Innerhalb von 24h war das behoben."}
{"ts": "139:10", "speaker": "I", "text": "How do you propagate mTLS handshake fixes like in GW-4821 into production without breaching SLAs?"}
{"ts": "139:18", "speaker": "E", "text": "We used a canary rollout on 5% of edge nodes in Zone C first, monitored handshake success rates and p95 latency. Nach 30 Minuten und stabilen Werten haben wir sukzessive bis 100% hochgefahren. Die Erfahrung aus RB-GW-011 half, die Rolloutstufen zeitlich so zu staffeln, dass kein SLO-Bruch entstand."}
{"ts": "139:36", "speaker": "I", "text": "Gab es dabei irgendwelche unvorhergesehenen Nebenwirkungen?"}
{"ts": "139:42", "speaker": "E", "text": "Ja, bei einem Node-Pool mit älteren TLS-Libs kam es zu erhöhten CPU-Spitzen. We quickly patched it by disabling certain cipher suites, documented under GW-4821-postmortem.md, und haben im RFC-1301 festgelegt, dass wir solche Library-Upgrades zuerst in einem separaten Compatibility-Testbed fahren."}
{"ts": "139:58", "speaker": "I", "text": "Wie messen Sie aktuell die Einhaltung des p95 Latenz-SLOs in der Build-Phase?"}
{"ts": "140:05", "speaker": "E", "text": "Wir nutzen synthetische Traffic-Generatoren, die per Terraform in ephemeral Environments hochgezogen werden. Every build triggers a 10-minute load test, die Ergebnisse landen in Grafana-Dashboards und werden mit SLA-ORI-02 abgeglichen. Alerts gehen direkt in unseren Incident-Channel."}
{"ts": "140:20", "speaker": "I", "text": "Welche größten Risiken sehen Sie jetzt noch für die Go-Live-Phase?"}
{"ts": "140:27", "speaker": "E", "text": "Das größte Risiko ist eine unerkannte Interaktion zwischen Rate-Limiting und Auth-Caching unter Last. If the cache misses spike, it could cascade into latency breaches. Wir haben deshalb in RFC-1315 eine Staged Rollout-Strategie mit erweiterten Cache-Warmup-Skripten dokumentiert, um dieses Risiko zu mitigieren."}
{"ts": "145:36", "speaker": "I", "text": "Wenn wir jetzt den Übergang zur Go-Live-Phase betrachten, welche größten Risiken sehen Sie konkret für das Orion Edge Gateway?"}
{"ts": "145:41", "speaker": "E", "text": "Eines der größten Risiken ist, ähm, dass die Auth-Integration mit Aegis IAM in der Produktionslast unerwartete Latenzspitzen erzeugt. Plus, wir haben noch ein offenes Thema bei GW-5199 zur mTLS-Zertifikatrotation, das könnte in Kombination kritisch werden."}
{"ts": "145:48", "speaker": "I", "text": "Und wie bewerten Sie das im Hinblick auf SLA-ORI-02, also p95 < 120ms?"}
{"ts": "145:53", "speaker": "E", "text": "Wir haben Simulationen in der Staging-Umgebung gefahren, with traffic replay from last quarter, und gesehen, dass wir im worst-case bei 115ms liegen. Aber das ohne die Zertifikatrotation. Sobald wir die einbeziehen, müssen wir laut meinem Modell noch 5–7ms einkalkulieren."}
{"ts": "145:59", "speaker": "I", "text": "Haben Sie dafür eine dokumentierte Abweichung oder einen Workaround in den Policies?"}
{"ts": "146:03", "speaker": "E", "text": "Ja, wir haben in DEC-GW-014 festgehalten, dass für die ersten zwei Wochen nach Go-Live eine temporäre Ausnahme von POL-SEC-001 greift, um die Rotation auf Off-Peak Windows zu verschieben."}
{"ts": "146:10", "speaker": "I", "text": "Interessant. Können Sie eine Referenz nennen, welche Tickets diese Entscheidung beeinflusst haben?"}
{"ts": "146:14", "speaker": "E", "text": "Das war TRK-8421, in dem wir einen Ausfall im Testbetrieb hatten, und RFC-221-B, wo wir die Anpassung der Rotation diskutiert und vom Security-Team absegnen lassen haben."}
{"ts": "146:20", "speaker": "I", "text": "Wie stellen Sie sicher, dass solche Ausnahmen audit-ready dokumentiert sind?"}
{"ts": "146:24", "speaker": "E", "text": "Wir nutzen das Decision-Log in Confluence, verlinken alle relevanten Tickets, fügen die Risikoanalyse und die temporäre Gültigkeit hinzu. Zusätzlich setzen wir einen Reminder in unserem Ops-Kalender, um die Ausnahme rechtzeitig zu beenden."}
{"ts": "146:31", "speaker": "I", "text": "Und gibt es noch einen Performance-Tradeoff, den Sie abwägen mussten?"}
{"ts": "146:35", "speaker": "E", "text": "Ja, wir haben für die JWT-Validierung von Aegis IAM entschieden, caching auf 30 Sekunden hochzusetzen. Das reduziert den Auth-Layer-Overhead um ca. 8ms, erhöht aber minimal das Risiko, dass ein revoked Token kurzzeitig akzeptiert wird."}
{"ts": "146:42", "speaker": "I", "text": "Wie wurde das Risiko akzeptiert?"}
{"ts": "146:45", "speaker": "E", "text": "Durch eine gemeinsame Sitzung mit Security und Product Owner, wir haben es in RISK-LOG-077 dokumentiert und den revocation check frequency in der Off-Peak Phase verdichtet."}
{"ts": "146:51", "speaker": "I", "text": "Können Sie abschließend sagen, was für Sie die wichtigsten Lessons Learned aus dieser Build-Phase sind?"}
{"ts": "146:55", "speaker": "E", "text": "Erstens: Frühzeitige Einbindung von Security in Performance-Entscheidungen. Zweitens: Runbooks wie RB-GW-011 müssen immer einen Abschnitt für unbekannte Fehlerbilder haben. Und drittens: Cross-System impacts, wie mTLS-Fixes plus Auth-Latenz, sollten immer in kombinierten Tests evaluiert werden, nicht isoliert."}
{"ts": "147:12", "speaker": "I", "text": "Wir hatten ja vorhin über die Build-Phase gesprochen — können Sie noch mal konkret sagen, wie Sie momentan die Auth-Integration gegen das Aegis IAM testen, ohne die Rate Limits von ORI-RateCfg-03 zu verletzen?"}
{"ts": "147:18", "speaker": "E", "text": "Ja, klar. Wir nutzen ein dediziertes Staging-VPN-Segment mit simulierten Tokens. English part: We throttle the synthetic user flows via our CI pipeline hooks, so the load on Aegis IAM stays below 60% of the configured limit, and we log all handshakes in the GW-Stage-Auth dashboard."}
{"ts": "147:26", "speaker": "I", "text": "Und wie hängen diese Tests mit dem SLA-ORI-02 p95 Latency Ziel zusammen?"}
{"ts": "147:33", "speaker": "E", "text": "Wir haben in den Smoke-Tests ein Latenz-Budget eingebaut. That budget is enforced in the k6 test scripts, so any Auth response exceeding 100ms is flagged, leaving headroom for downstream processing and still meeting the 120ms SLA."}
{"ts": "147:44", "speaker": "I", "text": "Middle anchor hier: Können Sie die mTLS-Handshake-Fixes aus GW-4821 erläutern und wie diese in Prod kommen, ohne SLAs zu brechen?"}
{"ts": "147:51", "speaker": "E", "text": "Natürlich. Wir haben das Zertifikats-Parsing im Nginx-Lua-Plugin gefixt, dann in einem canary slice von 5% der Nodes ausgerollt. English: Using RB-GW-014 blue/green steps, we monitored handshake times via Nimbus Observability, ensured p95 stayed under 110ms before promoting to full production."}
{"ts": "148:02", "speaker": "I", "text": "Gab es dabei Abhängigkeiten zu anderen Projekten, z.B. dem Nimbus Observability Team?"}
{"ts": "148:08", "speaker": "E", "text": "Ja, wir mussten das mTLS-Metric-Collector-Modul von Nimbus zuerst auf Version 2.3 heben. In English: Without that version, our handshake duration metrics would lag by 30 seconds, which is unacceptable for SLA breach detection."}
{"ts": "148:18", "speaker": "I", "text": "Bei einem Incident, wenn RB-GW-011 nicht alles abdeckt, welche zusätzlichen Heuristiken nutzen Sie?"}
{"ts": "148:26", "speaker": "E", "text": "Ich schaue zuerst auf die Error-Pattern in den letzten 5 Minuten Logs und vergleiche sie mit ähnlichen Tickets, z.B. GW-4377. English: Then I run a quick tcpdump on the suspect pod to see if the failure mode matches any known transient network anomalies."}
{"ts": "148:37", "speaker": "I", "text": "Welche Lessons Learned hatten Sie aus dem letzten Major Incident?"}
{"ts": "148:44", "speaker": "E", "text": "Wir haben gelernt, die Canary-Metriken früher zu eskalieren. English: Also, baseline snapshots from the observability cluster should be taken before any auth module upgrade, to enable faster rollback."}
{"ts": "148:54", "speaker": "I", "text": "Late anchor: Können Sie mir ein Beispiel geben, wo Sie eine Entscheidung gegen eine Standard-Policy getroffen haben, und wie Sie das audittauglich dokumentiert haben?"}
{"ts": "149:02", "speaker": "E", "text": "Ja, beim Notfall-Patch für GW-5099 haben wir temporär POL-SEC-001 gelockert, um einen externen Debugger zuzulassen. We documented the deviation in Decision Log DL-2023-09, with justification, risk assessment, and a rollback plan, so the audit trail is complete."}
{"ts": "149:14", "speaker": "I", "text": "Gab es bei dieser Entscheidung Trade-offs zwischen Sicherheit und Latenz?"}
{"ts": "149:20", "speaker": "E", "text": "Ja, wir wussten, dass die Debug-Schnittstelle 2–3ms extra Latenz bringt. English: But given the severity of the bug, the temporary latency hit was acceptable, and we reverted the change within 48 hours as per the mitigation plan."}
{"ts": "149:12", "speaker": "I", "text": "Lassen Sie uns noch etwas tiefer auf die Abhängigkeiten eingehen: Wie wirkt sich die mTLS-Handshake-Korrektur aus Ticket GW-4821 konkret auf die Interaktion mit Nimbus Observability aus?"}
{"ts": "149:18", "speaker": "E", "text": "Also, GW-4821 hatte initial ja das Problem, dass der Handshake in ca. 2% der Fälle > 800 ms dauerte. When we pushed the fix into our staging, the Nimbus agents initially dropped traces for those prolonged handshakes. Wir mussten also in der Observability-Pipeline ein Timeout-Parameter von 500 ms auf 950 ms erhöhen — und das abgestimmt mit dem Observability-Team, damit wir nicht unter die SLAs für Trace Completeness in SLA-NIM-03 fallen."}
{"ts": "149:27", "speaker": "I", "text": "Und wie haben Sie diese Änderung in der Produktionsumgebung propagiert, ohne die SLA-ORI-02 p95 Latenz von 120 ms zu verletzen?"}
{"ts": "149:33", "speaker": "E", "text": "Wir haben ein abgestuftes Blue/Green Deployment gemäß RB-GW-011 gefahren, aber dabei nur 10% des Traffics auf die neue Handshake-Logik geroutet. We monitored p95 latency in real-time mit den Canary nodes. Sobald wir nach 24 Stunden keine Regression sahen, gingen wir in 25%, 50% und dann 100% Traffic. Das war zwar ein Tag länger als geplant, aber dafür null SLA-Verletzungen."}
{"ts": "149:44", "speaker": "I", "text": "Wie stimmen Sie sich bei solchen Änderungen mit dem Security-Team ab, um POL-SEC-001 Least Privilege einzuhalten?"}
{"ts": "149:50", "speaker": "E", "text": "Für die mTLS-Fixes mussten wir temporär Zugriff auf den Zertifikats-Store in der Pre-Prod-Umgebung haben. According to POL-SEC-001, that access has to be time-bound and ticketed. Wir haben also über SEC-REQ-218 ein Zeitfenster von 4 Stunden beantragt, Credentials im Secrets Manager rotiert und danach den Zugriff wieder entzogen."}
{"ts": "149:59", "speaker": "I", "text": "Gab es bei diesem Prozess irgendwelche unvorhergesehenen Nebeneffekte, die Sie ins nächste Runbook-Update aufnehmen wollen?"}
{"ts": "150:05", "speaker": "E", "text": "Ja, tatsächlich. During the 25% rollout, we noticed a spike in auth retries. Das lag daran, dass ein Downstream-Service mit einem veralteten CA-Bundle lief. Wir haben jetzt als Heuristik im Runbook vermerkt: 'Vor mTLS-Änderungen CA-Bundle-Version bei allen Konsumenten prüfen'."}
{"ts": "150:15", "speaker": "I", "text": "Wie messen Sie in der Build-Phase aktuell die Einhaltung des p95-SLOs?"}
{"ts": "150:21", "speaker": "E", "text": "Wir nutzen synthetic load tests mit realistischen Traffic-Mustern aus der Staging-Datenbank. Every build pipeline run triggers a 30-minute soak test, und wir extrahieren aus den Prometheus-Metriken den p95-Wert. Dieser wird automatisch gegen SLA-ORI-02 validiert und im Build-Report dokumentiert."}
{"ts": "150:30", "speaker": "I", "text": "Haben Sie auch mit Request Sampling Strategien wie in RFC-1114 experimentiert?"}
{"ts": "150:36", "speaker": "E", "text": "Ja, aber wir mussten das Sampling adaptieren. In RFC-1114 steht ein statisches 10%-Sampling. We implemented adaptive sampling basierend auf Error Rates: bei >1% Error Rate gehen wir auf 50% Sampling hoch, um schneller Root Causes zu finden. Das hat uns bei Incident INC-ORI-77 enorm geholfen."}
{"ts": "150:46", "speaker": "I", "text": "Wenn Sie an die Go-Live-Phase denken: Was sind die größten Risiken?"}
{"ts": "150:52", "speaker": "E", "text": "Zum einen das Risiko, dass ein Upstream-Auth-System wie Aegis IAM eine Breaking Change einführt. Secondly, dass wir unter Last peaky traffic patterns sehen, die unsere Rate Limiter nicht smoothen können. Wir haben Ticket RISK-ORI-14 angelegt, um genau diese Szenarien in Lasttests zu simulieren."}
{"ts": "151:01", "speaker": "I", "text": "Können Sie ein Beispiel nennen, wo ein RFC oder Ticket eine große Architekturänderung ausgelöst hat?"}
{"ts": "151:07", "speaker": "E", "text": "Klar, RFC-EDGE-220 hat uns dazu gebracht, den Auth-Integrationsteil komplett als Sidecar Pattern zu deployen statt embedded. The ticket GW-ARCH-55 dokumentiert die Entscheidung, inklusive Latenz-Benchmarks und Security Review-Protokoll. Das war ein bewusst eingegangenes Trade-off: +5 ms Latenz, aber dafür klare Isolierung der Auth-Logik."}
{"ts": "150:48", "speaker": "I", "text": "Bevor wir zu den finalen Risiken kommen – können Sie noch mal den Zusammenhang zwischen der Auth-Integration und der Observability-Pipeline erläutern?"}
{"ts": "150:53", "speaker": "E", "text": "Ja, gern. Wir haben die Auth-Integration aus dem Aegis IAM direkt mit der Nimbus Observability Event-Queue verknüpft, sodass jeder Token-Issuance-Flow auch ein Trace-Event generiert. That way, when we debug latency spikes, we can correlate them with specific auth flows without manual log scraping."}
{"ts": "150:59", "speaker": "I", "text": "Und wie hängt das mit den mTLS-Handshake-Fixes aus Ticket GW-4821 zusammen?"}
{"ts": "151:04", "speaker": "E", "text": "Interessant ist, dass die mTLS-Patches die TLS-Session-Setup-Zeit verändert haben. Durch die Observability-Hooks konnten wir sehen, dass bei bestimmten Clients der Handshake 15–20 ms länger dauerte. We then adjusted our rate limiter burst settings to compensate and still meet SLA-ORI-02."}
{"ts": "151:12", "speaker": "I", "text": "Gab es dafür eine formelle Entscheidungsvorlage oder lief das eher adhoc?"}
{"ts": "151:16", "speaker": "E", "text": "Wir haben ein mini-RFC, die RFC-GW-112 erstellt, in der wir den Trade-off dokumentiert haben – etwas mehr Burst erlaubt, dafür aber keine p95-Latenzverletzung. The Security team signed off because POL-SEC-001 was still respected."}
{"ts": "151:24", "speaker": "I", "text": "Wie haben Sie das im Deployment-Prozess umgesetzt?"}
{"ts": "151:29", "speaker": "E", "text": "Wir haben RB-GW-011 blue/green genutzt. Die neue Config wurde in der Green-Umgebung mit simulierten Auth-Flows getestet. After 15 minutes of stable metrics, we flipped traffic gradually—10%, 50%, then 100%."}
{"ts": "151:37", "speaker": "I", "text": "Gab es während des Flips irgendwelche Alerts?"}
{"ts": "151:41", "speaker": "E", "text": "Nur ein paar Warnungen vom Nimbus Alerting über leicht erhöhte handshake times. We had pre-approved those in the change ticket CHG-775, so kein Incident-Trigger."}
{"ts": "151:47", "speaker": "I", "text": "Wenn Sie jetzt an den Go-Live denken – was ist aus Ihrer Sicht das größte Risiko?"}
{"ts": "151:51", "speaker": "E", "text": "Das größte Risiko ist ein plötzlicher Anstieg an Auth-Requests durch einen Partner-Launch. That could saturate the burst window. Wir haben dafür ein Auto-Tuning-Feature in Arbeit, siehe DEV-Task 9823."}
{"ts": "151:58", "speaker": "I", "text": "Und was wäre der Entscheidungsweg, wenn dieses Risiko eintritt?"}
{"ts": "152:02", "speaker": "E", "text": "Wir würden sofort RB-GW-014 für Emergency Scaling triggern, parallel eine CAB-Emergency-Session einberufen. Documentation in unserem Confluence-Runbook-Addendum sichert Audit-Readiness."}
{"ts": "152:09", "speaker": "I", "text": "Haben Sie schon mal mit diesem Emergency-Runbook geübt?"}
{"ts": "152:13", "speaker": "E", "text": "Ja, im letzten Chaos-Test. We found a missing step for updating the API Gateway certs post-scale. Das haben wir nachgezogen, damit wir im Ernstfall nicht gegen POL-SEC-001 verstoßen."}
{"ts": "152:08", "speaker": "I", "text": "Lassen Sie uns noch einmal auf die Dokumentation zurückkommen – wie stellen Sie sicher, dass Abweichungen von POL-SEC-001 im Audit nachvollziehbar bleiben, gerade wenn sie aus Performancegründen nötig waren?"}
{"ts": "152:13", "speaker": "E", "text": "Wir führen ein Deviations-Log im Repo `gw-sec-deviation.yml` – jede Ausnahme wird mit Ticket-ID und SLA-Verweis versehen. For instance, when we relaxed certain JWT validation steps in GW-5672 for latency reasons, we cross-linked it to SLA-ORI-02 and a compensating WAF rule in the audit notes."}
{"ts": "152:20", "speaker": "I", "text": "Und diese WAF-Regel – wurde die über ein IaC-Template ausgerollt oder manuell?"}
{"ts": "152:25", "speaker": "E", "text": "Automatisiert mit Terraform-Modulen aus `mod-waf-gw` – das Modul integriert direkt in unsere Blue/Green-Pipeline laut RB-GW-011, so dass auch Rollbacks die Regel rückgängig machen können."}
{"ts": "152:32", "speaker": "I", "text": "Interesting. How do you verify in staging that these compensating controls don't break existing auth flows from Aegis IAM?"}
{"ts": "152:37", "speaker": "E", "text": "Wir haben ein synthetisches Testset in Nimbus Observability repräsentiert, das die häufigsten OAuth2-Flows simuliert. Every push to `staging` triggers these and compares latency deltas; anything over +15ms flags a warning."}
{"ts": "152:45", "speaker": "I", "text": "Gab es in letzter Zeit einen Fall, wo dieser Warnmechanismus angesprungen ist?"}
{"ts": "152:50", "speaker": "E", "text": "Ja, bei GW-5930. Wir haben ein neues mTLS Cipher Suite Update eingespielt, das bei Mutual Auth mit älteren Clients zu Timeouts führte. The staging tests caught the p95 going from 110ms to 148ms."}
{"ts": "152:59", "speaker": "I", "text": "Und wie haben Sie darauf reagiert, ohne den Go-Live-Termin zu gefährden?"}
{"ts": "153:04", "speaker": "E", "text": "Wir haben einen Dual-Stack-Ansatz implementiert – ältere Cipher Suites parallel vorgehalten, aber via Policy nur für bekannte Client-IDs freigeschaltet. That let us preserve latency SLOs while maintaining forward security for most traffic."}
{"ts": "153:12", "speaker": "I", "text": "Das klingt nach einer sauberen Lösung. Wurde diese Entscheidung in einem RFC dokumentiert?"}
{"ts": "153:17", "speaker": "E", "text": "Ja, RFC-GW-221 beschreibt den Dual-Stack-Plan, Risikoanalyse, und die Sunset-Strategie für die schwächeren Cipher Suites. Wir haben es mit dem Security-Team abgestimmt, um POL-SEC-001 konform zu bleiben."}
{"ts": "153:24", "speaker": "I", "text": "Have you considered using feature flags instead of policy toggles for such compatibility modes?"}
{"ts": "153:29", "speaker": "E", "text": "Wir haben das evaluiert. Feature Flags würden mehr Flexibilität bringen, aber auch zusätzlichen Pfad im Code, der zu Regressionen führen könnte. Given our deployment velocity and RB-GW-011 rollback constraints, policy toggles were less risky."}
{"ts": "153:38", "speaker": "I", "text": "Abschließend – welche Lessons Learned nehmen Sie für zukünftige mTLS-Änderungen mit?"}
{"ts": "153:43", "speaker": "E", "text": "Frühzeitige Kompatibilitäts-Scans mit repräsentativer Client-Matrix, klare Sunset-Dates im RFC, und ein vorab getesteter Rollback-Plan im IaC-Code. And, avoid last-minute cipher deprecations without staged communication to dependent teams."}
{"ts": "153:38", "speaker": "I", "text": "Bevor wir auf die letzten Optimierungen eingehen – wie haben Sie in der Build-Phase konkret sichergestellt, dass die mTLS-Handshake-Fixes aus GW-4821 nicht nur in Staging, sondern auch in der Canary-Umgebung sauber liefen?"}
{"ts": "153:42", "speaker": "E", "text": "Ähm, also wir haben das über eine gestaffelte Pipeline gemacht, die in RB-GW-013 beschrieben ist. First stage war Staging mit simulierten Lastspitzen, dann Canary mit 5% real traffic. We monitored handshake success rate via Nimbus Observability dashboards, specifically chart set OB-GW-08."}
{"ts": "153:47", "speaker": "I", "text": "Und wenn da Abweichungen vom Latency-SLO SLA-ORI-02 sichtbar wurden – wie haben Sie reagiert?"}
{"ts": "153:51", "speaker": "E", "text": "Wir hatten ein automatisches Rollback-Trigger, wenn p95 > 120ms für mehr als 3 Minuten war. That was implemented in our GitOps controller with a webhook to alert SecOps, falls das Problem aus einer Policy-Änderung kam."}
{"ts": "153:56", "speaker": "I", "text": "Können Sie ein Beispiel nennen, wo so ein Rollback tatsächlich ausgelöst wurde?"}
{"ts": "154:00", "speaker": "E", "text": "Ja, Ticket GW-4932. Wir hatten eine neue Cipher Suite aktiviert, die zwar sicherer war, aber auf ARM-Nodes zu etwa 10ms zusätzlichen Handshake-Zeiten führte. The rollback preserved SLA compliance while we tested alternative cipher orderings."}
{"ts": "154:05", "speaker": "I", "text": "Wie haben Sie das dann langfristig gelöst?"}
{"ts": "154:09", "speaker": "E", "text": "Durch eine kombinierte Änderung in Auth-Integration und TLS-Konfig: wir haben ECDSA-Zertifikate auf den Edge-Nodes eingeführt und parallel im Aegis IAM kleine Token-Payloads erzeugt. That reduced both handshake and auth parsing time."}
{"ts": "154:14", "speaker": "I", "text": "Interessant. Haben Sie die Änderungen auch im Runbook RB-GW-011 ergänzt?"}
{"ts": "154:18", "speaker": "E", "text": "Teilweise, ja. Die generelle Deployment-Abfolge blieb, aber wir haben eine Note im Abschnitt 'TLS tuning' hinzugefügt, plus einen Verweis auf RFC-EDGE-221 für die Cipher-Präferenzliste."}
{"ts": "154:23", "speaker": "I", "text": "Was war das komplexeste an dieser Anpassung – technisch oder organisatorisch?"}
{"ts": "154:27", "speaker": "E", "text": "Technisch war's tricky, weil wir sicherstellen mussten, dass keine Legacy-Clients blockiert werden. Organisatorisch: convincing Product Management that a minimal latency regression during testing was acceptable to ensure long-term security compliance."}
{"ts": "154:32", "speaker": "I", "text": "Haben Sie dafür einen formalen Waiver von POL-SEC-001 beantragt?"}
{"ts": "154:36", "speaker": "E", "text": "Ja, Waiver-Request WR-SEC-77. We documented the rationale, linked Grafana latency graphs, and attached the cipher compatibility matrix. Security signed off with a 14-day exception period."}
{"ts": "154:41", "speaker": "I", "text": "Im Rückblick – würden Sie diesen Weg wieder wählen?"}
{"ts": "154:45", "speaker": "E", "text": "Ja, because it balanced risk and performance. Wir haben daraus eine Best Practice in unserem internen Confluence erstellt, um ähnliche Entscheidungen schneller zu treffen."}
{"ts": "155:02", "speaker": "I", "text": "Bezüglich der Go-Live-Risiken, könnten Sie bitte noch einmal konkretisieren, wie Sie das Thema Rate-Limit-Bypass durch fehlerhafte Auth-Module mitigieren?"}
{"ts": "155:08", "speaker": "E", "text": "Ja, wir haben ein Guardrail-Skript in Terraform implementiert, das vor jedem Deploy die Konfiguration gegen RL-POL-004 validiert. If the auth module's config deviates, the pipeline halts and triggers a manual review in Jira ticket GW-5932."}
{"ts": "155:15", "speaker": "I", "text": "Interessant, und wie fließt diese Validierung in Ihren Blue/Green-Flow gemäß RB-GW-011 ein?"}
{"ts": "155:21", "speaker": "E", "text": "Wir haben die Validierung als Pre-step im Blue-Deployment integriert. That means green stays untouched until the blue passes both functional and policy checks, otherwise the rollback is immediate."}
{"ts": "155:28", "speaker": "I", "text": "Gab es schon Situationen, in denen dieser Pre-step einen Go-Live verhindert hat?"}
{"ts": "155:34", "speaker": "E", "text": "Einmal, bei Release v1.8.2, hat ein mTLS-Zertifikat aus Aegis IAM nicht die CN-Pattern-Policy erfüllt. The guardrail caught it before traffic shifted, logged under Incident INC-ORI-774."}
{"ts": "155:42", "speaker": "I", "text": "Wie koordinieren Sie in solchen Fällen mit dem Security-Team, um schnell einen Fix zu liefern?"}
{"ts": "155:49", "speaker": "E", "text": "Wir haben ein Slack-Bridge-Channel #gw-sec-bridge. Dort posten wir die Incident-ID und die Non-Compliance-Details, dann starten die Kollegen aus Sec-Team ein Hotfix-Branch. Usually, we can patch and redeploy within 45 minutes without SLO breach."}
{"ts": "155:57", "speaker": "I", "text": "Und wie wird dieser Prozess dokumentiert, damit er bei Audits nachvollziehbar ist?"}
{"ts": "156:03", "speaker": "E", "text": "Wir ergänzen nach Abschluss des Incidents den Audit-Log in Confluence mit Verweis auf Ticket, Runbook-Abschnitt und Chat-Transcript. This links back to POL-SEC-001 compliance evidence."}
{"ts": "156:10", "speaker": "I", "text": "Haben Sie in der Build-Phase bereits Lasttests gefahren, um das Zusammenspiel von Auth und Rate Limiting unter Volllast zu prüfen?"}
{"ts": "156:16", "speaker": "E", "text": "Ja, wir haben mit Gatling-Scripts 100k RPS simuliert, while enabling all auth hooks. Dabei konnten wir beobachten, dass der p95 bei 118ms blieb, knapp innerhalb SLA-ORI-02."}
{"ts": "156:24", "speaker": "I", "text": "Wie gehen Sie vor, wenn der p95-Wert doch knapp überschritten wird?"}
{"ts": "156:30", "speaker": "E", "text": "Dann fahren wir einen Profiling-Run mit dem Nimbus Observability Agent. If we detect bottlenecks in JWT validation, we offload certain checks to a cache layer, as per RFC-NIM-219."}
{"ts": "156:38", "speaker": "I", "text": "Gab es bei dieser Offload-Strategie Bedenken hinsichtlich der Sicherheit?"}
{"ts": "156:44", "speaker": "E", "text": "Ja, wir mussten sicherstellen, dass die Cache-TTL nicht länger als 30 Sekunden ist, um Revokationslisten zu respektieren. This trade-off was documented in DEC-ORI-042 with sign-off from both Security and Performance leads."}
{"ts": "156:38", "speaker": "I", "text": "Könnten Sie mir bitte noch erläutern, wie Sie im Build-Stand jetzt die API-Rate-Limits gegen externe Testtools absichern?"}
{"ts": "156:43", "speaker": "E", "text": "Ja, wir nutzen dafür ein zweistufiges Limit: intern limitieren wir per Envoy Filter bei 500 RPS und extern via Kong Plugin bei 450 RPS. The internal limit is a guardrail for unexpected auth bypass attempts during QA load tests."}
{"ts": "156:53", "speaker": "I", "text": "Verstehe, und wie wird das in Ihrer IaC umgesetzt?"}
{"ts": "156:57", "speaker": "E", "text": "Wir haben in Terraform ein Modul 'gw_rate_limit', das die EnvoyFilter CRDs provisioniert. Zusätzlich haben wir ein variables.tf, das aus der CI/CD-Pipeline die aktuellen Testprofile injiziert."}
{"ts": "157:06", "speaker": "I", "text": "And how do you validate that this doesn't violate SLA-ORI-02 p95 latency?"}
{"ts": "157:10", "speaker": "E", "text": "We run synthetic traffic in staging, measure via Nimbus Observability’s latency dashboards, and compare p95 vs our 120ms SLO. Falls wir >110ms sehen, triggern wir automatisch einen Canary-Rollback."}
{"ts": "157:21", "speaker": "I", "text": "Gab es zuletzt einen Canary-Rollback aus diesem Grund?"}
{"ts": "157:25", "speaker": "E", "text": "Ja, Ticket GW-5120, am 03.05., ein neues Auth-Plugin hat TLS Handshake verlängert, wir lagen bei 128ms p95, rollback nach RB-GW-011 Abschnitt 4.2."}
{"ts": "157:36", "speaker": "I", "text": "Wie stimmen Sie solche Rollbacks mit Security ab, wenn es um Auth-Plugins geht?"}
{"ts": "157:40", "speaker": "E", "text": "Wir haben ein Kurzprotokoll-Format, das in Confluence unter POL-SEC-001 referenziert ist. There we justify the temporary rollback, plus a risk note if mTLS enforcement is reduced temporarily."}
{"ts": "157:50", "speaker": "I", "text": "Und wie wird das dann wieder auf Prod gehoben?"}
{"ts": "157:54", "speaker": "E", "text": "Fix wird als Hotpatch in Feature-Branch gepusht, durchläuft Blue/Green Deployment nach RB-GW-011, Abschnitt 5.1 bis 5.3, mit Live Traffic Shadowing."}
{"ts": "158:04", "speaker": "I", "text": "Do you simulate the shadow traffic with real auth tokens?"}
{"ts": "158:08", "speaker": "E", "text": "Nur mit synthetischen Tokens aus Aegis IAM Sandbox, um keine echten Credentials zu riskieren. But the payload patterns are production-like to hit the caching layers realistically."}
{"ts": "158:17", "speaker": "I", "text": "Interessant, und welche offenen Risiken sehen Sie jetzt noch bis zum Go-Live?"}
{"ts": "158:21", "speaker": "E", "text": "Größtes Risiko ist aktuell eine mögliche Race Condition zwischen Auth-Refresh und Rate-Limit-Counters. Das ist in RFC-ORI-2024-07 dokumentiert, Entscheidung pending in Arch-Board nächste Woche."}
{"ts": "158:14", "speaker": "I", "text": "Könnten Sie mir bitte noch ein Beispiel geben, wie Sie im Orion Edge Gateway die Rate-Limits dynamisch anpassen, wenn Traffic-Spitzen auftreten?"}
{"ts": "158:19", "speaker": "E", "text": "Ja, äh, wir nutzen da eine Kombination aus Prometheus-Alerts und einem kleinen Go-Skript, das die Envoy-Konfiguration über unsere IaC-Pipeline anpasst. This is triggered when the 5-minute moving average of requests per second exceeds 85% of the configured limit."}
{"ts": "158:32", "speaker": "I", "text": "Interessant. Und wie stellen Sie sicher, dass diese Anpassung nicht gegen SLA-ORI-02 verstößt?"}
{"ts": "158:37", "speaker": "E", "text": "Wir haben im Runbook RB-GW-014 festgelegt, dass vor jeder Erhöhung des Limits ein Latenz-Check via Canary-Request durchgeführt wird. If p95 latency exceeds 110ms during test, the limit increase is aborted."}
{"ts": "158:48", "speaker": "I", "text": "Das heißt, Sie integrieren Observability direkt in die Entscheidungsschleife?"}
{"ts": "158:52", "speaker": "E", "text": "Genau. Und das war ein Lessons Learned aus Incident INC-GW-2023-11, wo wir ohne diesen Check in einen SLA-Breach gerutscht sind."}
{"ts": "159:01", "speaker": "I", "text": "Wie sieht denn die Schnittstelle zu Nimbus Observability dabei aus?"}
{"ts": "159:05", "speaker": "E", "text": "Wir ziehen die Metriken direkt aus dem Nimbus gRPC-Stream. There's a small adapter service we wrote, documented in RFC-NIM-45, that normalizes labels so our Gateway controller can consume them."}
{"ts": "159:16", "speaker": "I", "text": "Und wie funktioniert das Zusammenspiel mit der Auth-Integration, wenn Sie mTLS-Fixes wie bei GW-4821 ausrollen?"}
{"ts": "159:21", "speaker": "E", "text": "Da müssen wir die Zertifikatsrotation synchronisieren. We schedule it in a maintenance window defined in POL-OPS-007, and stage the certs in both the Auth service and the Gateway before flipping traffic."}
{"ts": "159:34", "speaker": "I", "text": "Gab es dabei jemals Konflikte mit den Least-Privilege-Policies?"}
{"ts": "159:38", "speaker": "E", "text": "Ja, einmal mussten wir temporär erweitere Rechte für den Deployment-Service gewähren. Das wurde in Ticket SEC-EXC-119 dokumentiert und von Security in unter 2h genehmigt."}
{"ts": "159:49", "speaker": "I", "text": "Wie dokumentieren Sie diese Abweichungen für spätere Audits?"}
{"ts": "159:53", "speaker": "E", "text": "Wir nutzen das Decision Log im Projekt-Wiki. Each entry links to the relevant ticket, runbook section, and a short risk assessment per AUD-LOG-002 template."}
{"ts": "160:03", "speaker": "I", "text": "Letzte Frage: Welche Risiken sehen Sie noch für den Go-Live, speziell im Hinblick auf Performance?"}
{"ts": "160:07", "speaker": "E", "text": "Das größte Risiko ist ein unerwartetes Zusammenspiel zwischen Rate-Limit-Bursting und Auth-Token-Validation. If the token service slows down, our latency could spike beyond 120ms. Wir haben einen Fallback-Cache geplant, dokumentiert in RFC-GW-129, um das abzufangen."}
{"ts": "160:14", "speaker": "I", "text": "Sie hatten vorhin den Trade-off zwischen Sicherheit und Latenz erwähnt. Könnten Sie das mal an einem Beispiel aus der Auth-Integration illustrieren, vielleicht mit Bezug auf Ticket GW-5173?"}
{"ts": "160:19", "speaker": "E", "text": "Ja, klar. In GW-5173 ging es um die Entscheidung, ob wir zusätzliche JWT-Signaturprüfungen inline machen oder per async worker. The inline check erhöht Sicherheit, aber wir haben bei Lasttests sofort gesehen, dass p95 von 108ms auf 137ms steigt, was das SLA-ORI-02 verletzt. Letztlich haben wir eine Hybridlösung implementiert: critical claims inline, rest deferred."}
{"ts": "160:27", "speaker": "I", "text": "Und wie wurde diese Hybridlösung dokumentiert, um audit-ready zu bleiben?"}
{"ts": "160:31", "speaker": "E", "text": "Wir haben dazu eine Policy-Deviation-Note in Confluence angelegt, verknüpft mit dem Architecture Decision Record ADR-ORI-14. Außerdem Link zum entsprechenden Abschnitt in POL-SEC-001, wo wir die Abweichung sauber begründen."}
{"ts": "160:38", "speaker": "I", "text": "Gab es spezielle Monitoring-Anpassungen, um sicherzustellen, dass deferred checks nicht verloren gehen?"}
{"ts": "160:43", "speaker": "E", "text": "Ja, wir haben im Nimbus Observability eine Custom Metric `auth.deferred.check_latency` eingeführt. With that, we can alert if deferred processing exceeds 200ms, and cross-correlate with gateway request IDs."}
{"ts": "160:50", "speaker": "I", "text": "Wie fließt diese Metrik in Ihre Go-Live-Risikoabschätzung ein?"}
{"ts": "160:55", "speaker": "E", "text": "Sie ist Teil des Risk Register RSK-ORI-Build, Kategorie 'Performance-Linked Security'. Falls wir >0.5% delayed checks sehen, blockt das den Deploy nach Runbook RB-GW-011 §4.3. That’s a go/no-go criterion."}
{"ts": "161:02", "speaker": "I", "text": "Hatten Sie schon mal den Fall, dass dieser Block gegriffen hat?"}
{"ts": "161:07", "speaker": "E", "text": "Einmal in Staging, als wir mTLS handshake fix GW-4821 rolled out haben. The extra CPU cost verschob deferred auth workers, delay spiked auf 0.8%, wir haben per Blue/Green rollback gemacht."}
{"ts": "161:15", "speaker": "I", "text": "Interessant. Welche Lessons Learned haben Sie daraus gezogen?"}
{"ts": "161:19", "speaker": "E", "text": "Dass mTLS-Änderungen nicht isoliert betrachtet werden dürfen. Wir haben jetzt im Runbook eine Cross-Impact-Checkliste: jede TLS-Änderung muss gegen Auth- und Rate-Limit-Module getestet werden. It's a non-trivial multi-hop link we underestimated initially."}
{"ts": "161:27", "speaker": "I", "text": "Wie gehen Sie aktuell mit der Testing-Pipeline um, um solche Cross-Impacts früh zu finden?"}
{"ts": "161:32", "speaker": "E", "text": "Wir haben im CI/CD (Jenkins + Terraform IaC) eine Stage 'Integrated PerfSec Test', die mit synthetischen Load Patterns aus RFC-1114 arbeitet. Das deckt Latency und Security Enforcement in one go ab."}
{"ts": "161:39", "speaker": "I", "text": "Könnte diese Pipeline auch automatisiert entscheiden, ob ein Deployment gestoppt wird?"}
{"ts": "161:43", "speaker": "E", "text": "Ja, wir haben ein Gate-Script, das die KPIs aus Nimbus API zieht. If p95 latency >120ms oder deferred check ratio >0.5%, es erstellt automatisch ein Blocker-Ticket in JIRA, z.B. BLOCK-ORI-27, und der Deploy bleibt in Blue-Phase hängen."}
{"ts": "161:46", "speaker": "I", "text": "Lassen Sie uns noch mal auf die Optimierungen eingehen – wie haben Sie die Cache-Layer-Anpassungen so abgestimmt, dass sie sowohl das Auth-Modul als auch das Observability-Setup nicht beeinträchtigen?"}
{"ts": "161:50", "speaker": "E", "text": "Wir haben tatsächlich ein zweistufiges Cache-Design eingeführt. Die erste Stufe ist lokal im Gateway-Node, mit einem 200 ms TTL für Auth-Tokens, die zweite Stufe ist distributed via Memq-Fabric. By segmenting the cache namespaces, we avoided polluting the observability event stream with outdated auth metrics."}
{"ts": "161:58", "speaker": "I", "text": "Interessant. Hatten Sie dafür ein spezielles RFC oder Ticket als Basis?"}
{"ts": "162:02", "speaker": "E", "text": "Ja, RFC-ORION-128 war der Ausgangspunkt. Darin haben wir dokumentiert, wie Cache-Invaliderung unter 50 ms bleiben muss, um SLA-ORI-02 nicht zu verletzen. Ticket GW-5093 enthielt die Testscripte dazu."}
{"ts": "162:09", "speaker": "I", "text": "Und wie haben Sie diese Änderung ausgerollt, ohne die mTLS-Fixes aus GW-4821 zu gefährden?"}
{"ts": "162:13", "speaker": "E", "text": "Wir haben Blue/Green Deployments nach RB-GW-011 benutzt, mit einem zusätzlichen Canary-Step nur für das mTLS-Handshake-Modul. That allowed us to validate handshake timings before the cache layer change went live."}
{"ts": "162:20", "speaker": "I", "text": "Gab es dabei unerwartete Seiteneffekte auf die Latenz?"}
{"ts": "162:23", "speaker": "E", "text": "Minimal. Die p95 Latency stieg kurzfristig um ~8 ms in Green-Phase, wurde aber durch Justierung der Thread-Pools im Auth-Worker-Prozess kompensiert. Wir haben das in der Performance-Analyse vom 03.05. dokumentiert."}
{"ts": "162:31", "speaker": "I", "text": "Wie sieht hier die Zusammenarbeit mit dem Security-Team aus, um POL-SEC-001 einzuhalten, gerade bei solchen Paralleländerungen?"}
{"ts": "162:35", "speaker": "E", "text": "Wir halten wöchentliche Change-Review-Calls. Every non-standard deviation, like temporarily elevated cache read permissions for debugging, must be logged in DEC-LOG per SecOps policy. Diese Logs werden dann im Quartals-Audit geprüft."}
{"ts": "162:43", "speaker": "I", "text": "Gab es schon mal den Fall, dass ein solcher Ausnahme-Log Einwände im Audit ausgelöst hat?"}
{"ts": "162:47", "speaker": "E", "text": "Einmal, ja. Audit Q4/23 hat bemängelt, dass der Debug-Access nicht innerhalb der vorgesehenen 15 Minuten revoked wurde. Das hat zu Ticket SEC-774 geführt und wir haben daraufhin ein Auto-Revocation-Skript geschrieben."}
{"ts": "162:55", "speaker": "I", "text": "Das Auto-Revocation-Skript – war das in der IaC-Pipeline integriert?"}
{"ts": "162:58", "speaker": "E", "text": "Genau, wir haben es als Terraform-Post-Apply Hook implementiert. This ensures that any temporary IAM role created during a deployment is revoked automatically without manual intervention."}
{"ts": "163:05", "speaker": "I", "text": "Zum Abschluss: Welche Lessons Learned ziehen Sie für den Go-Live aus dieser Kette von Änderungen?"}
{"ts": "163:09", "speaker": "E", "text": "Dass technische Abhängigkeiten – Auth, Observability, Security – früh in der Planung zusammen betrachtet werden müssen. And, critically, that every latency optimization must be run through the same mTLS and policy compliance gates, even if it looks isolated."}
{"ts": "163:22", "speaker": "I", "text": "Können Sie mir bitte noch schildern, wie Sie im letzten Incident RB-GW-011 angepasst haben, um trotz hoher Last den Blue/Green Switch sauber hinzubekommen?"}
{"ts": "163:28", "speaker": "E", "text": "Ja, wir mussten im Abschnitt 4.3 vom Runbook einen zusätzlichen Check einbauen – ein pre-switch mTLS handshake verification, weil wir kurz davor GW-4821 in Staging gefixt hatten. Without that, we risked a partial handshake drop under peak load."}
{"ts": "163:36", "speaker": "I", "text": "Und diese Erweiterung war nicht offiziell dokumentiert?"}
{"ts": "163:39", "speaker": "E", "text": "Genau, das war eine dieser heuristischen Anpassungen, die wir aus Erfahrung kennen – in meinen persönlichen Notes unter 'RB-GW-011 delta cases'. We later proposed it in RFC-GW-1197 to formalize the step."}
{"ts": "163:46", "speaker": "I", "text": "Wie haben sich diese Änderungen auf das p95 Latenz-SLO ausgewirkt?"}
{"ts": "163:50", "speaker": "E", "text": "Minimal – wir haben vor dem Switch ein Sampling nach RFC-1114 gemacht, also 5% der Requests durch die geänderte Handshake-Prozedur geleitet. The measurement from Nimbus Observability showed only +4ms median impact, well within SLA-ORI-02."}
{"ts": "163:58", "speaker": "I", "text": "Interessant. Gab es dabei Abhängigkeiten zur Auth-Integration?"}
{"ts": "164:02", "speaker": "E", "text": "Ja, wir mussten sicherstellen, dass der Token refresh endpoint im Aegis IAM immer vor dem Gateway-Switch erreichbar war. Otherwise, authentication failures could spike and skew latency metrics."}
{"ts": "164:09", "speaker": "I", "text": "Wie haben Sie das verifiziert?"}
{"ts": "164:12", "speaker": "E", "text": "Wir haben in der CI/CD-Pipeline einen Post-Deploy-Test aus IaC-Script TF-GW-AuthCheck eingefügt, der mTLS + Token refresh in einem Step prüft. That way, blue environment is fully ready before cutover."}
{"ts": "164:20", "speaker": "I", "text": "Gab es Security-Trade-offs in diesem Prozess?"}
{"ts": "164:23", "speaker": "E", "text": "Ja, leicht – wir haben temporär POL-SEC-001 minimal gelockert, um den Test-Client mit erweiterten Rechten laufen zu lassen. Das war in Ticket SEC-4522 dokumentiert und mit dem Security-Team abgestimmt."}
{"ts": "164:30", "speaker": "I", "text": "Und wie wurde das für Audit-Readiness festgehalten?"}
{"ts": "164:33", "speaker": "E", "text": "In unserem Decision Log DL-GW-08, mit Verweisen auf SEC-4522 und RFC-GW-1197. Plus einem Abschnitt zu den messbaren Effekten: 0.3% höherer CPU-Load, keine SLA-Verletzung."}
{"ts": "164:40", "speaker": "I", "text": "Wie bewerten Sie rückblickend das Risiko für den Go-Live?"}
{"ts": "164:43", "speaker": "E", "text": "Das größte Risiko bleibt, dass eine künftige mTLS-Änderung im Aegis IAM nicht rechtzeitig ins RB-GW-011 einfließt. Wir haben daher einen wöchentlichen Cross-Projekt-Review eingeführt, um genau solche Lücken vor dem Go-Live zu schließen."}
{"ts": "165:22", "speaker": "I", "text": "Sie hatten vorhin angesprochen, dass Sie bei einem Incident den RB-GW-011 angepasst haben. Können Sie erläutern, wie Sie die Änderung dokumentiert haben, um Audit-Readiness sicherzustellen?"}
{"ts": "165:28", "speaker": "E", "text": "Ja, wir haben die Anpassung direkt im Confluence-Runbook-Repo festgehalten, inklusive einer Change-Log Section mit Verweis auf Ticket INC-GW-7734. And we also linked it to RFC-ORIGW-09 so that the architectural implications are traceable."}
{"ts": "165:35", "speaker": "I", "text": "How did you ensure that this change didn't negatively impact the SLA-ORI-02 p95 latency target?"}
{"ts": "165:42", "speaker": "E", "text": "Wir haben direkt nach dem Hotfix in der Staging-Umgebung eine Synthetic Load Simulation gefahren, 10 Minuten Dauer, 95th Percentile lag bei 112 ms. Zusätzlich haben wir einen Canary-Release in Prod mit nur 5 % Traffic gemacht, bevor wir das Full Rollout durchgeführt haben."}
{"ts": "165:51", "speaker": "I", "text": "Gab es besondere Heuristiken, die Sie angewendet haben, als der Runbook-Eintrag noch nicht aktualisiert war?"}
{"ts": "165:58", "speaker": "E", "text": "Ja, in solchen Fällen nutzen wir das sogenannte 'Gateway Triage Pattern': erst Rate Limit Counters prüfen, dann Auth-Zeitstempel gegen Aegis IAM verifizieren, und finally packet capture machen, um mTLS-Handshake-Anomalien zu sehen. Those steps aren't written down formally but are common practice in our team."}
{"ts": "166:08", "speaker": "I", "text": "Sie erwähnen mTLS, wie haben Sie die Fixes aus GW-4821 ohne SLA-Verletzung in Prod gebracht?"}
{"ts": "166:15", "speaker": "E", "text": "Wir haben die OpenSSL-Library nur auf den grünen Nodes im Blue/Green Setup aktualisiert, dann per RB-GW-011 den Traffic in 10 %-Steps umgeschwenkt. Parallel lief Nimbus Observability mit speziellen mTLS-Handshake-Metriken aus RFC-NIM-1442."}
{"ts": "166:26", "speaker": "I", "text": "How did Observability data influence your decision to proceed to 100% traffic?"}
{"ts": "166:31", "speaker": "E", "text": "Die Fehlerquote bei den Handshakes blieb unter 0,2 %, der p95 Response blieb im grünen Bereich. Also haben wir den finalen Switch gemacht, documented in CAB-Decision GW-CAB-2024-05."}
{"ts": "166:40", "speaker": "I", "text": "Gab es bei der Auth-Integration Einschränkungen, die Sie bei der Latenzoptimierung berücksichtigen mussten?"}
{"ts": "166:46", "speaker": "E", "text": "Ja, das Token-Introspection-Intervall aus Aegis IAM durfte nicht verkürzt werden, sonst riskieren wir Policy-Verletzungen gem. POL-SEC-001. Instead we cached successful introspection results for 30 seconds locally at the gateway, reducing repeated lookups."}
{"ts": "166:57", "speaker": "I", "text": "Wie haben Sie diese Cache-Strategie abgesichert gegen Security-Risiken?"}
{"ts": "167:02", "speaker": "E", "text": "Wir haben eine Revocation-Webhook-Integration implementiert, die bei Token-Entzug den Cache sofort leert. Das war in RFC-GW-117 beschrieben und von Security abgenommen."}
{"ts": "167:11", "speaker": "I", "text": "Looking ahead to Go-Live, what are your top two risks related to these changes?"}
{"ts": "167:16", "speaker": "E", "text": "Erstens, dass unter Volllast die Cache-Invalidation verzögert wird und damit kurzzeitig ungültige Tokens akzeptiert werden. Zweitens, dass ein nicht getesteter Failure Mode im mTLS-Subsystem bei hoher Verbindungsanzahl Latenzspitzen erzeugt. Beide Risiken sind in RISK-LOG-ORI-23 dokumentiert."}
{"ts": "167:02", "speaker": "I", "text": "Bevor wir schließen, könnten Sie mir noch schildern, wie Sie die Lessons Learned aus dem letzten Major Incident in den Build-Prozess zurückgespielt haben?"}
{"ts": "167:15", "speaker": "E", "text": "Ja, klar — wir haben das Incident Postmortem TCK-INC-2072 genommen, die Root-Cause-Analyse in Confluence dokumentiert, und daraus drei IaC-Checks in unserem Terraform-Pipeline-Template ergänzt. Also quasi lessons-learned-driven Automation."}
{"ts": "167:38", "speaker": "I", "text": "Wurden diese Checks auch gegen die Auth-Integration getestet, um die Rate-Limits zu validieren?"}
{"ts": "167:50", "speaker": "E", "text": "Genau, wir haben die Stage Auth-Staging-03 im CI/CD genutzt, die simulierte 500 RPS gegen den Gateway-Auth-Endpoint schickt. So konnten wir sehen, ob die Limits aus POL-RATE-005 verletzt werden."}
{"ts": "168:12", "speaker": "I", "text": "Did you tie that into Nimbus Observability's mTLS handshake metrics?"}
{"ts": "168:20", "speaker": "E", "text": "Yes, we added a span tag for `mtls.handshake.time` in the exporter. Das hat uns geholfen, die Korrelation zwischen TLS-Verzögerungen und hohen Auth-Latenzen zu sehen."}
{"ts": "168:42", "speaker": "I", "text": "Wie schnell konnten Sie diese Änderungen nach GW-4821 in Produktion bringen, ohne SLAs zu brechen?"}
{"ts": "168:53", "speaker": "E", "text": "Wir haben ein Blue/Green-Deployment gefahren, wie in RB-GW-011 beschrieben, und den Traffic-Switch in 2%-Schritten gemacht. Das dauerte etwa 25 Minuten total, blieb aber unter dem SLA-ORI-02 Latency-Target."}
