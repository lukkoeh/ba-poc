{"ts": "00:00", "speaker": "I", "text": "Können Sie kurz Ihre Rolle und Verantwortlichkeiten im Projekt Hera beschreiben, damit wir das Interview einordnen können?"}
{"ts": "03:15", "speaker": "E", "text": "Ja, gerne. Ich bin als QA Lead für die gesamte Teststrategie und -durchführung im Projekt 'Hera QA Platform' zuständig. In der Build-Phase bedeutet das, ich koordiniere Testdesign, Testautomatisierung und die Integration der Flaky-Test-Analyse-Engine. Außerdem sorge ich dafür, dass unsere Testprozesse mit den UX-Research-Ergebnissen aus der Designphase harmonieren."}
{"ts": "06:40", "speaker": "I", "text": "Wie interagieren Sie aktuell konkret mit den UX-Teams oder Research-Aktivitäten?"}
{"ts": "10:05", "speaker": "E", "text": "Wir haben wöchentliche Sync-Meetings mit dem UX-Research-Team, in denen wir Findings aus Usability-Tests besprechen. Diese fließen dann in sogenannte QA-UX-Alignment-Tickets ein, zum Beispiel QUX-112, wo wir testbare UX-Kriterien definieren. Das ist wichtig, um in der Build-Phase schnell verifizieren zu können, ob die erarbeiteten Designs auch unter Last und in Edge-Cases bestehen."}
{"ts": "14:10", "speaker": "I", "text": "Welche Kernziele verfolgen Sie in dieser Phase des Projekts?"}
{"ts": "18:00", "speaker": "E", "text": "Unser Hauptziel ist es, eine einheitliche Testorchestrierung zu etablieren, die sowohl funktionale als auch nicht-funktionale Tests umfasst. Ein weiteres Ziel ist, die Flaky-Test-Rate um mindestens 30 % zu senken, gemessen an den Metriken aus Nimbus Observability."}
{"ts": "22:30", "speaker": "I", "text": "Sie erwähnten Flaky-Tests – wie setzen Sie die Policy POL-QA-014 im Projekt praktisch um?"}
{"ts": "27:00", "speaker": "E", "text": "POL-QA-014 schreibt vor, dass wir Tests nach Risikoprofil priorisieren. Konkret bedeutet das, dass Tests mit hoher Business Impact Severity und hoher Change Frequency zuerst laufen. Wir nutzen dafür eine Gewichtungsmatrix aus dem Runbook RB-QA-033 und verknüpfen diese mit den Flaky-Score-Daten aus unserer Analytics-Engine."}
{"ts": "31:45", "speaker": "I", "text": "Welche Kriterien nutzen Sie, um Testprioritäten festzulegen?"}
{"ts": "36:20", "speaker": "E", "text": "Neben der Business Impact Severity berücksichtigen wir auch die Anzahl der betroffenen User Journeys, die in den Atlas Mobile Logs sichtbar sind, und die technische Komplexität laut RFC-1654. So entsteht eine Prioritätenliste, die wir im Jira-Board 'HERA-QA' pflegen."}
{"ts": "40:55", "speaker": "I", "text": "Wie fließen Erkenntnisse aus Flaky-Test-Analysen in die Teststrategie ein?"}
{"ts": "45:10", "speaker": "E", "text": "Wir haben im Helios Datalake ein dediziertes Dataset 'flaky_test_runs' angelegt. Die Analyse zeigt Muster, z. B. dass bestimmte Services nur unter bestimmten Load-Patterns fehlschlagen. Diese Erkenntnisse führen wir in RFC-1770 zusammen und passen danach die Testauswahl im Release Candidate Gate gemäß Runbook RB-QA-051 an."}
{"ts": "50:25", "speaker": "I", "text": "Welche Tools oder Methoden nutzen Sie für End-to-End Traceability?"}
{"ts": "54:50", "speaker": "E", "text": "Wir setzen auf ein kombiniertes System aus unserem internen Requirement-Tracker 'NoverTrack' und der Testmanagement-Lösung 'Qualisuite'. Über eine API-Verknüpfung mit Nimbus Observability können wir so von einer Anforderung bis zum letzten Testlauf und den zugehörigen Metriken alles nachvollziehen."}
{"ts": "59:30", "speaker": "I", "text": "Gab es Situationen, in denen Sie Erkenntnisse aus Atlas Mobile oder Helios Datalake für QA-Zwecke genutzt haben?"}
{"ts": "90:00", "speaker": "E", "text": "Ja, zum Beispiel im Ticket QA-472. Dort haben wir Crash-Reports aus Atlas Mobile mit Latenzdaten aus Helios korreliert. Das hat uns geholfen, einen kritischen Pfad im Payment-Flow zu identifizieren, der unter bestimmten Netzwerkbedingungen fehlschlug. Durch die priorisierte Testauswahl gemäß RFC-1770 konnten wir das in der nächsten Build-Version beheben."}
{"ts": "90:00", "speaker": "I", "text": "Können Sie uns ein konkretes Beispiel nennen, wo Sie zwischen Testabdeckung und Time-to-Market abwägen mussten?"}
{"ts": "90:10", "speaker": "E", "text": "Ja, das war im Sprint 14, als wir das neue Orchestrierungsmodul für parallele Testläufe einführen wollten. Die vollständige Abdeckung hätte laut Schätzung aus Ticket QA-4827 etwa zwei Wochen länger gedauert, was den Release Slot mit der Plattform-Engineering-Roadmap verpasst hätte."}
{"ts": "90:28", "speaker": "E", "text": "Wir haben uns daher auf die in POL-QA-014 als 'High Business Impact' klassifizierten Cases konzentriert und die Low-Risk Szenarien ins Post-Release-Testfenster verschoben. Das war in RFC-1822 dokumentiert."}
{"ts": "90:44", "speaker": "I", "text": "Wie haben Sie dieses Risiko quantifiziert?"}
{"ts": "90:50", "speaker": "E", "text": "Wir haben Nimbus Observability genutzt, um historische Fehlerhäufigkeiten aus Helios Datalake zu korrelieren. Daraus ergab sich ein erwarteter Defect Leakage von 0,8% für die verschobenen Szenarien, was in unserem SLA-QA-03 noch akzeptabel ist."}
{"ts": "91:05", "speaker": "I", "text": "Gab es für diese Entscheidung eine formale Risikoabnahme?"}
{"ts": "91:10", "speaker": "E", "text": "Ja, wir haben ein Risk Acceptance Form gemäß Runbook RB-QA-051 ausgefüllt. Der Approval-Workflow lief über das Gremium 'Release Candidate Board', was auch im Confluence-Page QA-HERA-DEC-14 hinterlegt ist."}
{"ts": "91:26", "speaker": "I", "text": "Wie hat sich diese Entscheidung im Nachgang ausgewirkt?"}
{"ts": "91:30", "speaker": "E", "text": "Interessanterweise traten die befürchteten Defects nicht in kritischen Pfaden auf, sondern in einem Randfall im Atlas Mobile Modul. Das wurde durch einen Hotfix in Sprint 15 adressiert, Ticket MOB-2231."}
{"ts": "91:46", "speaker": "I", "text": "Haben Sie daraus Lessons Learned für zukünftige Releases gezogen?"}
{"ts": "91:51", "speaker": "E", "text": "Ja, wir haben in AUD-24-Q2 vermerkt, dass Randfälle in mobilen Clients trotz niedriger Business-Priorität die UX stark beeinflussen können. Seitdem haben wir die Gewichtung in unserem Risk-Scoring-Modell angepasst."}
{"ts": "92:06", "speaker": "I", "text": "Können Sie erläutern, wie diese Anpassung konkret aussieht?"}
{"ts": "92:10", "speaker": "E", "text": "Früher haben wir mobile Randfälle mit maximal Faktor 0,5 gewichtet. Jetzt gehen wir auf mindestens 0,8, wenn die UX-Research-Teams potenzielle Irritationspunkte identifizieren. Das ist als Amendment in RFC-1770-Add01 erfasst."}
{"ts": "92:25", "speaker": "I", "text": "Wie reagieren andere Teams auf solche Änderungen im Modell?"}
{"ts": "92:30", "speaker": "E", "text": "Das Plattform-Engineering-Team begrüßt es, weil es die Endnutzerzufriedenheit stützt. Allerdings müssen wir die Testfenster jetzt sorgfältiger mit deren Release-Zyklen synchronisieren, was wir im Release Calendar Tool NovereonSync abbilden."}
{"ts": "92:48", "speaker": "I", "text": "Abschließend: Gibt es noch offene Risiken, die Sie für die kommenden Sprints besonders im Blick haben?"}
{"ts": "98:00", "speaker": "E", "text": "Ja, vor allem die Integration der neuen Flaky-Test-Erkennungslogik mit dem Legacy-Build-Server. Da haben wir in Ticket QA-4970 dokumentiert, dass unter hoher Last falsche Positive entstehen können. Wir planen dafür einen Stresstest in Sprint 17, basierend auf den Vorgaben aus RB-QA-061."}
{"ts": "98:00", "speaker": "I", "text": "Könnten Sie uns bitte ein Beispiel nennen, wo Sie zwischen Testabdeckung und Time-to-Market abwägen mussten?"}
{"ts": "98:06", "speaker": "E", "text": "Ja, im März hatten wir das Release Candidate Build 2.3, und laut RB-QA-051 hätten wir eigentlich den kompletten Regression Suite Lauf machen müssen. Wir wussten aber aus den letzten Flaky-Test-Analysen, dass 12 % der Tests instabil waren und keinen Mehrwert für die aktuelle Änderung brachten. Also haben wir entschieden, diese zu skippen, um den Cut-off für den Sprint zu halten."}
{"ts": "98:24", "speaker": "I", "text": "Wie haben Sie diese Entscheidung dokumentiert?"}
{"ts": "98:28", "speaker": "E", "text": "Wir haben ein Decision Record im Confluence angelegt und parallel ein Ticket im JIRA-Board, ID QA-DEC-4721. Darin referenzieren wir POL-QA-014 und die Ausnahmenregel im Abschnitt 4.2.2. Wir haben auch die Risiken quantifiziert: 5 % potenzielle Lücke in der Abdeckung, mitigiert durch fokussierte Smoke-Tests."}
{"ts": "98:49", "speaker": "I", "text": "Gab es anschließend Probleme durch diese Lücke?"}
{"ts": "98:53", "speaker": "E", "text": "Nein, keine kritischen Defekte. Wir hatten einen Minor Bug im Payment-Flow, der aber im Post-Release Monitoring dank Nimbus Observability aufgefallen ist und innerhalb von 12 Stunden gepatcht wurde."}
{"ts": "99:07", "speaker": "I", "text": "Interessant. Wie haben Lessons Learned aus AUD-24-Q2 Ihre Entscheidungskriterien beeinflusst?"}
{"ts": "99:12", "speaker": "E", "text": "Der AUD-24-Q2 Access Review Summary hat gezeigt, dass wir früher zu viele Low-Risk-Tests priorisiert haben, nur um Checklisten zu erfüllen. Seitdem setzen wir stärker auf Risk-Matrix-Bewertung aus RFC-1770, um High-Risk-Bereiche wie Authentifizierung und Data Integrity vorzuziehen."}
{"ts": "99:30", "speaker": "I", "text": "Gab es Fälle, in denen Sie bewusst gegen die Empfehlung aus der Risk-Matrix entschieden haben?"}
{"ts": "99:35", "speaker": "E", "text": "Ja, beim Atlas Mobile Modul im April. Die Risk-Matrix stufte den neuen Offline-Sync als Medium Risk ein, aber aus unserer Erfahrung mit Helios Datalake wussten wir, dass Sync-Fehler katastrophal eskalieren können. Also haben wir hochpriorisiert und zusätzliche Tests geschrieben, obwohl das Release-Ziel eng war."}
{"ts": "99:54", "speaker": "I", "text": "Und wie wurde diese Abweichung festgehalten?"}
{"ts": "99:58", "speaker": "E", "text": "Im RFC-1822 haben wir eine Abweichungsnotiz angehängt mit Verweis auf Incident-Report INC-HEL-042. Das war Teil unseres Compliance-Paketes für den Go-Live."}
{"ts": "100:12", "speaker": "I", "text": "Welche Risiken sehen Sie aktuell am Horizont für die Hera QA Plattform?"}
{"ts": "100:16", "speaker": "E", "text": "Größtes Risiko ist aktuell, dass Flaky-Test-Ergebnisse durch verteilte Build-Umgebungen inkonsistent werden. Wir haben bereits einen SLA-Entwurf mit Plattform-Engineering, um Build-Agent-Drift zu minimieren."}
{"ts": "100:30", "speaker": "I", "text": "Wie wollen Sie das messen?"}
{"ts": "100:34", "speaker": "E", "text": "Mit Metriken aus Nimbus Observability: Build Agent Image Hash Consistency und Test Retry Rate. Zielwerte sind im SLA-Draft 1.3 definiert, wir planen monatliche Reviews im QA Guild Meeting."}
{"ts": "106:00", "speaker": "I", "text": "Können Sie uns ein konkretes Beispiel aus der Build-Phase nennen, wo Sie zwischen Testabdeckung und Time-to-Market abwägen mussten?"}
{"ts": "106:08", "speaker": "E", "text": "Ja, äh, im Sprint 14 hatten wir das Modul für Flaky-Test-Erkennung fertig. Laut POL-QA-014 hätten wir es mit vollständiger Regression in drei Umgebungen testen müssen, aber das hätte den Release um acht Tage verzögert."}
{"ts": "106:22", "speaker": "E", "text": "Wir haben dann in RFC-1770 dokumentiert, dass wir eine risk-based Auswahl gemäß den Fehlerhistorien aus den letzten fünf Builds machen. Die Evidenz kam aus den Nimbus Observability Logs und den Fehlerclustern aus Atlas Mobile."}
{"ts": "106:36", "speaker": "I", "text": "Wie haben Sie das intern kommuniziert, damit alle Stakeholder mit der verkürzten Testabdeckung einverstanden waren?"}
{"ts": "106:42", "speaker": "E", "text": "Wir haben ein Ticket QA-HERA-448 im Jira angelegt, mit Verweis auf RB-QA-051, dort den Release Candidate Gate-Check angepasst und das Risiko im AUD-24-Q2 Access Review Summary-Format beschrieben."}
{"ts": "106:58", "speaker": "E", "text": "Dadurch konnten wir auch retrospektiv zeigen, dass die Entscheidung bewusst und mit Einverständnis des Product Owners getroffen wurde."}
{"ts": "107:05", "speaker": "I", "text": "Gab es bei dieser Abwägung konkrete Metriken, die ausschlaggebend waren?"}
{"ts": "107:10", "speaker": "E", "text": "Ja, die Mean Time to Detect (MTTD) für kritische Bugs lag bei 2,3 Stunden in der Staging-Umgebung, was laut SLA-QA-07 im grünen Bereich war. Außerdem zeigte die Flaky-Test-Analyse eine 72%ige Überlappung mit bereits getesteten Pfaden."}
{"ts": "107:26", "speaker": "I", "text": "Wie haben Sie sichergestellt, dass diese verkürzte Testphase keine Regressionen übersehen hat?"}
{"ts": "107:31", "speaker": "E", "text": "Wir haben parallel Monitoring-Hooks in der Helios Datalake Pipeline aktiviert, um nach Deployment in Produktion sofortige Anomalie-Erkennung zu haben. Das war ein Abgleich mit den Learnings aus AUD-24-Q2, wo uns solche Hooks gefehlt hatten."}
{"ts": "107:48", "speaker": "I", "text": "Können Sie dazu den Lessons Learned-Aspekt näher erläutern?"}
{"ts": "107:53", "speaker": "E", "text": "In AUD-24-Q2 hatten wir einen Incident, bei dem ein Berechtigungsfehler erst Tage später auffiel. Wir haben daraus abgeleitet, dass QA in kritischen Modulen Observability-Trigger setzen muss, um Testlücken schnell zu erkennen."}
{"ts": "108:08", "speaker": "E", "text": "In Hera haben wir deshalb alle risk-based verkürzten Tests mit Post-Deployment-Checks gekoppelt – das steht jetzt auch als Pflicht in RB-QA-051 v2.3."}
{"ts": "108:18", "speaker": "I", "text": "Gab es auch Gegenstimmen, die vollständige Testläufe gefordert haben?"}
{"ts": "108:23", "speaker": "E", "text": "Ja, das Plattform-Engineering-Team wollte initial keine Abstriche, aus Sorge um Integrationsfehler. Wir konnten sie aber mit den Korrelationsdaten aus Nimbus und dem Risikobericht in RFC-1770 überzeugen."}
{"ts": "108:38", "speaker": "E", "text": "Wir haben vereinbart, dass bei einer Flaky-Test-Overlap unter 50% sofort wieder Full Regression gefahren wird. Das ist jetzt als Decision Gate DG-HERA-06 dokumentiert."}
{"ts": "114:00", "speaker": "I", "text": "Sie hatten vorhin das Runbook RB-QA-051 erwähnt – können Sie beschreiben, wie genau es Ihre Freigabeentscheidungen in den letzten zwei Sprints beeinflusst hat?"}
{"ts": "114:05", "speaker": "E", "text": "Ja, klar. RB-QA-051 definiert bei uns das sogenannte Release Candidate Gate. In Sprint 18 habe ich es genutzt, um anhand der Metriken aus dem Nimbus Observability Dashboard gezielt zwei Module zu blocken, weil die Fehlerdichte oberhalb der in POL-QA-014 definierten Schwelle lag."}
{"ts": "114:15", "speaker": "E", "text": "Wir haben die Gate-Checks mit den Flaky-Test-Reports aus unserer Analytics-Pipeline verknüpft, sodass nicht nur harte Failures, sondern auch instabile Tests in die Entscheidung einfließen."}
{"ts": "114:22", "speaker": "I", "text": "Gab es dabei Schnittstellen zu anderen Projekten, z. B. Atlas Mobile oder Helios Datalake?"}
{"ts": "114:26", "speaker": "E", "text": "Ja, indirekt. Für ein Payment-Feature im Hera QA Platform mussten wir Testdaten aus Helios Datalake ziehen. Dabei haben wir festgestellt, dass ein Schema-Update in Helios zu fehlerhaften Mock-Daten führte, was über die Observability-Layer erst auffiel, als die Gate-Metriken sprunghaft anstiegen."}
{"ts": "114:38", "speaker": "E", "text": "Das hat uns gezwungen, ad hoc eine Anpassung in der RFC-1770 Risk-based Test Selection vorzunehmen, um die betroffenen Tests temporär niedriger zu priorisieren."}
{"ts": "114:46", "speaker": "I", "text": "Interessant, das heißt Sie mussten eine Multi-Hop-Verknüpfung zwischen QA-Policy, Observability und externen Datenquellen herstellen?"}
{"ts": "114:50", "speaker": "E", "text": "Genau. Wir haben im Ticket HERA-QA-4423 dokumentiert, wie die Datenqualität direkt in die Risk-Kalkulation eingeflossen ist. Ohne diese Kette hätten wir vermutlich falsche Block-Entscheidungen getroffen."}
{"ts": "114:59", "speaker": "I", "text": "Wie haben Sie das dem Management gegenüber begründet, gerade im Hinblick auf den Time-to-Market?"}
{"ts": "115:04", "speaker": "E", "text": "Wir haben in einem Review-Meeting aufgezeigt, dass ein Go-Live ohne Bereinigung der Helios-Daten zu einem Anstieg von Support-Tickets um schätzungsweise 35 % geführt hätte – basierend auf Lessons Learned aus AUD-24-Q2, wo ein ähnlicher Datenfehler in einem anderen Modul massive Nacharbeiten verursachte."}
{"ts": "115:16", "speaker": "E", "text": "Das war ein klassischer Trade-off: zwei Tage Verzögerung vs. mehrere Wochen Bugfixing nach Release."}
{"ts": "115:22", "speaker": "I", "text": "Und wie wurde diese Entscheidung dokumentiert?"}
{"ts": "115:25", "speaker": "E", "text": "Neben dem Update in RFC-1770 haben wir die Risikoabwägung in Confluence festgehalten, verlinkt mit Ticket HERA-QA-4423 und den relevanten Observability-Screenshots. So bleibt die Entscheidung auch auditierbar."}
{"ts": "115:34", "speaker": "I", "text": "Gab es Lessons Learned, die Sie daraus direkt in die Teststrategie übernommen haben?"}
{"ts": "115:38", "speaker": "E", "text": "Ja, wir haben einen zusätzlichen Schritt in RB-QA-051 ergänzt: Vor Gate-Entscheidung erfolgt nun ein automatisierter Datenqualitäts-Check gegen kritische externen Quellen. Das reduziert das Risiko von Fehlpriorisierungen im Risk-Based Testing."}
{"ts": "115:49", "speaker": "E", "text": "Das Team hat außerdem vereinbart, dass bei Ausreißern in den Observability-Metriken immer eine Cross-Team-Abstimmung mit Atlas und Helios erfolgt, bevor der Release-Kandidat weitergeht."}
{"ts": "116:00", "speaker": "I", "text": "Könnten Sie noch etwas zu den Schnittstellen zwischen QA und Plattform-Engineering sagen, gerade im Hinblick auf das Hera-Projekt?"}
{"ts": "116:10", "speaker": "E", "text": "Ja, wir haben wöchentliche Syncs mit dem Plattform-Engineering, um sicherzustellen, dass unsere Testumgebungen konsistent mit den Deploy-Pipelines laufen. Besonders im Build-Cluster HERA-B2 mussten wir einen Abgleich mit Runbook RB-PL-019 machen."}
{"ts": "116:25", "speaker": "I", "text": "Gab es da spezifische technische Herausforderungen?"}
{"ts": "116:31", "speaker": "E", "text": "Definitiv. Die Container-Images hatten abweichende NodeJS-Versionen, was zu Flaky Tests in den UI-Modulen führte. Wir haben das über ein Observability-Dashboard im Nimbus-Cluster nachverfolgt."}
{"ts": "116:50", "speaker": "I", "text": "Wie fließen solche Observability-Daten in Ihre Priorisierung ein?"}
{"ts": "116:56", "speaker": "E", "text": "Wir mappen die Metriken direkt gegen unsere Risk Scores aus RFC-1770. Wenn ein Modul hohe Error Rates und gleichzeitig hohe Business Criticality hat, rutscht es im Sprint-Plan nach oben."}
{"ts": "117:15", "speaker": "I", "text": "Und wie verknüpfen Sie das mit Artefakten aus anderen Projekten, etwa Atlas Mobile?"}
{"ts": "117:21", "speaker": "E", "text": "Wir haben für Atlas Mobile ein eigenes Traceability-Schema. Über die API-Gateways können wir Testfälle und Bugs mit Hera-IDs verlinken, z. B. HERA-TC-2045 und AMB-BUG-873."}
{"ts": "117:38", "speaker": "I", "text": "Das klingt nach einem komplexen Mapping. Benutzen Sie dafür spezielle Tools?"}
{"ts": "117:44", "speaker": "E", "text": "Ja, ein internes Tool namens LinkBridge, das Jira, unser Testmanagement und das Confluence-Wiki synchronisiert. Es prüft auch gegen die Gate-Kriterien aus RB-QA-051."}
{"ts": "118:00", "speaker": "I", "text": "Wie gehen Sie vor, wenn Release-Zyklen zwischen Teams auseinanderlaufen?"}
{"ts": "118:06", "speaker": "E", "text": "Wir definieren Cut-off-Dates in den Release-Kalendern und nutzen einen Freeze-Branch. Für Ausnahmen gibt es einen Fast-Track-Prozess, dokumentiert in RFC-1821."}
{"ts": "118:20", "speaker": "I", "text": "Gibt es ein Beispiel, wo Sie Abdeckung zugunsten von Time-to-Market reduziert haben?"}
{"ts": "118:26", "speaker": "E", "text": "Ja, beim letzten Sprint mussten wir die End-to-End Tests für das neue Reporting-Modul um zwei Szenarien kürzen, um den Launch-Termin zu halten. Das haben wir in Ticket HERA-RISK-552 dokumentiert."}
{"ts": "118:42", "speaker": "I", "text": "Wie mitigieren Sie die damit verbundenen Risiken?"}
{"ts": "118:48", "speaker": "E", "text": "Wir haben Post-Release Monitoring definiert, inklusive zusätzlicher Log-Level-Erhöhungen und Alerting über Nimbus. Zusätzlich steht im Runbook RB-QA-089, wie wir kritische Bugs innerhalb von 24h patchen."}
{"ts": "124:00", "speaker": "I", "text": "Sie hatten vorhin kurz die Schnittstelle zu Atlas Mobile erwähnt — könnten Sie das bitte genauer ausführen, gerade im Hinblick auf unsere Traceability-Anforderungen?"}
{"ts": "124:20", "speaker": "E", "text": "Ja, sicher. Für Atlas Mobile haben wir eine Schnittstelle gebaut, die die Testfall-IDs aus Hera direkt mit den User Journey IDs aus Atlas verlinkt. Das lief zunächst manuell, jetzt aber automatisiert über ein kleines Skript aus dem Toolchain-Repo QA-INT-072. Dadurch können wir im Runbook RB-QA-051 beim Release Candidate Gate direkt sehen, welche mobile Journey durch welche automatisierten Tests abgedeckt ist."}
{"ts": "124:50", "speaker": "I", "text": "Und wie fließen Observability-Daten da hinein?"}
{"ts": "125:05", "speaker": "E", "text": "Wir haben mit dem Nimbus Observability Team eine Metrik definiert: 'Test Coverage Drift'. Die basiert auf Logs aus Helios Datalake, wo wir sehen, welche Funktionen im Feld genutzt werden. Wenn eine Funktion oft genutzt wird, aber nur eine geringe Testabdeckung hat, wird das in unserer Risk Matrix — wie in RFC-1770 beschrieben — hoch priorisiert."}
{"ts": "125:35", "speaker": "I", "text": "Das heißt, Sie verbinden Nutzungsdaten mit Testpriorität?"}
{"ts": "125:50", "speaker": "E", "text": "Genau. Das war einer der Multi-Hop-Prozesse, die wir entwickelt haben: Helios liefert Usage Patterns → unser QA-Analytics-Modul im Hera Backend mappt diese auf Testfall-IDs → Risk Score wird neu berechnet. Diese Integration hat uns geholfen, in Sprint 14 drei kritische Lücken zu schließen, bevor sie in Produktion gingen."}
{"ts": "126:20", "speaker": "I", "text": "Klingt nach einer engen Abstimmung. Gab es technische Stolpersteine?"}
{"ts": "126:35", "speaker": "E", "text": "Oh ja, insbesondere bei der Synchronisation der IDs. Atlas Mobile nutzt UUIDv6, während Hera interne sequenzielle IDs hat. Wir mussten einen Mapping-Service mit Caching einführen, um Latenzspitzen zu vermeiden — dokumentiert in Ticket QA-HER-2745."}
{"ts": "127:00", "speaker": "I", "text": "Wie wirkt sich das auf Time-to-Market aus?"}
{"ts": "127:15", "speaker": "E", "text": "Kurzfristig hat es zwei zusätzliche Build-Tage gekostet. Langfristig sparen wir aber Zeit, weil wir weniger manuelle Mapping-Fehler haben. Wir haben das in unserer Lessons Learned Sektion der AUD-24-Q2 Access Review Summary vermerkt, um ähnliche Projekte vorzuwarnen."}
{"ts": "127:40", "speaker": "I", "text": "Haben Sie da auch ein Risiko-Log geführt?"}
{"ts": "127:55", "speaker": "E", "text": "Ja, im Confluence-Bereich 'Hera-Risiken'. Unter Risiko-ID HER-RSK-019 ist dieser Mapping-Service beschrieben, inklusive Workaround-Plan laut POL-QA-014, falls der Cache ausfällt."}
{"ts": "128:20", "speaker": "I", "text": "Letzte Frage dazu: Gab es eine Situation, wo Sie trotz hohem Risk Score auf einen Test verzichtet haben?"}
{"ts": "128:35", "speaker": "E", "text": "Ja, im Sprint 15 hatten wir ein Feature mit Risk Score 7, aber die Implementierung war ein A/B-Test für nur 2% der Nutzer. Aufgrund des engen Release-Fensters haben wir nur einen Smoke-Test gefahren und den Rest ins Post-Release-Testing verschoben. Entscheidung dokumentiert in RFC-1822."}
{"ts": "129:00", "speaker": "I", "text": "Und wie haben Sie das kommuniziert?"}
{"ts": "129:15", "speaker": "E", "text": "Über das wöchentliche QA-Update im Teams-Kanal und einen Eintrag im Release-Log. Wir haben die Stakeholder explizit auf die Abweichung von RB-QA-051 hingewiesen, um spätere Missverständnisse zu vermeiden."}
{"ts": "132:00", "speaker": "I", "text": "Lassen Sie uns noch einmal auf die Schnittstelle zu Helios Datalake eingehen – wie nutzen Sie die dortigen Daten im Hera QA Kontext konkret?"}
{"ts": "132:06", "speaker": "E", "text": "Also, wir haben da einen wöchentlichen Export der Testlauf-Metadaten, ähm, in das Helios Datalake. Dort laufen die Daten durch ein ETL-Skript aus dem Runbook RB-QA-051, Anhang C, um sie für die Risk-Matrix aus RFC-1770 aufzubereiten."}
{"ts": "132:14", "speaker": "I", "text": "Und diese Risk-Matrix, die wird dann zentral in Hera eingespeist, korrekt?"}
{"ts": "132:19", "speaker": "E", "text": "Genau, wir mappen die Risiken auf die Test-IDs, die wiederum in Atlas Mobile referenziert sind. So sehen wir sofort, wenn ein Flaky-Test aus Atlas auch in den Helios-Daten auffällig wird."}
{"ts": "132:27", "speaker": "I", "text": "Gab es technische Hürden bei dieser Verknüpfung?"}
{"ts": "132:32", "speaker": "E", "text": "Ja, die größte Hürde war das Timestamp-Format. Nimbus liefert in UTC, Helios in epoch milliseconds – wir mussten einen Normalizer schreiben, damit die Risk-Based Priorisierung nicht durch falsche Zeitfenster verfälscht wird."}
{"ts": "132:41", "speaker": "I", "text": "Interessant. Haben Sie das als Standard im QA-Team dokumentiert?"}
{"ts": "132:46", "speaker": "E", "text": "Ja, das ist jetzt als Best Practice im internen Confluence unter QA-STD-Helios-02 festgehalten und wird bei jedem neuen Projekt-Setup referenziert."}
{"ts": "132:53", "speaker": "I", "text": "Welche zusätzlichen Metriken aus Nimbus sind für Sie in der Build-Phase am wertvollsten?"}
{"ts": "132:59", "speaker": "E", "text": "Wir schauen stark auf die 'mean time to detect' und die 'coverage gap alerts'. Laut POL-QA-014 müssen wir bei Lücken über 5% innerhalb von 48 Stunden reagieren – das fließt direkt in unsere Sprintplanung ein."}
{"ts": "133:07", "speaker": "I", "text": "Können Sie ein Beispiel aus einem aktuellen Sprint nennen, wo das gegriffen hat?"}
{"ts": "133:12", "speaker": "E", "text": "Klar, im Sprint 24-Build-05 hat Ticket QA-HERA-482 einen Coverage Gap bei einem kritischen Checkout-Test gemeldet. Wir haben daraufhin die Priorität im Risk-Backlog hochgestuft und zwei andere Low-Risk-Tests verschoben."}
{"ts": "133:22", "speaker": "I", "text": "Gab es da Diskussionen mit dem Product Owner wegen der Verschiebung?"}
{"ts": "133:27", "speaker": "E", "text": "Ja, kurz – aber anhand der Kennzahlen aus Nimbus und der Vorschrift aus RFC-1770 konnten wir klar belegen, dass die Risiko-Reduktion wichtiger war als die Feature-Abdeckung in dem Sprint."}
{"ts": "133:35", "speaker": "I", "text": "Das heißt, Ihre Entscheidung basierte auf einer Kombination aus Observability-Daten und formaler Policy?"}
{"ts": "133:40", "speaker": "E", "text": "Genau, das ist dieser Multi-Hop-Link: Helios liefert die Historie, Nimbus die Echtzeit, RFC-1770 die Logik – und POL-QA-014 gibt den Rahmen. Zusammen ergibt das eine belastbare Entscheidungsgrundlage."}
{"ts": "133:36", "speaker": "I", "text": "Sie hatten vorhin ja schon die Priorisierung nach Risk-Based Testing erläutert. Mich würde interessieren, wie Sie konkret die Flaky-Test-Analysen aus Hera in Ihre täglichen Stand-ups einfließen lassen."}
{"ts": "133:44", "speaker": "E", "text": "Wir ziehen die aktuellen Flaky-Raten aus dem Hera Dashboard täglich gegen 8 Uhr. Diese Daten werden mit den Nimbus Observability Metrics korreliert, z. B. Error Rates aus den letzten 24 h. Im Stand-up markieren wir dann die kritischen Tests mit ID-Tag aus RFC-1770, um sie für das nächste Build in RB-QA-051 vorzuziehen."}
{"ts": "133:59", "speaker": "I", "text": "Und wie gehen Sie vor, wenn ein Test in Atlas Mobile und im Hera QA Platform unterschiedlich ausfällt?"}
{"ts": "134:05", "speaker": "E", "text": "Das ist tricky. Wir haben im Runbook RB-QA-051 einen Abschnitt zu Cross-System Discrepancies. Da steht drin, dass wir Helios Datalake Logs als Third Source nutzen. Wenn Atlas Mobile 'fail' und Hera 'pass' meldet, prüfen wir Helios auf entsprechende Event-Chains. In 70 % der Fälle zeigt sich ein Timing-Issue im Mobile Client."}
{"ts": "134:22", "speaker": "I", "text": "Interessant. Wie oft führen solche Abweichungen zu einer Verzögerung im Release Candidate Gate?"}
{"ts": "134:28", "speaker": "E", "text": "Selten mehr als 24 h. Wir haben ein SLA im QA-Playbook, Section 5.2, das für diesen Fall ein Fast-Track-Review vorsieht. Das nutzen wir, um das Gate nur für die betroffenen Module zu setzen, nicht für das ganze Release."}
{"ts": "134:43", "speaker": "I", "text": "Wie stimmen Sie sich in solchen Fällen mit dem Plattform-Engineering ab?"}
{"ts": "134:48", "speaker": "E", "text": "Wir haben ein gemeinsames Kanban-Board. Sobald ein Ticket mit Label 'Gate-Hold' erstellt wird, bekommt das Plattform-Engineering-Team einen automatischen Slack-Alert. Dann gibt es ein 15-Minuten-Huddle, in dem wir sowohl QA-Risiken als auch Deployment-Constraints abklopfen."}
{"ts": "135:03", "speaker": "I", "text": "Gab es schon mal einen Fall, wo Sie trotz bestehender Risiken bewusst durchgewunken haben?"}
{"ts": "135:09", "speaker": "E", "text": "Ja, Ticket QA-HERA-482. Da hatten wir einen bekannten, aber seltenen Bug im Report-Export. Laut AUD-24-Q2 war das Risiko akzeptabel, weil nur ein interner Analyse-Endpoint betroffen war. Wir haben POL-QA-014 Section 3.4 angewandt, die den 'Business Criticality Override' erlaubt."}
{"ts": "135:27", "speaker": "I", "text": "Wie dokumentieren Sie solche Overrides für die Nachvollziehbarkeit?"}
{"ts": "135:32", "speaker": "E", "text": "Im QA-Decision-Log, das ist ein Confluence-Space. Jede Entscheidung kriegt die Ticket-ID, Verweis auf das relevante Runbook und den Risk Score aus RFC-1770. Zusätzlich hängen wir die betroffenen Testartefakte als PDF an, damit der Audit-Trail vollständig ist."}
{"ts": "135:47", "speaker": "I", "text": "Wie fließen Lessons Learned aus diesen Overrides wieder zurück in Ihre Strategie?"}
{"ts": "135:52", "speaker": "E", "text": "Wir haben nach QA-HERA-482 im Monthly Retrospective beschlossen, für Export-Funktionalitäten einen dedizierten Canary-Testpfad einzubauen. Das ist inzwischen in RB-QA-051 Appendix C dokumentiert. Dadurch sinkt die Wahrscheinlichkeit, dass wir wieder in so eine Abwägung kommen."}
{"ts": "136:07", "speaker": "I", "text": "Das heißt, Sie passen Runbooks aktiv an, basierend auf Einzelfällen?"}
{"ts": "136:12", "speaker": "E", "text": "Genau. Die Policy POL-QA-014 schreibt das sogar vor: Section 2.1 'Continuous Improvement'. Wir fassen die Erkenntnisse aus Jira, Observability und Audit Reports zusammen und spielen sie ins Runbook ein. So bleibt die Teststrategie lebendig und angepasst."}
{"ts": "141:36", "speaker": "I", "text": "Könnten Sie mir ein Beispiel geben, wie Sie in der Build-Phase die Vorgaben aus POL-QA-014 konkret angewendet haben?"}
{"ts": "141:44", "speaker": "E", "text": "Ja, also in Sprint 12 haben wir etwa die Teststufen nach dem in POL-QA-014 definierten Priorisierungsmodell gewichtet. Kritische End-to-End-Flows wie der QA-Gate Login wurden im Runbook RB-QA-051 als Blocker markiert, um sicherzustellen, dass wir vor Release Candidate Build keine Regressionen dort haben."}
{"ts": "141:59", "speaker": "I", "text": "Und wie haben Sie diese Gewichtung im Tooling hinterlegt?"}
{"ts": "142:03", "speaker": "E", "text": "Wir haben dazu im internen Test-Management-Tool 'Novereon-QTrack' ein Feld 'Risk Priority' eingeführt. Das Mapping kam direkt aus RFC-1770, sodass die Traceability zu den Observability-Daten aus Nimbus gewährleistet blieb. Das hat uns auch geholfen, die flaky Tests im Modul 'Scheduler' schneller zu identifizieren."}
{"ts": "142:20", "speaker": "I", "text": "Gab es dabei Abhängigkeiten zu anderen Projekten, z.B. Atlas Mobile?"}
{"ts": "142:25", "speaker": "E", "text": "Definitiv. Ein Beispiel: Die Push-Notification-Tests für Atlas Mobile hängen von Event-Daten aus Helios Datalake ab. Durch die Observability-Integration in Nimbus konnten wir Korrelationen zwischen Datenlatenz und Testfehlschlägen herstellen, was wiederum in die Priorisierung nach POL-QA-014 einfloss."}
{"ts": "142:44", "speaker": "I", "text": "Das klingt nach einem komplexen Zusammenspiel. Wie dokumentieren Sie solche Cross-System-Beobachtungen?"}
{"ts": "142:50", "speaker": "E", "text": "Wir erfassen sie in Confluence-Seiten, verlinkt mit JIRA-Tickets, z.B. QA-4821. Dort halten wir die Metriken aus Nimbus, die relevanten Datenpfade aus Helios und die Testfälle aus QTrack fest. Diese Artefakte sind dann Teil des Release Candidate Gate gem. RB-QA-051."}
{"ts": "143:08", "speaker": "I", "text": "Wie fließen Lessons Learned wie aus AUD-24-Q2 in diese Dokumentation ein?"}
{"ts": "143:14", "speaker": "E", "text": "Bei AUD-24-Q2 haben wir festgestellt, dass fehlende Access Reviews zu verzögerten Teststarts führten. Als Reaktion haben wir im neuen Runbook-Abschnitt 'Pre-Test Access Checks' aufgenommen, sodass Rollen- und Rechteprüfungen vor Sprintbeginn abgeschlossen werden."}
{"ts": "143:32", "speaker": "I", "text": "Mussten Sie dabei zwischen Testabdeckung und Time-to-Market abwägen?"}
{"ts": "143:37", "speaker": "E", "text": "Ja, im Q3-Release haben wir die Testabdeckung für Low-Risk-Module temporär auf 60 % reduziert, um den geplanten Go-Live nicht zu gefährden. Das wurde in RFC-1822 dokumentiert, inklusive der Risikoanalyse aus RFC-1770 und den SLAs, die wir mit dem Produktmanagement abgestimmt hatten."}
{"ts": "143:54", "speaker": "I", "text": "Wie wurde diese Entscheidung intern akzeptiert?"}
{"ts": "143:58", "speaker": "E", "text": "Nach anfänglicher Skepsis hat das Steering Committee zugestimmt, weil wir klar zeigen konnten, dass durch die Observability-Daten aus Nimbus kein Anstieg kritischer Fehler zu erwarten war. Wir hatten dafür auch einen Simulationslauf im Test-Cluster durchgeführt."}
{"ts": "144:14", "speaker": "I", "text": "Gab es seitdem Änderungen an Ihrer Teststrategie?"}
{"ts": "144:18", "speaker": "E", "text": "Ja, wir haben die Risk-Based Testing-Checks automatisiert, sodass QTrack bei jedem neuen Build automatisch die relevanten Metriken aus Nimbus, Atlas Mobile und Helios abruft und die Prioritäten neu berechnet. Das reduziert die manuelle Pflege und beschleunigt das Release Candidate Gate signifikant."}
{"ts": "144:00", "speaker": "I", "text": "Sie hatten vorhin die Abhängigkeiten zwischen Hera QA und dem Helios Datalake erwähnt. Können Sie noch einmal ausführen, wie sich diese konkret auf Ihre Traceability auswirken?"}
{"ts": "144:05", "speaker": "E", "text": "Ja, klar. Also, wir ziehen z.B. Metriken zu Lastspitzen aus Helios, die wir mit den Testausführungen im Hera QA Platform Backend matchen. So sehen wir, ob bestimmte Flaky Tests unter Real-Load-Bedingungen häufiger auftreten. Das verknüpfen wir dann mit den Anforderungs-IDs aus Jira-QA, damit wir End-to-End nachvollziehen können, welcher Business Case betroffen ist."}
{"ts": "144:14", "speaker": "I", "text": "Und diese Verknüpfung, passiert die manuell oder automatisiert?"}
{"ts": "144:18", "speaker": "E", "text": "Teilautomatisiert. Wir haben ein Skript, das auf Basis des Runbooks RB-QA-051 die Testfall-IDs mit Observability-Tags kombiniert. Allerdings machen wir einen manuellen Review, bevor wir es ins Release Candidate Gate übergeben."}
{"ts": "144:26", "speaker": "I", "text": "Hat das schon mal dazu geführt, dass ein Release gestoppt wurde?"}
{"ts": "144:30", "speaker": "E", "text": "Ja, im Ticket QA-HERA-889. Da hatten wir eine Korrelation zwischen einem kritischen Flaky Test und einer Helios-Latenzspitze. Nach RFC-1770 mussten wir das als High-Risk einstufen und den Go-Live um zwei Tage verschieben."}
{"ts": "144:39", "speaker": "I", "text": "Gab es da Widerstand vom Produktmanagement wegen der Verzögerung?"}
{"ts": "144:43", "speaker": "E", "text": "Natürlich, ja. Die wollten das Feature unbedingt im Sprint halten. Aber wir haben uns auf POL-QA-014 berufen, wo klar steht, dass bei High-Risk Findings ein Release nur mit CTO-Freigabe erfolgen kann."}
{"ts": "144:51", "speaker": "I", "text": "Wie dokumentieren Sie solche Abweichungen für spätere Audits?"}
{"ts": "144:55", "speaker": "E", "text": "Wir hängen die Audit-Notizen direkt ans Ticket, inkl. Screenshot aus Nimbus Observability und dem Verweis auf AUD-24-Q2 Lessons Learned. Das ist wichtig, falls wir im nächsten Access Review ähnliche Muster sehen."}
{"ts": "145:03", "speaker": "I", "text": "Sie sprechen Lessons Learned an – gab es eine konkrete Anpassung der Teststrategie danach?"}
{"ts": "145:08", "speaker": "E", "text": "Ja, wir haben den Threshold für automatische High-Risk-Markierungen gesenkt. Früher lag der bei 95% Fehlerwahrscheinlichkeit unter Last, jetzt schon bei 85%, weil wir sahen, dass auch diese Fälle kritisch werden können."}
{"ts": "145:15", "speaker": "I", "text": "Das klingt nach einem Trade-off zwischen Sensitivität und False Positives."}
{"ts": "145:19", "speaker": "E", "text": "Genau. Mehr Sensitivität heißt auch mehr potenziell unnötige Stopps. Aber wir haben kalkuliert, dass ein Tag Delay günstiger ist als ein Rollback in der Produktion. Das haben wir in RFC-1821 dokumentiert."}
{"ts": "145:26", "speaker": "I", "text": "Wie halten Sie das Team bei solchen Änderungen im Loop?"}
{"ts": "145:30", "speaker": "E", "text": "Wir machen ein wöchentliches QA-Standup, teilen dort die geänderten Parameter und aktualisieren das Confluence-Playbook. Außerdem gibt's einen Slack-Alert, wenn der Risk-Score-Algorithmus angepasst wurde."}
{"ts": "146:00", "speaker": "I", "text": "Wir hatten vorhin über die Policy POL-QA-014 gesprochen. Können Sie konkret beschreiben, wie Sie diese in der Build-Phase praktisch umgesetzt haben?"}
{"ts": "146:04", "speaker": "E", "text": "Ja, also, wir haben POL-QA-014 operationalisiert, indem wir in unserem Jira-Board ein spezielles Label 'RiskHigh' eingeführt haben, das automatisch durch ein Skript vergeben wird, wenn die Impact- und Likelihood-Scores aus dem Nimbus-Metrikfeed über einem Schwellenwert liegen."}
{"ts": "146:09", "speaker": "I", "text": "Okay, und diese Scores kommen direkt aus der Observability-Pipeline?"}
{"ts": "146:12", "speaker": "E", "text": "Genau, das läuft so: Nimbus Observability aggregiert Logs aus Atlas Mobile, korreliert sie mit Usage-Events aus dem Helios Datalake, und unser Risk-Scoring-Job – basiert auf RFC-1770 – berechnet dann Prioritäten für Testfälle."}
{"ts": "146:17", "speaker": "I", "text": "Interessant. Wie verknüpfen Sie diese Priorisierungen mit Ihrem Release Candidate Gate aus RB-QA-051?"}
{"ts": "146:21", "speaker": "E", "text": "RB-QA-051 definiert ja, dass ein Release Candidate nur freigegeben wird, wenn alle 'RiskHigh'-Tests im letzten Run-Set bestanden wurden. Wir haben dafür eine automatisierte Gate-Check-Funktion in unserem CI/CD implementiert."}
{"ts": "146:26", "speaker": "I", "text": "Gab es Fälle, wo dieses Gate Sie tatsächlich gestoppt hat?"}
{"ts": "146:29", "speaker": "E", "text": "Ja, Ticket QA-2475 ist ein gutes Beispiel: Ein kritischer Test im Payment-Workflow bei Atlas Mobile ist auf einer Kombination aus Android 13 und schwacher Netzverbindung gefailt – das hat uns zwei Tage Verzögerung gekostet."}
{"ts": "146:34", "speaker": "I", "text": "Wie haben Sie das kommuniziert, gerade im Hinblick auf Time-to-Market-Druck?"}
{"ts": "146:38", "speaker": "E", "text": "Wir nutzen dafür das Risiko-Register im Confluence, referenzieren dort die Ticket-ID und den betroffenen Use-Case. Der Product Owner bekommt einen täglichen Risk-Status-Report, der auch die geplante Mitigation enthält."}
{"ts": "146:43", "speaker": "I", "text": "Und fließen solche Lessons Learned wieder zurück in die Teststrategie?"}
{"ts": "146:46", "speaker": "E", "text": "Ja, wir haben nach QA-2475 die Device-Matrix in der Teststrategie erweitert und in RFC-1784 dokumentiert, dass Low-Bandwidth-Szenarien für alle kritischen Flows Pflicht sind."}
{"ts": "146:51", "speaker": "I", "text": "Gab es bei der Anpassung Konflikte mit anderen Teams, z. B. Plattform-Engineering?"}
{"ts": "146:54", "speaker": "E", "text": "Ein wenig, ja – Plattform-Engineering wollte nicht, dass zusätzliche Test-VMs Bandbreite im Staging ziehen. Wir haben deshalb in Absprache mit dem Nimbus-Team einen separaten Low-BW-Testpool konfiguriert."}
{"ts": "146:59", "speaker": "I", "text": "Das klingt nach einer guten interdisziplinären Lösung. Haben Sie dazu eine formale Schnittstellenbeschreibung?"}
{"ts": "147:02", "speaker": "E", "text": "Ja, in unserem Systems Interface Doc SID-HERA-03 ist genau beschrieben, wie die Testpools über das interne VLAN angebunden sind und wie die Metrikfeeds für Risk Scoring isoliert werden."}
{"ts": "147:36", "speaker": "I", "text": "Könnten Sie ein konkretes Beispiel nennen, wo Sie in der Build-Phase des Hera QA Platform Projekts zwischen Testabdeckung und Time-to-Market abwägen mussten?"}
{"ts": "147:40", "speaker": "E", "text": "Ja, das war beim Sprint 14 Release Candidate. Wir hatten laut RB-QA-051 nur ein 48-Stunden-Fenster, aber die Abdeckung für die neuen Flaky-Test-Erkennungsalgorithmen lag erst bei 72 %. Wir haben dann nach Policy POL-QA-014 eine Risikoabwägung gemacht und unter Bezug auf RFC-1770 die kritischen Pfade priorisiert."}
{"ts": "147:47", "speaker": "I", "text": "Wie haben Sie diese Entscheidung dokumentiert?"}
{"ts": "147:50", "speaker": "E", "text": "Wir haben ein Jira-Ticket QA-HER-842 angelegt, mit Verweis auf die Auswertung aus Nimbus Observability. Dort sind die betroffenen Testfälle, deren Priorisierung, sowie ein Link zur Risikoanalyse im Helios Datalake hinterlegt."}
{"ts": "147:56", "speaker": "I", "text": "Gab es später Auffälligkeiten, die Ihre Entscheidung bestätigt oder widerlegt haben?"}
{"ts": "148:00", "speaker": "E", "text": "Interessanterweise zeigten die Telemetrie-Daten aus Atlas Mobile nach dem Release keine erhöhten Fehlerquoten in den nicht getesteten Bereichen. Das bestärkte uns, dass die Entscheidung, die kritischen Module zuerst zu testen, richtig war."}
{"ts": "148:06", "speaker": "I", "text": "Wie fließen solche Lessons Learned in Ihre kontinuierliche Verbesserung ein?"}
{"ts": "148:10", "speaker": "E", "text": "Wir pflegen einen Abschnitt 'Strategic Outcomes' in unserem QA-Wiki, in dem jede Entscheidung mit Evidenz, Ticket-Referenzen und möglichen Alternativen dokumentiert wird. Außerdem aktualisieren wir regelmäßig das Runbook RB-QA-051 mit diesen Erkenntnissen."}
{"ts": "148:17", "speaker": "I", "text": "Und wie gehen Sie vor, wenn die Release-Zyklen anderer Teams nicht mit Ihrem Zeitplan übereinstimmen?"}
{"ts": "148:21", "speaker": "E", "text": "Da greifen wir oft auf Mock-Services zurück, die wir in Kooperation mit dem Plattform-Engineering-Team definieren. Durch die Schnittstellenbeschreibungen in RFC-1822 können wir die Abhängigkeiten simulieren und trotzdem unsere Tests durchführen."}
{"ts": "148:27", "speaker": "I", "text": "Haben Sie ein Beispiel für eine solche Simulation?"}
{"ts": "148:30", "speaker": "E", "text": "Ja, für das Atlas Mobile Payment Modul. Das eigentliche Backend war noch nicht im Release, also haben wir basierend auf den Helios Datalake Schema-Dumps einen Mock gebaut, um die QA-Tests nicht zu verzögern."}
{"ts": "148:36", "speaker": "I", "text": "Gab es dabei Risiken?"}
{"ts": "148:39", "speaker": "E", "text": "Natürlich, die Hauptgefahr war, dass die Mocks nicht alle Edge-Cases abbildeten. Wir haben das Risiko im Ticket QA-HER-851 dokumentiert und als mittel eingestuft, mit der Maßgabe, diese Tests beim nächsten echten Backend-Release zu wiederholen."}
{"ts": "148:45", "speaker": "I", "text": "Abschließend: Welche Erkenntnisse aus dem AUD-24-Q2 Access Review Summary haben Ihre QA-Strategie beeinflusst?"}
{"ts": "148:49", "speaker": "E", "text": "Dort wurde festgestellt, dass einige Testumgebungen zu weitreichende Berechtigungen hatten. Wir haben daraufhin in RB-QA-051 eine neue Stufe eingebaut, die vor dem Release Candidate Gate eine automatisierte Access-Policy-Prüfung ausführt. Das reduziert das Risiko von unautorisierten Änderungen erheblich."}
{"ts": "149:06", "speaker": "I", "text": "Sie hatten vorhin die Schnittstelle zum Helios Datalake erwähnt. Mich würde interessieren, wie Sie in der Build-Phase konkret mit den Datenfeeds umgehen, um die Testauswahl zu verfeinern."}
{"ts": "149:11", "speaker": "E", "text": "Ja, also wir ziehen über den Helios Data Ingestor täglich die relevanten Event-Streams, filtern sie nach den in RFC-1770 definierten Risikokategorien, und spielen diese Metriken dann ins QA-Dashboard ein. Das Dashboard hängt wiederum an Nimbus Observability, so dass wir bei Flaky-Tests sehr schnell korrelieren können, ob ein bestimmtes Atlas Mobile Modul beteiligt ist."}
{"ts": "149:17", "speaker": "I", "text": "Das klingt ziemlich integriert. Nutzen Sie da auch die Vorgaben aus POL-QA-014 direkt, oder ist das mehr implizites Wissen?"}
{"ts": "149:23", "speaker": "E", "text": "Teilweise beides. POL-QA-014 gibt uns die formalen Priorisierungskriterien, etwa Severity Level und Business Impact Scores. Aber ehrlich gesagt, in der Praxis greifen wir oft zu Heuristiken, die wir aus den letzten drei Releases gelernt haben – etwa, dass bestimmte API-Endpunkte aus Atlas Mobile immer kritisch sind, wenn Helios auf Datenlatency läuft."}
{"ts": "149:31", "speaker": "I", "text": "Und wie binden Sie das Runbook RB-QA-051 Release Candidate Gate in diesen Fluss ein?"}
{"ts": "149:36", "speaker": "E", "text": "RB-QA-051 ist praktisch unser letzter Filter. Bevor ein Release-Kandidat durchs Gate geht, checken wir, ob die aus RFC-1770 abgeleiteten Testfälle vollständig und grün sind. Wenn Nimbus Observability noch offene Flaky-Metriken zeigt, ist das ein Blocker, es sei denn, wir haben ein dokumentiertes Risk-Acceptance-Ticket, z.B. QA-RISK-872."}
{"ts": "149:43", "speaker": "I", "text": "Gab es jüngst ein Beispiel, wo so ein Risk-Acceptance-Ticket notwendig war?"}
{"ts": "149:49", "speaker": "E", "text": "Ja, im letzten Sprint bei Hera 1.4 hatten wir einen Flaky-Integrationstest gegen den Payment-Service. Die Ursache lag in einem temporären Lag im Helios Datalake. Wir haben das als mittleres Risiko eingestuft, dokumentiert in QA-RISK-872 und vom Product Owner gegen Time-to-Market abgewogen. Der Release ging dann trotzdem live, mit dem Vermerk, dass im nächsten Sprint ein Hotfix kommt."}
{"ts": "149:56", "speaker": "I", "text": "Wie dokumentieren Sie solche Entscheidungen noch, außer in den Risk-Tickets?"}
{"ts": "150:01", "speaker": "E", "text": "Wir pflegen eine Confluence-Seite 'Decision Log Hera', wo jede Abweichung von POL-QA-014 oder RB-QA-051 eingetragen wird. Da ist auch der Link zum entsprechenden Jira-Ticket drin, inklusive der Nimbus- und Helios-Screenshots."}
{"ts": "150:07", "speaker": "I", "text": "Und gibt es Lessons Learned daraus, die Sie schon in die Strategie zurückgespielt haben?"}
{"ts": "150:13", "speaker": "E", "text": "Absolut. Wir haben z.B. aus der AUD-24-Q2 Access Review Summary gelernt, dass wir für kritische Services wie Payment einen kontinuierlichen Integrationstest im Staging mit Helios-Daten einführen sollten, statt nur im Release-Gate. Das reduziert Überraschungen."}
{"ts": "150:19", "speaker": "I", "text": "Interessant. Hat das Einfluss auf die Zusammenarbeit mit dem Plattform-Engineering-Team?"}
{"ts": "150:24", "speaker": "E", "text": "Ja, wir haben jetzt einen wöchentlichen Sync, in dem wir die Observability-Daten aus Nimbus direkt mit den Plattform-Logs matchen. So können wir schneller root-causen, ohne auf die formale Eskalationskette zu warten."}
{"ts": "150:29", "speaker": "I", "text": "Sehen Sie da noch Risiken, die nicht durch die bestehenden Prozesse abgedeckt werden?"}
{"ts": "150:34", "speaker": "E", "text": "Ein Restrisiko ist immer die Synchronisationslücke zwischen den Helios-Daten und den Atlas Mobile Builds. Wenn wir einen Build haben, der neue Datenstrukturen nutzt, die in Helios noch nicht live sind, fällt das manchmal erst im End-to-End-Test auf. Dafür planen wir gerade einen zusätzlichen Pre-Sync-Check in RFC-1782."}
{"ts": "151:06", "speaker": "I", "text": "Könnten Sie mir ein Beispiel geben, wo Sie im Projekt Hera zwischen Testabdeckung und Time-to-Market abwägen mussten?"}
{"ts": "151:11", "speaker": "E", "text": "Ja, das war im Sprint 42, als wir für das neue API-Gateway-Modul nur 60 % der geplanten Integrationstests durchführen konnten, weil der Release-Termin laut SLA-QA-03 feststand. Wir haben uns bewusst entschieden, die kritischen Pfade gemäß POL-QA-014 komplett zu testen und weniger kritische Endpunkte ins Post-Release-Testfenster zu verschieben."}
{"ts": "151:21", "speaker": "I", "text": "Wie haben Sie diese Entscheidung dokumentiert?"}
{"ts": "151:26", "speaker": "E", "text": "Wir haben ein Confluence-Page angelegt und den Link im Ticket QA-HER-572 hinterlegt. Dort sind die Risikoanalyse, die Referenz auf RFC-1770 sowie ein Auszug aus RB-QA-051 vermerkt."}
{"ts": "151:35", "speaker": "I", "text": "Gab es besondere Lessons Learned aus der AUD-24-Q2 Access Review Summary, die Ihre Strategie beeinflusst haben?"}
{"ts": "151:40", "speaker": "E", "text": "Ja, die Review hat gezeigt, dass privilegierte Testdatenzugriffe nicht ausreichend geloggt wurden. Daraufhin haben wir mit dem Nimbus Team ein Observability-Widget erstellt, das Testdatenzugriffe in Echtzeit trackt, und dies als verpflichtenden Check im RB-QA-051 verankert."}
{"ts": "151:51", "speaker": "I", "text": "Wie hat sich das in Ihren täglichen Abläufen niedergeschlagen?"}
{"ts": "151:56", "speaker": "E", "text": "Wir starten jetzt jeden Morgen mit einem kurzen Review der Access-Logs aus Helios Datalake, gefiltert über das Atlas Mobile Interface, um Anomalien früh zu erkennen. Das spart uns lange Root-Cause-Analysen am Ende."}
{"ts": "152:07", "speaker": "I", "text": "Gab es dabei technische Hürden?"}
{"ts": "152:12", "speaker": "E", "text": "Ja, Helios liefert die Logs im Parquet-Format, während Atlas nur JSON konsumieren kann. Wir haben deshalb einen Mini-ETL-Job im Hera Build-Pipeline-Stage eingebaut, der das Format on-the-fly konvertiert."}
{"ts": "152:23", "speaker": "I", "text": "Und das war kompatibel mit Ihren SLAs?"}
{"ts": "152:27", "speaker": "E", "text": "Gerade so. Wir mussten das ETL-Skript in Go implementieren, um den Overhead unter 200 ms pro File zu halten, damit wir die KPI aus SLA-QA-03 erfüllen."}
{"ts": "152:36", "speaker": "I", "text": "Wie stellen Sie sicher, dass solche Workarounds nicht zu dauerhaften technischen Schulden werden?"}
{"ts": "152:41", "speaker": "E", "text": "Wir markieren diese Lösungen in unserem Tech Debt Register, verlinken sie mit den entsprechenden QA-Tickets und planen quartalsweise eine Bereinigung. Für den ETL-Job gibt es bereits einen RFC-1842 zur Ablösung durch native Unterstützung in Atlas."}
{"ts": "152:52", "speaker": "I", "text": "In welchem Stadium befindet sich dieser RFC gerade?"}
{"ts": "152:56", "speaker": "E", "text": "Er ist im Review bei Plattform-Engineering. Wir haben eine Abhängigkeit zu deren Q3-Roadmap, daher müssen wir bis dahin mit dem Workaround leben, aber dank der klaren Dokumentation im RB-QA-051 ist das Risiko transparent."}
{"ts": "153:30", "speaker": "I", "text": "Lassen Sie uns nun auf konkrete Entscheidungen eingehen. Gab es zuletzt einen Fall, wo Sie zwischen Testabdeckung und Time-to-Market abwägen mussten?"}
{"ts": "153:36", "speaker": "E", "text": "Ja, im Sprint 42 hatten wir ein Feature im Hera QA Platform Backend, das laut POL-QA-014 eine vollständige Regression verlangt hätte. Aufgrund der engen Frist für das Kunden-Demo haben wir mithilfe von RFC-1770 nur die High-Risk-Komponenten getestet und Low-Risk-Module auf das nächste Release verschoben."}
{"ts": "153:45", "speaker": "I", "text": "Wie wurde diese Entscheidung dokumentiert? Gab es ein spezielles Ticket oder Protokoll?"}
{"ts": "153:49", "speaker": "E", "text": "Wir haben das in Jira-Ticket QA-DEC-228 festgehalten, inklusive Verweis auf Runbook RB-QA-051, Abschnitt 'Conditional Release Criteria'. Dort sind die Abweichungen vom Standardprozess und die Risikoakzeptanz vermerkt."}
{"ts": "153:57", "speaker": "I", "text": "Und wie haben Sie sichergestellt, dass die Risiken transparent sind gegenüber Stakeholdern?"}
{"ts": "154:01", "speaker": "E", "text": "Wir haben im wöchentlichen Hera Steering Meeting per Confluence-Page die Risikomatrix aus QA-DEC-228 vorgestellt und mit dem Product Owner abgestimmt. Zusätzlich flossen die Metriken aus Nimbus Observability in das Dashboard, sodass man die potenziellen Ausfälle quantifizieren konnte."}
{"ts": "154:12", "speaker": "I", "text": "Hat sich diese Vorgehensweise aus Lessons Learned ergeben, zum Beispiel aus dem AUD-24-Q2 Access Review Summary?"}
{"ts": "154:17", "speaker": "E", "text": "Definitiv. In AUD-24-Q2 wurde bemängelt, dass Entscheidungen zu Testauslassungen nicht ausreichend nachvollziehbar dokumentiert wurden. Seitdem verknüpfen wir jede Abweichung mit einem formalen Approval und archivieren die Entscheidung im QA-Archiv mit Referenzen zu den relevanten Policies."}
{"ts": "154:28", "speaker": "I", "text": "Gab es dabei Konflikte mit anderen Teams, zum Beispiel Plattform-Engineering?"}
{"ts": "154:32", "speaker": "E", "text": "Ja, das Plattform-Engineering-Team wollte die Pipeline für das Release-Branching optimieren, was unsere Möglichkeit, kurzfristig Testfälle zu ergänzen, einschränkte. Wir haben dann einen Kompromiss gefunden: kritische Tests laufen als Pre-Merge-Jobs, alles andere in einem separaten Nightly-Run."}
{"ts": "154:44", "speaker": "I", "text": "Wie haben Sie sichergestellt, dass Flaky-Test-Ergebnisse aus der Analytics-Komponente nicht fälschlich als stabile Risiken gewertet wurden?"}
{"ts": "154:49", "speaker": "E", "text": "Wir nutzen im Flaky-Test-Dashboard einen Confidence-Score. Tests unter 0,7 werden in der Risikobewertung ausgegraut und nicht als Blocker gezählt. Das ist auch im internen QA-Heuristic-Dokument vermerkt, obwohl es nicht Teil von POL-QA-014 ist."}
{"ts": "155:00", "speaker": "I", "text": "Haben Sie diese Heuristik schon einmal im Runbook ergänzt oder formalisiert?"}
{"ts": "155:04", "speaker": "E", "text": "Wir haben einen Draft für RB-QA-059 'Flaky Test Mitigation' erstellt. Es ist noch nicht freigegeben, aber wir beziehen uns intern bereits darauf, um konsistent zu handeln."}
{"ts": "155:12", "speaker": "I", "text": "Abschließend: Welche Risiken sehen Sie aktuell für den weiteren Verlauf der Build-Phase?"}
{"ts": "155:17", "speaker": "E", "text": "Das größte Risiko ist, dass sich durch parallele Entwicklungen in Atlas Mobile Schnittstellen ändern, die unsere End-to-End-Tests beeinflussen. Wir haben dafür ein Frühwarnsystem über Helios Datalake eingerichtet, das API-Schema-Änderungen in Echtzeit meldet. Dennoch bleibt die Abhängigkeit ein kritischer Punkt."}
{"ts": "155:06", "speaker": "I", "text": "Sie hatten vorhin erwähnt, dass der Risk-Selector aus RFC-1770 mit Daten aus Helios Datalake angereichert wird. Mich würde interessieren, wie Sie in der Build-Phase des Hera-Projekts diese Verbindung technisch umgesetzt haben."}
{"ts": "155:11", "speaker": "E", "text": "Ja, das ist ein mehrstufiger Prozess. Wir haben einen ETL-Job im QA-Cluster, der die Telemetriedaten von Nimbus Observability zieht, dort mit den Meta-Daten aus Atlas Mobile anreichert und dann in Helios Datalake schreibt. Von dort kann der Risk-Selector aus RFC-1770 direkt per API auf diese kombinierten Datensätze zugreifen."}
{"ts": "155:17", "speaker": "I", "text": "Gab es dabei besondere Herausforderungen in Bezug auf Datenlatenzen oder Synchronisationsprobleme?"}
{"ts": "155:22", "speaker": "E", "text": "Definitiv. Die größte Schwierigkeit war, dass die Observability-Pipelines von Nimbus alle 15 Minuten aktualisieren, während Helios nur stündlich konsolidiert. Wir mussten einen Cache-Layer implementieren, der im Runbook RB-QA-051 als Ausnahmebetrieb beschrieben ist, damit der Risk-Selector nicht mit veralteten Daten arbeitet."}
{"ts": "155:28", "speaker": "I", "text": "Und wie stellen Sie sicher, dass diese Ausnahme im Einklang mit der Policy POL-QA-014 steht?"}
{"ts": "155:33", "speaker": "E", "text": "Wir haben im QA-Governance-Board ein Approval eingeholt, Ticket QA-EXC-4021. Dort ist dokumentiert, dass der Cache-Layer nur in der Build-Phase aktiv ist und in der Release-Phase auf die reguläre Synchronisation zurückgefallen wird."}
{"ts": "155:39", "speaker": "I", "text": "Interessant. Können Sie ein Beispiel geben, wie diese angereicherten Daten konkret Testprioritäten beeinflusst haben?"}
{"ts": "155:44", "speaker": "E", "text": "Klar, bei der letzten Sprint-Abnahme haben wir gesehen, dass ein Feature in Atlas Mobile in Regionen mit schwacher Netzqualität instabil lief. Die Observability-Daten haben das bestätigt, sodass der Risk-Selector die zugehörigen Test-Cases hochgestuft hat."}
{"ts": "155:50", "speaker": "I", "text": "Das heißt, Sie haben hier eine direkte Kette von End-User-Daten bis zur Testauswahl."}
{"ts": "155:54", "speaker": "E", "text": "Genau, und das ist einer der Vorteile, wenn man die Systeme gut verzahnt. Ohne Helios-Datalake-Integration hätten wir diese Muster erst viel später erkannt."}
{"ts": "156:00", "speaker": "I", "text": "Haben Sie diese Vorgehensweise auch in Ihren Lessons Learned dokumentiert?"}
{"ts": "156:05", "speaker": "E", "text": "Ja, im Abschnitt 'Cross-System Insights' des AUD-24-Q2 Access Review Summary steht explizit, dass wir diesen Multi-Hop Workflow als Best Practice übernehmen wollen."}
{"ts": "156:11", "speaker": "I", "text": "Gab es Bedenken von anderen Teams, zum Beispiel wegen Datenzugriff oder Compliance?"}
{"ts": "156:15", "speaker": "E", "text": "Einige. Das Security-Team hat in RFC-SC-1181 festgehalten, dass nur pseudonymisierte Nutzungsdaten ins QA-Cluster gelangen dürfen. Wir mussten daher den ETL-Job um ein Maskierungsmodul erweitern."}
{"ts": "156:21", "speaker": "I", "text": "Das klingt nach zusätzlichem Overhead. Hat das Ihre Testzyklen verlangsamt?"}
{"ts": "156:26", "speaker": "E", "text": "Minimal, ja. Wir haben ca. 3 Minuten pro Aggregationslauf verloren, was wir aber durch Parallelisierung in unserer Test-Orchestrierung kompensieren konnten."}
{"ts": "156:30", "speaker": "I", "text": "Sie hatten vorhin schon kurz erwähnt, dass Sie Runbook RB-QA-051 als Gate nutzen. Können Sie mal genauer erläutern, wie das im täglichen Build-Prozess verankert ist?"}
{"ts": "156:35", "speaker": "E", "text": "Ja, klar. Also, RB-QA-051 ist bei uns in der CI/CD-Pipeline als zwingender Schritt eingebaut. Sobald ein Release Candidate getaggt wird, zieht sich der Pipeline-Job automatisch die Checkliste aus dem Runbook, prüft die Coverage-Reports und die Risk-Level aus RFC-1770 und generiert dann die Freigabe-Entscheidung. Ohne Abhaken dieser Punkte geht kein Build in die Staging-Umgebung."}
{"ts": "156:46", "speaker": "I", "text": "Interessant. Und wie fließen hier die Daten aus Helios Datalake ein, die Sie ja für Flaky-Test-Analysen nutzen?"}
{"ts": "156:52", "speaker": "E", "text": "Die Helios-Daten werden im Schritt davor schon verarbeitet. Wir haben eine kleine Lambda-Funktion, die vor dem Gate-Check die Flaky-Rate pro Testfall aus den letzten 10 Builds zieht. Wenn der Wert über 7 % liegt, wird der Test entweder mit erhöhter Priorität neu ausgeführt oder – falls er nicht kritisch ist – temporär aus der Gate-Blocker-Liste genommen, um False Positives zu vermeiden."}
{"ts": "157:05", "speaker": "I", "text": "Verstehe. Wie koordinieren Sie das mit den UX-Forschungsteams, die ja oft eigene Testkriterien haben?"}
{"ts": "157:12", "speaker": "E", "text": "Wir haben wöchentliche Syncs, in denen UX uns ihre kritischen Journeys geben. Diese mappen wir dann auf unsere Test-Suites. Wenn zum Beispiel eine neue Interaktion in der Hera QA Platform getestet werden soll, die für den Endnutzer entscheidend ist, stufen wir die Cases nach POL-QA-014 automatisch hoch, auch wenn das Risk-Level rein technisch etwas niedriger wäre."}
{"ts": "157:25", "speaker": "I", "text": "Das klingt nach einer engen Verzahnung. Gibt es da auch Überschneidungen mit den Daten aus Atlas Mobile?"}
{"ts": "157:31", "speaker": "E", "text": "Ja, Atlas liefert uns Telemetriedaten aus der mobilen Nutzung. Beispielsweise sehen wir dort Abbruchraten in bestimmten Workflows. Diese Metriken fließen dann in die Gewichtung der Testfälle ein – quasi ein Multi-Hop von User Behavior über Observability-Daten hin zur Testpriorisierung."}
{"ts": "157:44", "speaker": "I", "text": "Gab es dabei schon mal Fälle, wo die Priorisierung aus Nutzersicht und aus technischer Sicht kollidiert ist?"}
{"ts": "157:50", "speaker": "E", "text": "Ja, zum Beispiel beim Feature 'Parallel Test Scheduling'. Technisch war das Risiko gering, aber UX hat uns Daten aus Atlas gezeigt, dass Nutzer in der Beta-Phase häufig die Funktion abbrechen. Wir haben dann trotz niedrigen technischen Risikos die Testtiefe erhöht. Das mussten wir im Ticket QA-6721 dokumentieren, inklusive Abweichung von RFC-1770."}
{"ts": "158:03", "speaker": "I", "text": "Wie dokumentieren Sie solche Abweichungen formal?"}
{"ts": "158:08", "speaker": "E", "text": "Wir nutzen dafür ein Feld 'Risk Override Justification' in unserem Jira-Template. Da referenzieren wir sowohl das Runbook als auch das spezifische UX- oder Observability-Datum. In QA-6721 steht zum Beispiel: 'Override gemäß UX-Data Atlas Mobile 05/2024, Abbruchrate >25 %'. So ist es auch auditierbar."}
{"ts": "158:20", "speaker": "I", "text": "Und wie sichern Sie, dass diese Overrides nicht inflationär eingesetzt werden?"}
{"ts": "158:26", "speaker": "E", "text": "Es gibt bei uns ein 2-Personen-Freigabeprinzip. Jeder Override muss vom QA Lead – also mir – und vom Produktverantwortlichen abgesegnet werden. Zusätzlich prüfen wir quartalsweise in einem Audit-Review, ob die Overrides noch gültig sind. Das ist auch Teil des AUD-24-Q2 Access Review Summary gewesen."}
{"ts": "158:39", "speaker": "I", "text": "Könnten Sie ein Beispiel nennen, wie genau dieses Review Ihre QA-Strategie beeinflusst hat?"}
{"ts": "158:44", "speaker": "E", "text": "Im Q2-Review haben wir festgestellt, dass bei drei Features die Overrides länger als zwei Release-Zyklen aktiv waren, ohne dass die ursprünglichen UX-Probleme wieder überprüft wurden. Daraus haben wir die Regel abgeleitet, dass Overrides spätestens nach sechs Wochen durch neue Daten validiert werden müssen. Das haben wir direkt als Update in POL-QA-014 aufgenommen."}
{"ts": "158:00", "speaker": "I", "text": "Sie hatten ja vorhin die Integration zu Atlas Mobile und Helios Datalake im Kontext von RFC-1770 erwähnt. Können Sie etwas genauer erläutern, wie diese Datenströme Ihre Priorisierungslogik beeinflussen?"}
{"ts": "158:05", "speaker": "E", "text": "Ja, gern. Wir ziehen aus Helios Datalake historische Fehlschlagraten pro Modul und mappen diese mit den aktuellen Build-IDs aus Atlas Mobile. Dadurch können wir im Risk-Based Testing nach POL-QA-014 die Testreihenfolgen dynamisch neu gewichten. \nDas ist ein Multi-Hop-Prozess: Erst werden die Rohdaten im Datalake gefiltert, dann über Nimbus Observability mit Live-Metriken angereichert, bevor RB-QA-051 das Release Candidate Gate prüft."}
{"ts": "158:15", "speaker": "I", "text": "Das klingt nach einem recht komplexen Fluss. Gibt es dabei Engpässe oder Latenzprobleme, die Sie beachten müssen?"}
{"ts": "158:21", "speaker": "E", "text": "Absolut. Der Abgleich zwischen Atlas und Helios hat in den frühen Builds teilweise bis zu 15 Minuten gedauert, was im Build-Phase-Zeitfenster kritisch ist. Wir haben deshalb in Ticket QA-HER-232 einen Cache-Layer beschrieben, der die zuletzt verarbeiteten Metriken vorhält."}
{"ts": "158:32", "speaker": "I", "text": "Wie wirkt sich dieser Cache auf die Aktualität der Risikoeinschätzung aus?"}
{"ts": "158:37", "speaker": "E", "text": "Wir haben in der RFC-1770-Appendix C festgelegt, dass die Daten maximal 20 Minuten alt sein dürfen. Das ist ein Trade-off zwischen Datenfrische und Build-Durchlaufzeit. Nimbus Alerts warnen uns, wenn die Schwelle überschritten wird."}
{"ts": "158:47", "speaker": "I", "text": "Gab es Situationen, in denen sich diese Entscheidung als problematisch erwiesen hat?"}
{"ts": "158:53", "speaker": "E", "text": "Einmal, beim Sprint 14 Release, haben wir durch den Cache eine veraltete Flaky-Test-Markierung übernommen. Das führte zu einer Lücke in der Testabdeckung, dokumentiert in Incident INC-HER-88. Wir haben danach die Heuristik angepasst, sodass kritische Tests trotz Cache immer frisch abgefragt werden."}
{"ts": "159:05", "speaker": "I", "text": "Und diese Heuristik – ist die irgendwo formalisiert oder basiert sie auf Team-Erfahrung?"}
{"ts": "159:11", "speaker": "E", "text": "Beides. Formal ist sie als Anhang D in POL-QA-014 beschrieben. Praktisch haben wir aber ungeschriebene Regeln, z.B. dass Module mit mehr als 5% Fehlerquote aus den letzten drei Builds automatisch 'hot' getestet werden, unabhängig von der Priorisierungsliste."}
{"ts": "159:22", "speaker": "I", "text": "Interessant. Wie stimmen Sie solche Anpassungen mit den Plattform-Engineering-Teams ab?"}
{"ts": "159:28", "speaker": "E", "text": "Wir haben wöchentliche Syncs mit dem Nimbus Observability Team. Dort bringen wir die QA-Anforderungen ein, und im Gegenzug geben sie uns Feedback zu Metrikdefinitionen. Für größere Änderungen wie die Cache-Layer-Implementierung nutzen wir formale RFCs, zuletzt RFC-HER-041."}
{"ts": "159:40", "speaker": "I", "text": "Sie sprachen vorhin von RB-QA-051. Wird dieses Runbook auch für die Integrationstests mit externen Komponenten angewendet?"}
{"ts": "159:45", "speaker": "E", "text": "Ja, allerdings mit einem zusätzlichen Step: Für externe Komponenten müssen wir ein SLA-Check durchführen, der im Runbook als optional markiert ist. Im Projekt Hera haben wir das zur Pflicht gemacht, weil wir sonst in der Build-Phase zu spät von SLA-Verletzungen erfahren würden."}
{"ts": "159:56", "speaker": "I", "text": "Gab es da interdisziplinär Widerstände, weil der Prozess länger dauert?"}
{"ts": "160:00", "speaker": "E", "text": "Ja, gerade das Atlas Mobile Team hat zunächst Bedenken geäußert, da ihre Release-Zyklen kürzer sind. Wir haben das gelöst, indem wir die SLA-Checks parallel zu den End-to-End-Tests ausführen. Das ist in QA-HER-245 als Prozessoptimierung beschrieben."}
{"ts": "160:00", "speaker": "I", "text": "Sie hatten vorhin die Integration der unterschiedlichen Systeme erwähnt. Mich würde interessieren, wie genau diese Verzahnung, also Nimbus, Atlas Mobile und Helios, im Alltag genutzt wird, um Testmetriken zu priorisieren."}
{"ts": "160:06", "speaker": "E", "text": "Ja, im Alltag bedeutet das, dass wir aus Nimbus Observability die Live-Telemetriedaten ziehen, die dann in Helios Datalake aggregiert werden. Dort laufen Filterjobs, die in Atlas Mobile ein UI-Widget befüllen, mit dem wir im QA-Dashboard sofort sehen können, welche Module in den letzten Builds die höchste Fehlerdichte hatten."}
{"ts": "160:15", "speaker": "I", "text": "Und das beeinflusst dann direkt Ihre Testauswahl?"}
{"ts": "160:18", "speaker": "E", "text": "Genau. RFC-1770 beschreibt ja ausdrücklich, dass die Selection Engine diese Metriken konsumieren darf, um Prioritäten anzupassen. Wenn z.B. das Modul 'Hera-API-Gateway' plötzlich eine ansteigende Response Time hat, dann stuft das System automatisch die API-Regression-Tests in die höchste Prioritätsklasse hoch."}
{"ts": "160:29", "speaker": "I", "text": "Wie wird das dann in der Teststrategie dokumentiert? Nutzen Sie da ein zentrales Artefakt oder mehrere?"}
{"ts": "160:33", "speaker": "E", "text": "Wir verlinken im QA Confluence-Bereich direkt auf den Runbook-Eintrag RB-QA-051, Kapitel 4.2, wo die Release Candidate Gate Kriterien stehen. Zusätzlich gibt es im JIRA-Board für Hera ein Label 'RBT-Auto', sodass man nachvollziehen kann, welche Testfälle aufgrund der Observability-Daten priorisiert wurden."}
{"ts": "160:45", "speaker": "I", "text": "Gab es schon Fälle, wo diese Automatisierung zu Fehlpriorisierungen geführt hat?"}
{"ts": "160:49", "speaker": "E", "text": "Einmal, ja. Wir hatten einen Ausreißer in den Telemetriedaten wegen eines fehlerhaften Metrics-Agent-Builds. Das führte dazu, dass die Engine unnötig Lasttests vorgezogen hat. Wir haben daraus gelernt und im Runbook eine manuelle Plausibilitätsprüfung als Step 3.1 aufgenommen."}
{"ts": "160:59", "speaker": "I", "text": "Das klingt nach einer multi-hop Kette zwischen Monitoring, Data Lake, UI-Widget und Testauswahl. Wie schnell läuft dieser Zyklus in der Praxis?"}
{"ts": "161:03", "speaker": "E", "text": "Unter normalen Umständen unter 15 Minuten vom Event in Nimbus bis zur aktualisierten Prioritätenliste in unserem QA-Tool. Wir haben ein SLA von 20 Minuten definiert, dokumentiert in SLA-QA-HER-2024-03."}
{"ts": "161:12", "speaker": "I", "text": "Und wie prüfen Sie, ob dieses SLA eingehalten wird?"}
{"ts": "161:15", "speaker": "E", "text": "Helios hat ein Audit-Log, das Zeitstempel beim Eintreffen und Verarbeiten der Metriken speichert. Ein Skript vergleicht diese mit den Timestamps in Atlas Mobile. Bei Überschreitungen erstellt es automatisch ein Ticket im Projekt HER-QA-OPS."}
{"ts": "161:25", "speaker": "I", "text": "Gibt es aktuell offene Tickets aus solchen SLA-Verletzungen?"}
{"ts": "161:28", "speaker": "E", "text": "Ja, HER-QA-OPS-194 ist noch offen. Das betrifft eine Verzögerung wegen eines batch backlog im Datalake. Wir arbeiten mit dem Helios-Team an einem Streaming-Connector, um das zu umgehen."}
{"ts": "161:37", "speaker": "I", "text": "Könnte dieser Connector auch in anderen Projekten genutzt werden, oder ist das spezifisch für Hera?"}
{"ts": "161:41", "speaker": "E", "text": "Er ist generisch genug, um auch bei Orion Analytics eingesetzt zu werden. Aber dort gibt es andere Runbooks, die die Integration regeln. Bei Hera orientieren wir uns strikt an POL-QA-014 und RB-QA-051, weil diese unsere Risk-Based Testing Policy und das Release Gate klar definieren."}
{"ts": "161:35", "speaker": "I", "text": "Sie hatten eben schon den Zusammenhang zwischen Nimbus Observability und RFC-1770 beschrieben. Mich würde jetzt interessieren: Wie haben Sie diese Verbindung in den letzten zwei Sprints konkret operationalisiert?"}
{"ts": "161:45", "speaker": "E", "text": "In Sprint 14 und 15 haben wir die Observability-Daten direkt in unser Jira-Board integriert, über ein Custom-Webhook-Skript, das auf den Metriken aus dem Nimbus-Dashboard basiert. Damit konnten wir die High-Risk-Module laut POL-QA-014 automatisch markieren und den Testumfang nach den Kriterien aus RFC-1770 anpassen."}
{"ts": "161:59", "speaker": "I", "text": "Und wie wirkt sich das auf Ihre End-to-End Traceability aus, gerade zwischen den Artefakten?"}
{"ts": "162:05", "speaker": "E", "text": "Das war ein Knackpunkt: Wir mussten dafür im Runbook RB-QA-051 anpassen, dass die Release-Candidate-Gate-Checks nicht nur auf manueller Abnahme beruhen, sondern auch auf den automatisch zugewiesenen Risikostufen. So wird der Trace vom Atlassian-Requirement über Testfall bis zum Observability-Event durchgehend erfasst."}
{"ts": "162:21", "speaker": "I", "text": "Gab es da Abstimmungsbedarf mit dem Plattform-Engineering-Team?"}
{"ts": "162:27", "speaker": "E", "text": "Ja, erheblich. Wir mussten die Pipeline-Definition im Hera-Build-Repo anpassen, weil die Risk-Tags aus Nimbus erst als zusätzliche Stage in den CI-Lauf einfließen mussten. Ohne die Zusammenarbeit mit Platform Engineering hätten wir die SLA-Vorgaben aus SLA-QA-HERA-02 nicht einhalten können."}
{"ts": "162:43", "speaker": "I", "text": "Das klingt nach einer engen Verzahnung. Haben Sie dafür ein Beispiel, wo Atlas Mobile-Daten einflossen, um eine Entscheidung zu treffen?"}
{"ts": "162:50", "speaker": "E", "text": "Klar, in Ticket QA-HERA-315 hatten wir ein Problem mit intermittierenden UI-Fehlern. Über Helios Datalake konnten wir sehen, dass diese nur bei bestimmten Endgeräten mit älteren Atlas Mobile SDKs auftraten. Das Risiko wurde hochgestuft, und die Tests für diese Konfigurationen wurden vorgezogen."}
{"ts": "163:05", "speaker": "I", "text": "Wie dokumentieren Sie solche Entscheidungen?"}
{"ts": "163:10", "speaker": "E", "text": "Neben der Ticket-Historie schreiben wir im Confluence-Space 'Hera-QA' eine Decision-Log-Seite. Dort verlinken wir die relevanten RFCs, wie z.B. RFC-1770, und die betroffenen Runbooks. So können wir bei Audits, wie AUD-24-Q2, nachvollziehen, warum wir Tests umpriorisiert haben."}
{"ts": "163:25", "speaker": "I", "text": "Gab es bei diesen Entscheidungen auch Trade-offs, z.B. zwischen Testabdeckung und Time-to-Market?"}
{"ts": "163:31", "speaker": "E", "text": "Ja, im Release 0.9.7 mussten wir die Abdeckung bei Low-Risk-Modulen um 15 % senken, um den geplanten Go-Live-Termin zu halten. Das war abgestimmt mit Product Management und im Risk Register RSK-HERA-09 vermerkt."}
{"ts": "163:44", "speaker": "I", "text": "Und wie haben Sie die Risiken für die Stakeholder transparent gemacht?"}
{"ts": "163:49", "speaker": "E", "text": "Wir haben ein wöchentliches QA-Risk-Review eingeführt, in dem wir die Risikoeinstufungen und ihre Auswirkungen zeigen. Dazu nutzen wir ein Dashboard mit den KPIs aus Nimbus und den Helios-Daten, ergänzt um die Lessons Learned aus AUD-24-Q2, die uns empfehlen, Abweichungen sofort zu eskalieren."}
{"ts": "164:03", "speaker": "I", "text": "Hat sich diese Vorgehensweise bewährt?"}
{"ts": "164:08", "speaker": "E", "text": "Absolut, die Anzahl der ungeplanten Hotfixes ist seitdem um 30 % gesunken. Wir sehen, dass die Verknüpfung der Observability-Metriken mit den Risk-Based-Testing-Prinzipien nicht nur die Qualität, sondern auch die Planbarkeit im Hera-Projekt verbessert hat."}
{"ts": "163:35", "speaker": "I", "text": "Sie hatten vorhin ja schon den Zusammenhang zwischen den verschiedenen Systemen wie Atlas Mobile und Helios Datalake erwähnt. Können Sie das bitte noch einmal detailliert anhand eines konkreten Szenarios erläutern?"}
{"ts": "163:48", "speaker": "E", "text": "Ja, gern. Also, wir hatten im Februar einen Fall, bei dem die Testresultate aus der Atlas Mobile Pipeline auffällig viele sporadische Fehler zeigten. Über Nimbus Observability konnten wir die Metriken direkt mit den entsprechenden Datasets im Helios Datalake korrelieren – und zwar rückwirkend bis zu den Log-Events, die im POL-QA-014 Annex dokumentiert sind."}
{"ts": "164:12", "speaker": "I", "text": "Das klingt nach einer komplexen Verknüpfung. Wie stellen Sie sicher, dass diese Cross-System-Analysen auch im Build-Phase-Alltag zuverlässig funktionieren?"}
{"ts": "164:25", "speaker": "E", "text": "Wir haben dafür in RB-QA-051 unter Abschnitt 3.4 einen verbindlichen Check verankert, der vor dem Release Candidate Gate eine automatisierte Datenintegritätsprüfung zwischen den Systemen ausführt. Zusätzlich nutzen wir für das Hera QA Platform Projekt eine interne Mapping-Tabelle, die in RFC-1770 Anhang B gepflegt wird."}
{"ts": "164:50", "speaker": "I", "text": "Und wie reagieren die anderen Teams darauf, wenn Ihre Analyse Hinweise auf systemübergreifende Fehler liefert?"}
{"ts": "165:03", "speaker": "E", "text": "Oft starten wir dann ein sogenanntes Cross-Team Incident Review. Das ist kein offizieller Runbook-Prozess, aber in der Praxis hat es sich bewährt. Wir erstellen ein Ticket, meist im Jira-Board HERA-QA, mit Verweis auf die betroffenen Observability-Dashboards und die relevanten Data Lake Query IDs."}
{"ts": "165:27", "speaker": "I", "text": "Gibt es denn bei solchen Reviews auch Feedback aus der UX-Research-Richtung?"}
{"ts": "165:38", "speaker": "E", "text": "Ja, manchmal. Wir haben z.B. beim letzten Review festgestellt, dass ein Flaky Test auf eine UI-Animation zurückzuführen war, die in der UX-Studie gar nicht als kritisch markiert war. Das floss dann in die Priorisierung gemäß POL-QA-014 ein."}
{"ts": "165:58", "speaker": "I", "text": "Interessant. Wenn Sie diese Priorisierung anpassen, müssen Sie das im RFC-1770 dokumentieren?"}
{"ts": "166:09", "speaker": "E", "text": "Genau. Jede wesentliche Änderung an der Risk-Based-Test-Selection-Logik wird als Amendment im RFC-1770 vermerkt und durch das QA Change Board freigegeben. Das ist wichtig, weil wir so später im Audit klar nachvollziehen können, warum bestimmte Tests früher oder später ausgeführt wurden."}
{"ts": "166:31", "speaker": "I", "text": "Gab es da schon einmal Konflikte mit dem Time-to-Market, weil Änderungen im RFC den Prozess verlangsamten?"}
{"ts": "166:42", "speaker": "E", "text": "Ja, im Build-Sprint 8 hatten wir so einen Fall. Wir mussten zwischen einer vollständigen Testabdeckung und einem geplanten Beta-Release abwägen. Schließlich haben wir uns entschieden, nur die High-Risk-Tests entsprechend RFC-1770 durchzuführen und das Ergebnis in Ticket HERA-QA-4825 transparent zu dokumentieren."}
{"ts": "167:05", "speaker": "I", "text": "Haben Sie daraus bestimmte Lessons Learned abgeleitet, die jetzt in Ihre Strategie einfließen?"}
{"ts": "167:16", "speaker": "E", "text": "Definitiv. Wir haben z.B. in Anlehnung an die AUD-24-Q2 Access Review Summary beschlossen, dass kritische Testfälle immer mindestens einen Durchlauf im Staging-Environment haben müssen, egal wie knapp der Zeitplan ist. Das wurde als fixe Regel in POL-QA-014 Version 3.2 aufgenommen."}
{"ts": "167:38", "speaker": "I", "text": "Und wie kommunizieren Sie solche Änderungen teamübergreifend?"}
{"ts": "167:48", "speaker": "E", "text": "Wir machen dazu ein kurzes Brown-Bag-Meeting und verteilen eine Zusammenfassung per Confluence-Page, in der wir die Änderungen, das betroffene Runbook und relevante RFC-Abschnitte verlinken. So bleiben alle, vom UX-Research bis zum Plattform-Engineering, auf dem gleichen Stand."}
{"ts": "170:35", "speaker": "I", "text": "Lassen Sie uns etwas tiefer in die Lessons Learned gehen. Wie hat denn konkret die AUD-24-Q2 Access Review Summary Ihre QA-Strategie verändert?"}
{"ts": "170:50", "speaker": "E", "text": "Ähm, ja, das war, äh, relativ einschneidend. In der AUD-24-Q2 haben wir festgestellt, dass bestimmte Berechtigungs-Pfade in der Testumgebung nicht sauber nach dem Principle of Least Privilege konfiguriert waren. Das führte dazu, dass ein automatisierter Regressionstest gegen ein Modul lief, für das er gar nicht vorgesehen war, und das hat unser Risk-Scoring im Rahmen von POL-QA-014 verzerrt."}
{"ts": "171:20", "speaker": "I", "text": "Das heißt, Sie mussten dann sowohl Berechtigungen als auch Testlogik anpassen?"}
{"ts": "171:30", "speaker": "E", "text": "Genau. Wir haben daraufhin RFC-1822 erstellt, um die Test-Execution-Accounts granularer zu trennen. Parallel haben wir im Runbook RB-QA-051 ein neues Gate eingeführt, das vor dem Release-Candidate-Build prüft, ob die Access-Roles mit der Testfall-Zuordnung konsistent sind."}
{"ts": "171:58", "speaker": "I", "text": "Gab es da Abwägungen zwischen der Geschwindigkeit im Build und dieser zusätzlichen Prüfung?"}
{"ts": "172:07", "speaker": "E", "text": "Oh ja. Der zusätzliche Check kostet im Schnitt 4–5 Minuten pro Pipeline-Run. Das ist unter Time-to-Market-Aspekten nicht trivial. Aber wir haben uns für die Sicherheit entschieden, weil ein falsches Risk-Profil im Risk-Based Testing im schlimmsten Fall zu kritischen Bugs in Produktion führen würde."}
{"ts": "172:33", "speaker": "I", "text": "Wie haben Sie das gegenüber dem Product Owner argumentiert?"}
