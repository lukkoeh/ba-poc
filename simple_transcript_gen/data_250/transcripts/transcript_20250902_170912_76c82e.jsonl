{"ts": "00:00", "speaker": "I", "text": "Können Sie mir kurz den aktuellen Stand des Atlas Mobile Projekts schildern?"}
{"ts": "02:15", "speaker": "E", "text": "Ja, gern. Wir sind aktuell in der Pilotphase, also P-ATL läuft seit acht Wochen mit einer ausgewählten Nutzergruppe von etwa 150 internen Testern. Der Fokus liegt auf der Validierung von Offline-Synchronisation und dem gezielten Roll-out einzelner Features über unser internes Flag-Framework. Strategisch ist es für uns ein Türöffner für weitere Cross-Platform-Apps im Portfolio."}
{"ts": "06:10", "speaker": "I", "text": "Welche strategische Rolle spielt Atlas Mobile denn genau innerhalb des gesamten Portfolios?"}
{"ts": "08:40", "speaker": "E", "text": "Es ist im Prinzip unser Proof-of-Concept für eine modulare Mobile-Architektur. Die Idee ist, dass wir mit Atlas Mobile die Kernkomponenten entwickeln und später in anderen Projekten wie Orbis Field Service einsetzen. Erfolg heißt hier: Wir erreichen stabile Kernfunktionen, messen die Nutzerakzeptanz und minimieren Integrationsaufwand."}
{"ts": "12:05", "speaker": "I", "text": "Wie definieren Sie für sich den Erfolg in dieser Pilotphase?"}
{"ts": "14:22", "speaker": "E", "text": "Wir haben drei KPIs: Crash-Free Sessions > 98%, Sync-Latenz < 200ms im Median, und mindestens 80% Positivfeedback in den wöchentlichen Umfragen. Diese werden im Runbook RB-ATL-01 dokumentiert, mit Benchmarks aus früheren Projekten."}
{"ts": "18:00", "speaker": "I", "text": "Wie fließen aktuelle Erkenntnisse aus Nutzerstudien in Ihre Release-Planung ein?"}
{"ts": "20:45", "speaker": "E", "text": "Wir arbeiten eng mit dem UX-Team, das wöchentliche Heatmaps und Session-Recordings bereitstellt. Die Erkenntnisse fließen in die Tickets im JIRA-Board ATL-RLS, wo wir Features priorisieren. Ein Beispiel: Die Feedbacks zur Offline-Suche haben direkt zum Flagging und iterativen Release geführt."}
{"ts": "24:30", "speaker": "I", "text": "Gibt es konkrete UX-Metriken, die Sie als CTO im Blick behalten?"}
{"ts": "27:15", "speaker": "E", "text": "Ja, neben NPS schauen wir auf Time-to-Task-Completion und Error Rate pro Workflow. Das sind Metriken, die wir aus der Telemetrie gewinnen und mit den UX-Erhebungen abgleichen."}
{"ts": "31:50", "speaker": "I", "text": "Welche technischen Entscheidungen haben Sie bei der Implementierung der Feature Flags getroffen?"}
{"ts": "34:05", "speaker": "E", "text": "Wir haben uns für ein serverseitiges Evaluation-Pattern entschieden, um konsistente Flags über Plattformen hinweg zu gewährleisten. Genutzt wird ein internes Gateway, das auch mit Helios Datalake verknüpft ist, um Echtzeitmetriken in die Flag-Entscheidung einzubeziehen."}
{"ts": "38:20", "speaker": "I", "text": "Wie stellen Sie sicher, dass Offline Sync robust und sicher funktioniert?"}
{"ts": "41:00", "speaker": "E", "text": "Mehrschichtige Validierung: lokaler Queue-Mechanismus mit Retry-Policy aus dem Runbook RB-SYNC-04, plus Verschlüsselung auf Block-Level vor dem Persistieren. Zusätzlich führen wir Integrationstests gegen einen simulierten Helios Datalake-Node durch."}
{"ts": "45:35", "speaker": "I", "text": "Gibt es Abhängigkeiten zu anderen Plattform- oder Datenprojekten?"}
{"ts": "50:00", "speaker": "E", "text": "Ja, die wichtigste ist tatsächlich die IAM-Integration, weil wir Tokens aus dem zentralen Identity Provider nutzen, die auch für andere Apps gültig sind. Das bedeutet, Änderungen am IAM-Schema wirken sich direkt auf die Sync-Authentifizierung aus. Hier mussten wir mit dem Helios Datalake-Team koordinieren, um konsistente Claims sicherzustellen."}
{"ts": "90:00", "speaker": "I", "text": "Lassen Sie uns jetzt noch einmal gezielt auf die größten Risiken eingehen, die Sie für Atlas Mobile in dieser Phase sehen."}
{"ts": "90:15", "speaker": "E", "text": "Ja, also das größte Risiko ist aktuell tatsächlich die Synchronisationsstabilität bei schlechter Netzabdeckung. Wir haben im Runbook RB-ATL-042 festgehalten, dass bei Latenzen über 2 Sekunden die Retry-Logik greift, aber im Feldtest in Südtirol gab es Fälle, wo sie in einen Loop geraten ist."}
{"ts": "90:45", "speaker": "I", "text": "Das klingt nach einem kritischen Punkt. Haben Sie dafür schon einen konkreten Workaround oder ist das noch in Analyse?"}
{"ts": "91:00", "speaker": "E", "text": "Wir haben in Ticket JIRA-ATL-773 eine Zwischenlösung dokumentiert: Feature Flag 'sync_backoff' aktivieren, das einen exponentiellen Backoff einführt. Das reduziert die Serverlast und verhindert endlose Loops, allerdings verzögert es auch die Datenaktualisierung für den Nutzer."}
{"ts": "91:28", "speaker": "I", "text": "Also ein klarer Trade-off zwischen Performance und Stabilität."}
{"ts": "91:35", "speaker": "E", "text": "Genau. Wir mussten uns kurzfristig für Stabilität entscheiden, weil die SLA-Vorgaben eine maximal 0,5% Fehlerrate bei Datensynchronisation vorsehen. Ohne diesen Flag hätten wir den SLA verletzt."}
{"ts": "92:00", "speaker": "I", "text": "Wie fließt so eine Entscheidung in Ihre Roadmap ein?"}
{"ts": "92:12", "speaker": "E", "text": "Wir markieren solche Flags im internen Decision Log (DL-2024-15) und koppeln sie an Meilensteine. Für den Go-Live nach der Pilotphase ist geplant, den Backoff adaptiv zu machen – abhängig von Userprofil und Netzqualität, Daten aus dem Helios Datalake und dem IAM-Context."}
{"ts": "92:42", "speaker": "I", "text": "Das heißt, Sie wollen evidenzbasiert skalieren, indem Sie diese Kontexte auswerten?"}
{"ts": "92:50", "speaker": "E", "text": "Richtig. Wir haben bereits im Observability-System Metriken gesetzt, die uns zeigen, wie oft der Backoff greift und welche Usergruppen betroffen sind. Kombiniert mit den Authentifizierungslogs aus IAM können wir Muster erkennen."}
{"ts": "93:15", "speaker": "I", "text": "Können Sie dazu ein konkretes Beispiel nennen?"}
{"ts": "93:25", "speaker": "E", "text": "Zum Beispiel haben wir festgestellt, dass Nutzer mit älteren Geräten häufiger den Backoff triggern. Das steht so auch in Report REP-ATL-07. Diese Erkenntnis führt dazu, dass wir gezielt für diese Geräteklasse die Offline-Pakete kleiner schneiden."}
{"ts": "93:50", "speaker": "I", "text": "Welche UX-Themen leiten Sie daraus für die nächsten Monate ab?"}
{"ts": "94:00", "speaker": "E", "text": "Wir müssen klarer kommunizieren, wenn ein Sync verzögert wird. Dazu entwerfen wir gerade einen kleinen 'Sync-Status-Indicator', der auch offline verständlich ist. Das ist im UX-Backlog unter UX-ATL-112 erfasst."}
{"ts": "94:25", "speaker": "I", "text": "Gibt es sonstige Lessons Learned aus der Pilotphase, die Sie teilen möchten?"}
{"ts": "94:35", "speaker": "E", "text": "Ja, vor allem, dass Feature Flags nicht nur für A/B-Tests nützlich sind, sondern auch als operative Sicherungsschalter dienen können. Das hat uns mehrfach vor SLA-Brüchen bewahrt, siehe auch unser internes Post-Mortem PM-ATL-03."}
{"ts": "106:00", "speaker": "I", "text": "Sie hatten eben die Runbook-Referenz RB-ATL-042 erwähnt. Können Sie genauer sagen, wie diese in einem realen Incidentfall für Atlas Mobile angewendet wurde?"}
{"ts": "106:15", "speaker": "E", "text": "Ja, in einem Staging-Drift-Fall vor drei Wochen – das war Ticket IM-ATL-337 – haben wir exakt nach RB-ATL-042 gearbeitet. Das Runbook beschreibt die Isolation der betroffenen Feature Flag Configs, das Zurückrollen via CI-Pipeline und die Verifikation mittels Offline Sync Test Suite in weniger als 15 Minuten."}
{"ts": "106:45", "speaker": "I", "text": "Beeindruckend. Gab es bei diesem Vorfall Abhängigkeiten zu anderen Plattformdiensten, die den Ablauf verkompliziert haben?"}
{"ts": "107:00", "speaker": "E", "text": "Ja, der Helios Datalake war indirekt betroffen, weil eines der Feature Flags die Datenvorverarbeitung beeinflusste. Wir mussten also in Absprache mit dem DataOps-Team den ETL-Lauf pausieren, sonst hätten wir inkonsistente Offline-Datasets in der App angezeigt."}
{"ts": "107:28", "speaker": "I", "text": "Wie kommunizieren Sie solche Abhängigkeiten in Echtzeit? Nutzen Sie dafür interne ChatOps-Tools oder eher formale Change Requests?"}
{"ts": "107:42", "speaker": "E", "text": "Für akute Incidents nutzen wir primär unseren ChatOps-Channel in NovaLink, der ist im Runbook als 'Rapid Bridge' beschrieben. Change Requests laufen parallel über das RFC-Formular im Portal – in dem Fall RFC-ATL-88 – um die Nachvollziehbarkeit zu sichern."}
{"ts": "108:10", "speaker": "I", "text": "Wenn wir auf die Pilotphase zurückschauen: Welche Lessons Learned betreffen konkret die Balance zwischen Nutzerbedürfnissen und technischer Machbarkeit?"}
{"ts": "108:26", "speaker": "E", "text": "Wir haben gelernt, dass frühes Nutzerfeedback zu Offline Sync Prioritäten verschieben kann. Ein Beispiel: Nutzer in ländlichen Regionen wollten deutlich längere Sync-Intervals. Technisch hieß das, unsere Delta-Algorithmen zu optimieren, um den Speicherverbrauch in der App nicht explodieren zu lassen."}
{"ts": "108:58", "speaker": "I", "text": "Gab es dafür eine evidenzbasierte Entscheidungsvorlage?"}
{"ts": "109:10", "speaker": "E", "text": "Ja, wir haben DRE-Report #ATL-21 genutzt, der aus Telemetriedaten und UX-Umfragen bestand. Das Dokument zeigte klar, dass die wahrgenommene App-Qualität um 18 % stieg, wenn das Sync-Intervall angepasst wurde. Diese Zahl hat das Architekturgremium überzeugt."}
{"ts": "109:40", "speaker": "I", "text": "Welche Risiken sehen Sie, wenn wir nach der Pilotphase skalieren, insbesondere im Kontext von IAM-Integration?"}
{"ts": "109:55", "speaker": "E", "text": "Das größte Risiko ist die Latenz beim Token Refresh. In RB-IAM-019 steht, dass alles über 500 ms zu Timeouts im Offline Modus führen kann. Wenn wir auf 10× mehr Nutzer gehen, müssen wir das Refresh-Handling asynchronisieren, sonst steigt die Abbruchrate signifikant."}
{"ts": "110:25", "speaker": "I", "text": "Planen Sie dafür bereits Gegenmaßnahmen?"}
{"ts": "110:37", "speaker": "E", "text": "Ja, wir testen gerade mit einem lokal gecachten JWT-Store, der in POC-ATL-Cache dokumentiert ist. Damit reduzieren wir die Abhängigkeit vom zentralen IAM in kritischen Momenten."}
{"ts": "110:58", "speaker": "I", "text": "Zum Abschluss: Welche UX-Themen sollten wir aus Ihrer Sicht prioritär weiterverfolgen?"}
{"ts": "111:20", "speaker": "E", "text": "Ganz klar die Transparenz im Sync-Status. Nutzer wollen verstehen, ob Daten aktuell sind. Ein leicht zugängliches Sync-Log in der App, wie in UX-RFC-ATL-12 beschrieben, wäre da ein großer Schritt vorwärts."}
{"ts": "112:00", "speaker": "I", "text": "Bevor wir in die letzten Themen gehen – welche UX-Prioritäten haben Sie jetzt, da der Pilot fast abgeschlossen ist?"}
{"ts": "112:15", "speaker": "E", "text": "Wir haben aus den letzten drei Sprints sehr klare Signale gesehen, dass die Offline-Verfügbarkeit bei schwacher Netzabdeckung ganz oben steht. In unserem internen Runbook RB-ATL-UX-07 ist explizit vermerkt, dass wir diese Funktion vor den nächsten Beta-Rollouts stabilisieren müssen."}
{"ts": "112:36", "speaker": "I", "text": "Und wie priorisieren Sie das gegenüber neuen Features, die vielleicht aus dem Marketing kommen?"}
{"ts": "112:49", "speaker": "E", "text": "Da helfen uns die SLA-Vorgaben aus der Pilotvereinbarung. Wir haben eine Mindestverfügbarkeit von 98,5 % zugesagt, und jede neue Funktion, die diese gefährden könnte, wird in der sogenannten Impact-Matrix im Confluence geprüft, bevor sie in den Dev-Branch kommt."}
{"ts": "113:10", "speaker": "I", "text": "Gab es in letzter Zeit einen Fall, wo Sie aufgrund dieser Matrix ein Feature gestoppt haben?"}
{"ts": "113:24", "speaker": "E", "text": "Ja, das war Ticket ATL-3421. Wir wollten ein erweitertes Karten-Layer-Feature freischalten, aber die Simulationen zeigten eine 2 % höhere Crashrate im Offline-Modus. Also haben wir es auf Q4 verschoben."}
{"ts": "113:44", "speaker": "I", "text": "Verstehe. Welche Lessons Learned nehmen Sie aus solchen Entscheidungen mit?"}
{"ts": "113:55", "speaker": "E", "text": "Dass wir frühzeitig Lasttests mit realistischen Netzunterbrechungen fahren müssen. Unser Runbook RB-ATL-TEST-04 wurde nach diesem Vorfall erweitert, um genau diese Szenarien in den CI/CD-Pipeline zu integrieren."}
{"ts": "114:18", "speaker": "I", "text": "Gibt es aus UX-Sicht noch offene Fragen, die Sie gerne adressiert hätten?"}
{"ts": "114:29", "speaker": "E", "text": "Ja, wir haben noch keine finalen Heatmaps aus der Pilotgruppe, um zu sehen, wie oft das Feature-Flag für den neuen Sync-Dialog tatsächlich genutzt wurde. Diese Daten wollen wir vor dem Go/No-Go-Meeting in zwei Wochen haben."}
{"ts": "114:50", "speaker": "I", "text": "Wie können wir als UX-Team Sie dabei bestmöglich unterstützen?"}
{"ts": "115:01", "speaker": "E", "text": "Indem Sie uns die aggregierten Klickpfade und Abbruchraten liefern. Wir binden die dann direkt in unser Decision Deck ein, das wir im Steering Committee präsentieren."}
{"ts": "115:18", "speaker": "I", "text": "Klingt machbar. Gibt es darüber hinaus Themen, bei denen wir proaktiv werden sollten?"}
{"ts": "115:28", "speaker": "E", "text": "Vielleicht beim Accessibility-Check. Wir haben in Ticket ATL-UX-119 einige Hinweise auf fehlende Screenreader-Tags, die für den geplanten Marktstart in Skandinavien relevant sein könnten."}
{"ts": "115:47", "speaker": "I", "text": "Dann nehmen wir das in unsere nächste UX-Review-Session auf. Letzte Frage: Was ist Ihr persönliches Highlight aus der Pilotphase?"}
{"ts": "116:00", "speaker": "E", "text": "Dass wir es geschafft haben, den Offline Sync nicht nur technisch stabil, sondern auch so zu gestalten, dass die Nutzer den Unterschied sofort spüren. Das ist in einem Pilot mit so vielen beweglichen Teilen wie bei Atlas Mobile nicht selbstverständlich."}
{"ts": "120:00", "speaker": "I", "text": "Bevor wir zum Abschluss kommen – welche UX-Themen sehen Sie aktuell als kritisch für die nächsten Releases?"}
{"ts": "120:20", "speaker": "E", "text": "Ich würde insbesondere die Onboarding-Experience noch einmal unter die Lupe nehmen. Unsere letzten Heatmaps zeigen, dass 23 % der Nutzer im Offline-Modus den Sync-Button nicht finden. Das ist zwar in Runbook R-ATL-UX-004 dokumentiert, aber wir müssen das visuell klarer gestalten."}
{"ts": "120:48", "speaker": "I", "text": "Verstehe. Gibt es noch andere Punkte aus den Nutzerstudien, die Sie technisch beeinflussen können?"}
{"ts": "121:05", "speaker": "E", "text": "Ja, basierend auf den Feedback-Loops aus Ticket T-UX-812 haben wir Anpassungen am Feature-Flagging-UI vorgenommen, um klarer zu zeigen, welche Funktionen nur im Pilot verfügbar sind. Das reduziert Support-Anfragen und verringert die Fehlbedienung."}
{"ts": "121:32", "speaker": "I", "text": "Das heißt, Sie nutzen Feature Flags nicht nur technisch, sondern auch kommunikativ?"}
{"ts": "121:45", "speaker": "E", "text": "Genau. Wir haben im internen RFC-Doc RFC-ATL-FF-07 festgehalten, dass Feature Flags explizit im UI markiert werden. So können wir A/B-Tests fahren und gleichzeitig die User Journey steuern."}
{"ts": "122:12", "speaker": "I", "text": "Wie fließt das in Ihre Roadmap ein?"}
{"ts": "122:25", "speaker": "E", "text": "Wir haben einen Quartalszyklus definiert, in dem wir UX-Metriken wie Task Completion Time und Error Rate mit technischen KPIs wie Sync-Latenz korrelieren. Das ist im Strategie-Board P-ATL-Q2 hinterlegt."}
{"ts": "122:50", "speaker": "I", "text": "Und welche Lessons Learned nehmen Sie aus dieser Pilotphase mit?"}
{"ts": "123:05", "speaker": "E", "text": "Eine wichtige Erkenntnis ist, dass Offline-First-Architekturen zwar robust sein können, aber das Error Handling im Edge-Case oft unterschätzt wird. Runbook R-ATL-SYNC-009 beschreibt jetzt explizit, wie Konflikte bei gleichzeitigen Updates zu lösen sind – das hat uns zwei größere Incidents erspart."}
{"ts": "123:34", "speaker": "I", "text": "Das klingt nach einer wertvollen Ergänzung. Welche offenen Risiken sehen Sie noch?"}
{"ts": "123:48", "speaker": "E", "text": "Das größte Risiko ist aktuell die IAM-Integration in Verbindung mit dem Offline-Modus. Wenn Token Refresh fehlschlägt, müssen wir fallbacken, ohne die Sicherheit zu kompromittieren. Dafür gibt es ein SLA-Addendum SLA-ATL-IAM-02, das Maximalzeiten für Offline-Auth festlegt."}
{"ts": "124:15", "speaker": "I", "text": "Wie können wir als UX-Team Sie dabei unterstützen?"}
{"ts": "124:28", "speaker": "E", "text": "Indem ihr frühzeitig Prototypen für kritische Flows bereitstellt, die wir dann gegen unsere Test-APIs im Staging laufen lassen. So können wir UI-Fehler im Zusammenspiel mit den Feature Flags schneller erkennen."}
{"ts": "124:52", "speaker": "I", "text": "Also mehr iterative Schleifen zwischen UX und Dev?"}
{"ts": "125:00", "speaker": "E", "text": "Genau. Kleine, inkrementelle Änderungen testen, dokumentieren im Confluence-Space 'Atlas UX', und die Ergebnisse direkt ins nächste Sprint Planning einfließen lassen – das hat sich als sehr effektiv erwiesen."}
{"ts": "136:00", "speaker": "I", "text": "Lassen Sie uns noch einmal auf die Lessons Learned zurückkommen – was war aus Ihrer Sicht der wichtigste Aha-Moment in dieser Pilotphase?"}
{"ts": "136:10", "speaker": "E", "text": "Hm, also der größte Aha-Moment war tatsächlich, dass unser Offline Sync stabiler lief, wenn wir die Delta-Updates strikt nach dem Runbook R-ATL-OS-004 orchestriert haben. Da steht nämlich drin, dass wir vor jedem Merge in die lokale Queue einen CRC-Check fahren – vorher hatten wir das aus Performancegründen weggelassen, und das führte zu Inkonsistenzen."}
{"ts": "136:32", "speaker": "I", "text": "Das heißt, Sie haben Performance zugunsten von Datenkonsistenz geopfert?"}
{"ts": "136:36", "speaker": "E", "text": "Ja, kurzfristig. Wir haben dann aber parallel in Ticket T-ATL-231 dokumentiert, wie wir den CRC-Check asynchronisieren können, sodass der Nutzerfluss kaum beeinträchtigt wird. Das ist jetzt in der Staging-App aktiv und wird nächste Woche gemessen."}
{"ts": "136:58", "speaker": "I", "text": "Und wie messen Sie den Erfolg solcher Anpassungen?"}
{"ts": "137:02", "speaker": "E", "text": "Wir nutzen da sowohl unsere Observability-Events im Helios Datalake, speziell das Dashboard D-OS-Sync, als auch die SLA-Kennzahlen aus unserem Mobile-Sync-SLA v1.2. Ziel ist, unter 200ms zusätzliche Latenz pro Delta zu bleiben."}
{"ts": "137:24", "speaker": "I", "text": "Gab es bei der IAM-Integration auch so ein Aha-Erlebnis?"}
{"ts": "137:28", "speaker": "E", "text": "Definitiv. Wir hatten nicht bedacht, dass das Atlas Mobile Token Refresh-Intervall mit den Desktop-Clients konkurriert. Erst durch eine Korrelation in Runbook R-IAM-ATL-006 haben wir gesehen, dass wir ein Window von 90 Sekunden brauchten, um Race Conditions zu vermeiden."}
{"ts": "137:52", "speaker": "I", "text": "Wie schnell konnten Sie das umsetzen?"}
{"ts": "137:56", "speaker": "E", "text": "Innerhalb von zwei Tagen, da wir im Feature-Flag-System nur einen Parameter toggeln mussten. Wir haben das erst bei 5% der Nutzer aktiviert und über Helios-Metriken den Erfolg geprüft."}
{"ts": "138:16", "speaker": "I", "text": "Was bedeutet das für die weiteren Schritte nach der Pilotphase?"}
{"ts": "138:20", "speaker": "E", "text": "Wir werden die bewährten Flags und Sync-Optimierungen in die produktive Roadmap übernehmen, aber mit klaren Rollback-Plänen. Ticket T-ATL-Release-Prep-019 listet die Schritte, inkl. SLA-Validierung und Regressionstests."}
{"ts": "138:42", "speaker": "I", "text": "Gibt es noch offene Risiken, die Sie vor dem Go-Live minimieren wollen?"}
{"ts": "138:46", "speaker": "E", "text": "Ja, das größte Risiko ist aktuell die Abhängigkeit vom Helios-Datalake-Batchfenster. Wenn das sich verschiebt, leidet der Sync. Wir evaluieren gerade mit dem DataOps-Team eine Umstellung auf Near-Real-Time-Streams, siehe RFC-HEL-Stream-ATL-02."}
{"ts": "139:10", "speaker": "I", "text": "Abschließend: Welche UX-Themen sollten wir prioritär angehen?"}
{"ts": "139:14", "speaker": "E", "text": "Prioritär sind aus meiner Sicht die Offline-Conflict-Resolution-UI und die Klarheit bei Feature-Rollouts. Nutzer müssen verstehen, wenn ein Feature grad im Pilot ist. Das steht auch so in unserem Lessons-Learned-Dokument LL-ATL-Pilot-2024, Abschnitt 4."}
{"ts": "144:00", "speaker": "I", "text": "Bevor wir auf die offenen Punkte kommen – könnten Sie noch einmal konkret sagen, welche UX-Themen aus Ihrer Sicht jetzt oberste Priorität haben?"}
{"ts": "144:05", "speaker": "E", "text": "Ja, klar. Für den Piloten sind es vor allem die Offline-Navigation innerhalb der App, die Konsistenz der Feature-Flag-Anzeigen und das Onboarding. Gerade beim Onboarding sehen wir im internen Ticket #ATLM-152 eine Absprungrate von 18 % in den ersten 90 Sekunden."}
{"ts": "144:14", "speaker": "I", "text": "Das heißt, Sie sehen den direkten Zusammenhang zwischen Onboarding und Retention?"}
{"ts": "144:18", "speaker": "E", "text": "Genau. Wir haben im Runbook RB-UX-07 festgehalten, dass eine Reduktion der Onboarding-Dauer um 15 % die 7-Tage-Retention um rund 6 Punkte verbessern kann. Das basiert auf den Daten aus Helios Datalake, die wir mit den Mobile Analytics korrelieren."}
{"ts": "144:27", "speaker": "I", "text": "Sie hatten vorhin kurz das Onboarding erwähnt – gibt es technische Constraints, die wir als UX-Team kennen sollten?"}
{"ts": "144:32", "speaker": "E", "text": "Ja, wir haben eine harte Grenze von 1,5 MB für initiale Asset-Downloads, um das SLA für den Erststart von < 3 Sekunden einzuhalten. Dieses SLA ist in RFC-ATL-004 definiert. Wenn wir größere Assets brauchen, müssen wir sie nachladen und das UI entsprechend gestalten."}
{"ts": "144:42", "speaker": "I", "text": "Verstehe. Und wie gehen Sie mit Feedback aus der Pilotgruppe um, das außerhalb der geplanten Roadmap liegt?"}
{"ts": "144:47", "speaker": "E", "text": "Wir haben ein wöchentliches Grooming speziell für Pilot-Feedback. Dort prüfen wir gegen unsere Prioritäten in Jira und bewerten den Fit. Manche Dinge, wie die Wunschfunktion für Dark Mode, haben wir per Feature Flag schon eingebaut, obwohl sie nicht in der initialen Scope war."}
{"ts": "144:56", "speaker": "I", "text": "Gab es bei solchen kurzfristigen Features Trade-offs, die Sie in Kauf nehmen mussten?"}
{"ts": "145:01", "speaker": "E", "text": "Ja, beim Dark Mode mussten wir die Implementierung des erweiterten Offline-Caches um zwei Sprints verschieben. Das ist im Ticket ATLM-178 dokumentiert, mit Verweis auf die Risikoanalyse RA-2023-19, die besagt, dass wir dadurch nur 92 % statt 95 % Cache-Hit-Rate erreichen."}
{"ts": "145:12", "speaker": "I", "text": "Das sind klare Priorisierungen. Haben Sie Lessons Learned aus solchen Entscheidungen?"}
{"ts": "145:16", "speaker": "E", "text": "Ja, eine wichtige Lesson Learned ist, dass wir Feature Flags nicht nur zur Steuerung, sondern auch als Puffer für UX-Experimente nutzen können. Aber: Wir müssen die technische Schuld dokumentieren und in den nächsten Release-Zyklus einplanen."}
{"ts": "145:25", "speaker": "I", "text": "Wie können wir als UX-Team Sie in den kommenden Monaten am besten unterstützen?"}
{"ts": "145:29", "speaker": "E", "text": "Indem Sie uns frühzeitig Wireframes und Click-Dummies geben, die wir in unseren Staging-Builds mit realen Daten testen können. So erkennen wir Integrationsprobleme mit Helios-Datalake-Queries oder IAM-Flows vor dem Go-Live."}
{"ts": "145:38", "speaker": "I", "text": "Gibt es offene Risiken, die wir jetzt noch adressieren sollten?"}
{"ts": "145:42", "speaker": "E", "text": "Ein offenes Risiko ist die Synchronisationslast bei gleichzeitigen Offline-Uploads aus verschiedenen Clients. Laut Monitoring-Report MR-ATL-09 vom letzten Freitag hatten wir einen Peak von 320 gleichzeitigen Syncs, was unser Limit von 300 überschreitet. Hier müssen wir vor dem Rollout optimieren."}
{"ts": "146:00", "speaker": "I", "text": "Sie hatten vorhin die SLA-Anforderungen für den Offline Sync angesprochen. Können Sie das bitte noch etwas vertiefen? Mich interessiert, wie Sie die im Pilotbetrieb konkret messen."}
{"ts": "146:05", "speaker": "E", "text": "Ja, klar. Wir haben im Runbook RB-ATL-OS-04 eine Checkliste definiert, die alle 24 Stunden automatisiert durch unsere Observability-Pipeline läuft. Die misst die durchschnittliche Re-Sync-Zeit nach Wiederherstellung der Verbindung und vergleicht sie mit der SLA-Vorgabe von unter 15 Sekunden. Im Piloten liegen wir aktuell bei 12,8 Sekunden, was akzeptabel ist."}
{"ts": "146:15", "speaker": "I", "text": "Und wie gehen Sie damit um, wenn dieser Wert überschritten wird? Gibt es ein Eskalationsprotokoll?"}
{"ts": "146:20", "speaker": "E", "text": "Ja, wir haben in Ticket SYS-8745 definiert, dass bei zwei aufeinanderfolgenden Überschreitungen der Duty-Engineer den Sync-Worker neu startet und parallel die IAM-Tokenlaufzeiten prüft, weil wir in der Vergangenheit dort Timeout-Ketteneffekte hatten."}
{"ts": "146:33", "speaker": "I", "text": "Verstehe. Gibt es aus der UX-Perspektive besondere Rückmeldungen zum Verhalten bei Offline-Phasen?"}
{"ts": "146:38", "speaker": "E", "text": "Ja, die Nutzerbefragung im Ticket UXR-229 zeigte, dass die visuelle Indikation 'Daten werden synchronisiert' zu kurz eingeblendet wird. Wir passen das in Sprint 14 an, damit die Nutzer ein klareres Feedback haben und nicht denken, ihre Eingaben seien verloren."}
{"ts": "146:50", "speaker": "I", "text": "Sie hatten auch die Verbindung zum Helios Datalake erwähnt. Gibt es da mittlerweile eine stabile Schnittstelle?"}
{"ts": "146:55", "speaker": "E", "text": "Seit RFC-HEL-217 haben wir einen stabilen gRPC-Endpunkt, der die Metadaten synchronisiert. Allerdings mussten wir einen Adapter schreiben, weil die Atlas Mobile Payloads teilweise größer sind als die im Datalake üblichen 4MB-Limits. Das steht auch in unserem Integrations-Runbook RB-INT-09."}
{"ts": "147:09", "speaker": "I", "text": "Gab es bei der IAM-Integration für mobile Clients spezifische Stolpersteine?"}
{"ts": "147:14", "speaker": "E", "text": "Definitiv. Mobile Geräte verlieren öfter Refresh-Tokens durch OS-Updates. Wir haben deshalb im Pilot ein adaptives Re-Auth-Intervall getestet, das im Ticket SEC-993 dokumentiert ist. Die Balance zwischen Sicherheit und Nutzerkomfort ist da tricky."}
{"ts": "147:28", "speaker": "I", "text": "Hat diese Anpassung messbare Auswirkungen auf die Time-to-Market oder den Rollout-Plan?"}
{"ts": "147:33", "speaker": "E", "text": "Minimal. Wir mussten zwei zusätzliche QA-Zyklen einplanen, um sicherzustellen, dass die neuen Refresh-Logiken keine Regressionen verursachen. Das hat den Rollout um etwa eine Woche verschoben, was im Pilot aber verkraftbar war."}
{"ts": "147:45", "speaker": "I", "text": "Welche Lessons Learned ziehen Sie daraus für die Skalierung nach der Pilotphase?"}
{"ts": "147:50", "speaker": "E", "text": "Wir haben gelernt, dass Feature Flags nicht nur für Funktionen, sondern auch für Security-Policies extrem nützlich sind. So können wir neue Auth-Mechanismen schrittweise auf Teilgruppen ausrollen und Telemetriedaten sammeln, bevor wir global aktivieren."}
{"ts": "148:04", "speaker": "I", "text": "Damit reduzieren Sie also das Risiko größerer Ausfälle?"}
{"ts": "148:08", "speaker": "E", "text": "Genau. Und wir können anhand von Metriken aus dem Observability-Board OB-ATL-07 evidenzbasiert entscheiden. Wenn wir sehen, dass z. B. die Fehlerrate bei einer Gruppe unter 0,5% bleibt, schalten wir die Flag für weitere 10% der Nutzer frei."}
{"ts": "148:00", "speaker": "I", "text": "Bevor wir ins Detail gehen, würde ich gerne noch einmal auf die Lessons Learned eingehen – was sind für Sie die wichtigsten Erkenntnisse aus der bisherigen Pilotphase?"}
{"ts": "148:05", "speaker": "E", "text": "Also, ähm, ganz oben steht für mich, dass wir Feature Flags nicht nur als technischen Schalter sehen dürfen. Wir haben gemerkt, dass die organisatorische Disziplin, diese Flags auch sauber zu dokumentieren, entscheidend ist. Ticket MOB-1423 im JIRA zeigt zum Beispiel, wie ein vergessenes Flag im Staging monatelang unbemerkt blieb."}
{"ts": "148:15", "speaker": "I", "text": "Das klingt nach einem strukturellen Thema. Haben Sie daraus schon Prozesse abgeleitet?"}
{"ts": "148:21", "speaker": "E", "text": "Ja, wir haben im Runbook RBK-ATL-FF-02 festgelegt, dass jedes Feature Flag einen Lifecycle hat – von der Einführung, über Monitoring via Observability Dashboard, bis zur Entfernung. Wir koppeln das jetzt an unsere zweiwöchentliche Release Readiness Review."}
{"ts": "148:35", "speaker": "I", "text": "Und wie hängt das mit den UX-Anforderungen zusammen, die Sie vorher erwähnt hatten?"}
{"ts": "148:41", "speaker": "E", "text": "Well, wir nutzen Feature Flags auch, um gezielt nur einer kleinen Nutzerkohorte neue UI-Elemente zu zeigen. So können wir schnell Feedback sammeln, ohne das Risiko für die gesamte User Base zu erhöhen. Das Data-Team im Helios Datalake liefert uns dafür segmentierte Nutzerlisten."}
{"ts": "148:55", "speaker": "I", "text": "Gab es technische Hürden bei dieser segmentierten Aussteuerung?"}
{"ts": "149:00", "speaker": "E", "text": "Ja, die IAM-Integration musste erweitert werden. Ursprünglich konnten wir nur nach Rollen filtern. Jetzt, dank RFC-ATL-IAM-07, können wir auch nach Nutzungsverhalten filtern, das wir aus den Sync-Logs ableiten."}
{"ts": "149:15", "speaker": "I", "text": "Interessant. Und wie wirkt sich das auf die Performance aus, gerade im Offline-Modus?"}
{"ts": "149:21", "speaker": "E", "text": "Wir mussten die Offline Sync Engine anpassen. Im Runbook RBK-ATL-SYNC-05 ist dokumentiert, dass wir bei bestimmten Filterregeln eine Vorab-Selektion auf dem Gerät durchführen, um die Datenlast zu reduzieren."}
{"ts": "149:36", "speaker": "I", "text": "Gab es dabei Zielkonflikte oder Trade-offs, die Sie bewusst eingegangen sind?"}
{"ts": "149:42", "speaker": "E", "text": "Ja, klar. Ein klassischer Fall: wir haben uns zwischen kompletter Datenintegrität und schneller Synchronisierung entscheiden müssen. Aufgrund der UX-Feedbacks – siehe Usability Report UR-ATL-09 – haben wir uns für schnellere Sync-Zyklen mit einer leichten Verzögerung bei der Vollständigkeit entschieden."}
{"ts": "149:58", "speaker": "I", "text": "Welche Risiken sehen Sie, wenn Sie diesen Weg weitergehen?"}
{"ts": "150:04", "speaker": "E", "text": "Das größte Risiko ist, dass kritische Updates im Offline-Modus zu lange nicht ankommen. Deshalb haben wir im Monitoring-Tool einen SLA-Check eingebaut: wenn mehr als 5% der Devices länger als 48 Stunden nicht synchronisieren, wird ein Incident nach Vorlage INC-ATL-220 erstellt."}
{"ts": "150:19", "speaker": "I", "text": "Und wie können wir als UX-Team Sie dabei unterstützen, dieses Risiko zu minimieren?"}
{"ts": "150:24", "speaker": "E", "text": "Ich denke, wenn ihr in den nächsten Prototypen gezielt Stress-Szenarien im Offline-Modus testet und uns User Journeys gebt, in denen Daten veraltet sind, können wir Entscheidungen evidenzbasiert treffen. Diese Journeys sollten dann direkt in unser Test-Runbook aufgenommen werden."}
{"ts": "150:00", "speaker": "I", "text": "Lassen Sie uns noch einmal auf die Lessons Learned eingehen. Was waren für Sie die größten Überraschungen in der Pilotphase?"}
{"ts": "150:18", "speaker": "E", "text": "Ähm, ja, die größte Überraschung war tatsächlich, dass unser Offline Sync Modul im ländlichen Testgebiet deutlich stabiler lief als in städtischen Netzen. Wir hatten gedacht, dass die Netzwechsel dort weniger problematisch wären, aber laut Log-Analyse aus Runbook RB-OS-112 kam es in urbanen Bereichen vermehrt zu Konflikten bei gleichzeitigen Writes."}
{"ts": "150:52", "speaker": "I", "text": "Das klingt kontraintuitiv. Haben Sie ermittelt, woran das lag?"}
{"ts": "151:05", "speaker": "E", "text": "Ja, wir haben im Rahmen von Incident Ticket T-ATL-443 festgestellt, dass in Städten die Geräte häufiger zwischen WLAN und LTE wechseln. Unser Conflict Resolver war zwar für Netzwerkabbrüche optimiert, aber nicht für schnelle IP-Wechsel, was zu vermehrten Merge-Fällen führte."}
{"ts": "151:34", "speaker": "I", "text": "Verstehe. Welche Maßnahmen leiten Sie daraus für die nächste Iteration ab?"}
{"ts": "151:45", "speaker": "E", "text": "Wir planen, im nächsten Sprint einen zusätzlichen Heartbeat-Mechanismus einzubauen, der bei Network Switch Events einen Soft-Sync triggert. Das geht zurück auf eine Empfehlung aus unserem Performance Runbook RB-PS-089."}
{"ts": "152:10", "speaker": "I", "text": "Gab es auch im Bereich Feature Flags unerwartete Erkenntnisse?"}
{"ts": "152:23", "speaker": "E", "text": "Durchaus. Wir hatten ein Flag für den neuen Kartenrenderer nur für 5% der Nutzer aktiviert. Im Pilot zeigte sich jedoch, dass die Telemetrie-Events für diese Gruppe versehentlich an den gesamten Datalake-Cluster 'Helios-West' gingen. Das führte zu unerwünschter Lastspitze und wir mussten kurzfristig ein Limit in unserem Ingestor setzen."}
{"ts": "152:55", "speaker": "I", "text": "Hat das Auswirkungen auf andere Projekte im Portfolio gehabt?"}
{"ts": "153:09", "speaker": "E", "text": "Ja, Helios Datalake hostet auch Streams für das Projekt Orion Analytics. Durch die Lastspitze kam es zu einer Verzögerung in deren Batch-Processing um etwa 12 Minuten, was dort einen SLA-Breach (SLA-ID SLA-OR-07) verursacht hat. Wir haben daraufhin die Streams isoliert."}
{"ts": "153:40", "speaker": "I", "text": "Wie hat das Ihr Vorgehen bei der Integration mit bestehenden Systemen beeinflusst?"}
{"ts": "153:53", "speaker": "E", "text": "Wir haben nun eine feste Regel: Feature Flags mit potenziell hohem Datenvolumen werden nur in einer isolierten Sandbox-Stream-Umgebung getestet, bevor sie in die produktiven Pipelines des Datalake integriert werden. Das ist jetzt auch dokumentiert in RFC-ATL-FF-2024-03."}
{"ts": "154:20", "speaker": "I", "text": "Das klingt nach einer klaren Lehre. Gibt es noch offene Risiken, die Sie besonders im Auge behalten?"}
{"ts": "154:34", "speaker": "E", "text": "Ein Punkt ist die Abhängigkeit von unserem IAM-System. Wir nutzen aktuell den zentralen Token Service, aber im Lasttest (LT-ATL-07) gab es bei über 500 gleichzeitigen Offline-Reconnects eine Spike in den Auth-Latenzen. Sollte das in Produktion passieren, könnte es den Sync verzögern."}
{"ts": "154:58", "speaker": "I", "text": "Wie wollen Sie dieses Risiko mitigieren?"}
{"ts": "155:11", "speaker": "E", "text": "Kurzfristig setzen wir auf Token Caching im Client, mittelfristig prüfen wir mit dem IAM-Team eine dedizierte Atlas-Auth-Endpoint-Instanz. Das ist auch im Risk Register unter R-ATL-015 erfasst, mit Maßnahmenplan bis Q3."}
{"ts": "152:00", "speaker": "I", "text": "Zum Abschluss würde ich gern noch auf die Lessons Learned eingehen – was hat Sie in der Pilotphase von Atlas Mobile am meisten überrascht?"}
{"ts": "152:05", "speaker": "E", "text": "Ähm, ja, also was mich tatsächlich überrascht hat, war wie stark die Offline-Nutzung war. Wir hatten in den Annahmen für den Pilot nur mit etwa 15 % gerechnet, real lag der Wert bei knapp 38 %. Das hat direkte Auswirkungen auf unsere Sync-Strategie und auf die Priorisierung im nächsten Sprint."}
{"ts": "152:15", "speaker": "I", "text": "Das klingt, als müssten Sie auch die technischen Ressourcen anders allokieren?"}
{"ts": "152:19", "speaker": "E", "text": "Exakt. Wir haben zum Beispiel in Runbook RB-ATL-OS-004 festgehalten, dass wir den Sync-Executor von 2 auf 4 Threads erhöhen, um Peak-Loads abzufangen. Allerdings bedeutet das auch, dass wir Memory-Budgets neu verhandeln müssen, siehe Ticket #ATL-217."}
{"ts": "152:29", "speaker": "I", "text": "Gab es in diesem Kontext auch UX-Rückmeldungen, die Sie überrascht haben?"}
{"ts": "152:33", "speaker": "E", "text": "Ja, Nutzer haben uns signalisiert, dass sie bei Konflikten in der Offline-Synchronisation lieber eine klare Merge-Vorschau sehen wollen, statt eines automatischen Overwrites. Das müssen wir sowohl im Frontend-Design als auch in der Backend-API berücksichtigen."}
{"ts": "152:43", "speaker": "I", "text": "Wie wollen Sie das technisch umsetzen, ohne die Time-to-Market zu gefährden?"}
{"ts": "152:48", "speaker": "E", "text": "Wir planen, die Merge-Vorschau als Feature Flag 'mergePreview' auszurollen. Zunächst nur für die Pilotgruppe, gesteuert über unser internes Flag-Management-System, konfiguriert in YAML nach Vorlage aus RFC-ATL-FF-03."}
{"ts": "152:57", "speaker": "I", "text": "Klingt nach einem weiteren Trade-off zwischen Stabilität und Innovation."}
{"ts": "153:01", "speaker": "E", "text": "Genau. Stabilität sichern wir, indem wir die Merge-Preview in der CI/CD-Pipeline mit Simulationen gegen den Helios Datalake testen. So sehen wir früh, wenn die Vorschau zu lange Ladezeiten hat oder Konflikte falsch darstellt."}
{"ts": "153:11", "speaker": "I", "text": "Und wie wird das Monitoring dafür eingerichtet?"}
{"ts": "153:15", "speaker": "E", "text": "Wir erweitern unser Observability-Dashboard um zwei neue Graphen: 'Merge Preview Load Time' und 'Conflict Resolution Accuracy'. Die Metriken sind in SLA-ATL-UX-002 definiert, mit Zielwerten von <1,5 s Ladezeit und >95 % korrekter Auflösung."}
{"ts": "153:25", "speaker": "I", "text": "Das bringt mich zur letzten Frage: Welche UX-Themen sollten wir Ihrer Meinung nach als Nächstes angehen?"}
{"ts": "153:29", "speaker": "E", "text": "Prioritär sehe ich drei Punkte: verbesserte Konflikt-UI, ein klareres Offline-Status-Icon und eine schnellere Initial-Ladezeit bei schwacher Verbindung. Letzteres hängt auch wieder an den Caching-Strategien aus Runbook RB-ATL-CACHE-002."}
{"ts": "153:39", "speaker": "I", "text": "Vielen Dank für die ausführlichen Einblicke und die konkreten Verweise auf Tickets und Runbooks – das hilft uns im UX-Team enorm bei der Priorisierung."}
{"ts": "153:44", "speaker": "E", "text": "Sehr gerne, und geben Sie mir bitte Feedback, wenn wir aus technischer Sicht noch etwas anpassen sollten, damit Ihre UX-Tests reibungslos laufen. Wir wollen ja alle, dass Atlas Mobile nach der Pilotphase sauber skaliert."}
{"ts": "153:36", "speaker": "I", "text": "Bevor wir zum Abschluss kommen, würde ich gern noch einmal auf die Lessons Learned aus der Pilotphase eingehen. Gibt es Punkte, die Sie jetzt schon als Best Practice identifiziert haben?"}
{"ts": "153:41", "speaker": "E", "text": "Ja, definitiv. Wir haben festgestellt, dass ein engeres Alignment zwischen DevOps und UX-Team schon in der Sprint-Planung viel Reibung rausnimmt. Ein Beispiel ist unser Runbook RB-ATL-042, das wir nach einem kleineren Offline-Sync-Ausfall erneuert haben – dort haben wir gleich UX-Fehlerbilder mit aufgenommen."}
{"ts": "153:48", "speaker": "I", "text": "Das heißt, Sie dokumentieren nicht nur technische Recovery-Schritte, sondern auch Hinweise, wie sich Fehler im Frontend äußern?"}
{"ts": "153:53", "speaker": "E", "text": "Genau. Das war vorher nicht so explizit, aber wir haben im Ticket ATL-SUP-317 gesehen, dass First-Level-Support dadurch schneller reagieren kann. Das spart uns im Schnitt etwa 15 Minuten pro Incident."}
{"ts": "153:59", "speaker": "I", "text": "Gab es dabei technische Hürden, z. B. bei der Integration dieser Informationen in bestehende Systeme?"}
{"ts": "154:04", "speaker": "E", "text": "Nur kleinere. Wir mussten unser internes Observability-Dashboard so erweitern, dass UX-relevante Alerts aus dem Mobile-Client mitgeloggt werden. Das lief parallel zu einer IAM-Policy-Anpassung, weil nicht alle Support-Rollen Zugriff auf alle Logs hatten."}
{"ts": "154:11", "speaker": "I", "text": "Interessant, also wieder so eine Schnittmenge zwischen Security und Operations."}
{"ts": "154:15", "speaker": "E", "text": "Richtig, und genau da liegt oft die Herausforderung: eine Balance zwischen Datenschutzauflagen und schneller Problemerkennung."}
{"ts": "154:20", "speaker": "I", "text": "Wenn Sie in die nächsten Monate blicken – welche UX-Themen sollten wir prioritär weiterverfolgen?"}
{"ts": "154:25", "speaker": "E", "text": "Aus meiner Sicht: die Offline-Benachrichtigungen. Wir haben aus mehreren Nutzerinterviews die Rückmeldung, dass Push-Nachrichten nach einer Offline-Phase teils in falscher Reihenfolge erscheinen. Technisch hängt das an unserer Queue-Logik im Sync-Modul."}
{"ts": "154:31", "speaker": "I", "text": "Wäre das eine größere Architekturänderung oder lässt sich das inkrementell beheben?"}
{"ts": "154:36", "speaker": "E", "text": "Wir planen ein inkrementelles Vorgehen, haben dazu bereits RFC-ATL-015 eröffnet. Darin ist ein zweistufiges Sequencing beschrieben, das wir in einem Feature Flag kapseln, um es gestaffelt auszurollen."}
{"ts": "154:42", "speaker": "I", "text": "Und diese Änderungen würden innerhalb des bestehenden SLAs bleiben?"}
{"ts": "154:46", "speaker": "E", "text": "Ja, nach unserer Berechnung – siehe SLA-Dokument v2.3 – bleiben wir bei den vereinbarten 99,5 % Verfügbarkeit. Wir haben dazu auch Lasttests im Staging mit simulierten Offline-Phasen gefahren."}
{"ts": "154:52", "speaker": "I", "text": "Gibt es aus Ihrer Sicht Risiken, die wir als UX-Team bei der Einführung dieses Sequencing besonders beachten sollten?"}
{"ts": "154:57", "speaker": "E", "text": "Ja, vor allem das Thema Nutzererwartung: Wenn Nachrichten plötzlich anders sortiert sind, könnten Power-User irritiert reagieren. Wir sollten das über A/B-Tests mit klaren Kommunikationsstrings im UI begleiten, wie wir es schon im Ticket ATL-UX-204 dokumentiert haben."}
{"ts": "155:06", "speaker": "I", "text": "Zum Abschluss würde ich gern noch einmal auf die Lessons Learned eingehen – was hat Sie in der Pilotphase am meisten überrascht?"}
{"ts": "155:10", "speaker": "E", "text": "Überrascht hat mich, wie stark sich kleine Änderungen bei den Feature Flags direkt auf die Nutzerakzeptanz auswirken. In Ticket #P-ATL-342 haben wir dokumentiert, dass das Verschieben einer Offline-Sync-Optimierung um nur zwei Tage zu 15 % weniger Supportanfragen geführt hat."}
{"ts": "155:16", "speaker": "I", "text": "Das klingt nach einem klaren Zusammenhang zwischen technischer Entscheidung und User Experience. Gab es dazu interne Diskussionen?"}
{"ts": "155:20", "speaker": "E", "text": "Ja, im Architektur-Review vom 12.05., siehe Runbook RB-ATL-OS-07, haben wir genau diese Abhängigkeit analysiert. Das war auch der Moment, in dem wir festgelegt haben, dass Experiment-Flags mindestens 24 h vor einem Release in der Staging-Umgebung aktiv sein müssen."}
{"ts": "155:26", "speaker": "I", "text": "Interessant. Gab es noch andere Themen, die Sie in die Roadmap des nächsten Quartals übernehmen wollen?"}
{"ts": "155:30", "speaker": "E", "text": "Wir wollen die Schnittstellen zum Helios Datalake entkoppeln. Im Pilot hatten wir noch eine direkte Bindung der Sync-Queue an die Datalake-API v2, was bei einem Ausfall wie im Incident-Report IR-HEL-219 zu Verzögerungen von bis zu 90 Minuten geführt hat."}
{"ts": "155:36", "speaker": "I", "text": "Wenn Sie 'entkoppeln' sagen, meinen Sie eine asynchrone Pufferung?"}
{"ts": "155:40", "speaker": "E", "text": "Genau, wir wollen einen Message-Broker dazwischen setzen, sodass Offline-Sync-Pakete persistent zwischengespeichert werden. Laut unserem internen SLA-Dokument SLA-OS-2024 dürfen Daten maximal 5 Minuten verzögert werden, aber nicht verloren gehen."}
{"ts": "155:46", "speaker": "I", "text": "Und wie wirkt sich das auf die Integrationsarbeit mit IAM aus?"}
{"ts": "155:50", "speaker": "E", "text": "Für IAM bedeutet das, dass Token-Refresh-Events ebenfalls in diesen Puffer fließen. Wir müssen sicherstellen, dass abgelaufene Tokens vor der Synchronisation geprüft werden, um Konflikte im Offline-Betrieb zu vermeiden. Das ist ein Trade-off zwischen Sicherheit und Latenz."}
{"ts": "155:56", "speaker": "I", "text": "Wie priorisieren Sie solche Trade-offs, wenn mehrere Teams betroffen sind?"}
{"ts": "156:00", "speaker": "E", "text": "Wir nutzen eine Bewertungsmatrix aus unserem Decision-Log DL-2024-Q2. Darin fließen Risikopotenzial, Nutzerimpact und Implementierungsaufwand ein. Beim IAM-Case war der Nutzerimpact hoch, daher haben wir die Latenzsteigerung in Kauf genommen."}
{"ts": "156:06", "speaker": "I", "text": "Gibt es spezifische UX-Themen, die Sie aus diesen Learnings ableiten?"}
{"ts": "156:10", "speaker": "E", "text": "Ja, wir wollen im nächsten Sprint ein visuelles Indikator-Element einführen, das den Sync-Status explizit anzeigt. Die Anforderung kam aus drei separaten Feedback-Sessions, siehe Protokolle UX-WS-17 bis UX-WS-19."}
{"ts": "156:16", "speaker": "I", "text": "Dann ist das ein direktes Beispiel für evidenzbasierte UX-Verbesserung. Wie können wir Sie als UX-Team konkret unterstützen?"}
{"ts": "156:20", "speaker": "E", "text": "Indem Sie schon in der Vorabtestphase Mockups unter realen Netzwerkbedingungen validieren. Wir haben im Pilot gesehen, dass Labortests oft zu optimistisch sind – reale Offlinenutzung in Bahn oder ländlichen Gebieten liefert ganz andere Daten."}
{"ts": "156:22", "speaker": "I", "text": "Zum Abschluss würde ich gern noch einmal auf die Lessons Learned eingehen. Welche Punkte sind Ihnen aus der Pilotphase von Atlas Mobile am stärksten in Erinnerung geblieben?"}
{"ts": "156:28", "speaker": "E", "text": "Also, was mir sofort einfällt, ist die Erkenntnis, dass unsere initialen Sync-Intervalle zu aggressiv waren. Laut Runbook RM-ATL-042 hatten wir alle 30 Sekunden eine Hintergrund-Synchronisation vorgesehen, was in der Testgruppe mit schwacher Netzabdeckung zu Battery Drain geführt hat."}
{"ts": "156:42", "speaker": "I", "text": "Und wie haben Sie darauf reagiert? Wurde das direkt technisch angepasst?"}
{"ts": "156:46", "speaker": "E", "text": "Ja, wir haben über ein Feature Flag namens 'sync_interval_dynamic' den Standardwert auf 2 Minuten erhöht und gleichzeitig eine Logik eingebaut, die bei starker Verbindung wieder auf 30 Sekunden runtergeht. Das war in Ticket ATL-MOB-312 dokumentiert."}
{"ts": "156:59", "speaker": "I", "text": "Interessant. Gab es auch UX-spezifische Learnings, die Sie direkt in den Code übernommen haben?"}
{"ts": "157:04", "speaker": "E", "text": "Ja, wir haben festgestellt, dass Nutzer:innen oft unsicher waren, ob Daten im Offline-Modus gespeichert wurden. Daraufhin haben wir den Offline-Indikator aus dem UX-Styleguide v1.3 implementiert, der bei jeder erfolgreichen lokalen Speicherung kurz aufblinkt."}
{"ts": "157:16", "speaker": "I", "text": "Gab es dafür ebenfalls ein Runbook oder war das eher ein Ad-hoc-Entscheid?"}
{"ts": "157:20", "speaker": "E", "text": "Das war zunächst ad hoc, aber wir haben im Nachgang Runbook RM-UX-017 angelegt, um solche visuellen Feedbackmechanismen standardisiert einführen zu können."}
{"ts": "157:31", "speaker": "I", "text": "Wie möchten Sie diese Erfahrungen für die Skalierung nach der Pilotphase nutzen?"}
{"ts": "157:36", "speaker": "E", "text": "Wir planen, die dynamische Sync-Steuerung als generisches Modul zu extrahieren und im Helios Datalake Consumer SDK einzubauen. So profitieren auch andere Apps im Portfolio von der Logik und den daraus abgeleiteten SLA-Anpassungen."}
{"ts": "157:48", "speaker": "I", "text": "Sehen Sie Risiken, wenn Sie diese Module für andere Plattformen öffnen?"}
{"ts": "157:52", "speaker": "E", "text": "Ja, vor allem das Risiko, dass Plattform-spezifische Eigenheiten unter den Tisch fallen. Wir haben in Ticket SDK-COMP-045 dokumentiert, dass ältere Android-Versionen mit Doze-Modus die Timer-Logik aushebeln können."}
{"ts": "158:04", "speaker": "I", "text": "Wie mitigieren Sie so etwas?"}
{"ts": "158:08", "speaker": "E", "text": "Wir arbeiten an einem Fallback-Mechanismus, der beim Ausbleiben eines Scheduled-Events einen manuellen Trigger anbietet. Das wird aktuell im Branch 'heartbeat-fallback' getestet, gemäß Testplan TP-ATL-056."}
{"ts": "158:20", "speaker": "I", "text": "Alles klar. Gibt es noch offene Punkte, bei denen Sie sich explizit Unterstützung vom UX-Team wünschen?"}
{"ts": "158:25", "speaker": "E", "text": "Ja, wir bräuchten dringend Unterstützung beim Usability-Test für den Offline-Status-Dialog. Uns fehlt aktuell die Evidenz, ob die Farbwahl und das Wording in stressigen Situationen – etwa bei schwankender Verbindung – intuitiv verstanden werden."}
{"ts": "157:42", "speaker": "I", "text": "Bevor wir zum Abschluss kommen, würde mich interessieren: welche UX-Themen sehen Sie nach dieser Pilotphase als besonders dringend?"}
{"ts": "157:47", "speaker": "E", "text": "Also, ganz klar ist das Onboarding in der Offline-Umgebung ein Pain Point. Wir haben aus den letzten Nutzerinterviews gelernt, dass die visuelle Rückmeldung bei fehlender Konnektivität noch nicht konsistent ist. Das steht auch im internen Ticket MBL-4215, das wir im Runbook \u0000Atlas-UX-Flow\u0000 referenzieren."}
{"ts": "157:56", "speaker": "I", "text": "Verstehe. Haben Sie dafür schon eine konkrete Maßnahme oder bleibt das erstmal ein Beobachtungspunkt?"}
{"ts": "158:00", "speaker": "E", "text": "Wir haben entschieden, einen kleinen Sprint einzuschieben \u0000 Sprint 12a \u0000 um gezielt das Offline-Onboarding mit Feature Flag 'offline_onb_v2' zu testen. Das geht auch auf den Trade-off aus dem Runbook R-ATL-FF-003 zurück, wo wir abwägen, erst Performance oder erst UX zu optimieren."}
{"ts": "158:10", "speaker": "I", "text": "Und wie unterstützen wir als UX-Team diese Entscheidung am besten?"}
{"ts": "158:14", "speaker": "E", "text": "Am wertvollsten wäre, wenn ihr uns bis Ende der Woche zwei alternative Flow-Entwürfe liefert, jeweils mit Annotierungen zu erwarteten Nutzerreaktionen. Die kommen dann direkt in unseren Testplan TP-ATL-Pilot-UX04."}
{"ts": "158:22", "speaker": "I", "text": "Okay. Gibt es Lessons Learned aus der Pilotphase, die Sie gerne teilen möchten?"}
{"ts": "158:26", "speaker": "E", "text": "Ja, mehrere. Erstens: Feature Flags sind nur so gut wie unser Monitoring \u0000 ohne die Observability-Integration in das Helios-Datalake-Dashboard hätten wir zwei kritische Sync-Fehler nicht rechtzeitig erkannt. Zweitens: Offline-Sync muss immer mit IAM-Token-Refresh zusammengedacht werden, sonst läuft man in Edge Cases wie in Incident INC-ATL-2024-07-15 beschrieben."}
{"ts": "158:38", "speaker": "I", "text": "Das heißt, die IAM-Integration war nicht nur ein nice-to-have, sondern zwingend für die Stabilität?"}
{"ts": "158:43", "speaker": "E", "text": "Genau. Ohne die Änderung aus RFC-ATL-SEC-019 hätten wir in 12% der Offline-Sync-Fälle veraltete Berechtigungen gehabt. Das hat direkte UX-Auswirkungen, weil Nutzer dann Buttons sehen, die für sie nicht mehr gültig sind."}
{"ts": "158:52", "speaker": "I", "text": "Gab es bei der Observability-Integration auch Trade-offs?"}
{"ts": "158:56", "speaker": "E", "text": "Ja, wir mussten uns entscheiden zwischen granularer Event-Logs und der Performance der mobilen App. Laut Ticket PERF-ATL-778 haben wir Logging-Detailtiefe für Beta-User hochgeschraubt, aber für den Rest reduziert. Das ist evidenzbasiert, weil wir in Testlauf #ATL-PILOT-OBS03 gesehen haben, dass mehr Logging >15% CPU kostet."}
{"ts": "159:08", "speaker": "I", "text": "Verstanden. Welche nächsten Schritte planen Sie jetzt, um über die Pilotphase hinaus zu skalieren?"}
{"ts": "159:12", "speaker": "E", "text": "Wir erstellen bis Ende des Monats ein Skalierungskonzept, das die Abhängigkeiten zu Helios Datalake, IAM und dem internen API Gateway explizit ausweist. Basis sind die Metriken aus SLA-Report SLA-ATL-Q2, um Prioritäten zu setzen."}
{"ts": "159:20", "speaker": "I", "text": "Dann nehmen wir als UX-Team mit, die zwei Flow-Entwürfe vorzubereiten und Feedbackschleifen eng zu halten."}
{"ts": "159:24", "speaker": "E", "text": "Perfekt. So stellen wir sicher, dass wir technische Machbarkeit und Nutzerbedürfnisse weiterhin balancieren, und das Atlas Mobile Pilotprojekt als Blaupause für künftige cross-platform Initiativen nutzen können."}
{"ts": "159:42", "speaker": "I", "text": "Zum Abschluss würde ich gern noch einmal auf die Lessons Learned eingehen, die Sie aus der Pilotphase gewonnen haben."}
{"ts": "159:46", "speaker": "E", "text": "Ja, klar. Eine zentrale Erkenntnis ist, dass wir Feature Flags nicht nur als reines DevOps-Tool nutzen sollten, sondern auch als Instrument für schnelle UX-Iterationen. Wir hatten im Runbook RB-ATL-FF-07 dokumentiert, dass wir Flags innerhalb von 30 Minuten umschalten können, und das hat uns mehrfach geholfen, auf Nutzerfeedback zu reagieren."}
{"ts": "159:55", "speaker": "I", "text": "Gab es da ein konkretes Beispiel, wo Sie diesen schnellen Wechsel genutzt haben?"}
{"ts": "159:58", "speaker": "E", "text": "Ja, im Ticket ATL-UX-2217 ging es um die Offline-Sync-Statusanzeige. Die Testnutzer fanden das Symbol zu unklar. Wir haben per Feature Flag sofort eine alternative Anzeige aktiviert, ohne auf den nächsten Build zu warten."}
{"ts": "160:05", "speaker": "I", "text": "Das klingt, als hätten Sie so auch Risiken minimiert, oder?"}
{"ts": "160:08", "speaker": "E", "text": "Genau. Das Risiko, dass wir im Pilot mit einer suboptimalen UX weiterarbeiten, wurde damit stark reduziert. Das belegen auch die Metriken aus unserem Observability-System AtlasEye, wo die Fehlinteraktionsrate nach dem Flag-Switch um 18 % sank."}
{"ts": "160:15", "speaker": "I", "text": "Wie planen Sie denn, diese Erfolgsfaktoren in die Skalierung nach der Pilotphase mitzunehmen?"}
{"ts": "160:19", "speaker": "E", "text": "Wir wollen in der nächsten Phase ein sogenanntes 'Flag Governance Board' einführen. Das wird in RFC-ATL-12 beschrieben und soll sicherstellen, dass Flags mit klaren Ablaufdaten und Ownern versehen werden, um technischen Wildwuchs zu verhindern."}
{"ts": "160:27", "speaker": "I", "text": "Und welche Rolle kann das UX-Team dabei spielen?"}
{"ts": "160:30", "speaker": "E", "text": "Ihr könnt uns vor allem helfen, die Priorisierung der Flags aus Nutzersicht zu gestalten. Also: welche Änderungen haben den größten Impact auf die Nutzererfahrung, und welche sind eher nice-to-have."}
{"ts": "160:35", "speaker": "I", "text": "Gibt es neben Feature Flags noch andere Lessons Learned, die Sie hervorheben würden?"}
{"ts": "160:39", "speaker": "E", "text": "Ja, beim Offline Sync haben wir gelernt, dass die Robustheit stark von der Konfliktauflösung abhängt. In Runbook RB-ATL-SYNC-03 haben wir festgehalten, dass wir serverseitig 'last-write-wins' einsetzen, aber mit einer Ausnahme für kritische Datenfelder, wo wir manuelle Review-Queues vorschalten."}
{"ts": "160:47", "speaker": "I", "text": "Wie reagieren die Nutzer auf diese manuelle Queue?"}
{"ts": "160:50", "speaker": "E", "text": "Positiv, weil sie die Transparenz schätzen. In den Feedback-Sessions wurde mehrfach betont, dass ein Hinweis auf 'Datenprüfung ausstehend' Vertrauen schafft."}
{"ts": "160:55", "speaker": "I", "text": "Dann lassen Sie uns noch kurz auf offene UX-Themen schauen, die Sie priorisieren würden."}
{"ts": "160:59", "speaker": "E", "text": "Ganz oben steht für mich die Offline-Erstnutzung. Viele Nutzer starten die App beim ersten Mal ohne Netz, und da müssen wir sicherstellen, dass die Onboarding-Flows trotzdem klar und selbsterklärend sind. Das ist aktuell nur teilweise gelöst."}
{"ts": "161:18", "speaker": "I", "text": "Bevor wir zu den Lessons Learned kommen, würde mich interessieren, ob es in der Pilotphase unerwartete Wechselwirkungen zwischen den Feature Flags und dem Offline-Sync gab?"}
{"ts": "161:23", "speaker": "E", "text": "Ja, tatsächlich. Wir hatten in Sprint 4 ein Problem, dass ein Flag für den erweiterten Dokumentenmodus aktiviert war, während ein Teil der Offline-Sync-Routinen noch auf das alte Schema im Helios Datalake referenzierte. Das führte zu Konflikten in der Merge-Queue. Wir mussten im Runbook SYNC-042 temporäre Mapping-Regeln hinterlegen."}
{"ts": "161:33", "speaker": "I", "text": "Wie schnell konnten Sie reagieren, und gab es dafür einen festgelegten SLA?"}
{"ts": "161:37", "speaker": "E", "text": "Unser internes SLA für kritische Sync-Fehler liegt bei vier Stunden. In dem Fall waren wir nach zwei Stunden wieder stabil, weil wir im Observability-Dashboard eine klare Correlation-ID aus dem IAM-Log hatten und sofort wussten, welche User-Scopes betroffen waren."}
{"ts": "161:46", "speaker": "I", "text": "Gab es ähnliche Fälle, bei denen die Integration mit IAM zusätzliche Komplexität hineinbrachte?"}
{"ts": "161:51", "speaker": "E", "text": "Ja, die Token-Refresh-Logik. Wenn ein User offline ging und kurz danach ein Feature Flag umgelegt wurde, mussten wir sicherstellen, dass beim nächsten Token-Refresh die richtigen Berechtigungen geladen wurden. Im Ticket ATLAS-451 haben wir dafür eine dedizierte Middleware im Sync-Service beschrieben."}
{"ts": "162:00", "speaker": "I", "text": "Das klingt nach einer engen Kopplung zwischen Backend-Flags und Client-Verhalten."}
{"ts": "162:04", "speaker": "E", "text": "Genau, und das war einer der Multi-Hop-Learnings: Feature Toggles beeinflussen nicht nur die UI, sondern auch die Datenpfade. Deswegen haben wir in der Architektur-Übersicht v2.3 einen Abschnitt eingefügt, der bei jedem neuen Flag einen Impact-Check auf Sync-Module vorsieht."}
{"ts": "162:14", "speaker": "I", "text": "Wie haben Ihre UX-Teams diese Änderungen wahrgenommen?"}
{"ts": "162:18", "speaker": "E", "text": "Die UX-Kollegen waren froh, dass wir die Merge-Konflikte früh erkannt haben, weil sie so keine fehlerhaften Prototyp-Demos vor Kunden zeigen mussten. Wir haben einen wöchentlichen Sync-Report eingeführt, der auch Nicht-Technikern die aktuellen stabilen und instabilen Features auflistet."}
{"ts": "162:27", "speaker": "I", "text": "Gab es bei diesen Reports auch qualitative Nutzerstimmen, oder rein technische Kennzahlen?"}
{"ts": "162:31", "speaker": "E", "text": "Beides. Wir kombinieren Crash-Free-Rate und Sync-Latenz mit kurzen Auszügen aus Nutzerinterviews, die das UX-Team durchführt. Diese Hybrid-Metrik war z. B. ausschlaggebend in der Entscheidung, das Flag für den Offline-Export eine Woche länger in Beta zu halten."}
{"ts": "162:40", "speaker": "I", "text": "Das war also ein klarer Trade-off zwischen Time-to-Market und Stabilität?"}
{"ts": "162:44", "speaker": "E", "text": "Ja, und wir haben das im Change Advisory Board mit Verweis auf Runbook REL-109 und die Beta-Rückmeldungen dokumentiert. Risiko war hier höher, weil der Offline-Export auch regulatorische Daten enthält, wo ein Sync-Fehler rechtlich heikel wäre."}
{"ts": "162:54", "speaker": "I", "text": "Können Sie abschließend sagen, welche Lehren Sie aus genau dieser Situation für die Skalierung ziehen?"}
{"ts": "162:59", "speaker": "E", "text": "Wir wollen künftig jedes Feature Flag mit einem Pre-Flight-Sync-Test koppeln, der gegen einen Staging-Datalake mit anonymisierten Daten läuft. So vermeiden wir, dass sich Flag-Änderungen und Offline-Sync unbeabsichtigt blockieren. Das steht als RFC-Atlas-27 in der Pipeline."}
{"ts": "162:18", "speaker": "I", "text": "Lassen Sie uns noch mal konkret auf die Nutzerzielsetzungen zurückkommen: Welche UX-Themen haben sich im Verlauf der Pilotphase als besonders kritisch herausgestellt?"}
{"ts": "162:23", "speaker": "E", "text": "Also, wir haben gemerkt, dass die Offline-Sync-Geschwindigkeit für den Außendienst entscheidend ist. Laut Ticket #P-ATL-145 kam es in ländlichen Gebieten zu spürbaren Verzögerungen, was wir jetzt in Sprint 9 mit einer neuen Delta-Sync-Logik adressieren."}
{"ts": "162:29", "speaker": "I", "text": "Und wie fließt dieses Feedback in Ihre Release-Planung ein? Wird das ad hoc oder nach einem festen Prozess eingetaktet?"}
{"ts": "162:34", "speaker": "E", "text": "Wir nutzen einen festen Runbook-Prozess, 'RB-UX-Feedback-01', der beschreibt, wie kritische UX-Findings innerhalb von zwei Sprints umgesetzt werden. Ad hoc nur, wenn die SLA 'UX-Response-Critical' von 5 Arbeitstagen greift."}
{"ts": "162:40", "speaker": "I", "text": "Sie hatten vorhin den Helios Datalake erwähnt – gibt es da neue Abhängigkeiten, die für UX relevant sind?"}
{"ts": "162:45", "speaker": "E", "text": "Ja, indirekt. Die Filterfunktionen in Atlas Mobile ziehen jetzt Live-Segmente aus Helios, was die Personalisierung verbessert, aber auch Latenzrisiken birgt. Wir haben deshalb im Observability-Dashboard einen separaten UX-Latency-Graphen eingeführt."}
{"ts": "162:52", "speaker": "I", "text": "Hat diese neue Integration Auswirkungen auf Ihre Time-to-Market?"}
{"ts": "162:57", "speaker": "E", "text": "Leicht, ja. Durch die zusätzlichen End-to-End Tests gegen Helios verlängert sich die QA-Phase um etwa zwei Tage. Das ist ein Trade-off, den wir bewusst eingehen, weil die Segment-Qualität die Nutzerbindung deutlich steigert."}
{"ts": "163:03", "speaker": "I", "text": "Können Sie ein Beispiel geben, wie technische Machbarkeit und Nutzerbedürfnisse miteinander in Konflikt geraten sind?"}
{"ts": "163:08", "speaker": "E", "text": "Ein gutes Beispiel ist das Feature 'Smart Recommendations'. Nutzer wollten kontextbezogene Tipps auch offline. Technisch ist das schwierig, weil unsere ML-Modelle aktuell nur serverseitig laufen. Wir haben uns mit Ticket #P-ATL-162 für einen Kompromiss entschieden: Basis-Empfehlungen werden lokal gecached, für tiefergehende Analysen braucht es Online-Verbindung."}
{"ts": "163:16", "speaker": "I", "text": "Wie stellen Sie sicher, dass diese Kompromisse gut dokumentiert und nachvollziehbar bleiben?"}
{"ts": "163:21", "speaker": "E", "text": "Jeder Trade-off landet in unserem 'Decision Log' im Confluence, verknüpft mit den relevanten Jira-Tickets und den Abschnitten im Runbook, z.B. 'RB-Arch-Flag-02' für Feature-Flag-relevante Architekturentscheidungen."}
{"ts": "163:27", "speaker": "I", "text": "Blicken Sie voraus: Welche Risiken sehen Sie, wenn Sie nach der Pilotphase skalieren wollen?"}
{"ts": "163:32", "speaker": "E", "text": "Hauptsächlich zwei: Erstens, dass unser aktueller Feature-Flag-Dienst bei einer 5-fachen Nutzerzahl an Performancegrenzen stößt, siehe Lasttest-Report 'LT-FF-2024-03'. Zweitens, dass Offline-Datenkonflikte exponentiell zunehmen, wenn mehr gleichzeitige Syncs stattfinden."}
{"ts": "163:39", "speaker": "I", "text": "Wie planen Sie, diese Risiken evidenzbasiert zu adressieren?"}
{"ts": "163:44", "speaker": "E", "text": "Wir haben eine Roadmap mit drei Meilensteinen: Migration des Feature-Flag-Dienstes in eine skalierbare Kubernetes-Umgebung (siehe RFC-2024-FF-Scale), Implementierung eines Conflict-Resolution-Algorithmus nach Runbook 'RB-Sync-Resolve-03', und eine gestaffelte Nutzeraufnahme, die in den Tickets #P-ATL-200ff dokumentiert ist."}
{"ts": "164:48", "speaker": "I", "text": "Lassen Sie uns nochmal konkret auf die Lessons Learned aus der Pilotphase eingehen – was würden Sie rückblickend sofort wieder so machen?"}
{"ts": "164:52", "speaker": "E", "text": "Hm, ja… also, die Entscheidung, Feature Flags schon früh in der Architektur zu verankern, war goldrichtig. Wir konnten dadurch im Runbook RB-ATL-FF-03 klar definierte Rollback-Pfade dokumentieren und im Ticket T-1821 nachweisen, dass wir in unter 15 Minuten auf eine stabile Version zurückkehren konnten."}
{"ts": "164:58", "speaker": "I", "text": "Gab es dabei unerwartete Nebeneffekte, die Sie im Vorfeld nicht auf dem Radar hatten?"}
{"ts": "165:02", "speaker": "E", "text": "Ja, tatsächlich. Wir haben unterschätzt, wie stark die Feature-Flag-Auswertung die Offline-Sync-Logik beeinflusst, gerade bei inkonsistenten Netzwerken. Das führte zu zwei P1-Incidents, dokumentiert in INC-ATL-220 und 221, die wir dann mit einer zusätzlichen Cache-Ebene in der Sync-Pipeline gelöst haben."}
{"ts": "165:10", "speaker": "I", "text": "Wie hat sich diese Anpassung auf Ihre Time-to-Market ausgewirkt?"}
{"ts": "165:14", "speaker": "E", "text": "Minimal, weil wir parallel gearbeitet haben. Das DevOps-Team hatte schon in einem Proof-of-Concept aus dem Helios Datalake-Projekt eine ähnliche Cache-Implementierung getestet. Wir konnten den Code beinahe 1:1 übernehmen."}
{"ts": "165:20", "speaker": "I", "text": "Spannend. Und welche Rolle spielte das UX-Team bei der Priorisierung dieser Fixes?"}
{"ts": "165:24", "speaker": "E", "text": "Eine sehr große Rolle. Die UX-Analysen aus Sprint 7 haben gezeigt, dass Nutzer:innen Offline-Funktionen als kritisch einstufen. Das hat uns geholfen, gegenüber dem Steering Committee den Hotfix als SLA-relevant zu argumentieren."}
{"ts": "165:30", "speaker": "I", "text": "Gab es konkrete Kennzahlen, die Sie dem Steering Committee vorgelegt haben?"}
{"ts": "165:34", "speaker": "E", "text": "Ja, wir haben aus dem Observability-Dashboard die Metrik 'Offline Task Completion Rate' gezeigt – die war nach dem Fix von 62 % auf 91 % gestiegen. Das ist auch im Report REP-ATL-Q2 dokumentiert."}
{"ts": "165:40", "speaker": "I", "text": "Wie planen Sie, diese Verbesserungen nachhaltig zu sichern?"}
{"ts": "165:44", "speaker": "E", "text": "Wir haben im Runbook RB-ATL-SYNC-05 einen wöchentlichen Testplan verankert, der sowohl unter 3G- als auch unter simulierten Edge-Bedingungen die Sync-Stabilität überprüft. Zusätzlich fließen die Testergebnisse automatisiert ins SLA-Review ein."}
{"ts": "165:50", "speaker": "I", "text": "Klingt sehr strukturiert. Gibt es dennoch Risiken, die Sie für die nächsten Monate als kritisch einstufen?"}
{"ts": "165:54", "speaker": "E", "text": "Ja, vor allem das Zusammenspiel von IAM-Token-Refresh und Offline-Modus. Wenn ein Token während einer Offline-Phase abläuft, können Datensätze beim Re-Sync abgewiesen werden. Wir haben dazu ein RFC-Dokument RFC-ATL-12 in Arbeit, um einen Grace-Period-Mechanismus einzuführen."}
{"ts": "166:00", "speaker": "I", "text": "Wie können wir als UX-Team Sie bei diesem Thema konkret unterstützen?"}
{"ts": "166:04", "speaker": "E", "text": "Indem ihr in den nächsten Feldtests gezielt Szenarien einbaut, bei denen Nutzer:innen während langer Offline-Phasen arbeiten. Euer Feedback zu Fehlermeldungen oder Workarounds würde uns helfen, die Grace-Period so zu gestalten, dass sie verständlich und akzeptabel ist."}
{"ts": "166:24", "speaker": "I", "text": "Wir waren gerade bei den möglichen Risiken – könnten Sie vielleicht etwas genauer auf die Abhängigkeit zwischen dem Offline Sync und den Feature Flags eingehen?"}
{"ts": "166:32", "speaker": "E", "text": "Ja, gern. Der Offline Sync nutzt einen eigenen Synchronisations-Queue, der in unserem Runbook RB-ATL-034 dokumentiert ist. Wenn wir per Feature Flag ein Modul deaktivieren, muss dieser Queue auch seine Tasks anpassen, sonst riskieren wir Inkonsistenzen."}
{"ts": "166:46", "speaker": "I", "text": "Verstehe. Und wie testen Sie solche Szenarien im Piloten?"}
{"ts": "166:51", "speaker": "E", "text": "Wir fahren vor jedem Feature-Flag-Change einen Dry-Run auf der Staging-Umgebung, mit simulierten Netzwerkausfällen. Das ist in Ticket QA-2215 erfasst, inklusive Testprotokollen für drei Mobilplattformen."}
{"ts": "167:06", "speaker": "I", "text": "Klingt nach hohem Testaufwand. Haben Sie da automatisierte Unterstützung?"}
{"ts": "167:11", "speaker": "E", "text": "Teilweise. Wir haben in unserem CI/CD eine Pipeline, die mit Helios Datalake Mock-Daten generiert. Aber die Offline-Aspekte müssen wir noch manuell prüfen, besonders bei Konfliktauflösung."}
{"ts": "167:25", "speaker": "I", "text": "Wie spielt das IAM-System hier mit rein?"}
{"ts": "167:30", "speaker": "E", "text": "Das IAM liefert Tokens, die auch offline gecached werden. Wenn ein Feature per Flag gesperrt wird, muss der Cache invalidiert werden. Das ist in RFC-ATL-12 beschrieben, dort haben wir auch Edge Cases wie Token-Expiry im Flug behandelt."}
{"ts": "167:46", "speaker": "I", "text": "Gab es schon mal einen Vorfall, bei dem diese Invalidierung nicht funktioniert hat?"}
{"ts": "167:51", "speaker": "E", "text": "Einmal, ja. Incident-Report INC-ATL-77 dokumentiert, dass in Version 0.9.2 ein Token noch 48h gültig war und so ein deaktiviertes Feature weiter lief. Wir haben daraus eine zusätzliche Unit-Test-Suite abgeleitet."}
{"ts": "168:08", "speaker": "I", "text": "Welche Lessons Learned ziehen Sie daraus für die nächste Projektphase?"}
{"ts": "168:14", "speaker": "E", "text": "Vor allem, dass wir Feature Flag Changes wie einen kleinen Release behandeln müssen, mit vollständiger Regression. Das kostet Zeit, verkürzt aber später die MTTR und hält unsere SLA von 99,5% stabil."}
{"ts": "168:28", "speaker": "I", "text": "Und wie wirken sich diese zusätzlichen Prüfungen auf die Time-to-Market aus?"}
{"ts": "168:33", "speaker": "E", "text": "Kurzfristig verzögern sie um ein bis zwei Tage. Langfristig verhindern sie Hotfix-Marathons, die oft Wochen kosten. In unserer Risikoanalyse RSK-ATL-05 haben wir das gegenübergestellt."}
{"ts": "168:46", "speaker": "I", "text": "Gibt es schon Entscheidungen, wie Sie mit diesen Erkenntnissen in die Skalierung gehen?"}
{"ts": "168:51", "speaker": "E", "text": "Ja, wir wollen ein zentrales Feature-Flag-Dashboard einführen, das direkt mit dem Sync-Queue und dem IAM-Caching spricht. Das ist als Meilenstein M2 im Skalierungsplan vermerkt, mit Go/No-Go-Entscheidung nach dem Pilotreview."}
{"ts": "174:24", "speaker": "I", "text": "Zum Abschluss würde mich interessieren: welche konkreten UX-Themen haben sich aus Ihrer Sicht in den letzten Sprint-Retros als besonders kritisch herausgestellt?"}
{"ts": "174:38", "speaker": "E", "text": "Also, da gab es vor allem das Thema Latenz bei der Offline-Synchronisation – Nutzer haben berichtet, dass sie nach dem Wiederverbinden manchmal bis zu 12 Sekunden warten mussten, bis Änderungen sichtbar waren. Das ist zwar technisch erklärbar, weil wir laut Runbook-Abschnitt 4.3 erst einen Integritätscheck fahren, aber aus UX-Perspektive eben nicht ideal."}
{"ts": "174:58", "speaker": "I", "text": "Verstehe. Haben Sie schon überlegt, diesen Integritätscheck zu optimieren oder vielleicht asynchron zu gestalten?"}
{"ts": "175:10", "speaker": "E", "text": "Ja, wir haben dazu ein Ticket im System – ID ATLMOB-542 – das prüft, ob wir den Hash-Check im Hintergrund starten können. Das würde aber bedeuten, dass wir temporär inkonsistente Daten anzeigen könnten, was wieder ein Risiko wäre."}
{"ts": "175:29", "speaker": "I", "text": "Das klingt nach einem klassischen Trade-off zwischen Geschwindigkeit und Datenintegrität. Wie würden Sie da priorisieren?"}
{"ts": "175:44", "speaker": "E", "text": "Genau, und wir tendieren aktuell dazu, im Piloten eher die Integrität zu priorisieren. Bei einem späteren Rollout könnten wir dann abhängig von der SLA-Klasse der Nutzergruppe differenzieren."}
{"ts": "176:02", "speaker": "I", "text": "Interessant. Gab es aus der Nutzerforschung noch weitere Punkte, die Einfluss auf die Roadmap hatten?"}
{"ts": "176:15", "speaker": "E", "text": "Ja, wir haben z.B. festgestellt, dass die adaptive Navigation, die wir als Feature Flag eingeführt haben, bei 30% der Testnutzer zu Verwirrung geführt hat. Das kam über unser Feedback-Formular im Atlas Mobile Testflight-Kanal direkt rein."}
{"ts": "176:33", "speaker": "I", "text": "Und wie reagieren Sie darauf? Wird das Feature zurückgerollt oder angepasst?"}
{"ts": "176:45", "speaker": "E", "text": "Wir haben ein Phased Rollback vorbereitet, dokumentiert in Runbook ATLMOB-FLG-2. Dort ist beschrieben, wie wir die Flag serverseitig deaktivieren, ohne die App-Version zu ändern."}
{"ts": "177:04", "speaker": "I", "text": "Das klingt sehr kontrolliert. Gibt es Lessons Learned aus diesem Flag-Experiment?"}
{"ts": "177:16", "speaker": "E", "text": "Definitiv: wir sollten Feature Flags mit klaren Erfolgskriterien launchen. In diesem Fall hatten wir keine quantitativen Metriken definiert, nur qualitative Rückmeldungen. Das hat die Entscheidung erschwert."}
{"ts": "177:35", "speaker": "I", "text": "Könnte das UX-Team Sie in der Metrik-Definition künftig unterstützen?"}
{"ts": "177:47", "speaker": "E", "text": "Sehr gerne. Wenn UX schon vor dem Go-Live die Key-Metriken wie Task Completion Time oder Error Rate definiert, können wir die in unser Observability-Backend einklinken."}
{"ts": "178:03", "speaker": "I", "text": "Letzte Frage: Welche nächsten Schritte sehen Sie unmittelbar nach Ende des Piloten?"}
{"ts": "178:14", "speaker": "E", "text": "Wir planen ein Scale-out auf 500 interne Nutzer, parallel die Integration mit dem IAM-Projekt Aurelius v2. Dafür gibt es bereits ein RFC-Dokument RFC-AUR-77, das die Schnittstellen beschreibt und auch die Lessons Learned aus dem Piloten berücksichtigt."}
{"ts": "182:24", "speaker": "I", "text": "Welche UX-Themen sollten wir Ihrer Meinung nach nach der Pilotphase ganz oben auf die Agenda setzen?"}
{"ts": "182:36", "speaker": "E", "text": "Also ganz klar die Offline-Nutzerführung. Wir haben im Ticket MOB-412 einige Beschwerden protokolliert, dass die Nutzer nicht wissen, ob ihre Änderungen lokal gespeichert wurden. Das muss visuell und akustisch eindeutiger werden."}
{"ts": "182:58", "speaker": "I", "text": "Verstehe. Wäre das eher ein Design- oder ein technisches Thema aus Ihrer Sicht?"}
{"ts": "183:07", "speaker": "E", "text": "Eine Mischung. Design muss klare Signale definieren, aber die technische Schicht muss diese Events auslösen, sobald der Sync-Daemon einen Commit in die lokale Queue schreibt. Das ist in Runbook RB-ATL-05 beschrieben."}
{"ts": "183:29", "speaker": "I", "text": "Gab es Lessons Learned aus der Integration mit dem Helios Datalake, die hier helfen könnten?"}
{"ts": "183:41", "speaker": "E", "text": "Ja, wir haben dort gelernt, dass Event-IDs konsistent über Services hinweg sein müssen. Im Atlas Mobile Kontext bedeutet das, dass Offline-Events dieselben IDs verwenden wie später im Cloud-Sync, um Dubletten zu vermeiden."}
{"ts": "184:02", "speaker": "I", "text": "Wie sehen Sie die Rolle des IAM-Systems bei der Weiterentwicklung der UX?"}
{"ts": "184:14", "speaker": "E", "text": "Das IAM liefert uns kontextbezogene Rolleninformationen. Wenn wir wissen, dass ein User z.B. Admin ist, können wir ihm im Offline-Modus mehr Debug-Infos anzeigen. Das ist eine kleine, aber effektive UX-Verbesserung."}
{"ts": "184:36", "speaker": "I", "text": "Gibt es aus der Pilotphase Sicherheiten, die Sie als Entscheidungsgrundlage nutzen?"}
{"ts": "184:47", "speaker": "E", "text": "Ja, wir haben KPI-Reports aus SLA-Monitoring, die zeigen, dass 92% der Syncs unter 3 Sekunden bleiben. Das gibt uns das Vertrauen, visuelles Feedback eng an den technischen Status zu koppeln."}
{"ts": "185:09", "speaker": "I", "text": "Wie können wir als UX-Team Sie in den kommenden Monaten am besten unterstützen?"}
{"ts": "185:18", "speaker": "E", "text": "Indem ihr frühzeitig Prototypen erstellt, die wir gegen unsere Test-API fahren lassen. So können wir im Staging sehen, ob die Signale und Interaktionen auch unter simulierten Netzwerkausfällen funktionieren."}
{"ts": "185:39", "speaker": "I", "text": "Also ein engeres Testing-Feedback-Loop zwischen UX und DevOps?"}
{"ts": "185:47", "speaker": "E", "text": "Genau. In der Pilotphase hat sich gezeigt, dass wöchentliche Sync-Meetings mit Live-Demos in der Staging-Umgebung Probleme früh sichtbar machen. Das sollten wir institutionalize."}
{"ts": "186:08", "speaker": "I", "text": "Möchten Sie noch ein konkretes Risiko nennen, das wir im Auge behalten sollten?"}
{"ts": "186:18", "speaker": "E", "text": "Ja, das Risiko eines inkonsistenten Feature-Flag-Status zwischen Clients und Server. Wir hatten in MOB-427 einen Fall, wo ein Feature serverseitig deaktiviert wurde, der Client aber offline war und es weiter anbot. Hier brauchen wir einen Fallback-Mechanismus, wie in RFC-ATL-FF-07 vorgeschlagen."}
{"ts": "190:24", "speaker": "I", "text": "Lassen Sie uns nochmal auf die IAM-Anbindung eingehen – gab es da in den letzten Wochen neue Erkenntnisse oder Probleme?"}
{"ts": "190:33", "speaker": "E", "text": "Ja, tatsächlich. Wir haben im Ticket OPS-4321 dokumentiert, dass die Token-Refresh-Logik in der mobilen App nicht sauber mit dem zentralen Identity-Broker harmoniert hat. Das lag an einem kleinen Unterschied in der OAuth-Implementierung zwischen Atlas Mobile und dem bestehenden CRM-Portal."}
{"ts": "190:47", "speaker": "I", "text": "Und wie sind Sie da vorgegangen, um das zu lösen?"}
{"ts": "190:52", "speaker": "E", "text": "Wir haben gemäß Runbook IAM-RB-07 einen temporären Workaround implementiert, der die Session-Lifetime clientseitig auf 55 Minuten begrenzt. Parallel dazu haben wir ein RFC-Dokument aufgesetzt, um die Broker-Implementierung zu harmonisieren."}
{"ts": "191:08", "speaker": "I", "text": "Gab es Auswirkungen auf die Pilot-Nutzer?"}
{"ts": "191:12", "speaker": "E", "text": "Minimal – etwa 3 % der Nutzer mussten sich einmal zusätzlich einloggen. Das lag noch im vereinbarten SLA-Rahmen von maximal 5 % Session-Abbrüchen pro Testmonat."}
{"ts": "191:24", "speaker": "I", "text": "Wie hängt das mit der Offline-Sync-Architektur zusammen?"}
{"ts": "191:29", "speaker": "E", "text": "Das ist der Multi-Hop, den wir intern immer betonen: Wenn das IAM-Token ausläuft und der Nutzer offline ist, dürfen wir keine inkonsistenten Sync-States erzeugen. Deshalb haben wir eine Logik, die Pending Writes lokal puffert, bis das Token erneuert wurde. Diese Logik greift auch, wenn der Datalake-Connector in Helios gerade im Maintenance Mode ist."}
