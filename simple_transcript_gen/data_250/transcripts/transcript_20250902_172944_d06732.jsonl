{"ts": "00:00", "speaker": "I", "text": "Können Sie bitte kurz Ihre Rolle im Hera QA Platform Projekt beschreiben, gerade jetzt in der Build-Phase?"}
{"ts": "01:15", "speaker": "E", "text": "Klar, ich bin als QA Lead verantwortlich für die gesamte Teststrategie und -durchführung innerhalb von Projekt P-HER. In der Build-Phase bedeutet das, dass ich sowohl die Testorchestrierung als auch die Einführung von flaky test analytics koordiniere. Core fact: Wir sind aktuell bei Sprint 5 von 8, die ersten End-to-End-Szenarien werden gerade integriert."}
{"ts": "05:40", "speaker": "I", "text": "Welche Hauptverantwortlichkeiten haben Sie dabei und wie ist Ihr Team aufgestellt?"}
{"ts": "07:05", "speaker": "E", "text": "Mein Team besteht aus 4 Automation Engineers, 2 manuellen Testern und einer Person für Testdatenmanagement. Wir interagieren eng mit DevOps, weil die Hera QA Platform stark in unsere CI/CD-Pipelines eingebettet ist. Ich definiere Testpläne, prüfe deren Abdeckung gegen die Anforderungen aus dem Confluence-Backlog und verantworte die Umsetzung der Policy POL-QA-014."}
{"ts": "12:20", "speaker": "I", "text": "Wie setzen Sie den risikobasierten Testansatz konkret um?"}
{"ts": "14:10", "speaker": "E", "text": "Wir klassifizieren jede User Story nach Business Impact und technischer Komplexität. Die Matrix aus Runbook RB-QA-07 gibt uns Gewichtungen: Hoch/Hoch bedeutet Priorität 1 Testing mit tiefer Explorationsphase, Niedrig/Niedrig wird oft nur über Smoke Tests abgedeckt."}
{"ts": "19:45", "speaker": "I", "text": "Können Sie ein Beispiel geben, wie Sie Testfälle nach Risiko priorisieren?"}
{"ts": "21:05", "speaker": "E", "text": "Beim neuen Modul für Testdaten-Sharding hatten wir Schnittstellen zu Orion Edge Gateway. Da ein Ausfall hier sowohl Latenz als auch Datenverlust verursachen könnte, haben wir diese Tests direkt in den Nightly-Block verschoben und sie dreifach redundant in Jenkins ausgeführt."}
{"ts": "28:30", "speaker": "I", "text": "Welche Testorchestrierungs-Tools nutzen Sie aktuell?"}
{"ts": "30:00", "speaker": "E", "text": "Wir setzen Testrail für Testfallmanagement ein, orchestrieren die Läufe aber über unser internes Tool 'HeraRunner', das via YAML-Suites die Sequenz und Parallelität steuert. Für flaky test analytics binden wir 'FlakeWatch' an, das Fehlerhistorien auswertet und Instabilitätsquellen markiert."}
{"ts": "38:15", "speaker": "I", "text": "Gibt es Abhängigkeiten zu Observability-Daten aus Nimbus?"}
{"ts": "40:50", "speaker": "E", "text": "Ja, stark sogar. Wir nutzen die Traces und Metriken aus Nimbus, um Performance-Regressionen in unseren API-Tests zu erkennen. Beispiel: Ticket QA-334 zeigte, dass ein Timeout-Pattern aus dem Nimbus-Log direkt auf eine fehlerhafte Retry-Logik in der Hera QA Platform hinwies."}
{"ts": "48:20", "speaker": "I", "text": "Können Sie ein Szenario beschreiben, in dem mehrere Subsysteme gleichzeitig getestet werden mussten?"}
{"ts": "51:00", "speaker": "E", "text": "Während des Integrations-Sprints 3 haben wir Hera QA Platform, Nimbus Observability und Orion Edge Gateway in einer kombinierten Staging-Umgebung gefahren. Die Herausforderung war, dass API-Änderungen aus Orion Edge Gateway sofort in unsere Test-Suites reflektiert werden mussten, inklusive neuer Metriken aus Nimbus, um Fehlerbilder nachzuvollziehen. Das war ein klassischer multi-hop Testfall: Änderungserkennung -> Anpassung Tests -> Validierung über Observability."}
{"ts": "85:10", "speaker": "I", "text": "Gab es eine Entscheidung, bei der Sie zwischen Testabdeckung und Liefergeschwindigkeit abwägen mussten?"}
{"ts": "90:00", "speaker": "E", "text": "Ja, im Release Candidate 1. Wir mussten laut SLA-QA-05 in 48h liefern. Laut Runbook RB-QA-12 hätten wir eigentlich noch 32 Low-Risk-Cases laufen lassen müssen. Wir haben mit Evidenz aus Ticket QA-402 und aus FlakeWatch-Statistiken entschieden, diese zu verschieben, um den Liefertermin einzuhalten, und die Abdeckung in einem Post-Release Patch zu ergänzen."}
{"ts": "90:00", "speaker": "I", "text": "Könnten Sie bitte noch etwas genauer auf die spezifischen Qualitätsmetriken eingehen, die Sie im aktuellen Sprint verfolgen?"}
{"ts": "90:15", "speaker": "E", "text": "Ja, wir haben im Sprint 42 drei Kernmetriken: Defect Leakage Rate, automatisierte Testabdeckung und Mean Time to Detect. Letztere haben wir mit den Event-Logs aus Nimbus verknüpft, um schneller auf Anomalien zu reagieren."}
{"ts": "90:38", "speaker": "I", "text": "Und wie fließen diese Metriken in Ihre Sprintplanung ein?"}
{"ts": "90:49", "speaker": "E", "text": "Wenn z.B. die Defect Leakage Rate über 2,5 % liegt, setzen wir laut Runbook QA-OPS-07 einen zusätzlichen Regressionstest-Zyklus an. Das hat direkte Auswirkungen auf die Story Points, die wir für neue Features einplanen können."}
{"ts": "91:10", "speaker": "I", "text": "Haben Sie ein Beispiel, wo eine Metrik zu einer Anpassung der Teststrategie geführt hat?"}
{"ts": "91:22", "speaker": "E", "text": "Ja, im letzten Monat stieg die MTTR um 18 %. Wir haben daraufhin einen RFC-gestützten Prozess gestartet, RFC-QA-221, um Fehlertriage-Skripte zu optimieren und die Log-Parsing-Regeln zu verbessern."}
{"ts": "91:46", "speaker": "I", "text": "Wie dokumentieren Sie diese Änderungen und stellen sicher, dass das ganze Team informiert ist?"}
{"ts": "91:56", "speaker": "E", "text": "Wir nutzen das interne Confluence-Wiki, jede Änderung bekommt eine eigene Change-Page mit Link zum zugrundeliegenden Jira-Ticket, z.B. QA-4582 für die MTTR-Optimierung."}
{"ts": "92:15", "speaker": "I", "text": "Gab es in letzter Zeit Situationen, in denen Sie bewusst von einer Policy abgewichen sind?"}
{"ts": "92:27", "speaker": "E", "text": "Ja, bei einem Hotfix für das Orion Edge Gateway haben wir POL-QA-014 temporär ausgesetzt, um innerhalb von 4 Stunden liefern zu können. Die Risikoanalyse wurde nachträglich dokumentiert unter QA-RISK-77."}
{"ts": "92:50", "speaker": "I", "text": "War das mit allen Stakeholdern abgestimmt?"}
{"ts": "93:00", "speaker": "E", "text": "Ja, wir haben ein Ad-hoc-Meeting mit Engineering und Product einberufen. Entscheidung wurde per E-Mail-Thread mit Betreff 'Deviation Approval – Orion HF' bestätigt."}
{"ts": "93:18", "speaker": "I", "text": "Welche Risiken sind Ihnen dabei am meisten im Kopf geblieben?"}
{"ts": "93:29", "speaker": "E", "text": "Vor allem, dass wir ohne vollständige Regression Tests deployen. Aber wir hatten durch Nimbus Telemetrie die Möglichkeit, die Auswirkung in Echtzeit zu überwachen und bei Bedarf sofort zu rollen."}
{"ts": "93:48", "speaker": "I", "text": "Würden Sie diesen Trade-off in Zukunft wieder eingehen?"}
{"ts": "94:00", "speaker": "E", "text": "Nur wenn die geschäftskritische Priorität ähnlich hoch ist und wir die Observability-Checks wie in Runbook OB-NIM-03 parallel laufen lassen können. Sonst lieber vollständige Testabdeckung."}
{"ts": "98:00", "speaker": "I", "text": "Lassen Sie uns nochmal auf die Qualitätsmetriken zurückkommen – welche KPIs verfolgen Sie im Moment am intensivsten?"}
{"ts": "98:05", "speaker": "E", "text": "Aktuell sind das vor allem Defect Escape Rate, also wie viele Defekte nach der Auslieferung noch gefunden werden, und die Testausführungszeit pro Build. Die Defect Escape Rate muss laut SLA-QA-03 unter 2 % bleiben."}
{"ts": "98:18", "speaker": "I", "text": "Und wie messen Sie diese in der Praxis, gibt es da automatisierte Reports?"}
{"ts": "98:23", "speaker": "E", "text": "Ja, wir haben ein Dashboard in unserem internen Tool HeraMetrics. Das zieht automatisch Daten aus Jira-Tickets vom Typ BUG und aus den Testlaufprotokollen der Orchestrierung. Reports laufen täglich um 02:00 Uhr, ganz automatisch."}
{"ts": "98:39", "speaker": "I", "text": "Gab es zuletzt einen Fall, in dem diese Metriken zu einer Anpassung der Teststrategie geführt haben?"}
{"ts": "98:44", "speaker": "E", "text": "Ja, im Ticket QA-4112 haben wir bemerkt, dass die Escape Rate in der Beta-Phase 3,4 % betrug. Wir haben daraufhin in Absprache mit DEV zwei zusätzliche Risikokategorien in die Testfallmatrix aufgenommen, Runbook RB-QA-015 hat den Prozess dokumentiert."}
{"ts": "98:59", "speaker": "I", "text": "Interessant. Wie war die Reaktion des Entwicklungsteams auf diese kurzfristige Erweiterung?"}
{"ts": "99:04", "speaker": "E", "text": "Gemischt – ein Teil war froh über die präzisere Abdeckung, andere hatten Bedenken wegen der verlängerten Build-Zyklen. Wir haben dann in einem RFC-Papier RFC-QA-07 festgelegt, dass diese zusätzlichen Tests nur in Nightly Builds laufen, um den Tagesfluss nicht zu stören."}
{"ts": "99:22", "speaker": "I", "text": "Können Sie beschreiben, wie Sie Risiken dokumentieren, wenn Sie von einer Policy abweichen?"}
{"ts": "99:27", "speaker": "E", "text": "Das läuft über unser QA-Risk-Register. Wir legen dort eine Risk-ID an, z.B. RSK-208, verlinken zu den relevanten Jira-Issues und legen im Runbook fest, welche temporären Maßnahmen gelten. In diesem Fall haben wir eine Abweichung von POL-QA-014 vermerkt."}
{"ts": "99:45", "speaker": "I", "text": "Wie stellen Sie sicher, dass solche temporären Maßnahmen nicht dauerhaft bestehen bleiben?"}
{"ts": "99:50", "speaker": "E", "text": "Wir setzen Review-Reminder in Confluence, meist 4 Wochen nach Einführung. Außerdem prüft das QA-Gremium bei jedem Sprint-Review die offenen Risiken. Wenn die Metriken wieder im grünen Bereich sind, wird die Maßnahme zurückgenommen."}
{"ts": "100:05", "speaker": "I", "text": "Noch eine Frage zu den SLAs: Wie fließen die genau in Ihre Testplanung ein?"}
{"ts": "100:10", "speaker": "E", "text": "Wir mappen jede SLA-Anforderung auf mindestens einen Testfall in unserer Traceability-Matrix. Für Geschwindigkeitsszenarien gilt SLA-QA-05, da darf die Antwortzeit der API nicht über 500 ms liegen. Das wird in Performance-Tests vor jedem Release geprüft."}
{"ts": "100:25", "speaker": "I", "text": "Gab es schon mal, äh, eine bewusste Entscheidung, eine SLA-Prüfung zu verschieben?"}
{"ts": "100:30", "speaker": "E", "text": "Ja, bei Release 1.8 haben wir den Performance-Test um 48 Stunden verschoben, weil ein kritischer Fix aus dem Orion Edge Gateway noch ausstand. Die Entscheidung haben wir in Ticket RELNOTE-18 dokumentiert, mit Risiko-Analyse in RSK-301."}
{"ts": "102:00", "speaker": "I", "text": "Könnten Sie bitte näher erläutern, wie Sie die SLA-Anforderungen konkret in Ihre Testpläne einarbeiten?"}
{"ts": "102:12", "speaker": "E", "text": "Ja, wir nehmen die SLA-Ziele aus dem Dokument SLA-HER-2024-02 und mappen sie direkt auf unsere Test-Suites. Beispielsweise bedeutet ein Response-Zeit-Ziel von 200ms, dass wir in den Performance-Tests einen Threshold von 180ms setzen, um Puffer zu haben."}
{"ts": "102:36", "speaker": "I", "text": "Verwenden Sie dafür bestimmte Tools oder eher manuelle Überprüfungsschritte?"}
{"ts": "102:45", "speaker": "E", "text": "Wir nutzen eine Kombination. Die Thresholds werden in Gatling-Skripten automatisiert hinterlegt, zusätzlich prüfen wir in den wöchentlichen QA-Reviews manuell ausgewählte Runs gegen die SLA-Tabelle."}
{"ts": "103:05", "speaker": "I", "text": "Gab es schon Fälle, in denen diese automatisierten Checks einen drohenden SLA-Bruch früh erkannt haben?"}
{"ts": "103:15", "speaker": "E", "text": "Ja, im März hatten wir einen Anstieg der Latenz bei einer Orion Edge Gateway API. Das Alerting aus der Gatling-Pipeline hat uns 48 Stunden vor dem geplanten Release gewarnt, wir konnten mit dem Dev-Team einen Hotfix einplanen."}
{"ts": "103:40", "speaker": "I", "text": "Wie dokumentieren Sie solche Vorfälle?"}
{"ts": "103:48", "speaker": "E", "text": "Wir legen ein Incident-Ticket im JIRA-Projekt HER-QA an, verlinken die betroffenen Test-Runs und die Auszüge aus dem SLA-Dokument, und ergänzen Lessons Learned im Runbook RB-HER-Perf-02."}
{"ts": "104:10", "speaker": "I", "text": "Und wie fließen diese Lessons Learned wieder zurück in die Strategie?"}
{"ts": "104:18", "speaker": "E", "text": "Die Lessons werden in der vierteljährlichen QA-Strategie-Review-Session diskutiert, oft passen wir danach die Priorisierung im risikobasierten Testplan an, z.B. höhere Gewichtung für kritische API-Endpunkte."}
{"ts": "104:40", "speaker": "I", "text": "Beeinflusst das auch Ihre Zusammenarbeit mit dem Nimbus-Team?"}
{"ts": "104:48", "speaker": "E", "text": "Ja, weil die Observability-Daten von Nimbus helfen, reale Nutzungsmuster zu erkennen. Wir können so z.B. sehen, welche Endpunkte am meisten Traffic haben und diese im Performance-Test stärker fokussieren."}
{"ts": "105:10", "speaker": "I", "text": "Gibt es ein Beispiel, wo diese Daten Ihre Testplanung direkt verändert haben?"}
{"ts": "105:20", "speaker": "E", "text": "Im letzten Release zeigte Nimbus, dass ein neuer Filter-Endpunkt in der Orion API plötzlich 40% aller Requests ausmachte. Wir haben ad hoc einen neuen Test-Case gebaut und in die Regression aufgenommen, obwohl er nicht im ursprünglichen Plan stand."}
{"ts": "105:45", "speaker": "I", "text": "Wie stellen Sie sicher, dass solche Ad-hoc-Tests nicht die geplanten Abnahmen verzögern?"}
{"ts": "105:55", "speaker": "E", "text": "Wir haben im Runbook RB-HER-Plan-03 ein Verfahren für Express-Tests definiert: Diese laufen in einer separaten Jenkins-Queue, sodass sie nicht den kritischen Pfad blockieren, und Ergebnisse werden in einem separaten Tab im QA-Dashboard angezeigt."}
{"ts": "110:00", "speaker": "I", "text": "Sie hatten vorhin den risikobasierten Ansatz erwähnt – könnten Sie erläutern, wie Sie diesen im letzten Sprint konkret angewandt haben?"}
{"ts": "110:06", "speaker": "E", "text": "Ja, im letzten Sprint haben wir die POL-QA-014 Richtlinie mit einem Fokus auf die kritischen Payment-Flows aus dem Hera-Kernmodul angewandt. Wir haben dafür eine Risikomatrix aus dem Runbook RB-QA-07 gezogen, die die Eintrittswahrscheinlichkeit und Auswirkung jeder Anforderung bewertet."}
{"ts": "110:18", "speaker": "I", "text": "Gab es dabei Defects, die außerhalb der erwarteten Risikokategorie aufgetreten sind?"}
{"ts": "110:24", "speaker": "E", "text": "Tatsächlich ja, ein API-Timeout beim Orion Edge Gateway, der laut Risiko-Score nur Medium war, hat in Kombination mit einem Nimbus Observability Alarm eine kritische User Journey blockiert. Das war ein gutes Beispiel für emergente Risiken."}
{"ts": "110:38", "speaker": "I", "text": "Wie sind Sie mit so einer Abweichung umgegangen?"}
{"ts": "110:44", "speaker": "E", "text": "Wir haben ad hoc eine Eskalation im Ticket QA-INC-4523 gemacht und das Runbook ergänzt, um bei Medium-Risiken mit hoher Benutzerfrequenz zusätzliche Canary-Tests einzuplanen."}
{"ts": "110:56", "speaker": "I", "text": "Und diese Canary-Tests – laufen die vollautomatisch durch Ihre Orchestrierung?"}
{"ts": "111:02", "speaker": "E", "text": "Genau, wir haben sie in den Hera Orchestrator integriert, sodass bei bestimmten Observability-Events automatisch ein Regression-Subset getriggert wird. Das minimiert die Mean Time To Detect."}
{"ts": "111:14", "speaker": "I", "text": "Wie fließen diese Ergebnisse in Ihre Qualitätsmetriken ein?"}
{"ts": "111:20", "speaker": "E", "text": "Wir erfassen sie als 'Reactive Test Coverage' KPI in unserem QA-Dashboard. Das ist ein Zusatz zu den klassischen Defect-Detection-Rates und wird in den wöchentlichen QA-Reports für die SLA-Review-Meetings ausgewertet."}
{"ts": "111:34", "speaker": "I", "text": "Gab es jüngst einen SLA-Breach, der zu Anpassungen geführt hat?"}
{"ts": "111:40", "speaker": "E", "text": "Vor zwei Wochen haben wir die Response-Zeit-SLOs um 5% verfehlt, hauptsächlich durch einen Burst von flaky Tests, die den Pipeline-Durchsatz blockiert haben. Daraufhin haben wir laut RFC-QA-022 einen neuen Stabilitäts-Check eingeführt."}
{"ts": "111:54", "speaker": "I", "text": "War das ein schwieriger Trade-off in Bezug auf Liefergeschwindigkeit?"}
{"ts": "112:00", "speaker": "E", "text": "Absolut, wir mussten eine geplante Deployment-Welle um 48 Stunden verschieben. Das war bewusst in Kauf genommen, um die Teststabilität auf den geforderten SLA-Level zu bringen."}
{"ts": "112:12", "speaker": "I", "text": "Wie dokumentieren Sie solche Entscheidungen?"}
{"ts": "112:18", "speaker": "E", "text": "Wir pflegen dafür ein Confluence-Log 'Critical QA Decisions', verlinkt mit den entsprechenden Jira-Tickets und Runbook-Änderungen, um die Nachvollziehbarkeit für Audits sicherzustellen."}
{"ts": "116:00", "speaker": "I", "text": "Sie hatten vorhin erwähnt, dass Sie bei einem Release weniger Abdeckung akzeptiert haben, um den Liefertermin zu halten. Können Sie mir bitte genauer schildern, wie Sie das dokumentiert haben?"}
{"ts": "116:10", "speaker": "E", "text": "Ja, klar. Wir haben das im Runbook RB-QA-221 festgehalten. Dort gibt es eine Rubrik 'Abdeckungsabweichung', in der wir sowohl die geplante Coverage als auch die tatsächlich erreichte in Prozent dokumentieren, zusammen mit einem Verweis auf das JIRA-Ticket QA-DEV-4521, das die Entscheidungshistorie enthält."}
{"ts": "116:24", "speaker": "I", "text": "Und wie wurde diese Abweichung gegenüber den Stakeholdern kommuniziert?"}
{"ts": "116:32", "speaker": "E", "text": "Wir hatten ein Ad-hoc-Meeting mit dem Produktmanagement, in dem ich die Risikoanalyse aus POL-QA-014 erläutert habe. Zusätzlich ging eine E-Mail mit einem Screenshot aus unserem QA-Dashboard raus, in dem die betroffenen Testbereiche markiert waren."}
{"ts": "116:45", "speaker": "I", "text": "Gab es nachträglich Qualitätsprobleme, die auf diese reduzierte Abdeckung zurückzuführen waren?"}
{"ts": "116:53", "speaker": "E", "text": "Nur einen Minor-Bug im Konfigurationsmodul, der über das Monitoring von Nimbus Observability auffiel. Wir konnten ihn binnen 4 Stunden beheben, also noch innerhalb unseres SLO von 8 Stunden für Minor Severity."}
{"ts": "117:06", "speaker": "I", "text": "Wie gehen Sie generell damit um, wenn SLAs oder SLOs in Gefahr geraten?"}
{"ts": "117:14", "speaker": "E", "text": "Wir haben einen Eskalationspfad im Runbook RB-QA-199. Wenn ein SLO droht, überschritten zu werden, löst unser Orchestrierungstool automatisch ein PagerDuty-Event aus, und wir priorisieren die entsprechenden Tests und Fixes vor allen anderen Aufgaben."}
{"ts": "117:28", "speaker": "I", "text": "Können Sie ein Beispiel nennen, wo eine Metrik direkt zu einer strategischen Anpassung führte?"}
{"ts": "117:36", "speaker": "E", "text": "Ja, im März zeigte die Flaky-Rate in den API-Tests für das Orion Edge Gateway 18 %. Wir haben daraufhin die Ausführungsreihenfolge geändert und die Tests isoliert, um Side-Effects zu vermeiden. Das stand später als Lessons Learned im Post-Mortem-Dokument PM-QA-031."}
{"ts": "117:52", "speaker": "I", "text": "War dafür eine formale Änderung der Teststrategie nötig?"}
{"ts": "118:00", "speaker": "E", "text": "Ja, wir haben eine RFC, die RFC-QA-087, erstellt. Darin sind neue Isolationsrichtlinien für API-Tests definiert, und das wurde vom Architektur-Board abgesegnet."}
{"ts": "118:12", "speaker": "I", "text": "Haben Sie in solchen Phasen zusätzliche Ressourcen angefordert?"}
{"ts": "118:20", "speaker": "E", "text": "Teilweise, ja. Wir haben temporär zwei Tester aus dem Nebula-UI-Team übernommen, weil sie Erfahrung mit dem genutzten Mock-Service hatten. Das wurde im Ressourcenplan RP-QA-056 vermerkt."}
{"ts": "118:33", "speaker": "I", "text": "Wie sichern Sie das Wissen aus solchen Sonderaktionen für die Zukunft?"}
{"ts": "118:40", "speaker": "E", "text": "Wir dokumentieren die gesamte Maßnahme im internen Confluence-Bereich 'QA Learnings'. Dazu gehören Runbook-Updates, Screenshots, Code-Snippets und ein Link auf das Ursprungsticket. So vermeiden wir, dass diese Informationen nur in Köpfen bleiben."}
{"ts": "122:00", "speaker": "I", "text": "Sie hatten eben die Priorisierung nach Risiko erwähnt. Können Sie das bitte noch einmal an einem aktuellen Beispiel aus der Hera QA Platform konkretisieren?"}
{"ts": "122:12", "speaker": "E", "text": "Ja, gern. Wir haben letzte Woche im Build-Stream das Modul TestDispatcher implementiert, und da gab es ein hohes Risiko wegen der neuen Parallelisierungslogik. Laut Policy POL-QA-014 haben wir dafür 60% der Automatisierungsressourcen auf High-Risk-Szenarien gelenkt. Niedrigrisiko-Tests wurden nur stichprobenartig ausgeführt."}
{"ts": "122:38", "speaker": "I", "text": "Und wie fließt das in Ihre Traceability ein?"}
{"ts": "122:44", "speaker": "E", "text": "Wir mappen in unserem Testmanagement-Tool alle Testfälle auf die Anforderungs-IDs aus dem Jira-Board HER-QA. Zusätzlich verlinken wir Defects in unserem Bugtracker direkt auf die entsprechenden TestRuns. Das ist auch in Runbook RB-QA-07 dokumentiert, Schritt 4 bis 6."}
{"ts": "123:05", "speaker": "I", "text": "Können Sie beschreiben, wie flaky test analytics operativ eingebunden sind?"}
{"ts": "123:12", "speaker": "E", "text": "Wir haben das Tool FlakeScan 3.2 in die Orchestrierung integriert. Jeder nightly build erzeugt einen Flake-Report, der in den CI-Pipelines als Gate fungiert. Falls eine Suite mehr als 4% flakiness aufweist, wird automatisch ein HER-FLAKE Ticket erstellt. Diese Tickets werden dann vor Release in einem eigenen Board priorisiert."}
{"ts": "123:38", "speaker": "I", "text": "Gab es vor kurzem so einen Fall?"}
{"ts": "123:44", "speaker": "E", "text": "Ja, beim API-Gateway-Test zur Auth-Session gab es 6,7% flakiness. Das stand im Zusammenhang mit einer Änderung aus Orion Edge Gateway, die wiederum Monitoring-Daten aus Nimbus anders serialisierte. Hier mussten wir cross-team gemeinsam debuggen."}
{"ts": "124:05", "speaker": "I", "text": "Interessant. Welche KPIs überwachen Sie daraufhin?"}
{"ts": "124:12", "speaker": "E", "text": "Primär Defect Density, Test Case Pass Rate und Mean Time to Detect für kritische Bugs. Dazu kommen SLA-bezogene Metriken wie 'maximale Unterbrechung durch Testfehler < 30 Min.'. Die SLA-Werte sind in SLA-QA-HER-2024 festgehalten."}
{"ts": "124:36", "speaker": "I", "text": "Wie haben diese Metriken Ihre Teststrategie kürzlich beeinflusst?"}
{"ts": "124:42", "speaker": "E", "text": "Als die Defect Density im letzten Sprint um 18% über Ziel lag, haben wir laut Change-Request HER-CR-58 zwei zusätzliche Exploratory-Testing-Sessions eingeplant. Das hat dazu geführt, dass wir zwei kritische Race-Conditions vor Go-Live gefunden haben."}
{"ts": "125:05", "speaker": "I", "text": "Gab es dabei Zielkonflikte mit der Liefergeschwindigkeit?"}
{"ts": "125:10", "speaker": "E", "text": "Ja, wir mussten entscheiden, ob wir das Sprintziel wie geplant releasen oder um drei Tage verschieben. Basierend auf Ticket HER-RISK-22 und dem Abgleich mit Runbook RB-QA-Tradeoff haben wir die Verschiebung gewählt, um Abdeckungsgrad bei High-Risk zu sichern."}
{"ts": "125:32", "speaker": "I", "text": "Wie dokumentieren Sie solche Entscheidungen für spätere Audits?"}
{"ts": "125:38", "speaker": "E", "text": "Wir erstellen nach jedem Entscheidungsmeeting ein Decision Log im Confluence-Space HER-QA, mit Verweisen auf alle relevanten Tickets, Metriken und Runbooks. Das ist Teil unseres internen Audit-Checklistenpunkts QA-AUD-05."}
{"ts": "128:00", "speaker": "I", "text": "Sie hatten vorhin erwähnt, dass Sie bei knappen Release-Terminen manchmal Abstriche machen müssen. Können Sie ein konkretes Beispiel aus dem letzten Quartal nennen?"}
{"ts": "128:10", "speaker": "E", "text": "Ja, im März hatten wir ein Release-Fenster von nur drei Tagen, weil ein kritischer Fix für das Hera QA Platform Backend ausgerollt werden musste. Laut Runbook QA-RB-021 hätten wir eigentlich die vollständige Regression fahren müssen, aber ich habe entschieden, nur die risikorelevanten Szenarien gemäß Policy POL-QA-014 zu testen."}
{"ts": "128:27", "speaker": "I", "text": "Und wie haben Sie diese Entscheidung intern abgesichert?"}
{"ts": "128:33", "speaker": "E", "text": "Ich habe ein internes Approval-Ticket HERA-QA-558 im JTrack-System erstellt, mit Verweis auf die SLA-Anforderungen für die betroffenen Kunden. Wir haben das Risiko im QA-Risikolog (Sheet RISK-HERA-2024Q1) dokumentiert und durch die Erkenntnisse aus den letzten Flaky-Test-Analysen abgesichert."}
{"ts": "128:52", "speaker": "I", "text": "Gab es dabei Bedenken aus anderen Abteilungen, zum Beispiel vom Produktmanagement?"}
{"ts": "128:58", "speaker": "E", "text": "Ja, das Produktmanagement hat nachgehakt, ob wir dadurch SLA-Verletzungen riskieren. Wir konnten anhand der Metriken aus dem letzten Orion Edge Gateway API-Loadtest und den Nimbus Observability-Daten aber zeigen, dass die nicht getesteten Bereiche seit Monaten stabil laufen."}
{"ts": "129:15", "speaker": "I", "text": "Das heißt, Sie nutzen historische Observability-Daten aktiv zur Entscheidungsfindung?"}
{"ts": "129:20", "speaker": "E", "text": "Genau. Wir haben im Runbook QA-RB-034 einen Abschnitt, der beschreibt, wie man Anomalie-Daten aus Nimbus in die Risikoabwägung einbezieht. Dieser Prozess ist zwar nicht offiziell in allen Policies verankert, aber er hat sich in der Praxis bewährt."}
{"ts": "129:38", "speaker": "I", "text": "Wie gehen Sie mit der Dokumentation solcher Abweichungen von der Policy um?"}
{"ts": "129:43", "speaker": "E", "text": "Wir führen dafür einen sogenannten Deviations-Log. Darin wird jede Abweichung mit Datum, Ticket-ID und einer kurzen Begründung festgehalten, plus Verweis auf die relevanten Runbooks oder Testsuites. Für den März-Fall steht dort: 'Partial Regression approved due to SLA-critical fix – see HERA-QA-558'."}
{"ts": "130:02", "speaker": "I", "text": "Hat diese Vorgehensweise schon einmal zu Problemen geführt?"}
{"ts": "130:07", "speaker": "E", "text": "Einmal, ja. Im vergangenen Jahr haben wir bei einem Security-Patch einen Low-Risk-Bereich nicht getestet, der dann aber durch eine versteckte Abhängigkeit zum Orion Edge Gateway eine Störung verursachte. Seitdem prüfen wir auch Low-Risk-Bereiche kurz mit Smoke-Tests."}
{"ts": "130:25", "speaker": "I", "text": "Wie haben Sie diese Lektion in Ihre Prozesse integriert?"}
{"ts": "130:30", "speaker": "E", "text": "Wir haben in QA-RB-021 ein Appendix eingefügt: 'Mandatory Smoke-Tests for All Risk Levels if API Dependencies Exist'. Außerdem wurde ein wöchentlicher Cross-Team-Review mit den Orion- und Nimbus-Teams eingeführt, um Schnittstellenänderungen früh zu erkennen."}
{"ts": "130:48", "speaker": "I", "text": "Wenn Sie jetzt zurückblicken: Würden Sie die Entscheidung im März wieder so treffen?"}
{"ts": "130:54", "speaker": "E", "text": "Ja, mit den vorliegenden Daten und dem Zeitdruck war es die richtige Wahl. Wir konnten die Liefergeschwindigkeit halten und die SLA-Verpflichtungen erfüllen. Aber ich würde heute zusätzlich die minimalen Smoke-Tests einplanen, um das Restrisiko weiter zu senken."}
{"ts": "136:00", "speaker": "I", "text": "Sie hatten vorhin den Trade-off erwähnt, bei dem Sie unter Zeitdruck Features ausliefern mussten. Können Sie genauer auf die Risiken eingehen, die Sie dabei dokumentiert haben?"}
{"ts": "136:20", "speaker": "E", "text": "Ja, wir haben das im Risk Log RSK-2024-112 festgehalten. Darin steht, dass wir bei drei Modul-Integrationen auf tiefgehende Regressionstests verzichtet haben. Die Risikoabschätzung stützte sich auf historische Defektdaten aus unserem Jira-Board HERA-QA und den Lessons Learned aus Runbook RB-QA-07."}
{"ts": "136:48", "speaker": "I", "text": "Und wie haben Sie diese Entscheidung gegenüber dem Steering Committee gerechtfertigt?"}
{"ts": "137:05", "speaker": "E", "text": "Wir haben dargelegt, dass die SLA für die Bereitstellung der Testumgebung von 24 Stunden einzuhalten war. Das Steering Committee hat akzeptiert, dass wir stattdessen stichprobenartige Regressionstests gemacht haben, weil die Metriken aus dem letzten Release unter dem Defektschwellenwert lagen."}
{"ts": "137:32", "speaker": "I", "text": "Gab es dabei ungeschriebene Regeln oder Heuristiken, die Ihre Entscheidung beeinflusst haben?"}
{"ts": "137:50", "speaker": "E", "text": "Ja, intern gilt die Faustregel: Wenn ein Modul in den letzten zwei Releases keine kritischen Bugs hatte und keine High-Risk-Changes eingeflossen sind, können wir den Regressionstestumfang um bis zu 40 % reduzieren. Das ist nicht formal in der Policy POL-QA-014 verankert, aber im Team als akzeptiert angesehen."}
{"ts": "138:15", "speaker": "I", "text": "Wie wirken sich solche Abweichungen auf Ihre Qualitätsmetriken aus?"}
{"ts": "138:33", "speaker": "E", "text": "Wir beobachten dann besonders die Defektrate in den ersten 48 Stunden nach Release. In einem Fall stieg sie um 0,3 %, was noch innerhalb unseres SLO von maximal 1 % liegt. Parallel tracken wir die Mean Time to Detect, die bei 2,1 Stunden lag – also akzeptabel."}
{"ts": "138:58", "speaker": "I", "text": "Haben Sie in so einem Fall auch Anpassungen an der Teststrategie vorgenommen?"}
{"ts": "139:15", "speaker": "E", "text": "Ja, beim nächsten Sprint haben wir gezielt die API-Calls aus Orion Edge Gateway stärker mit Nimbus-Daten kombiniert, um Hotspots schneller zu erkennen. Das war eine direkte Folge der Erkenntnisse aus dem Ticket HERA-QA-5561."}
{"ts": "139:40", "speaker": "I", "text": "Interessant. Könnten Sie beschreiben, wie Sie das technisch umgesetzt haben?"}
{"ts": "140:00", "speaker": "E", "text": "Wir haben in unserer Testorchestrierung einen Pre-Processing-Step eingeführt, der Metriken aus Nimbus' Event-Logs in die Testauswertung integriert. Ein Python-Skript filtert die relevanten API-Events, korreliert sie mit den TestIDs und priorisiert jene Suites, die in der Vergangenheit zu Latenzspitzen geführt haben."}
{"ts": "140:28", "speaker": "I", "text": "Gab es dafür eine formale Freigabe?"}
{"ts": "140:42", "speaker": "E", "text": "Ja, wir haben einen RFC, RFC-HERA-23-019, erstellt. Der wurde im QA-Architektur-Board vorgestellt und einstimmig freigegeben. Darin sind auch die Rollback-Schritte definiert, falls die Integration der Nimbus-Daten zu Falschalarmen führen sollte."}
{"ts": "141:05", "speaker": "I", "text": "Wie stellen Sie sicher, dass diese Lessons Learned nicht verloren gehen?"}
{"ts": "141:20", "speaker": "E", "text": "Wir pflegen einen Confluence-Bereich 'Hera QA Knowledge Base'. Dort dokumentieren wir jede Abweichung, Entscheidung, die dahinterliegenden Metriken, und verlinken Tickets, Runbooks sowie relevante Slack-Threads. So bleibt die Kontext- und Evidenzkette erhalten."}
{"ts": "144:00", "speaker": "I", "text": "Zum Abschluss würde ich gern noch verstehen, wie Sie SLAs konkret in die Testplanung einbauen. Können Sie ein Beispiel nennen?"}
{"ts": "144:05", "speaker": "E", "text": "Ja, wir haben für Hera QA definierte SLOs aus SLA-QA-002 übernommen, z.B. „kritische Bugs < 0,5% in Produktion pro Release“. In der Planungsphase mappen wir diese auf Test-Suiten, die wir als 'must-run' vor jedem Deployment markieren."}
{"ts": "144:15", "speaker": "I", "text": "Und wie stellen Sie sicher, dass diese 'must-run' Suiten immer aktuell sind?"}
{"ts": "144:20", "speaker": "E", "text": "Wir haben ein halbautomatisches Review alle zwei Wochen. Dazu gibt es Runbook RB-QA-07, das beschreibt, wie Suiten gegen die aktuelle Risiko-Matrix aus POL-QA-014 validiert werden."}
{"ts": "144:30", "speaker": "I", "text": "Gab es schon Fälle, in denen Sie die priorisierte Liste kurzfristig anpassen mussten?"}
{"ts": "144:35", "speaker": "E", "text": "Ja, bei Ticket HERA-231 haben wir eine Suite temporär hochgestuft, weil Orion Edge Gateway eine Breaking-Change-API eingeführt hat. Da hat uns die Traceability-Matrix geholfen, den Impact sofort zu erkennen."}
{"ts": "144:45", "speaker": "I", "text": "Interessant. Wie dokumentieren Sie solche Ad-hoc-Änderungen?"}
{"ts": "144:50", "speaker": "E", "text": "Im QA-Change-Log, das ist ein Confluence-gestütztes Register. Jeder Eintrag verweist auf das JIRA-Ticket, die geänderte Suite und den Grund, plus Rückbau-Datum."}
{"ts": "145:00", "speaker": "I", "text": "Und wie wirkt sich das auf Ihre Metriken aus?"}
{"ts": "145:05", "speaker": "E", "text": "Kurzfristig steigt die Laufzeit der Pipeline um ca. 12 Minuten, was wir in den Deployment-Lead-Time-KPI einrechnen. Langfristig sinkt aber das Produktionsfehler-Risiko."}
{"ts": "145:15", "speaker": "I", "text": "Sie hatten vorhin den Trade-off zwischen Abdeckung und Geschwindigkeit erwähnt. Gab es jüngst eine Entscheidung, die besonders schwierig war?"}
{"ts": "145:20", "speaker": "E", "text": "Ja, in Sprint 42. Wir mussten entscheiden, ob wir ein neues Lasttest-Set vollständig fahren. Laut RB-PERF-03 hätte das 8 Stunden gedauert. Wir haben es auf Kern-Szenarien reduziert, um den Release-Kandidaten rechtzeitig zu liefern."}
{"ts": "145:32", "speaker": "I", "text": "Wie haben Sie diese Entscheidung abgesichert?"}
{"ts": "145:37", "speaker": "E", "text": "Mit einer Risikoabschätzung im Ticket HERA-RISK-58 und der Freigabe durch den Product Owner. Wir haben dokumentiert, welche Szenarien entfallen und welche Monitoring-Checks in Nimbus das kompensieren."}
{"ts": "145:47", "speaker": "I", "text": "Hat das Monitoring anschließend etwas Auffälliges gezeigt?"}
{"ts": "145:52", "speaker": "E", "text": "Nein, die KPIs blieben im grünen Bereich. Wir hatten in den ersten 48 Stunden Post-Release keine SLA-Verletzung, was die Entscheidung im Rückblick bestätigt hat."}
{"ts": "146:00", "speaker": "I", "text": "Sie hatten vorhin den Trade-off zwischen Abdeckung und Geschwindigkeit erwähnt. Können Sie das bitte noch anhand eines konkreten Projekttages im Hera-Build schildern?"}
{"ts": "146:05", "speaker": "E", "text": "Ja, klar. Also, zum Beispiel am 14. Build-Tag – wir hatten gerade die API-Änderungen aus Orion integriert – standen wir vor der Entscheidung: Führen wir den vollen Regressionstestlauf durch, was laut Runbook QA-RB-07 etwa 9 Stunden dauert, oder beschränken wir uns auf die risikorelevanten Module. Wir haben uns, nach Abgleich mit Ticket QA-4215, für Letzteres entschieden, um das geplante Deployment-Fenster nicht zu verpassen."}
{"ts": "146:17", "speaker": "I", "text": "Wie dokumentieren Sie solche Abweichungen von der normalen Testtiefe?"}
{"ts": "146:22", "speaker": "E", "text": "Wir nutzen dafür das Confluence-Dokument QA-DEC-Log, dort wird die Entscheidung, die Begründung, sowie die Referenz auf relevante Runbooks und Jira-Tickets hinterlegt. Das ist Teil unserer internen Policy POL-QA-014, Abschnitt 5.3."}
{"ts": "146:31", "speaker": "I", "text": "Gab es im Nachhinein Qualitätsprobleme durch diese Entscheidung?"}
{"ts": "146:36", "speaker": "E", "text": "Interessanterweise nicht direkt. Wir hatten dank der vorherigen Nimbus-Metriken eine gute Risikoeinschätzung. Allerdings hat ein Minor-Defekt in einem Randmodul später zu einem Hotfix geführt. Das war Ticket QA-4290, und wir haben das dann als Lesson Learned ins Runbook eingepflegt."}
{"ts": "146:48", "speaker": "I", "text": "Wie fließen solche Lessons Learned in künftige Testplanungen ein?"}
{"ts": "146:53", "speaker": "E", "text": "Wir haben eine wöchentliche QA-Retrospektive, in der wir diese Punkte besprechen. Darauf basierend passen wir die Risiko-Scoring-Matrix an. Beispielsweise haben wir nach QA-4290 die Gewichtung für Randmodule mit komplexen Abhängigkeiten erhöht."}
{"ts": "147:02", "speaker": "I", "text": "Wie reagieren andere Abteilungen auf solche Anpassungen?"}
{"ts": "147:07", "speaker": "E", "text": "Development ist meistens dankbar, weil es verdeutlicht, wo besondere Sorgfalt nötig ist. Product Management hingegen fragt gelegentlich nach, ob dadurch die Liefergeschwindigkeit leidet. Wir müssen dann transparent machen, wie sich die SLA-konforme Qualität auf die Time-to-Market auswirkt."}
{"ts": "147:18", "speaker": "I", "text": "Gibt es formale Thresholds in den SLAs, die Sie im Blick behalten müssen?"}
{"ts": "147:23", "speaker": "E", "text": "Ja, wir haben z.B. eine SLA-Vorgabe, dass maximal 2% der ausgelieferten Builds kritische Defekte in Produktion enthalten dürfen. Diese Metrik wird monatlich im Dashboard 'Hera-QA-KPIs' ausgewiesen."}
{"ts": "147:31", "speaker": "I", "text": "Und wenn ein Build diesen Threshold überschreitet?"}
{"ts": "147:36", "speaker": "E", "text": "Dann greift unser Eskalationspfad laut Runbook QA-RB-12: Sofortige Sperrung weiterer Deployments, Root-Cause-Analyse mit DevOps und ein Review-Meeting mit dem Steering Committee. Das ist uns im Hera-Projekt bisher zum Glück erspart geblieben."}
{"ts": "147:47", "speaker": "I", "text": "Haben Sie abschließend einen Tipp, wie man den Spagat zwischen Geschwindigkeit und Abdeckung gut managt?"}
{"ts": "147:52", "speaker": "E", "text": "Transparenz ist der Schlüssel. Man sollte die Entscheidungskriterien offenlegen, aktuelle Metriken aus Tools wie Nimbus heranziehen und sicherstellen, dass alle Stakeholder die Risiken verstehen. Dann kann man pragmatisch, aber fundiert, abwägen."}
{"ts": "148:00", "speaker": "I", "text": "Sie hatten vorhin die Abwägung zwischen Testabdeckung und Liefergeschwindigkeit angesprochen. Könnten Sie dazu noch ein praktisches Beispiel geben, wie sich das im Hera-Build ausgewirkt hat?"}
{"ts": "148:10", "speaker": "E", "text": "Ja, gern. Im Sprint 34 standen wir vor der Entscheidung, ob wir die komplette Regression gegen alle Microservices fahren oder nur die kritischen Pfade. Laut Runbook RB-QA-021 hätten wir voll testen müssen, aber das hätte den Release um drei Tage verzögert. Wir haben dann auf Basis des Risikologs RSK-112 priorisiert und nur die API-Endpunkte aus dem Orion Edge Gateway getestet, die laut Nimbus Metriken in den letzten 14 Tagen auffällig waren."}
{"ts": "148:28", "speaker": "I", "text": "Und wie haben Sie dokumentiert, dass Sie von RB-QA-021 abgewichen sind?"}
{"ts": "148:34", "speaker": "E", "text": "Das ging über ein Abweichungsprotokoll im Ticket QADEV-7421. Dort haben wir die Begründung, das Risiko-Scoring und die erwarteten Auswirkungen festgehalten. Außerdem haben wir im Confluence-Abschnitt 'Policy Deviations' einen Eintrag gemacht, um beim nächsten Audit transparent zu sein."}
{"ts": "148:50", "speaker": "I", "text": "Gab es nach dem Release Rückmeldungen, dass diese gekürzte Testabdeckung Probleme verursacht hat?"}
{"ts": "148:58", "speaker": "E", "text": "Tatsächlich nicht. Wir hatten zwei Minor Bugs, die aber in Bereichen lagen, die laut Risikoanalyse Low Impact waren. Das hat uns bestätigt, dass die risikobasierte Kürzung in diesem Fall vertretbar war."}
{"ts": "149:10", "speaker": "I", "text": "Wie fließen solche Learnings in die Weiterentwicklung Ihrer Teststrategie ein?"}
{"ts": "149:16", "speaker": "E", "text": "Wir ergänzen die Lessons Learned im Abschnitt 'Strategieanpassungen' des Master-Testplans MTP-HER-001. Außerdem passen wir die Gewichtung bestimmter Risiken im Tool QRiskCalc an, damit ähnliche Entscheidungen künftig schneller mit belastbaren Daten getroffen werden können."}
{"ts": "149:32", "speaker": "I", "text": "Sie erwähnten QRiskCalc – integrieren Sie dieses Tool direkt in Ihre Testorchestrierung?"}
{"ts": "149:39", "speaker": "E", "text": "Ja, via API-Connector. Die Testorchestrierung in Hera zieht sich vor dem Suite-Start automatisch die aktuellen Risiko-Scores aus QRiskCalc. Das ist in RFC-QA-057 beschrieben, und so stellen wir sicher, dass die Ausführungsreihenfolge dynamisch nach Risikoprofil angepasst wird."}
{"ts": "149:56", "speaker": "I", "text": "Wie wirkt sich das auf Ihre SLAs aus, gerade wenn Sie priorisieren?"}
{"ts": "150:03", "speaker": "E", "text": "Unsere SLA-QA-002 schreibt vor, dass kritische Defects innerhalb von 24 Stunden nach Fund gefixt oder mitigiert sein müssen. Durch die Priorisierung erreichen wir diese Vorgabe zuverlässiger, weil wir kritische Pfade zuerst testen und so schneller reagieren können."}
{"ts": "150:18", "speaker": "I", "text": "Gab es dennoch Situationen, in denen diese Priorisierung zu SLA-Verletzungen geführt hat?"}
{"ts": "150:25", "speaker": "E", "text": "Einmal, im Build 0.9.12, haben wir einen Low-Risk-Bereich zu spät getestet, und dort trat ein Fehler auf, der dann doch eine kritische Abhängigkeit hatte. Das führte zu einer leichten SLA-Verletzung. Wir haben daraus die Regel abgeleitet, Low-Risk-Bereiche mit potenziellen versteckten Abhängigkeiten in einer Minimal-Suite früh mitlaufen zu lassen."}
{"ts": "150:44", "speaker": "I", "text": "Das klingt nach einer feinen Balance. Haben Sie dafür jetzt einen festen Prozess?"}
{"ts": "150:50", "speaker": "E", "text": "Ja, wir haben das als Step 3.4 in Runbook RB-QA-025 aufgenommen: 'Include minimal coverage for all modules regardless of risk score'. So verhindern wir, dass uns versteckte Kopplungen durchrutschen."}
{"ts": "152:00", "speaker": "I", "text": "Sie hatten ja gerade den Trade-off zwischen Abdeckung und Geschwindigkeit erwähnt. Können Sie erläutern, wie sich diese Entscheidung konkret auf den letzten Sprintplan ausgewirkt hat?"}
{"ts": "152:07", "speaker": "E", "text": "Ja, im Sprint 42 haben wir die Testabdeckung von 96 % auf 91 % reduziert, um ein kritisches API-Update vom Orion Edge Gateway noch vor dem Stichtag in die Hera QA Platform zu integrieren. Wir haben dafür Runbook RB-QA-221 genutzt, das beschreibt, wie Regressionstests priorisiert werden, wenn SLA-Risiken bestehen."}
{"ts": "152:23", "speaker": "I", "text": "Gab es für diese Priorisierung auch einen formalen Freigabeprozess?"}
{"ts": "152:28", "speaker": "E", "text": "Absolut. Laut Policy POL-QA-014, Abschnitt 5.3, müssen wir das in einem RFC festhalten. In diesem Fall war es RFC-HER-88. Darin haben wir dokumentiert, welche Testmodule entfallen und wie wir die Risiken mitigieren – z. B. durch manuelle Exploratory Sessions."}
{"ts": "152:44", "speaker": "I", "text": "Wie haben Sie sichergestellt, dass die entfallenen Tests nicht zu Produktionsfehlern führen?"}
{"ts": "152:50", "speaker": "E", "text": "Wir haben mit den Observability-Daten aus Nimbus nach dem Release ein Live-Monitoring eingerichtet. Ticket QA-MON-562 beschreibt den Watchdog-Alert, der speziell auf Anomalien in den API-Response-Zeiten des Edge Gateway reagiert."}
{"ts": "153:05", "speaker": "I", "text": "Gab es da Auffälligkeiten nach dem Go-Live?"}
{"ts": "153:09", "speaker": "E", "text": "Minimal. Ein Spike von 120 ms auf 350 ms in der Antwortzeit bei einem Endpunkt. Das war in Ticket BUG-HER-778 erfasst, konnte aber durch einen Hotfix in 6 Stunden behoben werden, bevor das SLA verletzt wurde."}
{"ts": "153:22", "speaker": "I", "text": "Interessant. Und wie fließen solche Learnings zurück in die Testplanung?"}
{"ts": "153:28", "speaker": "E", "text": "Wir haben im wöchentlichen QA-Review die Lessons Learned dokumentiert und ins Runbook RB-QA-310 aufgenommen: dort steht jetzt, dass für kritische Endpunkte immer ein reduzierter, aber gezielter Lasttest vorgezogen wird, selbst wenn andere Tests geschoben werden."}
{"ts": "153:43", "speaker": "I", "text": "Das heißt, Sie passen Ihre Strategie kontinuierlich an?"}
{"ts": "153:46", "speaker": "E", "text": "Genau. Continuous improvement ist Kern unseres Modells. Auch wenn POL-QA-014 Rahmen vorgibt, nutzen wir Ausnahmen, wenn Evidenz aus Tickets und Monitoring eine Änderung rechtfertigt."}
{"ts": "153:58", "speaker": "I", "text": "Gab es schon einmal Kritik vom Management zu solchen Abweichungen?"}
{"ts": "154:03", "speaker": "E", "text": "Ja, beim Release 3.1 gab es Rückfragen, warum wir eine Policy-Ausnahme ohne vollständige Stakeholder-Abzeichnung gemacht haben. Wir haben daraus gelernt und seitdem ein Express-Approval-Formular eingeführt, das im Confluence hinterlegt ist."}
{"ts": "154:16", "speaker": "I", "text": "Und wie bewerten Sie rückblickend diesen Trade-off bei Sprint 42?"}
{"ts": "154:21", "speaker": "E", "text": "Er war gerechtfertigt. Wir haben das Feature pünktlich geliefert, das SLA gehalten und nur minimalen, schnell behebbare Defects gehabt. Die Dokumentation in RFC-HER-88 und die Monitoring-Tickets dienen uns künftig als Entscheidungsgrundlage."}
{"ts": "160:00", "speaker": "I", "text": "Sie hatten vorhin den Trade-off angesprochen. Könnten Sie noch genauer ausführen, wie Sie die Auswirkungen solcher Entscheidungen auf nachgelagerte Builds messen?"}
{"ts": "160:05", "speaker": "E", "text": "Ja, wir nutzen dafür im Grunde zwei Pfade: einerseits die Build Health Metriken im Hera Dash, andererseits Rückmeldungen aus den Smoke Tests der Integrationsumgebung. Wenn wir zum Beispiel laut Runbook QA-RB-021 weniger Regression Suites fahren, tracken wir die Defect Density in den nächsten zwei Build-Zyklen."}
{"ts": "160:17", "speaker": "I", "text": "Und bei einer erhöhten Defect Density, wie reagieren Sie?"}
{"ts": "160:21", "speaker": "E", "text": "Dann greifen wir zu einem Escalation Pfad, der in Ticket QAT-447 beschrieben ist. Das sieht vor, dass wir temporär wieder auf volle Abdeckung hochfahren, auch wenn das die Liefergeschwindigkeit etwas dämpft."}
{"ts": "160:32", "speaker": "I", "text": "Gibt es Situationen, in denen Sie diese Eskalation nicht anwenden?"}
{"ts": "160:36", "speaker": "E", "text": "Nur wenn der Defect Impact sehr gering ist, also im SLA-Korridor bleibt. Unser SLA für kritische Bugs ist max. 0,5% der ausgelieferten Features in einem Release. Bleibt der Wert darunter, dokumentieren wir das im QA-Log und beobachten weiter."}
{"ts": "160:48", "speaker": "I", "text": "Wie binden Sie das Team in solche Monitoring-Prozesse ein?"}
{"ts": "160:52", "speaker": "E", "text": "Wir haben ein wöchentliches QA-Sync, dort teilen wir die Observability-Daten aus Nimbus direkt im Board. Die Teammitglieder sehen dann die KPI-Trends und können in Confluence verlinkte Runbooks direkt aufrufen."}
{"ts": "161:04", "speaker": "I", "text": "Hat sich diese Transparenz positiv ausgewirkt?"}
{"ts": "161:08", "speaker": "E", "text": "Ja, deutlich. Die Fehlermeldungszeit (Mean Time to Detect) sank laut unserem KPI-Sheet um etwa 18%. Das hat auch dazu geführt, dass wir im letzten Orion Edge Gateway API-Update keine späten Integration Bugs hatten."}
{"ts": "161:20", "speaker": "I", "text": "Gab es dafür ein spezielles Vorgehen?"}
{"ts": "161:24", "speaker": "E", "text": "Wir haben im Vorfeld einen Simulation Run gefahren, wie im RFC QA-RFC-058 empfohlen. Das hat uns erlaubt, die Testorchestrierung mit simulierten Nimbus Streams zu prüfen, bevor das echte API-Live ging."}
{"ts": "161:36", "speaker": "I", "text": "Könnten Sie beschreiben, wie Sie sicherstellen, dass solche Lessons Learned ins nächste Release einfließen?"}
{"ts": "161:40", "speaker": "E", "text": "Sicher. Wir pflegen ein Living Document namens QA-Continuous-Improvement, Version 3.2 aktuell. Da dokumentieren wir jeden Runbook- oder Tooling-Change, verlinkt mit den entsprechenden Tickets, damit das für das nächste Hera QA Platform Sprint Planning verfügbar ist."}
{"ts": "161:54", "speaker": "I", "text": "Wie wirkt sich das auf die Kommunikation mit den Entwicklern aus?"}
{"ts": "161:58", "speaker": "E", "text": "Die Entwickler sehen, dass QA nicht nur blockierend, sondern auch optimierend arbeitet. Wenn wir belegen können, dass eine temporäre Abdeckungskürzung keinen SLA-Bruch erzeugt hat, steigt die Akzeptanz für flexible Teststrategien erheblich."}
{"ts": "161:35", "speaker": "I", "text": "Lassen Sie uns jetzt noch etwas tiefer in die Qualitätsmetriken eintauchen. Welche KPIs sind für Sie in der aktuellen Build-Phase der Hera QA Platform am aussagekräftigsten?"}
{"ts": "161:42", "speaker": "E", "text": "Wir schauen vor allem auf Defect Leakage Rate, Test Execution Coverage und Mean Time to Detect. Zusätzlich erfassen wir Flaky Test Rate, weil das direkt in unsere Orchestrierung einfließt. Die Metriken sind im Runbook RB-QA-07 festgelegt."}
{"ts": "161:55", "speaker": "I", "text": "Und wie werden diese Werte gegen SLAs oder SLOs gespiegelt?"}
{"ts": "162:00", "speaker": "E", "text": "Wir haben SLOs, die z.B. maximal 5% Defect Leakage erlauben. Wenn wir über 3% kommen, triggern wir einen Review gemäß Policy POL-QA-014. Das steht auch so im internen SLA-Dokument SLA-HER-01."}
{"ts": "162:15", "speaker": "I", "text": "Gab es kürzlich einen Fall, wo eine Metrik eine Anpassung ausgelöst hat?"}
{"ts": "162:20", "speaker": "E", "text": "Ja, beim letzten Sprint hatten wir eine plötzliche Erhöhung der Flaky Test Rate von 7% auf 12%. Das haben wir im Ticket QA-452 dokumentiert und ein Hotfix-Skript aus dem Runbook RB-AUTO-03 angewendet."}
{"ts": "162:35", "speaker": "I", "text": "Können Sie kurz skizzieren, wie dieses Hotfix-Skript eingebettet wird?"}
{"ts": "162:40", "speaker": "E", "text": "Es wird als Jenkins-Pipeline-Step eingefügt, triggert eine automatische Neupriorisierung der betroffenen Tests und markiert sie für dedizierte Runs in der Nacht. Das steht Schritt für Schritt im RB-AUTO-03 Abschnitt 4.2."}
{"ts": "162:55", "speaker": "I", "text": "Interessant. Sie erwähnten vorhin Policies – wie strikt sind diese in der Build-Phase?"}
{"ts": "163:00", "speaker": "E", "text": "In der Build-Phase sind wir etwas flexibler, aber wir dokumentieren jede Abweichung. Zum Beispiel haben wir im DevOps-Ticket DEVOPS-311 eine temporäre Ausnahme von POL-QA-014 vermerkt, um einen kritischen Build rechtzeitig auszuliefern."}
{"ts": "163:15", "speaker": "I", "text": "Wie stellen Sie sicher, dass solche Abweichungen später nicht zu Qualitätsproblemen führen?"}
{"ts": "163:20", "speaker": "E", "text": "Wir setzen Post-Release Audits auf. Innerhalb von zwei Wochen nach Release prüfen wir betroffene Komponenten mit erhöhter Testtiefe. Diese Audits sind in unserem QA-Handbuch Abschnitt 9.5 beschrieben."}
{"ts": "163:35", "speaker": "I", "text": "Gibt es bekannte Risiken, die Sie aktuell besonders im Auge behalten?"}
{"ts": "163:40", "speaker": "E", "text": "Ja, vor allem Schnittstellenänderungen zwischen Hera und dem Orion Edge Gateway, die nicht vollständig rückwärtskompatibel sind. Wir haben dazu ein Risikoregister-Eintrag RSK-HER-22 mit Verweis auf Testplan TP-OR-05."}
{"ts": "163:55", "speaker": "I", "text": "Abschließend: Welche Lessons Learned nehmen Sie aus dieser Build-Phase mit?"}
{"ts": "164:00", "speaker": "E", "text": "Dass enge Verzahnung von Observability-Daten, API-Management und risikobasierter Testplanung entscheidend ist. Und dass dokumentierte Trade-offs uns helfen, später fundierte Verbesserungen einzuleiten."}
{"ts": "163:35", "speaker": "I", "text": "Sie hatten vorhin erwähnt, dass Sie bei Abhängigkeiten aus Orion und Nimbus eine Art Cross-Test-Plan entwickeln. Können Sie beschreiben, wie dieser Plan dokumentiert wird?"}
{"ts": "163:40", "speaker": "E", "text": "Ja, wir pflegen dafür ein zentrales Confluence-Board, das wöchentlich mit Daten aus dem Runbook RB-HER-042 abgeglichen wird. Da sind die Testfenster, API-Änderungslogs und Observability-KPIs alle verknüpft."}
{"ts": "163:48", "speaker": "I", "text": "Und wie stellen Sie sicher, dass die API-Änderungen aus Orion nicht erst zu spät in Ihre Testpipelines einfließen?"}
{"ts": "163:54", "speaker": "E", "text": "Wir haben eine Vorab-Benachrichtigung via unserem internen Event-Bus konfiguriert. Der triggert ein Jenkins-Job-Template, das vor dem Merge die relevanten Testfälle aus der Hera QA Platform automatisch zieht."}
{"ts": "164:02", "speaker": "I", "text": "Gibt es dabei auch manuelle Prüfpunkte?"}
{"ts": "164:06", "speaker": "E", "text": "Ja, ein Review-Step im QA-Standup. Da prüfen wir Änderungen gegen die Policy POL-QA-014, speziell den Abschnitt zu Third-Party API Stability."}
{"ts": "164:14", "speaker": "I", "text": "Das klingt sehr engmaschig. Welche Herausforderungen hatten Sie zuletzt bei dieser Koordination?"}
{"ts": "164:20", "speaker": "E", "text": "Vor zwei Sprints hatten wir eine Orion-Payload, die ein neues JSON-Feld enthielt. Nimbus-Logs zeigten erhöhte Latenzen, und wir mussten adhoc Tests aus Runbook RB-HER-057 ziehen, um Regressionen auszuschließen."}
{"ts": "164:30", "speaker": "I", "text": "Wie haben Sie das in Bezug auf SLA/SLO bewertet?"}
{"ts": "164:35", "speaker": "E", "text": "Unser SLO für Response-Zeit liegt bei 500ms P95. Die Latenzen lagen knapp drüber, also haben wir einen Defect mit ID QA-DEF-221 eröffnet und die Teststrategie für die API-Route angepasst."}
{"ts": "164:44", "speaker": "I", "text": "Mussten Sie dafür Tests depriorisieren, um schneller reagieren zu können?"}
{"ts": "164:48", "speaker": "E", "text": "Ja, wir haben niedrig priorisierte UI-Regressionstests verschoben. Das war ein bewusster Trade-off, um kritische Schnittstellen vor dem Release stabil zu bekommen."}
{"ts": "164:56", "speaker": "I", "text": "Wie wird eine solche Abweichung von der ursprünglichen Testplanung dokumentiert?"}
{"ts": "165:00", "speaker": "E", "text": "Wir nutzen dafür ein Deviations-Log im Jira-Board des Projekts. Jede Abweichung referenziert das entsprechende Runbook und den betroffenen SLA-Abschnitt."}
{"ts": "165:08", "speaker": "I", "text": "Gibt es Lessons Learned aus dieser Situation?"}
{"ts": "165:12", "speaker": "E", "text": "Definitiv: Wir haben jetzt einen automatischen Latenz-Alert in die Testorchestrierung integriert. So werden kritische Metriken schon im Build-Job sichtbar und nicht erst im Staging."}
{"ts": "165:05", "speaker": "I", "text": "Lassen Sie uns noch etwas tiefer in die Qualitätsmetriken eintauchen. Welche KPIs verfolgen Sie aktuell im Hera QA Platform Build?"}
{"ts": "165:15", "speaker": "E", "text": "Wir messen vor allem Defect Density pro Modul, Mean Time to Detect und Mean Time to Resolve. Zusätzlich tracken wir die Flakiness Rate pro Testrun – laut unserem Runbook RB-QA-07 liegt das Ziel bei unter 2%."}
{"ts": "165:31", "speaker": "I", "text": "Und wie fließen SLA- oder SLO-Vorgaben konkret in Ihre Planung ein?"}
{"ts": "165:40", "speaker": "E", "text": "Für SLA-Schnittstellen, die Orion Edge Gateway bereitstellt, haben wir SLOs von maximal 200ms Latenz in 95% der Calls. Wir mappen diese auf Performance-Regressionstests, die im Orchestrator als 'critical' markiert werden. Policy POL-QA-014 gibt hier die Priorisierung vor."}
{"ts": "165:57", "speaker": "I", "text": "Gab es Situationen, wo Metriken eine unmittelbare Strategieanpassung ausgelöst haben?"}
{"ts": "166:05", "speaker": "E", "text": "Ja, im Build-Sprint 12 zeigte das Nimbus Observability Dashboard eine steigende Error Rate von 1,8% auf 3,2% in API v2. Wir haben daraufhin die Regressionstests für diese API vorgezogen und ein Hotfix-Testset angelegt, siehe Ticket QA-HER-456."}
{"ts": "166:24", "speaker": "I", "text": "Interessant. Können Sie beschreiben, wie Sie in so einem Fall die Prioritäten neu setzen?"}
{"ts": "166:33", "speaker": "E", "text": "Wir nutzen eine Risiko-Matrix aus Runbook RB-QA-03. Hohe Auswirkung + hohe Eintrittswahrscheinlichkeit = sofortige Testslot-Reservierung. In dem API-Fall haben wir Low-Risk-UI-Tests verschoben, um mehr Kapazität für API-Loadtests zu schaffen."}
{"ts": "166:50", "speaker": "I", "text": "Gab es dabei Zielkonflikte mit anderen Teams?"}
{"ts": "166:58", "speaker": "E", "text": "Ja, das Frontend-Team wollte ihre neuen Komponenten sofort getestet haben. Wir mussten in einem Alignment-Call erklären, dass laut SLA-Verpflichtung die Backend-Stabilität Vorrang hatte. Wir haben das in Confluence unter 'Testplan Sprint 12' dokumentiert."}
{"ts": "167:15", "speaker": "I", "text": "Wie stellen Sie die Traceability zwischen den Anforderungen, Tests und Defects in solch dynamischen Situationen sicher?"}
{"ts": "167:23", "speaker": "E", "text": "Unser Orchestrator ist mit dem Requirement-Tool verknüpft. Jeder Testfall hat ein Feld 'Req-ID'. Defects in Jira tragen dieselbe ID. So können wir jederzeit von einer Anforderung über den Test zum Defect springen, auch wenn Testpläne kurzfristig geändert werden."}
{"ts": "167:40", "speaker": "I", "text": "Nutzen Sie für Toolauswahl oder Änderungen einen formalen Prozess?"}
{"ts": "167:48", "speaker": "E", "text": "Ja, RFC-gestützt. Beispiel: RFC-TOOL-22, in dem wir die Einführung des flaky test analytics Moduls beschrieben haben. Enthält Risikoanalyse, Integrationsplan mit Nimbus-Logs und eine Pilotphase in Staging."}
{"ts": "168:02", "speaker": "I", "text": "Abschließend: Gab es eine bewusste Abweichung von einer Policy, und wie haben Sie das begründet?"}
{"ts": "168:10", "speaker": "E", "text": "Im Sprint 9 haben wir von POL-QA-014 abgewichen, indem wir für ein Low-Priority-Feature keine vollständige Regression gefahren haben. Begründung: Liefertermin für einen Demo-Release, abgesichert durch manuelle Smoke-Tests. Dokumentiert in QA-HER-389 mit Freigabe des CTO."}
{"ts": "167:65", "speaker": "I", "text": "Sie hatten vorhin den Zusammenhang zwischen Nimbus und Orion erwähnt. Können Sie erläutern, wie diese Cross-Team Tests in der Praxis ablaufen, gerade wenn mehrere Subsysteme gleichzeitig betroffen sind?"}
{"ts": "168:10", "speaker": "E", "text": "Ja, klar. In solchen Fällen erstellen wir ein kombiniertes Test-Orchestration-Board in Hera, das sowohl die Observability-Events aus Nimbus als auch die API-Mocks von Orion berücksichtigt. Wir nutzen dafür Runbook RB-QA-077, das genau beschreibt, welche Schritte in welcher Reihenfolge zu triggern sind."}
{"ts": "168:42", "speaker": "I", "text": "Und wie stellen Sie sicher, dass diese kombinierten Tests die SLA-Anforderungen erfüllen?"}
{"ts": "169:05", "speaker": "E", "text": "Wir haben für kritische Endpunkte SLO-Definitionen in der Datei SLO-HERA-12 hinterlegt. Das Runbook verweist auf diese und in der Orchestrierung setzen wir automatische Threshold-Checks, sodass bei Überschreitung der erlaubten Latenz sofort ein Defect-Ticket im System erstellt wird."}
{"ts": "169:37", "speaker": "I", "text": "Gab es zuletzt einen Fall, wo so ein Threshold überschritten wurde?"}
{"ts": "170:00", "speaker": "E", "text": "Ja, im Ticket QA-448 haben wir dokumentiert, dass bei einem simultanen Deployment von Orion und Hera die Antwortzeit um 320 ms über dem SLO lag. Wir mussten daraufhin im Build die parallel laufenden Tests umstrukturieren."}
{"ts": "170:32", "speaker": "I", "text": "Interessant. Wie gehen Sie vor, wenn solche Anpassungen kurzfristig erfolgen müssen und die Testabdeckung trotzdem gewahrt bleiben soll?"}
{"ts": "170:58", "speaker": "E", "text": "Da greifen wir auf eine heuristische Priorisierung zurück: Zuerst die High-Risk-Flows aus POL-QA-014, dann die restlichen. Zusätzlich dokumentieren wir im Changelog, welche Szenarien temporär ausgesetzt wurden, und planen diese für einen Nightly-Run nach."}
{"ts": "171:29", "speaker": "I", "text": "Sie sprechen von heuristischer Priorisierung. Gibt es dafür ein festes Schema oder ist das eher Erfahrungssache?"}
{"ts": "171:52", "speaker": "E", "text": "Es ist ein Mix. Wir haben im internen Wiki eine Matrix hinterlegt, die Risiko, Komplexität und letzte Änderungszeit kombiniert. Aber ehrlich gesagt, in kritischen Momenten zählt auch mein Bauchgefühl und das der Senior Tester."}
{"ts": "172:20", "speaker": "I", "text": "Wie fließen flaky test analytics hier ein?"}
{"ts": "172:45", "speaker": "E", "text": "Die Analytics aus Hera zeigen uns, welche Tests in den letzten zehn Runs instabil waren. Diese markieren wir im Board und behandeln sie nur dann in der Hot-Path-Priorisierung, wenn sie High-Risk sind und wir einen Fix erwarten."}
{"ts": "173:12", "speaker": "I", "text": "Gab es schon mal die Entscheidung, solche Tests komplett aus einem Release-Zyklus zu nehmen?"}
{"ts": "173:36", "speaker": "E", "text": "Ja, das war ein bewusster Trade-off in Release 2.1. Laut Ticket QA-512 haben wir zwei instabile Orion-Integrationstests entfernt, um die Liefergeschwindigkeit zu halten. Das Risiko wurde im Risk-Log RSK-HERA-09 dokumentiert, mit Verweis auf die geplante Behebung im nächsten Sprint."}
{"ts": "174:08", "speaker": "I", "text": "Und rückblickend, war das die richtige Entscheidung?"}
{"ts": "174:32", "speaker": "E", "text": "Ja, weil wir die SLAs einhalten konnten und keine kritischen Incidents auftraten. Wir haben die Tests im Folgesprint gefixt und wieder integriert, was im Retrospective-Doc RETRO-HERA-21 positiv bewertet wurde."}
{"ts": "175:05", "speaker": "I", "text": "Sie hatten vorhin kurz die SLA-Kennzahlen angerissen – könnten Sie bitte genauer erläutern, welche KPIs für Sie im Hera-Projekt gerade am kritischsten sind?"}
{"ts": "175:18", "speaker": "E", "text": "Ja, aktuell sind es drei Kern-KPIs: die durchschnittliche Defect Resolution Time, die Testfall-Durchlaufquote pro Build und die Flaky-Test-Rate. Letztere messen wir wöchentlich, weil laut SLA-Sektion 4.3 keine Komponente über 2 % Flaky-Rate liegen darf."}
{"ts": "175:41", "speaker": "I", "text": "Und wenn diese Flaky-Rate überschritten wird – welche Maßnahmen greifen Sie dann?"}
{"ts": "175:50", "speaker": "E", "text": "Dann greifen wir Runbook RB-QA-009, das beschreibt einen dreistufigen Analyse- und Quarantäneprozess. Wir isolieren die betroffenen Tests, korrelieren mit Logdaten aus Nimbus und stimmen uns mit dem API-Team vom Orion Edge Gateway ab."}
{"ts": "176:16", "speaker": "I", "text": "Das klingt stark prozessorientiert. Gab es jüngst einen Fall, der dazu führte, dass Sie die Testplanung umstellen mussten?"}
{"ts": "176:27", "speaker": "E", "text": "Ja, Ticket QA-5721 dokumentiert so einen Fall: Ein API-Änderungs-Commit aus Orion führte zu 15 % Flaky-Rate in einem kritischen Regression-Cluster. Wir mussten in Sprint 42 die Prioritäten verschieben und nicht-funktionale Tests zugunsten von API-Stabilitätstests zeitlich vorziehen."}
{"ts": "176:55", "speaker": "I", "text": "Wie kommunizieren Sie solche Verschiebungen an Stakeholder, ohne dass es als Verzögerung wahrgenommen wird?"}
{"ts": "177:06", "speaker": "E", "text": "Wir binden es in unseren wöchentlichen Quality Report ein und verweisen auf die SLA-Verpflichtungen. Explizit steht dort, dass Stabilität Vorrang vor Feature-Delivery hat, wenn KPI-Schwellen überschritten sind."}
{"ts": "177:27", "speaker": "I", "text": "Haben Sie dabei auch schon mal gegen die Policy POL-QA-014 verstoßen, um schneller zu liefern?"}
{"ts": "177:37", "speaker": "E", "text": "Einmal, ja – im Ticket QA-5590 dokumentiert: Wir haben auf Anweisung des Product Owners ein High-Risk-Modul ohne vollständige Regression freigegeben. Wir haben das Risiko im Risk-Log RL-2023-11-18 transparent gemacht und einen Hotfix-Plan hinterlegt."}
{"ts": "178:02", "speaker": "I", "text": "Wie stellen Sie sicher, dass solche Entscheidungen nicht zur Regel werden?"}
{"ts": "178:11", "speaker": "E", "text": "Durch retrospektive Reviews im QA-Guild-Meeting und Anpassung der Runbooks. Nach QA-5590 haben wir RB-QA-014 um einen „Exception Approval“-Schritt mit CTO-Signoff ergänzt."}
{"ts": "178:34", "speaker": "I", "text": "Sie erwähnten vorhin die Traceability – wie gehen Sie vor, wenn Anforderungen aus mehreren Subsystemen gleichzeitig einfließen?"}
{"ts": "178:45", "speaker": "E", "text": "Wir nutzen das Hera Traceability Dashboard, das Jira-Epics aus verschiedenen Subsystemen verknüpft. So können wir z. B. eine Orion-API-Änderung direkt mit entsprechenden Testfällen und Nimbus-Observability-Metriken verbinden."}
{"ts": "179:08", "speaker": "I", "text": "Wie wirkt sich diese Verknüpfung auf Ihre Risikoanalyse aus?"}
{"ts": "179:17", "speaker": "E", "text": "Sie erlaubt uns eine Multi-Hop-Risikoabschätzung: Wir sehen, wenn eine API-Änderung nicht nur die direkte Funktion betrifft, sondern über Observability-Trigger auch Alarm-Logiken beeinflusst. Das haben wir bei QA-5721 genutzt, um zusätzliche Tests in den Build zu ziehen."}
{"ts": "184:05", "speaker": "I", "text": "Wir hatten eben das Thema Metriken kurz gestreift. Mich würde interessieren, welche KPIs Sie im Hera QA Platform Projekt konkret verfolgen, um Qualität messbar zu machen."}
{"ts": "184:20", "speaker": "E", "text": "Aktuell tracken wir primär Defect-Density pro Release-Zyklus, Mean Time to Detect, Mean Time to Resolve und den Flaky-Test-Anteil. Letzteren haben wir seit Einführung der automatischen Retries um 18 % senken können."}
{"ts": "184:38", "speaker": "I", "text": "Und wie wirken sich SLA- oder SLO-Vorgaben auf Ihre Testplanung aus?"}
{"ts": "184:48", "speaker": "E", "text": "Wir haben im internen SLA-Dokument SLA-QA-022 festgelegt, dass kritische Bugs innerhalb von 24 h nach Detektion gepatcht sein müssen. Das zwingt uns, in den Smoke-Tests eine hohe Priorität auf die High-Risk-Pfade zu legen und Regressionstests in Parallelpipelines zu fahren."}
{"ts": "185:10", "speaker": "I", "text": "Gab es ein Beispiel, wo eine Metrik direkt zu einer Anpassung der Strategie geführt hat?"}
{"ts": "185:18", "speaker": "E", "text": "Ja, im Build 1.4 zeigte unser KPI-Board eine MTTR von über 72 h für Module aus dem Orion-Adapter. Wir haben daraufhin eine dedizierte 'hotfix lane' in der CI erstellt und im Runbook RB-QA-07 dokumentiert, dass Orion-Adapter-Tests nun isoliert ausführbar sind."}
{"ts": "185:42", "speaker": "I", "text": "Sie hatten vorhin schon die Toolauswahl erwähnt. Gibt es dafür einen formalen, RFC-gestützten Prozess?"}
{"ts": "185:51", "speaker": "E", "text": "Ja, jede Tool-Neueinführung muss über ein RFC-Dokument laufen, z. B. RFC-QA-311 für den Wechsel zu Orchestrator ProX. Darin werden Integrationsaufwand, Sicherheitsaspekte und Kompatibilität mit Nimbus-Feeds bewertet."}
{"ts": "186:12", "speaker": "I", "text": "Wie binden Sie flaky test analytics aus Orchestrator ProX in den Workflow ein?"}
{"ts": "186:23", "speaker": "E", "text": "ProX liefert uns nach jedem Run einen Confidence Score pro Test. Alles unter 0,85 Flaggen wir, ein Jenkins-Job schreibt dann automatisch ein Ticket im QA-Board (Prefix FTA-) und verlinkt direkt auf die Nimbus-Logs."}
{"ts": "186:45", "speaker": "I", "text": "Gab es jüngst eine Abhängigkeit, die besondere Beachtung brauchte?"}
{"ts": "186:53", "speaker": "E", "text": "Ja, der letzte Merge vom Helios Payment Modul in Hera. Wir mussten parallel Observability-Daten aus Nimbus abgreifen und gleichzeitig gegen die neuen Auth-APIs aus Orion testen. Im Runbook RB-QA-12 haben wir eine Schritt-für-Schritt-Paralleltest-Sequenz definiert."}
{"ts": "187:18", "speaker": "I", "text": "Können Sie dazu ein wenig mehr ins Detail gehen, wie Sie die Paralleltests orchestriert haben?"}
{"ts": "187:28", "speaker": "E", "text": "Wir haben die Testmatrix in zwei Achsen aufgeteilt: Feature-Fokus und System-Interaktion. Mit Orchestrator ProX ließen sich die Szenarien in getrennten Pipelines fahren, während Nimbus-Streams synchronisiert wurden. Das minimierte Race Conditions."}
{"ts": "187:50", "speaker": "I", "text": "Wenn Sie auf die Build-Phase zurückblicken: Gab es eine Entscheidung, bei der Sie bewusst von einer Policy abgewichen sind?"}
{"ts": "187:59", "speaker": "E", "text": "Ja, bei POL-QA-014 steht eigentlich, dass keine nicht-reproduzierbaren Bugs geschlossen werden dürfen. In Sprint 37 haben wir Ticket QA-1423 trotzdem auf 'won’t fix' gesetzt, weil die Repro-Rate unter 5 % lag und das SLA-Risiko höher war, wenn wir weitere Ressourcen blockieren. Das haben wir mit Verweis auf RB-QA-Exceptions dokumentiert."}
{"ts": "192:45", "speaker": "I", "text": "Sie hatten vorhin die Metriken kurz angerissen. Können Sie bitte noch genauer erklären, welche KPIs aktuell im Hera QA Platform Build-Phase Dashboard getrackt werden?"}
{"ts": "193:02", "speaker": "E", "text": "Ja, klar. Wir haben im QA-Board vor allem die Build-Verlässlichkeit, Defect Escape Rate, also wie viele Bugs in die Staging-Umgebung durchrutschen, und die durchschnittliche Flaky-Test-Quote. Zusätzlich tracken wir die Mean Time to Detect und Mean Time to Repair aus dem Runbook RB-QA-018."}
{"ts": "193:28", "speaker": "I", "text": "Und wie fließen SLA- oder SLO-Vorgaben in diese Metriken ein?"}
{"ts": "193:41", "speaker": "E", "text": "Unsere SLA mit dem internen DevOps-Team besagt, dass Critical Bugs innerhalb von 4 Stunden nach Deployment-Start erkannt werden müssen. Das SLO für Flaky Tests liegt bei maximal 5% pro Test-Suite. Wir haben dafür in der Testorchestrierung einen Alert-Job konfiguriert, der gegen diese Schwellen prüft."}
{"ts": "194:05", "speaker": "I", "text": "Gab es kürzlich einen Fall, wo ein KPI direkt zu einer Anpassung der Teststrategie geführt hat?"}
{"ts": "194:16", "speaker": "E", "text": "Ja, im Ticket QA-2341 haben wir festgestellt, dass die Defect Escape Rate über zwei Sprints hinweg 2% über dem Zielwert lag. Wir haben daraufhin die Smoke-Tests für die API-Endpunkte aus Orion Edge Gateway erweitert und parallel mehr Observability-Checks aus Nimbus eingebunden."}
{"ts": "194:42", "speaker": "I", "text": "Interessant. Wenn Sie sagen, Sie haben mehr Observability-Checks eingebunden – war das ein formaler Prozess über ein RFC?"}
{"ts": "194:54", "speaker": "E", "text": "Genau, das lief über RFC-QA-77. Darin haben wir die neuen Metrik-Feeds aus Nimbus spezifiziert und im Testorchestrator konfiguriert. Der RFC wurde gemeinsam mit dem Observability-Architekten abgestimmt und in Runbook RB-QA-022 dokumentiert."}
{"ts": "195:18", "speaker": "I", "text": "Wie gehen Sie bei solchen Anpassungen mit dem Risiko um, die Build-Zeit zu verlängern?"}
{"ts": "195:31", "speaker": "E", "text": "Wir machen eine Risikobewertung im QA-Risk-Log. Dort kalkulieren wir, wie viel zusätzliche Ausführungszeit akzeptabel ist, um die SLA einzuhalten. Im Fall von RFC-QA-77 war das ein +3 Minuten Build-Zuwachs, was unterhalb unserer 10%-Toleranz lag."}
{"ts": "195:55", "speaker": "I", "text": "Gab es schon Situationen, wo Sie bewusst gegen eine Policy wie POL-QA-014 verstoßen haben?"}
{"ts": "196:05", "speaker": "E", "text": "Einmal, ja – im Incident INC-HE-092. Wir mussten ein Hotfix-Release ohne vollständige risikobasierte Testabdeckung freigeben, weil eine kritische Sicherheitslücke bestand. Dokumentiert haben wir das im Deviation-Report DR-014, mit Genehmigung des CTO."}
{"ts": "196:31", "speaker": "I", "text": "Wie wird so ein Deviation-Report später in den Lessons-Learned-Prozess integriert?"}
{"ts": "196:43", "speaker": "E", "text": "Wir besprechen jeden DR im monatlichen QA-Guild-Meeting. Die Abweichung aus DR-014 führte dazu, dass wir ein Mini-Testset im Runbook RB-QA-030 verankert haben, das bei Hotfixes obligatorisch ist, um zumindest Kernfunktionen zu prüfen."}
{"ts": "197:07", "speaker": "I", "text": "Welche ungeschriebenen Regeln haben sich in Ihrem Team in Bezug auf solche Entscheidungen etabliert?"}
{"ts": "197:20", "speaker": "E", "text": "Eine wichtige ungeschriebene Regel ist: Wenn wir von Policies abweichen, muss mindestens einer aus dem QA-Lead-Kreis und einer aus dem DevOps-Team zustimmen, auch wenn es formell nicht vorgeschrieben ist. Das sorgt für gegenseitige Absicherung und Vertrauen."}
{"ts": "200:45", "speaker": "I", "text": "Lassen Sie uns noch einmal auf die Qualitätsmetriken zurückkommen – welche KPIs haben sich in den letzten Sprints als besonders kritisch erwiesen?"}
{"ts": "201:10", "speaker": "E", "text": "Wir haben zuletzt den Defect Leakage Rate und die Test Execution Coverage sehr eng verfolgt. Vor allem der Leakage Rate KPI aus Sprint 42–44 lag laut Runbook QA-MET-07 über dem internen Grenzwert von 2 %, was sofortige Root-Cause-Analysen auslöste."}
{"ts": "201:45", "speaker": "I", "text": "Und wie haben diese Analysen konkret Ihre Testplanung beeinflusst?"}
{"ts": "202:05", "speaker": "E", "text": "Wir haben in RFC #HER-QA-311 dokumentiert, dass wir Regression Suites gegen das Orion Edge Gateway API stärker parallelisieren müssen. Das kam aus der Beobachtung, dass die erhöhten Defect Rates aus genau diesen Integrationspunkten stammten."}
{"ts": "202:40", "speaker": "I", "text": "Gab es dabei Zielkonflikte mit bestehenden SLAs oder SLOs?"}
{"ts": "203:00", "speaker": "E", "text": "Ja, das SLA mit dem Produktteam schreibt vor, dass kritische Integrationsbugs binnen 24 Stunden gefixt und verifiziert werden. Die Parallelisierung bedeutete aber auch, dass wir unsere Testumgebungen häufiger neu aufsetzen mussten – was das SLA-Risiko kurzfristig erhöht hat."}
{"ts": "203:35", "speaker": "I", "text": "Wie sind Sie damit umgegangen?"}
{"ts": "203:50", "speaker": "E", "text": "Wir haben eine temporäre Ausnahme im SLA verhandelt, Ticket SLA-EXC-19, gültig für drei Sprints. Parallel haben wir im Runbook ENV-SETUP-05 einen schnelleren Deployment-Workflow für QA-Umgebungen eingepflegt."}
{"ts": "204:25", "speaker": "I", "text": "Interessant. Gab es auch qualitative Metriken, die Sie einbezogen haben?"}
{"ts": "204:40", "speaker": "E", "text": "Ja, wir haben User Journey Stability Scores aus dem Nimbus Observability Feed aggregiert. Die Scores zeigen, ob reale Nutzerszenarien in Staging stabil laufen. Ein Rückgang um mehr als 5 Punkte triggert bei uns automatische Exploratory Tests."}
{"ts": "205:15", "speaker": "I", "text": "Können Sie ein Beispiel nennen, wo genau so ein Trigger ausgelöst wurde?"}
{"ts": "205:35", "speaker": "E", "text": "Letzten Monat, bei Build #HER-921, ist der Score für den Checkout-Flow auf 82 gefallen. Das hat dazu geführt, dass wir ein Ad-hoc-Testteam gebildet haben, um mögliche Race Conditions in der Payment-API zu finden – dokumentiert in DEF-HER-447."}
{"ts": "206:05", "speaker": "I", "text": "Gab es dabei wieder den Zielkonflikt Geschwindigkeit versus Tiefe der Analyse?"}
{"ts": "206:20", "speaker": "E", "text": "Definitiv. Wir hätten die Analyse vertiefen können, aber der Release-Zyklus war bereits fix. Wir haben daher 80 % der Findings sofort gefixt und die restlichen als Known Issues mit Workarounds in KB-HER-12 erfasst."}
{"ts": "206:55", "speaker": "I", "text": "Abschließend – wie dokumentieren Sie solche Trade-offs für die Nachvollziehbarkeit?"}
{"ts": "207:15", "speaker": "E", "text": "Alle Abweichungen von Policies oder SLAs werden in unserem QA Decision Log hinterlegt, referenziert auf Tickets, Runbooks und betroffene Sprints. So können wir bei Audits jederzeit belegen, warum wir welche Entscheidung unter welchen Risiken getroffen haben."}
{"ts": "215:45", "speaker": "I", "text": "Könnten Sie noch einmal genauer erläutern, wie Sie SLAs in Ihre Testmetriken einbinden, gerade wenn sich während der Build-Phase Anforderungen verschieben?"}
{"ts": "216:02", "speaker": "E", "text": "Ja, also wir haben im Hera Projekt für jede kritische User Journey ein SLO-Dokument im Confluence hinterlegt. Das verknüpfen wir direkt mit unseren automatisierten Test-Suites über die Test-ID-Referenz. Wenn sich Anforderungen verschieben, aktualisieren wir die SLA-Referenzen in unserem Runbook RB-HER-OPS-07, damit die Berichte konsistent bleiben."}
{"ts": "216:28", "speaker": "I", "text": "Und wie schnell können Sie so ein Update in der Praxis umsetzen?"}
{"ts": "216:40", "speaker": "E", "text": "Meistens innerhalb von einem Sprint, also zwei Wochen. Wir haben dafür ein kleines Script in unserer Pipeline, das die SLA-IDs aus einer YAML-Datei zieht und mit dem Testmanagement-Tool synchronisiert."}
{"ts": "216:59", "speaker": "I", "text": "Gab es jüngst ein Beispiel, wo so ein Update besonders kritisch war?"}
{"ts": "217:12", "speaker": "E", "text": "Ja, Ticket QA-4827. Da wurde die Latenzanforderung für den Payment-Service gesenkt, und wir mussten binnen weniger Tage die Lasttests nachjustieren, sonst hätten wir das SLA verfehlt."}
{"ts": "217:32", "speaker": "I", "text": "Wie haben Sie in diesem Fall mit dem Development-Team koordiniert?"}
{"ts": "217:45", "speaker": "E", "text": "Wir haben ein Ad-hoc Meeting mit dem Dev Lead und dem Ops-Team gehalten, direkt nach dem Eingang der Anforderung. Dort haben wir die Testorchestrierung angepasst und die Observability-Alerts in Nimbus so eingestellt, dass wir Vorwarnungen bei 80% Latenzauslastung bekommen."}
