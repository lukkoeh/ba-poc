{"ts": "00:00", "speaker": "I", "text": "Können Sie mir kurz den aktuellen Stand des Atlas Mobile Piloten schildern?"}
{"ts": "01:15", "speaker": "E", "text": "Ja, gern. Wir sind jetzt seit sechs Wochen live mit einer begrenzten Nutzergruppe von etwa 120 internen Field Engineers. Die Kernfunktionen – Auftragsübersicht, Ticket-Updates und Basis-Offline-Sync – sind aktiv. Wir tracken KPIs wie Sync-Erfolgsquote und durchschnittliche Ladezeiten im internen Dashboard. Das Ganze läuft unter Feature Flags, so dass wir neue Module wie die Geo-Tagging-Funktion nur für Untergruppen freischalten."}
{"ts": "03:05", "speaker": "I", "text": "Was war denn ursprünglich der Auslöser für dieses Projekt?"}
{"ts": "04:20", "speaker": "E", "text": "Der initiale Trigger kam aus einer Serviceprozess-Analyse im letzten Jahr. Wir haben festgestellt, dass Techniker oft in Regionen ohne stabile Netzabdeckung arbeiten und dadurch Auftragsdaten verzögert ins System gelangen. Die Geschäftsführung hat dann entschieden, eine cross-platform Lösung zu entwickeln, um die Durchgängigkeit der Prozesse zu verbessern und gleichzeitig die Abhängigkeit von einzelnen mobilen Betriebssystemen zu reduzieren."}
{"ts": "06:10", "speaker": "I", "text": "Wie passt Atlas Mobile in die Gesamtstrategie von Novereon Systems?"}
{"ts": "07:25", "speaker": "E", "text": "Das Projekt ist ein Baustein unserer Mobile-First-Initiative. Wir wollen, dass 80 % der Service-Interaktionen bis 2026 auch mobil abgewickelt werden können. Atlas Mobile ist außerdem ein Testfeld für unser Feature-Flag-Framework, das später auch in anderen Produktlinien wie Novereon CRM eingesetzt werden soll."}
{"ts": "09:00", "speaker": "I", "text": "Welche Hauptnutzergruppen haben Sie denn aktuell identifiziert?"}
{"ts": "10:15", "speaker": "E", "text": "Primär sind das die Field Engineers, wie erwähnt. Sekundär gibt es Pilotkunden aus dem Bereich Anlagenwartung, die wir bewusst früh einbezogen haben, um echtes Kundenfeedback zu sammeln. Intern haben wir auch ein kleines QA-Team, das die App im Alltag nutzt, um Edge Cases zu finden."}
{"ts": "12:00", "speaker": "I", "text": "Wie sammeln Sie denn aktuell Feedback aus der Pilotphase?"}
{"ts": "13:20", "speaker": "E", "text": "Wir kombinieren mehrere Kanäle: wöchentliche Umfragen via In-App-Popups, strukturierte Interviews alle zwei Wochen, und wir werten Support-Tickets im internen JIRA-Board aus. Außerdem haben wir ein Slack-Channel #atlas-pilotfeedback, wo spontane Beobachtungen gepostet werden."}
{"ts": "15:05", "speaker": "I", "text": "Gab es ein konkretes Beispiel, wo Kundenfeedback direkte Priorisierungsänderungen bewirkt hat?"}
{"ts": "16:30", "speaker": "E", "text": "Ja, gleich in der zweiten Woche haben mehrere Field Engineers bemängelt, dass die Offline-Suche nur auf Kunden-ID, nicht aber auf Standortnamen funktioniert. Wir haben das als Ticket MOB-2145 hochpriorisiert, da es die Nutzbarkeit im Feld stark einschränkte. Innerhalb von acht Tagen war der Patch unter einem Feature Flag ausgerollt."}
{"ts": "18:15", "speaker": "I", "text": "Welche kritischen Abhängigkeiten bestehen zu anderen Plattform- oder Backend-Teams?"}
{"ts": "19:40", "speaker": "E", "text": "Die größte Abhängigkeit ist das Sync-Backend vom Cloud Services Team. Sie stellen die API-Gateways und das Conflict-Resolution-Modul. Außerdem hängt unsere Authentifizierung am Identity Provider des Security-Teams. Änderungen dort müssen wir früh testen, sonst bricht uns die Login-Funktion weg."}
{"ts": "21:30", "speaker": "I", "text": "Wie nutzen Sie Feature Flags, um Risiken zu minimieren?"}
{"ts": "22:55", "speaker": "E", "text": "Wir haben in unserem Runbook RB-FF-03 definiert, dass neue Features zunächst nur für 5 % der Pilotnutzer aktiviert werden, dann stufenweise hochskaliert. Bei Fehlermeldungen über ein definiertes Threshold im Error-Monitoring wird automatisch ein Rollback-Flag gesetzt. Das erlaubt uns, problematische Funktionen ohne App-Update zu deaktivieren."}
{"ts": "90:00", "speaker": "I", "text": "Sie hatten vorhin die Abhängigkeiten zu anderen Plattformteams erwähnt – können Sie das etwas genauer ausführen?"}
{"ts": "90:10", "speaker": "E", "text": "Ja, also wir hängen stark am Identity-Service, der von unserem Core-Platform-Team betreut wird. Ohne deren OAuth-Refresh-Endpoint würde die Offline-Sync-Queue nicht sauber entleert. Außerdem brauchen wir das Billing-API vom ERP-Integrations-Team, um bestimmte Datensätze korrekt zu taggen."}
{"ts": "90:35", "speaker": "I", "text": "Und wie koordinieren Sie diese Abhängigkeiten, gerade in einer Pilotphase?"}
{"ts": "90:44", "speaker": "E", "text": "Wir nutzen wöchentliche Sync-Calls und ein gemeinsames Dependency-Board in Jira. Dort sind z. B. Tasks wie DEP-421 verlinkt, das war die Anpassung der Token-Lifetime für längere Offline-Perioden. Wir haben auch ein internes SLA-Dokument, SLA-MOB-02, das Reaktionszeiten für kritische Fehler zwischen den Teams festlegt."}
{"ts": "91:08", "speaker": "I", "text": "Feature Flags kamen auch zur Sprache – wie setzen Sie die in diesem Kontext ein?"}
{"ts": "91:17", "speaker": "E", "text": "Wir haben ein zentrales Flag-Management, das per Config-Endpoint gesteuert wird. Für den Pilot haben wir z. B. das Flag 'offline_sync_v2' nur für Nutzergruppe 'FieldTest' aktiviert. So konnten wir gezielt die neue Conflict-Resolution-Logik testen, ohne alle Pilotteilnehmer zu beeinflussen."}
{"ts": "91:42", "speaker": "I", "text": "Gab es Fälle, in denen so ein Flag auch mal Probleme verursacht hat?"}
{"ts": "91:51", "speaker": "E", "text": "Ja, einmal wurde ein Flag versehentlich im Staging-Cluster deaktiviert, Ticket FF-137. Das führte dazu, dass QA-Tests auf veralterter Logik liefen. Wir haben daraufhin im Runbook RB-FLAG-04 einen Schritt ergänzt: 'Double-check Flag-Status vor Testdurchlauf'."}
{"ts": "92:15", "speaker": "I", "text": "Beim Offline-Sync – wie stellen Sie Robustheit sicher, gerade bei langen Verbindungsausfällen?"}
{"ts": "92:24", "speaker": "E", "text": "Wir simulieren in QA bewusst Netzabbrüche von bis zu 72 Stunden, basierend auf Feldberichten aus ländlichen Regionen. Unser Sync-Client speichert Änderungen in einer lokalen SQLite-DB mit Versionsstempeln. Der Merge-Algorithmus läuft in einer isolierten Worker-Queue, die nach RFC-SYNC-07 implementiert ist."}
{"ts": "92:52", "speaker": "I", "text": "Welche Edge Cases haben Sie dabei schon identifiziert?"}
{"ts": "93:00", "speaker": "E", "text": "Ein häufiger Edge Case sind doppelte Primärschlüssel nach parallelen Änderungen offline und online. Wir hatten z. B. in Testfall OS-EC-12 zwei Nutzer, die denselben Auftrag offline editierten. Unser Merge-Tool musste den Konflikt anhand des 'last_write_wins'-Heuristik und eines Nutzer-Priority-Feldes auflösen."}
{"ts": "93:26", "speaker": "I", "text": "Und wie arbeitet das QA-Team mit Ihnen zusammen, um solche Fälle zu prüfen?"}
{"ts": "93:35", "speaker": "E", "text": "Wir führen gemeinsame Test-Sessions durch, die im QA-Kalender als 'Sync Storm' markiert sind. QA nutzt Skripte aus dem Git-Repo 'mob-sync-tests', um definierte Konfliktmuster zu erzeugen. Nach jedem Run werden die Ergebnisse in TestRail unter dem Plan 'Pilot Offline Sync v2' dokumentiert."}
{"ts": "94:00", "speaker": "I", "text": "Das heißt, Sie verknüpfen Nutzerfeedback, technische Abhängigkeiten und Testprozesse recht eng?"}
{"ts": "94:09", "speaker": "E", "text": "Genau. Wenn z. B. Feldnutzer melden, dass bei schlechtem Empfang bestimmte Datensätze verschwinden, prüfen wir, ob das ein Sync-Edge-Case ist, ob ein Feature Flag aktiv war und ob Backend-Änderungen zeitgleich liefen. Erst wenn alle drei Stränge passen, priorisieren wir einen Fix in den nächsten Sprint."}
{"ts": "96:00", "speaker": "I", "text": "Wir hatten ja schon über QA und die Edge Cases gesprochen – können Sie mir nun ein konkretes Beispiel nennen, wo Sie zwischen Time-to-Market und Funktionsumfang abwägen mussten?"}
{"ts": "96:20", "speaker": "E", "text": "Ja, das war im April, als wir die erste Version für den internen Vertrieb launchen wollten. Wir hatten das Feature 'Delta-Sync' fast fertig, aber es gab noch offene Bugs im Ticket #ATLMOB-327. Laut Runbook R-OS-12 hätten wir eigentlich noch zwei volle Testzyklen gebraucht. Wir haben uns dann entschieden, Delta-Sync über Feature Flag zu deaktivieren, um den Release-Termin zu halten."}
{"ts": "96:55", "speaker": "I", "text": "Gab es dafür intern viel Diskussion?"}
{"ts": "97:05", "speaker": "E", "text": "Auf jeden Fall. Das Backend-Team wollte es live sehen, um Lasttests unter Realbedingungen zu fahren. Aber im Steering-Committee-Meeting (Protokoll SC-2023-04-15) war klar: Time-to-Market hat Priorität, mit der Bedingung, dass wir das Feature in der folgenden Iteration stabilisieren."}
{"ts": "97:35", "speaker": "I", "text": "Wie dokumentieren Sie solche Trade-off-Entscheidungen?"}
{"ts": "97:45", "speaker": "E", "text": "Wir haben im Confluence-Bereich 'Atlas Mobile Decisions' eine Vorlage, die neben Risikoabschätzung, betroffenen SLAs und Rückfallplan auch die Entscheidungsträger listet. Für Delta-Sync war der Rückfallplan einfach: Flag off, bis QA-Runbook R-OS-12 erfüllt ist."}
{"ts": "98:15", "speaker": "I", "text": "Sie erwähnten SLAs – wie fließen regulatorische Anforderungen da ein?"}
{"ts": "98:25", "speaker": "E", "text": "Wir haben für Kundendaten einen internen SLA von 99,5% Sync-Verfügbarkeit, plus die DSGVO-Anforderungen. Bei Offline-Sync gilt: keine Daten dürfen verloren gehen, auch wenn der Client 72 Stunden offline ist. Das ist in SLA-Dokument SLA-ATL-01 definiert. Entsprechend wird jede Entscheidung gegen diese Vorgaben geprüft."}
{"ts": "98:55", "speaker": "I", "text": "Wenn Sie auf die gesamte Pilotphase schauen – welche Hauptrisiken sehen Sie aktuell?"}
{"ts": "99:05", "speaker": "E", "text": "Nummer eins ist die Abhängigkeit von der Auth-Plattform, die gerade selbst migriert wird (Projekt P-AUTH-MIG). Das zweite ist die Netzwerkinstabilität in ländlichen Pilotregionen, was Offline-Sync stark beansprucht. Drittes Risiko: Feature-Flag-Management bei gleichzeitigen Hotfixes, siehe Incident #INC-2023-09-07."}
{"ts": "99:40", "speaker": "I", "text": "Wie adressieren Sie diese Risiken proaktiv?"}
{"ts": "99:50", "speaker": "E", "text": "Für Punkt eins stimmen wir uns wöchentlich mit dem Auth-Team ab, haben sogar ein gemeinsames Runbook-Addendum erstellt. Für Netzwerkinstabilität führen wir in QA künstliche Paketverluste ein (Testplan TP-NET-05). Beim Feature-Flag-Management haben wir ein Vier-Augen-Prinzip vor Deployments eingeführt."}
{"ts": "100:20", "speaker": "I", "text": "Und welche Meilensteine stehen als Nächstes an?"}
{"ts": "100:30", "speaker": "E", "text": "Ende des Quartals wollen wir die Pilotphase abschließen und eine Go/No-Go-Entscheidung für den Rollout treffen. Erfolg messen wir an drei KPIs: tägliche aktive Nutzer > 500, Sync-Fehlerquote < 0,5% und positives Feedback von mindestens 70% der Pilot-User laut Survey SURV-ATL-2."}
{"ts": "101:00", "speaker": "I", "text": "Letzte Frage: Gibt es Lessons Learned, die Sie schon jetzt ableiten können?"}
{"ts": "101:10", "speaker": "E", "text": "Ja – Feature Flags sind mächtig, aber nur mit klaren Prozessen sicher. Außerdem: frühes Einbeziehen von QA in die Definition von Offline-Edge-Cases spart später viel Aufwand. Und: Entscheidungen müssen transparent dokumentiert werden, damit bei Risiken wie im Incident #INC-2023-09-07 nicht erst lange Ursachenforschung nötig ist."}
{"ts": "112:00", "speaker": "I", "text": "Lassen Sie uns mal zu den Priorisierungen kommen – gab es zuletzt einen Moment, in dem Sie zwischen einem engen Release-Zeitfenster und zusätzlichen Features abwägen mussten?"}
{"ts": "112:15", "speaker": "E", "text": "Ja, das war vor etwa sechs Wochen, als wir den letzten Build für die Pilotgruppe fertigstellen mussten. Wir standen vor der Wahl, die neue Kartenansicht mit Heatmap noch einzubauen oder pünktlich zum geplanten Start innerhalb des vereinbarten SLA-Fensters zu releasen. Wir haben uns für Time-to-Market entschieden, da die SLA-Vereinbarung mit den Pilotkunden klar den Zeitrahmen vorgibt."}
{"ts": "112:44", "speaker": "I", "text": "Und wie dokumentieren Sie solche Trade-offs?"}
{"ts": "112:50", "speaker": "E", "text": "Wir nutzen dafür unser internes Decision-Log im Confluence, verknüpft mit den Jira-Tickets. In diesem Fall war es das Ticket P-ATL-347. Dort haben wir in einem Abschnitt 'Abwägung' die Gründe, die Risiken und die Auswirkungen auf Folge-Features beschrieben."}
{"ts": "113:13", "speaker": "I", "text": "Gab es dabei auch regulatorische Anforderungen, die Ihre Entscheidung beeinflusst haben?"}
{"ts": "113:20", "speaker": "E", "text": "Ja, indirekt. Unsere Kartenansicht hätte eine zusätzliche Datenquelle aus einem Drittland angebunden, und die Datenschutzprüfung gem. interner Richtlinie DS-Runbook-07 war noch nicht abgeschlossen. Das war ein weiterer Grund, die Integration zu verschieben."}
{"ts": "113:44", "speaker": "I", "text": "Verstehe. Wie binden Sie QA in solche Verschiebungen ein, gerade wenn es um mögliche spätere Regressions geht?"}
{"ts": "113:52", "speaker": "E", "text": "QA bekommt sofort ein Update im Test-Plan-Dokument, und wir setzen ein Flag im Testmanagement-Tool, um Regressionstests für diese Komponente zu terminieren. Für Offline-Sync haben wir z.B. immer einen Batch an Edge Case-Tests in Reserve, falls Features später integriert werden."}
{"ts": "114:18", "speaker": "I", "text": "Was sind aktuell die Hauptrisiken, die Sie für Atlas Mobile sehen?"}
{"ts": "114:24", "speaker": "E", "text": "Das größte Risiko ist derzeit die Synchronisationslogik bei sehr hoher Datenlast. In unseren Stresstests (Ticket QA-ATL-221) haben wir gesehen, dass bei einer Netzunterbrechung während des Delta-Merges Daten dupliziert werden können. Außerdem gibt es Abhängigkeiten zu einem Backend-Service, der noch nicht redundant läuft."}
{"ts": "114:54", "speaker": "I", "text": "Wie adressieren Sie diese Risiken proaktiv?"}
{"ts": "115:00", "speaker": "E", "text": "Wir haben mit dem Backend-Team ein RFC-Dokument (RFC-BE-142) erstellt, um die Service-Redundanz bis zum nächsten Meilenstein sicherzustellen. Für die Sync-Logik haben wir ein Feature Flag 'safe_merge_mode' eingeführt, das in kritischen Umgebungen automatisch aktiviert wird und einen konservativeren Merge-Algorithmus nutzt."}
{"ts": "115:26", "speaker": "I", "text": "Welche Meilensteine stehen als Nächstes an und woran messen Sie den Erfolg?"}
{"ts": "115:32", "speaker": "E", "text": "Als Nächstes, in sechs Wochen, steht die Ausweitung des Piloten auf zwei weitere Kundengruppen an. Erfolg messen wir dabei an drei KPIs: Fehlerrate bei der Synchronisation < 0,5%, App-Startzeit unter 2 Sekunden und mindestens 80% positive Rückmeldungen in den Pilotumfragen."}
{"ts": "115:56", "speaker": "I", "text": "Gibt es für diese KPIs automatisierte Monitoring-Lösungen?"}
{"ts": "116:00", "speaker": "E", "text": "Ja, wir haben in unserem Observability-Stack Dashboards eingerichtet, die auf den Runbook-Triggern basieren. Zum Beispiel löst ein Anstieg der Sync-Fehlerrate über 0,3% einen Alert im Incident-Channel aus, und wir haben definierte Playbooks, um innerhalb von 30 Minuten zu reagieren."}
{"ts": "128:00", "speaker": "I", "text": "Sie hatten vorhin die QA-Tests angesprochen – können Sie mir erklären, wie genau die Erkenntnisse aus diesen Tests in Ihre Release-Planung einfließen?"}
{"ts": "128:20", "speaker": "E", "text": "Ja, also wir haben einen festen Slot im zweiwöchigen Sprint, wo QA-Reports ausgewertet werden. Diese sind im Runbook QA-RB-17 dokumentiert. Falls dort ein Edge Case mit hoher Priorität auftaucht, wird ein Hotfix-Flag im Feature-Flag-Dashboard gesetzt, um das Feature gezielt zu deaktivieren, bis ein Patch eingespielt ist."}
{"ts": "128:50", "speaker": "I", "text": "Und diese Hotfix-Flags – wie lange bleiben die typischerweise aktiv?"}
{"ts": "129:05", "speaker": "E", "text": "Das variiert, aber im Median etwa 36 Stunden. Wir haben intern die Policy PR-FF-03, die besagt, dass Flags entweder nach erfolgreichem Regressionstest oder nach Ablauf von 72 Stunden entfernt werden müssen, um Technical Debt zu vermeiden."}
{"ts": "129:35", "speaker": "I", "text": "Können Sie ein Beispiel nennen, bei dem so ein Flag tatsächlich größere Probleme verhindert hat?"}
{"ts": "129:50", "speaker": "E", "text": "Ja, Ticket ATLAS-482: während der Pilotphase hat eine Änderung im Backend-Schema eine NullPointerException in der Offline-Sync-Queue ausgelöst. Das Flag 'sync_batch_v2' wurde sofort deaktiviert und so wurde ein Ausrollen auf alle 120 Pilotnutzer verhindert."}
{"ts": "130:15", "speaker": "I", "text": "Das klingt nach einem direkten Zusammenspiel zwischen Backend- und Mobile-Team."}
{"ts": "130:30", "speaker": "E", "text": "Absolut, wir arbeiten hier eng über den Integrationskanal in unserem Chat-Tool zusammen. Außerdem gibt es das wöchentliche Cross-Team-Sync-Meeting. Da wird anhand des Dependency-Boards geprüft, ob Änderungen kollidieren könnten."}
{"ts": "130:55", "speaker": "I", "text": "Wie sieht in diesem Kontext Ihre Zusammenarbeit mit dem Plattform-Team aus?"}
{"ts": "131:10", "speaker": "E", "text": "Das Plattform-Team liefert uns die Build-Pipelines und Test-Container. Zum Beispiel haben sie jüngst die iOS-Build-Zeit um 40 % gekürzt, was uns mehr Raum für manuelle Exploratory Tests gibt. Das war eine direkte Folge eines RFCs, den wir gemeinsam verfasst haben (RFC-PLT-221)."}
{"ts": "131:40", "speaker": "I", "text": "Gibt es dabei auch SLAs, die bestimmte Reaktionszeiten festlegen?"}
{"ts": "131:55", "speaker": "E", "text": "Ja, für kritische Build-Blocker gibt es ein 4h-SLA, dokumentiert im Service Agreement SA-PLT-01. Das hat uns schon mehrfach geholfen, vor Wochenend-Deployments noch rechtzeitig Builds zu fixen."}
{"ts": "132:20", "speaker": "I", "text": "Welche Risiken sehen Sie aktuell, falls solche SLAs nicht eingehalten werden können?"}
{"ts": "132:35", "speaker": "E", "text": "Das größte Risiko ist ein verspäteter Rollout, der wiederum die vertraglich zugesagte Pilotphase verlängert und damit Kosten verursacht. Wir haben dafür eine Fallback-Strategie im Dokument RSK-ATLAS-09: notfalls wird ein minimaler Funktionsumfang ohne die problembehafteten Features live gestellt."}
{"ts": "133:00", "speaker": "I", "text": "Und wie entscheiden Sie, welche Funktionen in so einem Minimal-Rollout enthalten sind?"}
{"ts": "133:20", "speaker": "E", "text": "Das basiert auf einer Impact-Analyse aus dem letzten Sprint-Review. Wir bewerten jede Funktion nach Geschäftswert und technischer Kritikalität. Im Fall ATLAS-482 haben wir z. B. nur die Lesefunktionalität für Berichte aktiviert, da diese im SLA mit dem Kunden als 'must-have' markiert war."}
{"ts": "144:00", "speaker": "I", "text": "Sie hatten vorhin erwähnt, dass es beim Offline-Sync einige knifflige Edge Cases gab. Können Sie mir ein konkretes Beispiel nennen, das auch die Zusammenarbeit mit QA illustriert?"}
{"ts": "144:05", "speaker": "E", "text": "Ja, gerne. Ein typischer Fall war, ähm, wenn ein Nutzer gleichzeitig auf zwei Geräten arbeitet, beide offline, und dann wieder online geht. Laut Runbook ORB-221 müssen wir hier Konflikte per Last-Write-Wins-Strategie auflösen, aber QA hat im Ticket SYS-8845 festgestellt, dass bei gleichzeitiger Rückkehr ins Netz der Merge-Algorithmus auf dem Tablet einen älteren Stand bevorzugt hat."}
{"ts": "144:14", "speaker": "I", "text": "Und wie sind Sie mit diesem Fund umgegangen? War das ein reiner Bugfix oder mussten Sie auch konzeptionell etwas ändern?"}
{"ts": "144:20", "speaker": "E", "text": "Wir haben tatsächlich beides gemacht. Kurzfristig gab es einen Hotfix nach SLA-Klasse 3, um den Merge korrekt zu priorisieren. Parallel haben wir das Sync-Runbook ergänzt, dass QA nun auch Dual-Device-Scenarios in den Regressionsplan aufnimmt."}
{"ts": "144:27", "speaker": "I", "text": "Gab es dabei Abhängigkeiten zu anderen Teams, etwa den Plattform-Entwicklern?"}
{"ts": "144:31", "speaker": "E", "text": "Definitiv. Die Konfliktauflösung läuft in einem Backend-Service, der auch von der Webplattform genutzt wird. Wir mussten mit dem Core-API-Team abstimmen, dass ein zusätzlicher Parameter `sync_origin` übergeben wird, um die Quelle zu markieren."}
{"ts": "144:38", "speaker": "I", "text": "Das klingt nach einer klassischen multi-hop-Abhängigkeit – vom Client über Sync-Logik zum Core-API."}
{"ts": "144:42", "speaker": "E", "text": "Genau, das war so ein Fall, wo wir Backend-Änderungen und Client-Logik synchronisieren mussten. Wir haben es unter Feature Flag `sync_conflict_v2` ausgerollt, um erst im Pilot-Cluster zu testen."}
{"ts": "144:49", "speaker": "I", "text": "Und haben Sie unter diesem Feature Flag auch wieder Probleme entdeckt?"}
{"ts": "144:53", "speaker": "E", "text": "Ja, in der zweiten Testwoche gab’s einen Memory Leak im Conflict-Resolver, gemeldet als BUG-9012. Zum Glück war das Flag nur für 15% der Pilotnutzer aktiv, sodass wir es schnell zurückdrehen konnten."}
{"ts": "145:00", "speaker": "I", "text": "Das war vermutlich eine bewusste Entscheidung, um das Risiko zu begrenzen – können Sie diesen Trade-off beschreiben?"}
{"ts": "145:05", "speaker": "E", "text": "Klar. Wir wollten das neue Merge-Verhalten möglichst früh validieren, aber ohne die gesamte Pilotgruppe zu gefährden. In der Trade-off-Doku TRA-ATL-07 haben wir festgehalten: lieber langsame Ausrollung bei höherem QA-Aufwand als großflächige Störung."}
{"ts": "145:12", "speaker": "I", "text": "Wie kommunizieren Sie solche Entscheidungen an Stakeholder, die vielleicht nicht tief in der Technik stecken?"}
{"ts": "145:17", "speaker": "E", "text": "Wir nutzen ein wöchentliches Pilot-Update in Confluence, mit Ampelfarben für Risiken und Fortschritt. Für dieses Flag stand die Ampel auf Gelb, mit Hinweis auf Memory Leak und geplanten Fix in Sprint 42."}
{"ts": "145:23", "speaker": "I", "text": "Abschließend: Welche Lehren ziehen Sie aus diesem Fall für künftige Feature-Flag-Einsätze?"}
{"ts": "145:28", "speaker": "E", "text": "Wir werden künftig in jedem Rollout-Plan einen expliziten Rückfallpfad definieren, der schon im Runbook steht. Außerdem wollen wir QA früher einbinden, um atypische Nutzungsmuster – wie im Dual-Device-Szenario – proaktiv zu testen."}
{"ts": "146:00", "speaker": "I", "text": "Wir hatten vorhin die kritischen Abhängigkeiten angerissen. Könnten Sie mir jetzt noch konkreter sagen, wie das Zusammenspiel mit dem Backend-Team im Alltag aussieht?"}
{"ts": "146:05", "speaker": "E", "text": "Ja, klar. Wir haben ein wöchentliches Sync-Meeting, plus asynchrone Updates im Confluence. Für Atlas Mobile sind die API-Endpunkte aus dem Projekt Nebula Backend entscheidend, besonders für das Offline-Sync-Delta-Pulling. Wenn dort ein Schema geändert wird, muss unser Mobile-Client sofort angepasst werden."}
{"ts": "146:14", "speaker": "I", "text": "Und wie stellen Sie sicher, dass solche Änderungen nicht unbemerkt durchrutschen?"}
{"ts": "146:18", "speaker": "E", "text": "Wir haben im Runbook RB-ATL-013 ein Pre-Deployment-Check definiert: jedes Backend-Release triggert einen automatischen Contract-Test gegen unsere Staging-Builds. Zusätzlich prüfen wir die Feature Flags – zum Beispiel kann der neue Endpunkt nur für interne Tester aktiviert werden."}
{"ts": "146:28", "speaker": "I", "text": "Wie verknüpfen Sie diese Tests mit den Feature Flags im Code?"}
{"ts": "146:32", "speaker": "E", "text": "Das ist im Config-Service hinterlegt. Wir nutzen eine Flag-Library, die auf Umgebungsvariablen hört. Im Testlauf setzen wir Flags wie 'sync_v2_enabled' auf 'true' in Staging, um die neuen Pfade zu testen, ohne die Pilotnutzer zu beeinflussen."}
{"ts": "146:42", "speaker": "I", "text": "Gab es Fälle, bei denen so ein Flag tatsächlich ein Problem verhindert hat?"}
{"ts": "146:46", "speaker": "E", "text": "Ja, Ticket ATL-457: Wir hatten einen NullPointer im neuen JSON-Parser, der nur bei leeren Payloads auftrat. Weil der Flag nur intern an war, konnten wir den Fix deployen, bevor es in der Pilotgruppe knallte."}
{"ts": "146:56", "speaker": "I", "text": "Beim Thema Offline-Sync, wie testen Sie da aktuell Edge Cases?"}
{"ts": "147:00", "speaker": "E", "text": "Wir simulieren Netzwerkflaps mit einem Proxy, der zufällig Pakete droppt. QA nutzt dabei eine Liste aus dem Runbook RB-ATL-021 – z.B. Testfall 'Gerät schläft während Sync' oder 'Konflikt bei doppelter Bearbeitung'. Die Fehlerbilder werden in Jira direkt mit den Logcat-Outputs verknüpft."}
{"ts": "147:12", "speaker": "I", "text": "Und wie fließt dieses Feedback dann in die Priorisierung?"}
{"ts": "147:16", "speaker": "E", "text": "Wir bewerten jeden Fund mit einer Matrix aus Nutzerimpact und technischer Komplexität. Bei hohem Impact, wie Datenverlust, ziehen wir das sofort vor – auch wenn dafür ein geplantes UI-Feature verschoben werden muss. Siehe Priorisierungsdoku PRIO-ATL-Q1."}
{"ts": "147:26", "speaker": "I", "text": "Gab es da zuletzt einen Trade-off, den Sie bewusst entschieden haben?"}
{"ts": "147:30", "speaker": "E", "text": "Ja, im Februar: Wir haben die Exportfunktion für Berichte um vier Wochen verschoben, um den Offline-Konflikt-Resolver zu härten. Das war auch Risiko Nr. 1 im Risk-Register RR-ATL-2024-02, mit 'High' bewertet. Die Entscheidung ist im Steering-Meeting-Protokoll vom 12.02. dokumentiert."}
{"ts": "147:44", "speaker": "I", "text": "Und wie messen Sie, ob diese Entscheidung richtig war?"}
{"ts": "147:48", "speaker": "E", "text": "Seit dem Fix ist die Support-Queue für Sync-Probleme um 60 % runtergegangen. Das SLA für kritische Sync-Vorfälle – aktuell 4h – konnten wir in allen Fällen halten. Das Monitoring-Dashboard zeigt keine neuen Datenkonflikt-Alerts seit Deploy 1.4.3."}
{"ts": "148:00", "speaker": "I", "text": "Sie hatten vorhin erwähnt, dass Sie beim Offline-Sync auch unerwartete Edge Cases hatten. Können Sie mir ein besonders kniffliges Beispiel schildern?"}
{"ts": "148:05", "speaker": "E", "text": "Ja, eines der schwierigsten war tatsächlich ein Konflikt, der nur bei gleichzeitigen Änderungen auf zwei Devices ohne Netzverbindung auftrat. Unser Runbook OR-ATL-14 beschreibt zwar die Standard-Merge-Strategie, aber in diesem Fall führte die Zeitstempel-Logik zu einem Datenverlust."}
{"ts": "148:15", "speaker": "I", "text": "Wie sind Sie vorgegangen, um das zu lösen?"}
{"ts": "148:20", "speaker": "E", "text": "Wir haben in Abstimmung mit dem Backend-Team einen zusätzlichen Conflict-Resolver implementiert, der nicht nur Timestamps, sondern auch Feld-Level-Änderungshistorien vergleicht. Das war in RFC-ATL-22 beschrieben und ging dann in den nächsten QA-Build."}
{"ts": "148:30", "speaker": "I", "text": "Gab es dazu einen speziellen Testfall bei QA?"}
{"ts": "148:35", "speaker": "E", "text": "Ja, QA hat basierend auf Ticket TST-ATL-58 eine Reihe von Szenarien mit simulierten Netzwerkunterbrechungen gefahren. Die haben sogar ein eigenes Skript im Testframework geschrieben, um die Offline-Phase zu verlängern und Konflikte gezielt zu provozieren."}
{"ts": "148:45", "speaker": "I", "text": "Und wie flossen diese Erkenntnisse in die Feature-Flag-Strategie ein?"}
{"ts": "148:50", "speaker": "E", "text": "Wir haben den Conflict-Resolver hinter einem separaten Flag `offline_conflict_resolver_v2` aktiviert. So konnten wir ihn nur für ausgewählte Pilotnutzer einschalten und in der Telemetrie überwachen, bevor er global live ging."}
{"ts": "149:00", "speaker": "I", "text": "Das klingt nach enger Verzahnung mehrerer Teams. Gab es dabei Koordinationsprobleme?"}
{"ts": "149:05", "speaker": "E", "text": "Einmal hat das Plattform-Team ein Minor-Update der Sync-Library ausgerollt, das nicht dokumentierte Änderungen an der Konfliktauflösung enthielt. Das haben wir erst über einen Spike in den Error-Logs gesehen und dann über das wöchentliche Interlock geklärt."}
{"ts": "149:15", "speaker": "I", "text": "Wie gehen Sie mit solchen Zwischenfällen prozessual um?"}
{"ts": "149:20", "speaker": "E", "text": "Wir öffnen immer ein Incident-Ticket, in diesem Fall INC-ATL-09, und dokumentieren im Postmortem die Lessons Learned. Danach kommt ein Update ins Runbook, damit alle Beteiligten wissen, welche Abhängigkeiten zu prüfen sind."}
{"ts": "149:30", "speaker": "I", "text": "Gab es durch diese Postmortems auch Änderungen an den SLAs zwischen den Teams?"}
{"ts": "149:35", "speaker": "E", "text": "Ja, wir haben ein zusätzliches SLA eingeführt: Änderungen an Libraries, die den Sync betreffen, müssen jetzt mindestens 72 Stunden vorher im Atlas-Change-Channel angekündigt werden. Das steht in SLA-ATL-01."}
{"ts": "149:45", "speaker": "I", "text": "Das ist ein gutes Beispiel für die Verbindung von Technik und Prozessen. Sehen Sie darin auch einen Vorteil für künftige Rollouts?"}
{"ts": "149:50", "speaker": "E", "text": "Absolut. Durch diese enge Abstimmung und das Flag-basierte Ausrollen können wir neue Features iterativ und risikoarm einführen. Die Erfahrungen aus den Incidents fließen direkt in die nächste Sprintplanung ein, was den Gesamtprozess robuster macht."}
{"ts": "149:20", "speaker": "I", "text": "Sie hatten vorhin erwähnt, dass die QA die Offline-Sync-Edge Cases nach Runbooks testet. Mich würde interessieren, wie detailliert diese Runbooks sind und ob sie auch Problemumgehungen dokumentieren?"}
{"ts": "149:26", "speaker": "E", "text": "Ja, die Runbooks sind tatsächlich sehr granular. Wir haben pro Edge Case eine Schritt-für-Schritt-Anleitung, inklusive Screenshots, und in manchen Fällen auch sogenannte \"Fallback Procedures\" – also Workarounds, falls das Sync-Modul nicht wie erwartet reagiert. Diese Workarounds sind oft aus realen Ticket-Erfahrungen entstanden, z. B. Ticket SYNC-217 aus dem letzten Sprint."}
{"ts": "149:34", "speaker": "I", "text": "Können Sie bei SYNC-217 ein wenig ins Detail gehen, was da passiert ist?"}
{"ts": "149:40", "speaker": "E", "text": "Klar. In SYNC-217 ging es um den Fall, dass ein Nutzer sein Gerät während einer teilweisen Synchronisation ausgeschaltet hat. Das führte zu einem inkonsistenten Datensatz zwischen dem lokalen Cache und der Cloud. Unser Workaround im Runbook beschreibt, wie man beim nächsten Online-Start eine gezielte Delta-Synchronisation anstößt, statt den kompletten Datenbestand neu zu laden."}
{"ts": "149:48", "speaker": "I", "text": "Interessant. Sie sprachen vorhin auch mal an, dass gewisse Abhängigkeiten zwischen Backend und Plattform über Feature Flags entkoppelt werden. Wie wirkt sich das auf Ihre QA-Strategie aus?"}
{"ts": "149:54", "speaker": "E", "text": "Das ist ein wichtiger Punkt. Wir nutzen in der QA eine Matrix, in der wir Feature-Flag-Kombinationen definieren und priorisieren. Nicht alle Kombinationen sind gleich kritisch. Flags, die Backend-Änderungen triggern, bekommen eine höhere Testtiefe. Das erfordert Koordination mit dem Plattform-Team, weil wir oft Staging-Endpunkte brauchen, die nur in bestimmten Flag-Zuständen verfügbar sind."}
{"ts": "150:02", "speaker": "I", "text": "Gibt es denn einen dokumentierten Prozess dafür, wie Sie neue Flags in diese Matrix aufnehmen?"}
{"ts": "150:06", "speaker": "E", "text": "Ja, im QA-Runbook Kapitel 4.3. Da steht, dass jede neue Flag beim Erstellen eines RFCs vom Entwicklerteam zusammen mit QA bewertet wird. Wir fügen dann im sogenannten Flag-Registry-Dokument eine Zeile hinzu, inkl. Risikokategorie, Abhängigkeiten und Testfällen. Das erlaubt uns, im Regressionstest gezielt zu entscheiden, welche Flag-Stände wir unbedingt prüfen müssen."}
{"ts": "150:14", "speaker": "I", "text": "Sie hatten auch erwähnt, dass manche Workarounds aus Ticket-Erfahrungen stammen. Wie fließen diese Lessons Learned zurück ins Produkt?"}
{"ts": "150:20", "speaker": "E", "text": "Wir haben ein monatliches Post-Mortem-Meeting, in dem QA, Dev und PO zusammensitzen. Dort gehen wir kritische Tickets durch. Bei SYNC-217 zum Beispiel haben wir beschlossen, nicht nur das Runbook zu ergänzen, sondern auch die App-Logik so anzupassen, dass sie einen Stromausfall während der Sync erkennt und automatisch in den Delta-Mode wechselt."}
{"ts": "150:28", "speaker": "I", "text": "Das klingt nach einer engen Verzahnung der Teams. Gibt es dabei Situationen, wo Sie zwischen schneller Lösung und langfristiger Architektur abwägen mussten?"}
{"ts": "150:34", "speaker": "E", "text": "Definitiv. Ein Beispiel war die Entscheidung, ob wir die Sync-Engine kurzfristig patchen, um einen Bug in der Sortierung zu beheben, oder ob wir gleich die gesamte Sortierlogik refactoren. Kurzfristig haben wir einen Patch eingespielt (Fix in Build 1.4.2), um SLA R-12 einzuhalten, haben aber parallel ein Architektur-Refactoring als Epic ATLAS-REF-05 angelegt. Das ist der klassische Trade-off zwischen Time-to-Market und nachhaltiger Codequalität."}
{"ts": "150:42", "speaker": "I", "text": "Und wie dokumentieren Sie solche Trade-offs für die Nachvollziehbarkeit?"}
{"ts": "150:46", "speaker": "E", "text": "Wir nutzen im Confluence-Bereich 'Atlas Decisions' ein Template, das die Entscheidung, Alternativen, Gründe, beteiligte Personen und erwartete Risiken festhält. Für den genannten Patch gibt es z. B. Eintrag DEC-2023-11-07, wo das alles beschrieben ist. Das hilft uns später, falls ähnliche Situationen auftreten."}
{"ts": "150:54", "speaker": "I", "text": "Abschließend für diesen Block: Welche übergreifenden Risiken sehen Sie aktuell, die sowohl die Offline-Sync-Module als auch die Feature-Flag-Strategie betreffen?"}
{"ts": "151:00", "speaker": "E", "text": "Ein Risiko ist, dass zu viele Flags gleichzeitig aktiv sind und sich unvorhersehbar beeinflussen – besonders, wenn Offline-Sync im Spiel ist. Ein weiteres ist, dass wir bei komplexen Edge Cases im Sync trotz Runbooks auf seltene Race Conditions stoßen könnten, die in der Pilotphase nicht auftreten, aber in der Breite schon. Deshalb planen wir vor dem Go-Live eine zweiwöchige 'Chaos-Sync'-Testkampagne, um genau solche Fälle künstlich zu erzeugen."}
{"ts": "151:00", "speaker": "I", "text": "Lassen Sie uns nochmal auf die Priorisierung zurückkommen – gab es kürzlich eine Situation, in der Sie zwischen einem schnelleren Rollout und zusätzlicher Funktionalität wählen mussten?"}
{"ts": "151:05", "speaker": "E", "text": "Ja, vor etwa drei Wochen. Wir standen vor der Entscheidung, die neue Kartenansicht sofort live zu nehmen oder erst nach Integration der erweiterten Filter. Laut Ticket ATLAS-PRIO-78 sah der Runbook-Eintrag vor, MVP-Features im Pilot maximal zwei Sprints zu verzögern. Deshalb haben wir uns für den früheren Rollout entschieden."}
{"ts": "151:28", "speaker": "I", "text": "Und wie haben Sie das kommuniziert, gerade im Hinblick auf Stakeholder-Erwartungen?"}
{"ts": "151:33", "speaker": "E", "text": "Wir haben ein RFC-Dokument erstellt, RFC-2024-05, in dem die Trade-offs explizit benannt wurden. Darin stand auch, dass die Filterfunktion als Feature Flag nachträglich aktiviert werden kann, um Risiken zu minimieren."}
{"ts": "151:52", "speaker": "I", "text": "Gab es dabei technische Risiken, die Sie besonders im Auge hatten?"}
{"ts": "151:56", "speaker": "E", "text": "Ja, vor allem die Lastspitzen beim initialen Kartenrendering. Wir haben dazu mit dem Backend-Team SLA-Checks vereinbart: 95% der Requests müssen unter 800ms bleiben. Unser Monitoring-Runbook ‚Atlas_Perf_02‘ beschreibt die Alarmierung."}
{"ts": "152:18", "speaker": "I", "text": "Wie passt das zu den Offline-Funktionen, gerade wenn Karten offline verfügbar sein sollen?"}
{"ts": "152:22", "speaker": "E", "text": "Offline-Karten sind in einem separaten Modul. Wir haben in der QA einen Edge-Case-Test, der bei schwankender Verbindung gezielt Sync-Konflikte provoziert. Das steht im Testplan TP-Offline-07 und ist eng mit unserem Sync-Resolver gekoppelt."}
{"ts": "152:45", "speaker": "I", "text": "Gab es da schon kritische Findings?"}
{"ts": "152:48", "speaker": "E", "text": "Einmal, ja. Bei einem Kunden in einer ländlichen Region traten doppelte Datensätze auf. Wir haben das über Feature Flag atlas.sync.safe_mode entschärft, was den Sync-Intervall temporär verdoppelt."}
{"ts": "153:06", "speaker": "I", "text": "Wie dokumentieren Sie solche Eingriffe, damit sie später nachvollziehbar sind?"}
{"ts": "153:10", "speaker": "E", "text": "Wir führen eine Change-Log-Tabelle, verknüpft mit Jira. Jeder Flag-Wechsel bekommt einen Eintrag mit Zeitstempel und Link zum Incident-Report, z.B. INC-ATL-442."}
{"ts": "153:27", "speaker": "I", "text": "Welche Risiken sehen Sie derzeit noch für den nächsten Meilenstein?"}
{"ts": "153:31", "speaker": "E", "text": "Hauptsächlich Integration-Risiken mit dem Auth-Service. Der Auth-Handshake ist noch nicht für Offline-Token optimiert. Im Risk-Register RSK-15 haben wir das als 'hoch' gelistet, mit einem Mitigation-Plan bis Sprint 14."}
{"ts": "153:50", "speaker": "I", "text": "Wie messen Sie dann den Erfolg des nächsten Meilensteins?"}
{"ts": "153:54", "speaker": "E", "text": "Wir haben drei KPIs: Crash-Free-Rate über 99%, Sync-Fehlerquote unter 0,5%, und Nutzerzufriedenheit >4,0 in der In-App-Bewertung. Diese sind im SLA-Dokument Atlas_SLA_v1.3 festgehalten."}
{"ts": "153:00", "speaker": "I", "text": "Sie hatten vorhin schon die Verzahnung von Backend- und Plattform-Teams erwähnt. Mich würde interessieren: gab es in der letzten Iteration besondere Herausforderungen bei dieser Abstimmung?"}
{"ts": "153:08", "speaker": "E", "text": "Ja, tatsächlich. Wir hatten im Sprint 34 ein Problem, dass ein Backend-Endpunkt für den Offline-Abgleich erst mit zwei Tagen Verzögerung stabil war. Unser Feature Flag 'sync_v2' musste deshalb länger im Staging bleiben. Das hat QA in der Runbook-Prüfung Ticket QA-482 dokumentiert."}
{"ts": "153:20", "speaker": "I", "text": "Wie haben Sie in so einem Fall sichergestellt, dass Time-to-Market nicht komplett leidet?"}
{"ts": "153:28", "speaker": "E", "text": "Wir haben ein sogenanntes 'Grace Deployment' durchgeführt: die App ging live, aber der kritische Endpunkt war weiter über das Flag abgeschaltet. So konnten wir andere Features wie das neue Kartenmodul schon ausrollen."}
{"ts": "153:40", "speaker": "I", "text": "Gab es Auswirkungen auf die Pilotnutzer?"}
{"ts": "153:47", "speaker": "E", "text": "Minimal. Wir haben per In-App-Message informiert, dass die automatische Sync-Funktion in zwei Tagen aktiviert wird. Die manuelle Synchronisation blieb verfügbar."}
{"ts": "153:55", "speaker": "I", "text": "Und intern, wie haben Sie das kommuniziert?"}
{"ts": "154:02", "speaker": "E", "text": "Über unser Release-Channel im Chat und ein kurzes Addendum im Deployment-Runbook (Version 2.3.1). Wir fügen dort einen 'Delayed Activation'-Abschnitt hinzu, damit alle wissen, wie Flags später gesetzt werden."}
{"ts": "154:15", "speaker": "I", "text": "Können Sie ein Beispiel geben, wie QA in diesem Verfahren Edge Cases einplant?"}
{"ts": "154:23", "speaker": "E", "text": "Ja, QA hat für Offline-Sync den Testfall 'TC-OFF-17' ergänzt: User startet Sync, verliert das Netz nach 50%, reconnect nach 3 Min., und Flag wird währenddessen aktiviert. So prüfen wir, ob Konflikte korrekt gelöst werden."}
{"ts": "154:37", "speaker": "I", "text": "Das klingt nach aufwendiger Koordination. Wie dokumentieren Sie diese komplexen Abhängigkeiten?"}
{"ts": "154:45", "speaker": "E", "text": "Wir nutzen ein internes Confluence-Board mit einer Matrix: Spalten sind Backend-Module, Zeilen sind mobile Features. In jeder Zelle steht das zugehörige Feature Flag und das verantwortliche Team. So vermeiden wir, dass etwas unbeabsichtigt aktiviert wird."}
{"ts": "154:59", "speaker": "I", "text": "Gibt es SLA-Vorgaben für diese Schnittstellen?"}
{"ts": "155:06", "speaker": "E", "text": "Ja, intern gilt SLA-API-07: 99,5% Verfügbarkeit pro Monat und max. 250ms Latenz für Sync-Endpunkte. Wenn wir darunter liegen, wie im März, müssen wir einen RCA-Report im Ticketing-System erstellen."}
{"ts": "155:18", "speaker": "I", "text": "Und wie fließen diese technischen Metriken zurück in die Priorisierung?"}
{"ts": "155:25", "speaker": "E", "text": "Wenn ein Modul die SLA-Grenzen mehrfach reißt, priorisieren wir Stabilitätsverbesserung vor neuen Features. Das habe ich zuletzt bei 'sync_v1' getan, indem wir zwei geplante UI-Optimierungen um einen Sprint verschoben."}
{"ts": "155:00", "speaker": "I", "text": "Sie hatten vorhin erwähnt, dass Feature Flags bei der Steuerung der Abhängigkeiten helfen. Mich würde interessieren, ob es in der Pilotphase konkrete Situationen gab, wo Sie diese Flags kurzfristig umkonfigurieren mussten."}
{"ts": "155:05", "speaker": "E", "text": "Ja, tatsächlich. In Sprint 14 hatten wir ein Backend-Modul, das von Team Orion geliefert wurde, mit einer leichten Latenz unter hoher Last. Wir haben daraufhin das Flag `atlas.sync_priority` im Config-Repo von `true` auf `false` gesetzt, um den betroffenen Endpunkt nur noch einmal pro Stunde zu triggern."}
{"ts": "155:12", "speaker": "I", "text": "Haben Sie das vorab in einem Runbook dokumentiert oder war das eher ein Ad-hoc-Entscheid?"}
{"ts": "155:17", "speaker": "E", "text": "Das stand so nicht im Runbook R-OS-07, das betrifft eigentlich nur den Offline-Sync. Aber wir haben im Ticket P-ATL-442 eine temporäre Regel ergänzt und die DevOps-Kollegen informiert, sodass sie das Monitoring anpassen konnten."}
{"ts": "155:23", "speaker": "I", "text": "Verstehe. Und wie hat sich das auf die Nutzererfahrung ausgewirkt?"}
{"ts": "155:27", "speaker": "E", "text": "Minimal. Wir haben vorher A/B-Testing gefahren, 10% der Pilotnutzer waren in der reduzierten Sync-Kohorte. Die Feedback-Formulare zeigten keine signifikante Verschlechterung der Zufriedenheit."}
{"ts": "155:34", "speaker": "I", "text": "Sie verknüpfen also Backend-Auslastung und UX-Metriken aktiv – ist das ein fester Prozess oder eher ein einmaliger Fall?"}
{"ts": "155:39", "speaker": "E", "text": "Das ist mittlerweile fester Bestandteil unseres Pilot-Monitorings. In der wöchentlichen Sync-Analyse vergleichen wir die SLA-Daten vom Backend mit den NPS-Werten aus der App."}
{"ts": "155:45", "speaker": "I", "text": "Klingt nach einer guten Verzahnung. Gab es durch diese Verzahnung auch Anpassungen im Offline-Sync-Konzept?"}
{"ts": "155:50", "speaker": "E", "text": "Ja, wir haben die Konfliktauflösung im Sync-Algorithmus so erweitert, dass bei zu hoher Backend-Latenz lokale Änderungen länger vorgehalten werden. Das wurde als RFC-2024-05 intern durch die Architekten abgesegnet."}
{"ts": "155:56", "speaker": "I", "text": "Das bringt mich zu den Edge Cases – gab es neue, die durch diese Änderung sichtbar wurden?"}
{"ts": "156:01", "speaker": "E", "text": "Ein seltener Fall war, dass zwei Geräte offline denselben Datensatz editieren, und der Merge dann nach mehreren Stunden verzögert stattfand. Unser QA-Team hat diesen Fall anhand des erweiterten Testplans T-ATL-SYNC-09 simuliert."}
{"ts": "156:08", "speaker": "I", "text": "Und wie haben Sie diesen Edge Case adressiert?"}
{"ts": "156:12", "speaker": "E", "text": "Wir haben einen Prioritätsmechanismus eingebaut: Änderungen vom Gerät mit dem aktuelleren App-Build werden bevorzugt. Das haben wir nach interner Diskussion dokumentiert, obwohl es nicht explizit in den funktionalen Anforderungen stand."}
{"ts": "156:18", "speaker": "I", "text": "Das klingt nach einem klassischen Trade-off zwischen Datenintegrität und Time-to-Market. Wie haben Sie das Team überzeugt?"}
{"ts": "156:23", "speaker": "E", "text": "Durch die Auswertung der Support-Tickets aus der Beta. 85% der betroffenen Nutzer wollten ihre Änderungen schnell sehen, selbst wenn das Risiko bestand, dass eine ältere Device-Änderung überschrieben wird. Wir haben das als Risiko R-ATL-07 im Risikoregister mit \"akzeptiert\" markiert."}
{"ts": "156:30", "speaker": "I", "text": "Sie haben vorhin schon die Abhängigkeiten und Feature Flags erwähnt. Mich würde interessieren: wie priorisieren Sie, wenn Backend-Teams und App-Teams unterschiedliche Timelines haben?"}
{"ts": "156:36", "speaker": "E", "text": "Ja, das ist, äh, tatsächlich häufig der Fall. Wir nutzen da eine Kombination aus unserem internen SLA-Kalender und einem wöchentlichen Sync-Meeting, bei dem wir die Flags so anpassen, dass wir Features notfalls isolieren können, bis das Backend stabil ist."}
{"ts": "156:44", "speaker": "I", "text": "Das heißt, Sie nehmen bewusst in Kauf, dass Features temporär nicht sichtbar sind, um die Stabilität zu sichern?"}
{"ts": "156:49", "speaker": "E", "text": "Genau. Wir haben das z. B. bei der neuen Kartenansicht gemacht – Ticket MOB-4823 dokumentiert das – und so konnten wir die App schon ausrollen, obwohl das Karten-Backend noch nicht final war."}
{"ts": "156:57", "speaker": "I", "text": "Und wie wird so etwas in Ihren Runbooks festgehalten?"}
{"ts": "157:02", "speaker": "E", "text": "Im Runbook RB-MOB-12 gibt es ein Kapitel \"Feature Flag Rollout\", da sind die Schritte drin: Flag setzen, QA-Check in Staging, Monitoring aktivieren. Das QA-Team prüft dann auch Offline-Szenarien, falls die Funktion Flags wechselt."}
{"ts": "157:12", "speaker": "I", "text": "Apropos Offline: gab es in der Pilotphase neue Edge Cases, die Sie vorher gar nicht auf dem Schirm hatten?"}
{"ts": "157:18", "speaker": "E", "text": "Ja, bei einem Feldtest in einer Region mit sehr sporadischem 2G haben wir entdeckt, dass unser Delta-Sync mehrfach dieselben Objekte sendet. Das war nie im Labor aufgefallen. QA hat das als EdgeCase-27 ins Testprotokoll aufgenommen."}
{"ts": "157:27", "speaker": "I", "text": "Wie sind Sie damit umgegangen?"}
{"ts": "157:31", "speaker": "E", "text": "Wir haben kurzfristig einen Patch über ein Server-Side-Flag aktiviert, der die Prüfsumme vor dem Versand vergleicht. Parallel läuft ein RFC-Request für eine dauerhafte Lösung, RFC-MOB-91."}
{"ts": "157:39", "speaker": "I", "text": "Das klingt nach schneller Reaktion. Gab es dabei Zielkonflikte mit Time-to-Market?"}
{"ts": "157:44", "speaker": "E", "text": "Ja, wir mussten eigentlich eine Marketing-Kampagne starten, haben die aber um eine Woche verschoben. Die Entscheidung ist in unserem Decision-Log DL-Atlas-05 dokumentiert, mit Begründung: Risikominimierung vor schneller Veröffentlichung."}
{"ts": "157:53", "speaker": "I", "text": "Und wie kommunizieren Sie solche Verschiebungen intern?"}
{"ts": "157:57", "speaker": "E", "text": "Über den Projektkanal in unserem Chat-Tool, plus ein kurzes Steering-Committee-Update. Wir hängen die relevanten Tickets und Runbook-Abschnitte dran, damit alle nachvollziehen können, warum und wie entschieden wurde."}
{"ts": "158:05", "speaker": "I", "text": "Wenn Sie nach vorne schauen: welche Hauptrisiken sehen Sie in den nächsten Meilensteinen?"}
{"ts": "158:10", "speaker": "E", "text": "Das größte Risiko ist, dass wir die geplante Offline-First-Architektur nicht rechtzeitig für alle Module umsetzen. Außerdem könnten regulatorische Änderungen bei den Standortdaten neue Freigaben erfordern. Beides ist in unserem Risk-Register RR-ATL als hoch eingestuft."}
{"ts": "158:06", "speaker": "I", "text": "Sie sagten vorhin, dass QA gezielt nach den Runbooks testet – können Sie ein aktuelles Beispiel nennen, wo das im Offline-Sync-Bereich besonders knifflig war?"}
{"ts": "158:15", "speaker": "E", "text": "Ja, ähm, letzte Woche im Ticket MOB-472 hatten wir einen Edge Case, bei dem ein Nutzer im Funkloch einen Datensatz löschte, der parallel auf dem Server durch einen anderen Vorgang verändert wurde. Das Runbook ORB-OS-07 beschreibt den Merge-Algorithmus, aber wir mussten den Ablauf erweitern, um Konflikte korrekt zu behandeln."}
{"ts": "158:31", "speaker": "I", "text": "Wie haben Sie den Merge-Algorithmus angepasst?"}
{"ts": "158:38", "speaker": "E", "text": "Wir haben eine zusätzliche Prüfschicht eingebaut, die anhand der Change-UUIDs erkennt, ob eine Löschung oder eine Feldänderung Priorität hat. Diese Logik wurde erst in einem Feature Flag 'sync_conflict_resolve_v2' gekapselt und nur für fünf Pilotnutzer aktiviert."}
{"ts": "158:55", "speaker": "I", "text": "Gab es dafür auch Abhängigkeiten zu anderen Teams?"}
{"ts": "159:02", "speaker": "E", "text": "Ja, das Backend-Team musste ein neues API-Endpoint bereitstellen, das den Konfliktstatus bei der Synchronisation zurückmeldet. Ohne deren Änderung im Service AtlasSync v1.3 hätten wir die Client-Seite nicht sauber testen können."}
{"ts": "159:16", "speaker": "I", "text": "Das klingt nach enger Abstimmung. Haben Sie dafür spezielle Koordinationsformate?"}
{"ts": "159:24", "speaker": "E", "text": "Wir haben wöchentliche Cross-Team-Standups und ein gemeinsames Confluence-Board, auf dem wir Abhängigkeiten und Blocker visualisieren. Für kritische Flags gibt es zusätzlich einen Eintrag im Release-Kalender, um die Aktivierung zu orchestrieren."}
{"ts": "159:39", "speaker": "I", "text": "Wie messen Sie, ob diese Konfliktlösung erfolgreich ist?"}
{"ts": "159:47", "speaker": "E", "text": "Wir tracken die Fehlerrate im Sync-Log über unser Monitoring-Tool und setzen ein internes SLA: weniger als 0,5 % nicht auflösbare Konflikte pro Woche. Außerdem machen wir manuelle QA-Tests nach jedem Hotfix."}
{"ts": "160:02", "speaker": "I", "text": "Gab es schon messbare Verbesserungen?"}
{"ts": "160:08", "speaker": "E", "text": "Ja, die Rate ist von 1,8 % auf 0,3 % gefallen. Das ist signifikant, und wir überlegen, die Funktion nach der nächsten Sprint-Review breiter freizugeben."}
{"ts": "160:19", "speaker": "I", "text": "Haben Sie Bedenken, dass ein breiter Rollout neue Probleme bringt?"}
{"ts": "160:26", "speaker": "E", "text": "Natürlich, vor allem im Zusammenspiel mit älteren Clients, die die neuen Conflict-Statuscodes nicht verstehen. Deshalb planen wir ein gestaffeltes Rollout mit Canary-Gruppen und einem klaren Rollback-Plan im Runbook REL-FLG-05."}
{"ts": "160:41", "speaker": "I", "text": "Wie sieht dieser Rollback-Plan konkret aus?"}
{"ts": "160:49", "speaker": "E", "text": "Falls die Fehlerrate über 0,8 % steigt oder wir eine kritische User-Story im Support-Tool sehen, deaktivieren wir das Flag innerhalb von 30 Minuten. Dazu gibt es ein automatisiertes Script, das auch gleich die betroffenen Nutzer benachrichtigt."}
{"ts": "160:06", "speaker": "I", "text": "Sie hatten eben schon die Abhängigkeiten erwähnt – könnten Sie noch einmal konkret schildern, welche Schnittstellen für Atlas Mobile im Pilot kritisch waren?"}
{"ts": "160:14", "speaker": "E", "text": "Ja, klar. Im Pilot waren drei Hauptschnittstellen kritisch: die Auth-API unseres Identity-Teams, der Sync-Endpunkt für Offline-Daten und die Push-Notification-Bridge. Jede davon hängt an separaten Deployments, daher nutzen wir Feature Flags, um neue Endpunkte erst dann global freizuschalten, wenn die Integrationstests im Staging grün sind."}
{"ts": "160:32", "speaker": "I", "text": "Und wie wird das Zusammenspiel dieser APIs im Pilot überwacht?"}
{"ts": "160:38", "speaker": "E", "text": "Wir haben ein zentrales Monitoring-Dashboard im internen Tool 'Aquila'. Dort sind Metriken wie Latenz, Error-Rate und Flag-Status je API hinterlegt. Zusätzlich gibt es einen Runbook-Eintrag RBK-ATL-17, der beschreibt, wie wir im Falle einer Auth-API-Störung temporär auf einen Fallback-Mechanismus umschalten."}
{"ts": "160:57", "speaker": "I", "text": "Interessant. Gab es im Pilot einen Moment, wo Sie diesen Fallback tatsächlich aktivieren mussten?"}
{"ts": "161:03", "speaker": "E", "text": "Ja, am 14. März. Da hatten wir einen Ausfall im Identity-Cluster IC2. Ticket #ATL-OPS-442 dokumentiert das. Wir mussten das Feature Flag 'useNewAuth' deaktivieren, damit die Clients wieder die alte Auth-Logik nutzen. Das hat die Ausfallzeit von potenziell Stunden auf 18 Minuten reduziert."}
{"ts": "161:22", "speaker": "I", "text": "Wie reagiert QA in so einer Situation – gibt es eine Art Notfalltestplan?"}
{"ts": "161:29", "speaker": "E", "text": "Ja, das QA-Team hat einen Abschnitt im Runbook RBK-ATL-17A. Darin steht, wie nach dem Umschalten Smoke-Tests für Login, Sync und Push auszuführen sind. Die haben wir direkt nach dem Flag-Switch in der Staging-Umgebung gefahren, bevor der Rollout auf Produktion ging."}
{"ts": "161:45", "speaker": "I", "text": "Wechseln wir kurz zum Thema Offline-Sync: Welche Edge Cases sind seit unserem letzten Gespräch neu dazugekommen?"}
{"ts": "161:52", "speaker": "E", "text": "Neu ist ein Problem bei gleichzeitigen Änderungen auf zwei Geräten im Flugmodus. Wenn beide wieder online gehen, kann es zu Merge-Konflikten kommen, die unser aktueller Resolver nicht sauber behandelt. Das ist als Defekt DEF-ATL-219 erfasst. QA hat dazu jetzt Testfälle mit simulierten Clock-Skews ergänzt."}
{"ts": "162:11", "speaker": "I", "text": "Klingt knifflig. Gibt es schon eine technische Strategie zur Behebung?"}
{"ts": "162:17", "speaker": "E", "text": "Wir planen, den Resolver mit einer Versions-Historie pro Datensatz auszustatten, sodass wir Konflikte auf Feldebene statt auf Objektebene lösen können. Das erfordert allerdings Änderungen im Backend-Schema, daher arbeiten wir eng mit dem Plattform-Team zusammen, um das in den nächsten Sprint zu bringen."}
{"ts": "162:35", "speaker": "I", "text": "Lassen Sie uns zum Abschluss auf die Zukunft blicken: Welche Hauptrisiken sehen Sie aktuell?"}
{"ts": "162:41", "speaker": "E", "text": "Das größte Risiko ist, dass wir beim Go-Live unter realer Last im Sync-Subsystem Bottlenecks sehen, die im Pilot nicht auftreten. Zweitens: regulatorische Änderungen bei der Datenspeicherung, die eine Anpassung der Offline-Caches erfordern könnten. Wir haben dazu vorsorglich ein RFC-Dokument RFC-ATL-09 erstellt, das mögliche Anpassungspfade skizziert."}
{"ts": "163:02", "speaker": "I", "text": "Wie messen Sie, ob diese Risiken erfolgreich mitigiert wurden?"}
{"ts": "163:08", "speaker": "E", "text": "Für die Last-Thematik haben wir ein SLA von 500 ms Median-Latenz beim Sync festgelegt; wir fahren vor Go-Live Stresstests mit 5-facher Pilotlast. Für regulatorische Änderungen tracken wir die Umsetzung in Confluence mit Verweis auf das RFC und prüfen Compliance in einem Audit-Runbook Schritt für Schritt."}
{"ts": "162:06", "speaker": "I", "text": "Sie hatten vorhin die Runbooks für Offline-Sync erwähnt. Mich würde interessieren, wie Sie diese im Pilot aktuell weiterentwickeln?"}
{"ts": "162:11", "speaker": "E", "text": "Wir passen die Runbooks iterativ an. Nach jedem Sprint-Review werden neue Edge Cases ergänzt. Zum Beispiel haben wir nach Ticket #ATL-217 die Reihenfolge der Retry-Strategien aktualisiert, weil wir merkten, dass bei gleichzeitiger Flag-Aktivierung und Netzwechsel falsche Konfliktlösungen ausgelöst wurden."}
{"ts": "162:18", "speaker": "I", "text": "Das klingt nach einer komplexen Wechselwirkung. Wie kommunizieren Sie solche Änderungen an das QA-Team?"}
{"ts": "162:24", "speaker": "E", "text": "Wir haben ein wöchentliches Sync-Meeting mit QA, in dem wir die Runbook-Änderungen durchgehen. Zusätzlich gibt’s einen Slack-Channel #atlas-sync, in dem wir die geänderten YAML-Spezifikationen der Testcases posten. So kann QA die Testumgebungen zeitnah anpassen."}
{"ts": "162:33", "speaker": "I", "text": "Gab es auch schon Fälle, wo QA einen Edge Case gefunden hat, der noch gar nicht im Runbook stand?"}
{"ts": "162:38", "speaker": "E", "text": "Ja, tatsächlich. QA hat im Ticket #ATL-229 einen Fall dokumentiert, bei dem ein Feature Flag mitten in einer Offline-Transaktion deaktiviert wurde. Das führte zu einer unvollständigen Datensynchronisation. Wir haben daraufhin im Runbook ein neues Kapitel 'Flag-Boundary-Handling' ergänzt."}
{"ts": "162:48", "speaker": "I", "text": "Wie stellen Sie sicher, dass diese Lessons Learned nicht verloren gehen, gerade wenn es in Richtung Rollout geht?"}
{"ts": "162:54", "speaker": "E", "text": "Wir binden die Runbooks direkt in unser Confluence-Wiki ein, mit einer Change-Log-Historie. Vor größeren Releases machen wir ein sogenanntes 'Runbook Review', das verpflichtend im Go-Live-Checklist-Template verlinkt ist. So haben alle Teams denselben Wissensstand."}
{"ts": "163:03", "speaker": "I", "text": "Und wie beeinflusst das Ihre Priorisierung zwischen Bugfixes und neuen Features?"}
{"ts": "163:09", "speaker": "E", "text": "Bei kritischen Sync-Bugs priorisieren wir Bugfixes immer über neue Features, auch wenn das Time-to-Market verzögert. Das ist in unserem internen SLA-Dokument so festgelegt: 'Data Integrity P1 > Feature Delivery'. Dieser Grundsatz gilt, seitdem wir beim Projekt Orion 2019 durch Datenverluste viel Vertrauen verspielt hatten."}
{"ts": "163:19", "speaker": "I", "text": "Sie sprachen SLA-Dokumente an. Gibt es für Atlas Mobile eigene SLA-Kriterien?"}
{"ts": "163:24", "speaker": "E", "text": "Ja, im RFC-ATL-12 haben wir definiert: Sync-Fehlerquote < 0,3% pro Monat, Feature-Flag-Rollback-Zeit < 5 Minuten. Diese Werte sind direkt im Monitoring-Dashboard hinterlegt, sodass wir bei Überschreitung sofort Alerts bekommen."}
{"ts": "163:34", "speaker": "I", "text": "Wenn Sie jetzt in die Zukunft schauen: Welche Risiken könnten das Erreichen dieser SLA-Werte gefährden?"}
{"ts": "163:39", "speaker": "E", "text": "Das größte Risiko sehe ich in unvorhersehbaren Netzwerkausfällen in ländlichen Gebieten. Außerdem könnten regulatorische Änderungen im Datenschutz dazu führen, dass wir Teile des Sync-Protokolls anpassen müssen – was wiederum neue Fehlerquellen schafft."}
{"ts": "163:48", "speaker": "I", "text": "Und welche Maßnahmen planen Sie, um das proaktiv abzufedern?"}
{"ts": "163:53", "speaker": "E", "text": "Wir testen aktuell mit simulierten Netzwerkausfällen in der Staging-Umgebung, basierend auf dem Runbook-Szenario 'Offline-Interruption-03'. Für regulatorische Themen haben wir einen monatlichen Abgleich mit Legal, um Änderungen früh zu erkennen und Anpassungen in den Backlog aufzunehmen."}
{"ts": "163:30", "speaker": "I", "text": "Sie hatten ja vorhin die Entscheidung erwähnt, regulatorische Reporting-Funktionen später zu liefern. Können Sie mir den Abwägungsprozess dahinter noch etwas detaillierter schildern?"}
{"ts": "163:36", "speaker": "E", "text": "Ja, also das war wirklich ein klassischer Time-to-Market vs. Compliance Trade-off. Wir hatten intern das Ticket RFC-45-ATL, in dem sowohl die rechtlichen Anforderungen als auch die geschätzten Entwicklungsaufwände dokumentiert waren. Nach Rücksprache mit Legal haben wir uns entschlossen, die Berichte in ein Minor Release nach dem Pilot zu schieben."}
{"ts": "163:45", "speaker": "I", "text": "Gab es Bedenken aus dem QA- oder Security-Team zu dieser Verschiebung?"}
{"ts": "163:50", "speaker": "E", "text": "QA hatte vor allem Sorge, dass wir technische Schulden aufbauen, wenn wir das Reporting später integrieren. Security war eher entspannt, weil die Daten ohnehin verschlüsselt im Backend liegen. Wir haben im Runbook RBK-ATL-07 einen Abschnitt ergänzt, wie wir die Integrität der Daten bis zum Reporting sicherstellen."}
{"ts": "163:59", "speaker": "I", "text": "Und wie messen Sie jetzt im Pilot den Erfolg ohne diese Funktion?"}
{"ts": "164:04", "speaker": "E", "text": "Wir nutzen stattdessen Proxy-Metriken, zum Beispiel die Anzahl erfolgreich synchronisierter Datensätze pro Nutzer und Tag. Außerdem tracken wir, wie oft Nutzer den Export-Button drücken, um ein Gefühl für das Bedürfnis nach Reporting zu bekommen."}
{"ts": "164:12", "speaker": "I", "text": "Könnte das auch Einfluss auf die Priorisierung im nächsten Sprint haben?"}
{"ts": "164:16", "speaker": "E", "text": "Genau. Wenn wir sehen, dass der Export-Button sehr häufig genutzt wird, dann erhöhen wir die Priorität des Reporting-Features im Backlog. Das ist auch im Priorisierungs-Board unter KPI-Triggern hinterlegt."}
{"ts": "164:23", "speaker": "I", "text": "Wie dokumentieren Sie solche dynamischen Anpassungen, damit das Team den Kontext versteht?"}
{"ts": "164:28", "speaker": "E", "text": "Wir pflegen dafür ein Confluence-Log, das jede Änderung mit Datum, Auslöser und betroffenen Tickets listet. Zusätzlich gibt es im JIRA-Workflow ein Pflichtfeld 'Context Link', das auf den entsprechenden Log-Eintrag verweist."}
{"ts": "164:36", "speaker": "I", "text": "Gibt es besondere Risiken, die sich aus dieser flexiblen Priorisierung ergeben?"}
{"ts": "164:41", "speaker": "E", "text": "Ja, zum einen die Gefahr, dass wir uns zu stark von kurzfristigen Signalen leiten lassen. Zum anderen könnten wir durch häufige Kontextwechsel die Predictability unserer Velocity senken. Wir haben deshalb eine Regel, dass nur jede zweite Sprintplanung für Ad-hoc-Anpassungen geöffnet wird."}
{"ts": "164:51", "speaker": "I", "text": "Wie stellen Sie sicher, dass diese Regel eingehalten wird?"}
{"ts": "164:55", "speaker": "E", "text": "Das wird durch den Scrum Master überwacht. Außerdem haben wir ein einfaches Script im Planungstool, das prüft, ob ein Ticket mit dem Label 'Hotfix-Priorisierung' in einen nicht dafür vorgesehenen Sprint geschoben wird."}
{"ts": "165:02", "speaker": "I", "text": "Abschließend, welche nächsten Meilensteine sehen Sie nach Abschluss des Piloten?"}
{"ts": "165:06", "speaker": "E", "text": "Direkt nach dem Pilot wollen wir ein Beta-Release mit aktiviertem Reporting und optimierter Offline-Queue ausrollen. Der Erfolg wird an einer Reduktion der Sync-Fehlerquote unter 0,5% gemessen, das ist auch so in SLA-Doc SLA-ATL-01 definiert."}
{"ts": "165:06", "speaker": "I", "text": "Sie hatten vorhin die Verschiebung der regulatorischen Reports erwähnt. Können Sie genauer erläutern, wie Sie das intern kommuniziert haben?"}
{"ts": "165:13", "speaker": "E", "text": "Ja, wir haben ein internes RFC-Dokument erstellt, RFC-ATL-042, in dem wir die Gründe, die Risiken und den neuen geplanten Liefertermin dargelegt haben. Das ging dann in den wöchentlichen Steering Committees an alle relevanten Stakeholder."}
{"ts": "165:27", "speaker": "I", "text": "Gab es von Compliance-Seite sofortige Rückfragen oder Widerstände?"}
{"ts": "165:33", "speaker": "E", "text": "Es kam eine Anfrage von Compliance mit Ticket-ID COMP-117, in der sie wissen wollten, ob wir durch die Verschiebung gegen SLA-§5 verstoßen. Wir konnten belegen, dass wir noch innerhalb der erlaubten 90-Tage-Frist bleiben."}
{"ts": "165:48", "speaker": "I", "text": "Und wie haben Sie das Risiko für die Pilotkunden minimiert, dass fehlende Reports deren Prozesse stören?"}
{"ts": "165:54", "speaker": "E", "text": "Wir haben einen temporären Export via CSV in der Admin-Konsole aktiviert, gesteuert über das Feature Flag 'reg-report-csv', sodass Pilotkunden zumindest Rohdaten exportieren konnten."}
{"ts": "166:08", "speaker": "I", "text": "War das CSV-Export-Flag bereits vorhanden oder mussten Sie es kurzfristig entwickeln?"}
{"ts": "166:14", "speaker": "E", "text": "Das Flag existierte seit einem früheren Hackathon, war aber nie produktiv ausgerollt worden. Wir haben es reaktiviert und in Runbook RB-ATL-CSV dokumentiert, inklusive QA-Checks für Sonderzeichen und Encoding."}
{"ts": "166:29", "speaker": "I", "text": "Gab es technische Stolpersteine bei der Reaktivierung?"}
{"ts": "166:34", "speaker": "E", "text": "Ja, minor issues mit der Zeichensatzkodierung bei Umlauten, die in der Offline-Queue doppelt escaped wurden. QA hat das in TST-ATL-332 nachgestellt und gefixt."}
{"ts": "166:48", "speaker": "I", "text": "Wie wirkt sich diese Art von kurzfristigen Workarounds auf Ihre langfristige Roadmap aus?"}
{"ts": "166:54", "speaker": "E", "text": "Wir kennzeichnen solche Workarounds im Jira mit Label 'temp-solution'. Einmal pro Quartal prüfen wir, ob sie ersetzt oder entfernt werden. Das verhindert, dass technische Schulden unbemerkt wachsen."}
{"ts": "167:08", "speaker": "I", "text": "Gibt es KPI, an denen Sie erkennen, dass ein Workaround zu lange aktiv ist?"}
{"ts": "167:14", "speaker": "E", "text": "Ja, wenn ein Flag länger als 120 Tage aktiv ist und mehr als 30 % der Sessions es nutzen, dann triggert das einen Review-Workflow laut SOP-ATL-Flags-07."}
{"ts": "167:27", "speaker": "I", "text": "Abschließend: Welche Lehren ziehen Sie aus dieser Verschiebung für künftige Pilotphasen?"}
{"ts": "167:33", "speaker": "E", "text": "Wir wollen künftig einen Puffer von mindestens zwei Sprints für regulatorische Features einplanen und ein dediziertes Pre-Mortem-Meeting mit Compliance durchführen, um mögliche Konflikte früh zu erkennen."}
{"ts": "167:06", "speaker": "I", "text": "Sie hatten vorhin die QA-Runbooks erwähnt, die bei kombinierten Offline- und Feature-Flag-Tests zum Einsatz kommen. Mich würde interessieren: Wie oft werden diese Runbooks denn im Pilot tatsächlich aktualisiert?"}
{"ts": "167:14", "speaker": "E", "text": "Ähm, also im Schnitt alle zwei Wochen im Rahmen unseres Sprint-Endes. Wir haben sogar eine Checkliste im Runbook RNB-ATL-07, die festlegt, wann ein Update zwingend ist, z. B. bei Änderung an den Sync-Algorithmen oder wenn ein neues Backend-Endpunkt-Flag eingeführt wird."}
{"ts": "167:28", "speaker": "I", "text": "Das klingt sehr strukturiert. Gibt es da ein Review-Board oder ist das eher Team-Entscheidung?"}
{"ts": "167:34", "speaker": "E", "text": "Wir haben ein kleines internes Board, bestehend aus QA Lead, einem DevOps-Vertreter und mir. Wir stimmen Änderungen ab, bevor sie ins Confluence-Dokument wandern. Das hängt auch mit unserem SLA für Fehlerbehebungen zusammen – wir müssen gemäß SLA-ATL-Pilot-1 innerhalb von 48 Stunden reagieren."}
{"ts": "167:49", "speaker": "I", "text": "Wie hat sich das auf die Geschwindigkeit der Pilotentwicklung ausgewirkt?"}
{"ts": "167:55", "speaker": "E", "text": "Positiv, weil wir weniger Überraschungen im Feld haben. Früher kamen Hotfixes unkoordiniert rein, jetzt sehen wir Muster früher. Das Runbook zwingt uns, auch mal ein Feature-Flag nicht sofort zu aktivieren, wenn die Offline-Queue noch nicht durchgetestet ist."}
{"ts": "168:09", "speaker": "I", "text": "Gab es zuletzt ein konkretes Beispiel, wo Sie aufgrund eines Runbook-Eintrags eine Aktivierung verschoben haben?"}
{"ts": "168:15", "speaker": "E", "text": "Ja, Ticket ATL-FF-223: Da ging es um 'GeoTagging Offline'. Wir haben in der QA-Simulation festgestellt, dass bei einer Flag-Aktivierung mitten in einer Sync-Session Metadaten verloren gingen. Der Runbook-Punkt 'No mid-sync flag toggling' hat uns gezwungen, den Rollout um drei Tage zu verschieben."}
{"ts": "168:31", "speaker": "I", "text": "Und wie haben die Stakeholder auf die Verzögerung reagiert?"}
{"ts": "168:36", "speaker": "E", "text": "Natürlich gab es Rückfragen vom Vertrieb, aber wir konnten mit den QA-Logs und den Szenario-Beschreibungen aus RNB-ATL-07 belegen, dass ein Ausfall im Feld teurer gewesen wäre. Diese Transparenz hilft, Akzeptanz für Trade-offs zu schaffen."}
{"ts": "168:51", "speaker": "I", "text": "Das führt mich zu den Risiken: Sehen Sie aktuell neue Problemfelder, die vielleicht im nächsten Runbook-Update adressiert werden müssen?"}
{"ts": "168:57", "speaker": "E", "text": "Ja, wir sehen im Monitoring, dass bei sehr langen Offline-Phasen – länger als 72 Stunden – die Merge-Strategien an Grenzen stoßen. Da könnten wir im Runbook einen neuen Edge-Case-Durchlauf aufnehmen, inklusive Recovery-Plan, falls Konfliktauflösung fehlschlägt."}
{"ts": "169:12", "speaker": "I", "text": "Wer würde diesen Recovery-Plan umsetzen, QA oder DevOps?"}
{"ts": "169:17", "speaker": "E", "text": "Das ist eine Kombination. QA erstellt die Testfälle, DevOps baut die Monitoring-Hooks. Laut Runbook wird bei Fehlercode ATL-SYNC-409 automatisch ein Incident im System IDN-Atlas angelegt, den Level-2-Support innerhalb von 4 Stunden übernimmt."}
{"ts": "169:32", "speaker": "I", "text": "Klingt nach einem klar definierten Prozess. Denken Sie, dass diese Prozesse auch nach der Pilotphase so bestehen bleiben?"}
{"ts": "169:38", "speaker": "E", "text": "Ich denke ja, aber wir werden sie verschlanken müssen. In der Pilotphase darf man mehr Tests fahren, im Rollout müssen wir balancieren: Time-to-Market vs. absolute Robustheit. Das ist ähnlich wie bei den regulatorischen Reports, die wir vorhin verschoben hatten – immer eine Abwägung zwischen Risiko und Geschwindigkeit."}
{"ts": "174:06", "speaker": "I", "text": "Sie hatten vorhin den Offline-Queueing-Mechanismus erwähnt. Können Sie mir ein Beispiel geben, wo dieser direkt mit einer Backend-Abhängigkeit kollidiert ist?"}
{"ts": "174:15", "speaker": "E", "text": "Ja, das war im Sprint 14. Da hatten wir eine Änderung im Auth-Service des Backend-Teams, die eine neue Token-Refresh-Policy einführte. Unser Offline-Queueer hat damit nicht gerechnet und nach 12 Stunden ohne Netz sind die gespeicherten Requests an einem ungültigen Token gescheitert."}
{"ts": "174:31", "speaker": "I", "text": "Wie haben Sie darauf reagiert? Gab es ein Runbook für diesen Fall?"}
{"ts": "174:39", "speaker": "E", "text": "Unser Runbook RB-ATL-05 beschreibt für 'Auth-Failures beim Sync' einen Fallback: wir versuchen, ein Refresh-Token im Silent-Mode anzufordern. Damals mussten wir das erweitern, um auch lange inaktive Sessions nachzuladen. Das wurde als Hotfix zusammen mit Backend v2.3.7 ausgeliefert."}
{"ts": "174:58", "speaker": "I", "text": "Gab es in der Pilotgruppe Beschwerden dazu?"}
{"ts": "175:04", "speaker": "E", "text": "Ja, drei Power-User haben im Feedback-Formular gemeldet, dass ihre Änderungen 'verschwunden' seien. Wir konnten aber aus den Logs rekonstruieren, dass sie im Queue lagen und nach dem Hotfix synchronisiert wurden."}
{"ts": "175:18", "speaker": "I", "text": "Interessant. Und wie priorisieren Sie solche Backend-Abhängigkeiten gegenüber neuen Features?"}
{"ts": "175:26", "speaker": "E", "text": "Wir haben im Jira-Board ein Label 'Blocker-Backend'. Alles, was dort drin ist, hat automatisch Priorität 1. Neue Features – solange nicht SLA-kritisch – rutschen dann eine Iteration nach hinten."}
{"ts": "175:39", "speaker": "I", "text": "Sie hatten auch Feature Flags erwähnt. Haben Sie schon mal ein Flag gezogen, um so ein Problem temporär zu umgehen?"}
{"ts": "175:47", "speaker": "E", "text": "Ja, bei FF-ATL-AuthFallback. Wir konnten den betroffenen Offline-Sync-Code per Flag deaktivieren und den alten Pfad reaktivieren, bis das Backend stabil war. Das war in Ticket ATL-INC-229 dokumentiert."}
{"ts": "176:03", "speaker": "I", "text": "Das klingt nach enger Verzahnung von QA, Dev und Ops. Wie koordinieren Sie das unter Zeitdruck?"}
{"ts": "176:11", "speaker": "E", "text": "Wir haben einen wöchentlichen 'Pilot War Room'. Dort sind QA, Mobile-Dev, Backend-Dev und Support drin. Wenn ein Incident wie ATL-INC-229 auftaucht, gibt es einen 30-Minuten-Slot zur Lösungsfindung, direkt mit Entscheidungskompetenz."}
{"ts": "176:26", "speaker": "I", "text": "Zum Schluss noch: Welche Risiken sehen Sie aktuell als kritischsten Faktor für den Rollout?"}
{"ts": "176:34", "speaker": "E", "text": "Das größte Risiko ist derzeit die Kombination aus Offline-Sync und geplanter Mandantenfähigkeit. Multi-Tenant bringt komplexe Auth-Flows, und wenn die Offline-Warteschlange tenantübergreifend nicht sauber trennt, gibt es Datenleakage-Gefahr."}
{"ts": "176:51", "speaker": "I", "text": "Wie gehen Sie das an?"}
{"ts": "176:57", "speaker": "E", "text": "Wir haben einen Proof-of-Concept in QA, gesichert durch automatisierte Tests aus Runbook RB-ATL-12. Außerdem planen wir, das Feature unter einem 'dark launch' Flag erst in 5% der Mandanten zu aktivieren, um Monitoring-Daten zu sammeln, bevor wir hochskalieren."}
{"ts": "182:06", "speaker": "I", "text": "Lassen Sie uns noch ein bisschen tiefer auf die Verbindung zwischen dem Offline-Sync und den Backend-Limits eingehen – wie wirkt sich das konkret auf Ihre Release-Planung aus?"}
{"ts": "182:15", "speaker": "E", "text": "Also, wir mussten im Runbook R-OS-14 explizit festhalten, dass die Synchronisationsjobs zeitlich gestaffelt werden. Wenn wir das nicht tun, erzeugen die Pilotnutzer einen Peak, der die API-Gateway-Limits überschreitet. Das fließt direkt in die Planung ein, weil wir Feature-Flags für neue Sync-Funktionen nur aktivieren, wenn die Backend-Teams die Kapazität freigegeben haben."}
{"ts": "182:34", "speaker": "I", "text": "Und wie gehen Sie mit Nutzerfeedback um, wenn es gerade um diese technischen Limits geht?"}
{"ts": "182:42", "speaker": "E", "text": "Wir markieren solche Rückmeldungen in unserem JIRA-Board mit dem Label 'tech-constraint'. Ein Beispiel war Ticket ATL-212, wo mehrere Nutzer längere Sync-Zeiten meldeten. Wir haben das Feedback aufgenommen, aber die Umsetzung einer schnelleren Queue erst nach dem Backend-Upgrade priorisiert."}
{"ts": "182:59", "speaker": "I", "text": "Das klingt nach einem bewussten Trade-off zwischen Nutzerzufriedenheit und Systemstabilität."}
{"ts": "183:04", "speaker": "E", "text": "Genau. In unserem Priorisierungs-Runbook steht, dass Stabilität Vorrang hat, wenn SLAs gefährdet sind. Der Atlas-Mobile-Pilot hat ein SLA von 99,5 % Verfügbarkeit – wenn wir das reißen, ist der Imageschaden größer als der Nutzen der beschleunigten Syncs."}
{"ts": "183:21", "speaker": "I", "text": "Gab es denn Fälle, wo Sie dieses Prinzip ausnahmsweise gebrochen haben?"}
{"ts": "183:27", "speaker": "E", "text": "Nur einmal, bei einem kritischen Partner-Demo im März. Da haben wir für eine kleine Nutzerkohorte das neue Delta-Sync-Feature trotz Limit freigeschaltet, mit enger Monitoring-Schleife. Das war in Ticket ATL-245 dokumentiert, inklusive Rückfallplan."}
{"ts": "183:45", "speaker": "I", "text": "Wie hat QA diese Sonderfreigabe begleitet?"}
{"ts": "183:51", "speaker": "E", "text": "QA hat ein temporäres Testskript aus der Suite 'offline_sync_edge' angepasst, um die Error-Rates alle 15 Minuten zu prüfen. Außerdem stand ein Kollege in einem dedizierten Chatkanal mit den Backend-Leads in ständigem Austausch."}
{"ts": "184:09", "speaker": "I", "text": "Haben Sie dadurch neue Risiken identifiziert?"}
{"ts": "184:14", "speaker": "E", "text": "Ja, dass unsere Error-Logging-Pipeline bei zu vielen gleichzeitigen Retries selbst ins Straucheln kommt. Wir haben das als Risiko R-ATL-07 in der Risikomatrix eingetragen und eine Maßnahme definiert: Limitierung der Retry-Bursts im Client-Code."}
{"ts": "184:31", "speaker": "I", "text": "Und wie fließt diese Erkenntnis jetzt in die Zukunftsplanung ein?"}
{"ts": "184:37", "speaker": "E", "text": "Wir haben im Backlog einen Epik 'Resilient Sync', der genau diese Lessons Learned umsetzt: verbessertes Throttling, bessere Nutzer-Hinweise bei langen Warteschlangen, und ein automatischer Fallback auf manuelles Sync anstoßen."}
{"ts": "184:54", "speaker": "I", "text": "Das heißt, Sie sehen die künftigen Meilensteine stark in der technischen Robustheit verankert?"}
{"ts": "185:01", "speaker": "E", "text": "Absolut. Der nächste große Meilenstein M-ATL-05 im Juni misst Erfolg nicht nur an Feature-Completion, sondern auch an einer Reduktion der Sync-Error-Rate um 40 % gegenüber der Pilotbasislinie."}
{"ts": "188:06", "speaker": "I", "text": "Sie hatten vorhin schon die Verzahnung zwischen Backend-Limits und Offline-Sync erwähnt. Mich würde interessieren, wie Sie das jetzt im Pilotbetrieb kontinuierlich überwachen."}
{"ts": "188:22", "speaker": "E", "text": "Wir haben dafür im Runbook RB-ATL-07 definierte Health-Checks, die alle 15 Minuten Latenz- und Queue-Längen messen. Zusätzlich gibt es Alerts im internen Dashboard, die bei >200 Pending Requests im Sync-Buffer alarmieren."}
{"ts": "188:45", "speaker": "I", "text": "Und wenn so ein Alert auslöst, was ist dann der erste Schritt?"}
{"ts": "189:00", "speaker": "E", "text": "Erst prüfen wir im Log-Collector, ob es sich um einen Peak durch bekannte Nutzeraktionen handelt – etwa Bulk-Uploads vom Außendienst. Falls nicht, ziehen wir Ticket-Template TT-INC-14, das eine schrittweise Analyse vorgibt."}
{"ts": "189:25", "speaker": "I", "text": "Gibt es bei solchen Peaks auch Anpassungen an Feature Flags, um Last zu reduzieren?"}
{"ts": "189:38", "speaker": "E", "text": "Ja, genau. Wir haben ein Flag 'SYNC_THROTTLE' – wenn das gesetzt wird, reduziert der Client die gleichzeitigen Requests. Das ist in der Pilotphase schon zweimal aktiviert worden, siehe Change-Log CL-ATL-112."}
{"ts": "190:02", "speaker": "I", "text": "Wie kommunizieren Sie solche temporären Eingriffe an die Pilotnutzer?"}
{"ts": "190:14", "speaker": "E", "text": "Kurze Banner-Nachricht in der App und eine Mitteilung im Pilot-Forum. Wir vermeiden E-Mails, um nicht unnötige Panik zu schüren – das ist so eine ungeschriebene Regel bei uns."}
{"ts": "190:34", "speaker": "I", "text": "Klar. Jetzt, wo der Pilot sich dem Ende nähert, welche technischen Risiken sehen Sie für den Rollout?"}
{"ts": "190:46", "speaker": "E", "text": "Das größte Risiko ist aus meiner Sicht die Skalierung des Offline-Syncs bei >10.000 gleichzeitigen Sessions. Unser SLA für Sync liegt bei <5 Sekunden Latenz, und in Lasttests mit Staging-Datenbank haben wir das nur knapp gehalten."}
{"ts": "191:10", "speaker": "I", "text": "Welche Gegenmaßnahmen planen Sie?"}
{"ts": "191:22", "speaker": "E", "text": "Wir haben ein RFC erstellt (RFC-ATL-09), das den Wechsel auf inkrementelle Deltas statt Full-Sync vorsieht. Außerdem prüfen wir mit dem Backend-Team ein Sharding-Konzept für die Sync-Queues."}
{"ts": "191:45", "speaker": "I", "text": "Wie wirkt sich das auf Ihre Time-to-Market Planung aus?"}
{"ts": "191:58", "speaker": "E", "text": "Es könnte den Rollout um 3 Wochen verzögern. Deshalb haben wir im Steering Committee diskutiert, ob wir initial mit kleinerer Nutzergruppe live gehen, um die SLA-Risiken zu minimieren – das steht im Protokoll SC-2024-05."}
{"ts": "192:22", "speaker": "I", "text": "Das klingt nach einem klaren Trade-off zwischen Reichweite und Stabilität."}
{"ts": "192:32", "speaker": "E", "text": "Genau, und angesichts der Ticket-Historie – vor allem INC-ATL-77, wo ein Sync-Ausfall 6 Stunden dauerte – tendieren wir dazu, Stabilität höher zu gewichten, selbst wenn das Marketing lieber sofort skaliert."}
{"ts": "197:06", "speaker": "I", "text": "Wenn wir jetzt auf den nächsten Meilenstein schauen, was steht konkret auf Ihrer Checkliste für den Abschluss der Pilotphase?"}
{"ts": "197:15", "speaker": "E", "text": "Also, wir haben laut Runbook RB-ATL-07 noch drei Punkte offen: Erstens die finale Offline-Sync-Regression in der QA-Umgebung, zweitens die Integration des neuen Feature-Flag-Services in die Staging-Pipeline, und drittens ein kleines UX-Update basierend auf Nutzerfeedback aus Ticket P-ATL-982."}
{"ts": "197:34", "speaker": "I", "text": "Und für den Offline-Sync: gibt es da noch offene Risiken oder Blocking Issues?"}
{"ts": "197:42", "speaker": "E", "text": "Ja, wir haben in der letzten Nacht einen Edge Case entdeckt, bei dem die Queue unter bestimmten Netzwerk-Latenzen doppelte Einträge erzeugt. Ist in Jira als BUG-ATL-417 dokumentiert, wir haben schon einen Hotfix im Review."}
{"ts": "197:59", "speaker": "I", "text": "Wie schnell kann so ein Hotfix in den Pilot ausgerollt werden, wenn Sie den Review heute abschließen?"}
{"ts": "198:07", "speaker": "E", "text": "Gemäß unserem SLA für Pilotumgebungen innerhalb von 24 Stunden. Wir nutzen den Canary-Release, um erstmal nur 10 % der Pilotnutzer zu erreichen, bevor wir auf 100 % hochfahren."}
{"ts": "198:21", "speaker": "I", "text": "Das klingt nach einer soliden Absicherung. Apropos Canary, gab es schon mal den Fall, dass Sie zurückrollen mussten?"}
{"ts": "198:29", "speaker": "E", "text": "Ja, im April. Da hat ein Feature Flag für die neue Kartenansicht bei 15 % der Geräte zu Abstürzen geführt. Rollback erfolgte innerhalb von 40 Minuten, dokumentiert in Incident Report IR-ATL-042."}
