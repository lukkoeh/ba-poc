{"ts": "00:00", "speaker": "I", "text": "Können Sie zum Einstieg kurz beschreiben, wie Ihre Rolle als UX Lead im Atlas Mobile Projekt aussieht?"}
{"ts": "02:15", "speaker": "E", "text": "Gerne. Ich bin seit Beginn der Pilotphase der Atlas Mobile App als UX Lead involviert. Meine Hauptaufgabe ist es, das Design System DS-ATLAS v2 über alle Plattformen — iOS, Android und Web — konsistent zu halten. Ich steuere das Interface zwischen Design, Entwicklung und QA, insbesondere bei der Aktivierung neuer Feature Flags im Pilotbetrieb."}
{"ts": "06:40", "speaker": "I", "text": "Und wie interagieren Sie in diesem Rahmen mit den anderen Teams wie Platform oder QA?"}
{"ts": "09:05", "speaker": "E", "text": "Mit dem Platform-Team stimmen wir vor allem API-Änderungen ab, die UI-relevant sind, z. B. Field-Namen im Offline-Sync-Module. QA ist beim Release Candidate Gate ein direkter Partner, wir prüfen dort die UX-Checkliste aus Runbook RB-UX-004, bevor der Build ins Pilot-Rollout geht."}
{"ts": "13:20", "speaker": "I", "text": "Welche Hauptziele verfolgen Sie aktuell im Rahmen des Pilotbetriebs?"}
{"ts": "15:45", "speaker": "E", "text": "Momentan wollen wir drei Dinge sicherstellen: erstens, dass alle kritischen Journeys auch offline zuverlässig funktionieren; zweitens, dass die UI-Komponenten unter Feature Flags keine visuellen Brüche zeigen; und drittens, dass die Accessibility-Level AA-Plus aus unserer internen Richtlinie DS-A11Y-02 eingehalten werden."}
{"ts": "19:10", "speaker": "I", "text": "Welche Methoden setzen Sie zur Erhebung von Nutzerfeedback ein?"}
{"ts": "21:50", "speaker": "E", "text": "Wir nutzen ein In-App-Feedback-Modul mit kurzen Mikroumfragen und Heatmap-Tracking für Touch-Events. Zusätzlich führen wir wöchentliche Remote-Interviews mit ausgewählten Pilotnutzern, um qualitative Insights zu sammeln. Diese Daten werden dann in Jira unter UXF-Backlog referenziert."}
{"ts": "26:30", "speaker": "I", "text": "Und wie stellen Sie sicher, dass Accessibility-Anforderungen durchgängig erfüllt werden?"}
{"ts": "29:05", "speaker": "E", "text": "Wir haben eine automatisierte Prüfung in unserem CI, die auf Axe-Core basiert. Aber zusätzlich führen wir manuelle Screenreader-Tests nach Checkliste RB-A11Y-005 durch. Die Findings fließen direkt ins DS-ATLAS v2, sodass Verbesserungen plattformübergreifend wirken."}
{"ts": "34:00", "speaker": "I", "text": "Gab es konkrete Accessibility-Findings, die in der Pilotphase zu Änderungen geführt haben?"}
{"ts": "36:50", "speaker": "E", "text": "Ja, im Ticket MOB-A11Y-17 wurde gemeldet, dass Kontraste im Offline-Sync-Statusbalken unzureichend waren. Wir haben daraufhin die Farbvarianten im Token-Set angepasst und das in Release 0.9.3 unter Feature Flag 'syncStatusUIRevamp' ausgerollt."}
{"ts": "41:20", "speaker": "I", "text": "Wie binden Sie das DS-ATLAS v2 Tokenized Components Artefakt in die Entwicklung ein?"}
{"ts": "44:00", "speaker": "E", "text": "Das Artefakt wird als private NPM-Registry verteilt. Entwickler binden es über ein CLI-Tool ein, das auch gleich die korrekte Version je Branch prüft. Jede Änderung im Token-Set durchläuft unser RFC-Board, um sicherzustellen, dass es keine negativen Auswirkungen auf bestehende Feature Flags gibt."}
{"ts": "49:30", "speaker": "I", "text": "Welche Herausforderungen gab es bei der Kombination von Feature Flags mit UI-Komponenten?"}
{"ts": "54:00", "speaker": "E", "text": "Die größte Herausforderung ist die Synchronität der Flags über Plattformen hinweg. Wenn z. B. das Flag für einen neuen Button-Style auf Android aktiv ist, aber auf iOS nicht, entstehen Inkonsistenzen. Wir haben deshalb im Runbook RB-FF-009 definiert, dass UI-relevante Flags nur plattformgleich aktiviert werden dürfen."}
{"ts": "90:00", "speaker": "I", "text": "Lassen Sie uns bitte noch etwas tiefer auf das Zusammenspiel von QA und UX im Release Candidate Gate eingehen. Wie sieht dieser Prozess konkret aus?"}
{"ts": "90:05", "speaker": "E", "text": "Im RC-Gate prüfen wir gemeinsam mit QA nicht nur funktionale Tests, sondern auch visuelle Regressionen. Wir nutzen dafür das Visual-Delta-Skript aus dem Runbook RB-UX-014, um pixelgenaue Abweichungen gegenüber dem DS-ATLAS v2-Referenzbuild zu erkennen."}
{"ts": "90:17", "speaker": "I", "text": "Gab es zuletzt Fälle, in denen das RC-Gate wegen UX-relevanter Findings blockiert wurde?"}
{"ts": "90:21", "speaker": "E", "text": "Ja, im Ticket MOB-QA-332 hatten wir z. B. auf iOS eine Abweichung bei den tokenisierten Button-States. Das war durch ein Feature Flag ausgelöst, das versehentlich auch in der Pilotgruppe aktiviert war. Wir haben das Flag dann temporär deaktiviert und eine Korrektur in Sprint 14 eingeplant."}
{"ts": "90:36", "speaker": "I", "text": "Wie fließen solche Erkenntnisse in Ihre künftigen UX-Entscheidungen ein?"}
{"ts": "90:40", "speaker": "E", "text": "Wir haben intern ein Lessons-Learned-Dokument, in dem wir pro Incident die Auswirkung auf UX und mögliche Präventionsmaßnahmen festhalten. Diese fließen dann in die Anpassung unserer Feature-Flag-Guidelines und in das Figma-Komponenten-Repository ein."}
{"ts": "90:55", "speaker": "I", "text": "Sie hatten vorhin SLAs angesprochen – wie konkret berücksichtigen Sie Service Level in Ihrer Arbeit?"}
{"ts": "91:00", "speaker": "E", "text": "Unser SLA für die Pilotphase sieht z. B. eine maximale Time-to-Interactive von 2,5 Sekunden vor. Das beeinflusst direkt, wie wir Animationen timen oder welche Bildgrößen wir im Design zulassen. Im Runbook RB-PERF-007 sind diese Designrestriktionen dokumentiert."}
{"ts": "91:15", "speaker": "I", "text": "Gibt es bestimmte Metriken, die Sie dafür im Auge behalten?"}
{"ts": "91:20", "speaker": "E", "text": "Ja, neben Time-to-Interactive auch First Contentful Paint und die Error Rate im Offline-Sync. Letztere ist besonders wichtig, weil das Feature in der Pilotphase stark genutzt wird und direkt in unsere UX-SLOs einfließt."}
{"ts": "91:35", "speaker": "I", "text": "Unter SLA-Druck – wie priorisieren Sie dann UX-Verbesserungen?"}
{"ts": "91:39", "speaker": "E", "text": "Wir nutzen eine Priorisierungsmatrix, die SLA-Verletzungsrisiko und Nutzerwert kombiniert. Wenn z. B. ein UI-Lag droht, das SLA zu reißen, bekommt es Vorrang vor rein kosmetischen Verbesserungen."}
{"ts": "91:52", "speaker": "I", "text": "Mit Blick auf die Skalierung nach der Pilotphase – welche Risiken sehen Sie aus UX-Sicht?"}
{"ts": "91:57", "speaker": "E", "text": "Ein großes Risiko ist die Fragmentierung des Design Systems durch parallele Feature-Entwicklung. Wenn wir nicht streng auf Token-Konsistenz achten, kann die UI auf Android und iOS auseinanderlaufen. Auch die Accessibility-Validierung muss dann skaliert werden."}
{"ts": "92:12", "speaker": "I", "text": "Wie wollen Sie DS-ATLAS v2 für neue Feature-Sets anpassen?"}
{"ts": "92:16", "speaker": "E", "text": "Wir planen ein DS-ATLAS v2.1-Release mit erweiterter Token-Bibliothek für neue Interaktionsmuster, etwa bei erweiterten Offline-Modi. Dabei werden wir auch die automatisierten QA-Hooks für Feature Flags direkt in die Komponenten integrieren, um künftige Incidents wie MOB-QA-332 zu vermeiden."}
{"ts": "98:00", "speaker": "I", "text": "Wir sind ja jetzt schon recht tief im Thema, aber mich würde interessieren: wie fließen eigentlich die definierten SLAs konkret in Ihre täglichen UX-Entscheidungen ein?"}
{"ts": "98:15", "speaker": "E", "text": "Also, wir haben im Projekt für Atlas Mobile klare SLA-Parameter, z. B. Response-Zeit < 200 ms für Kerninteraktionen und Offline-Sync innerhalb von 5 Sekunden nach Reconnect. In meinem Alltag bedeutet das, dass wir Designideen, die diese Budgets gefährden, sofort challengen. Das steht auch so im UX-SLA-Abschnitt des Runbooks RB-UX-004."}
{"ts": "98:45", "speaker": "I", "text": "Das heißt, Sie haben eine Art Checkliste?"}
{"ts": "98:50", "speaker": "E", "text": "Genau, wir nutzen eine Pre-Deployment Checklist im Confluence, da gibt es eine Sektion 'SLA Compliance'. Bevor ein Feature-Flag auf 'on' gesetzt wird, prüfe ich mit dem QA Lead, ob unsere Messwerte im Observability-Dashboard innerhalb der SLOs liegen."}
{"ts": "99:20", "speaker": "I", "text": "Welche Metriken sind für Sie persönlich am wichtigsten zur Messung der Servicequalität?"}
{"ts": "99:25", "speaker": "E", "text": "Neben der Time-to-Interactive messe ich die Error Rate bei UI-Events und die Abbruchquote im Onboarding. Letzteres haben wir im Ticket UX-MET-087 als KPI definiert, weil wir in der Pilotphase dort einen Drop von 15 % hatten, nachdem ein Feature-Flag falsch konfiguriert war."}
{"ts": "99:55", "speaker": "I", "text": "Und wenn SLA-Druck herrscht, wie priorisieren Sie?"}
{"ts": "100:00", "speaker": "E", "text": "Dann gehen Stabilität und Kernpfade vor. Ein Beispiel: Letzte Woche gab es Incident MOB-CRIT-042, Crash bei Offline-Sync. Wir haben ein geplantes UI-Redesign verschoben und stattdessen sofort mit DevOps den Bugfix deployed, um das SLA > 99,5 % Availability zu halten."}
{"ts": "100:30", "speaker": "I", "text": "Lassen Sie uns auf die Zukunft schauen: Welche Risiken sehen Sie bei der Skalierung nach der Pilotphase?"}
{"ts": "100:35", "speaker": "E", "text": "Ein großes Risiko ist Inconsistency zwischen Plattformen, wenn Feature Flags asynchron ausgerollt werden. Wenn iOS schon neue DS-ATLAS-Komponenten nutzt, Android aber noch nicht, kann das zu UX-Brüchen führen. Außerdem steigt die Komplexität bei Accessibility-Regression-Tests enorm."}
{"ts": "101:05", "speaker": "I", "text": "Wie wollen Sie das Design System dafür anpassen?"}
{"ts": "101:10", "speaker": "E", "text": "Wir planen ein 'Adaptive Token Layer' einzuführen, der per Flag automatisch alte und neue Tokens mappt. Das erfordert eine Erweiterung des Build-Skripts, siehe RFC-DS-221, und erlaubt uns, inkrementell zu migrieren ohne Brüche im UI."}
{"ts": "101:35", "speaker": "I", "text": "Gibt es Lessons Learned aus der Pilotphase, die Sie auf jeden Fall beibehalten wollen?"}
{"ts": "101:40", "speaker": "E", "text": "Ja, unbedingt die enge Verzahnung mit QA schon vor dem Release Candidate Gate. Der gemeinsame Review von Feature-Flags und UX-Flows hat uns mehrfach vor Production Incidents bewahrt, z. B. bei RB-MOB-021, wo wir einen Crash Loop vor dem Go-Live abfangen konnten."}
{"ts": "102:05", "speaker": "I", "text": "Können Sie das als abschließendes Fazit formulieren?"}
{"ts": "102:10", "speaker": "E", "text": "Zusammengefasst: UX im Pilotbetrieb ist ein permanentes Austarieren zwischen Innovationsdrang und SLA-Stabilität. Mit klaren Metriken, abgestimmten Runbooks und einem adaptiven Design System können wir die Risiken bei der Skalierung deutlich reduzieren."}
{"ts": "114:00", "speaker": "I", "text": "Könnten Sie bitte noch einmal konkret erläutern, wie die Erkenntnisse aus dem Incident RB-MOB-021 in zukünftige UX-Designentscheidungen eingeflossen sind?"}
{"ts": "114:05", "speaker": "E", "text": "Ja, also bei RB-MOB-021 hatten wir ja die Crash Loops im Offline-Sync, die durch ein Race Condition in der State-Maschine ausgelöst wurden. Wir haben daraufhin im Runbook UX-07 ergänzt, dass bei kritischen Sync-UI-Komponenten ein explizites Loading- und Retry-Muster eingebaut werden muss. Das hat direkte Auswirkungen auf unsere Component Library gehabt."}
{"ts": "114:12", "speaker": "I", "text": "Das heißt, Sie haben die Design Patterns angepasst, um technische Fehlerzustände besser abzufangen?"}
{"ts": "114:17", "speaker": "E", "text": "Genau, und wir haben auch mit QA ein Mock-Failure-Flag eingeführt, um solche States gezielt auszulösen. Das ist jetzt Teil des DS-ATLAS v2 Test-Kits, sodass Entwickler schon im Feature-Flagging-Stadium UI-Fallbacks checken können."}
{"ts": "114:23", "speaker": "I", "text": "Wie wird das im Piloten überprüft – gibt es da spezielle Gates?"}
{"ts": "114:28", "speaker": "E", "text": "Ja, beim Release Candidate Gate prüfen wir jetzt nicht nur funktionale Acceptance Criteria, sondern auch die UX-Fallback-States. QA hat dafür im Gate-Template ein eigenes Tab 'UX Recovery' angelegt, das wir als Lead sign-offen müssen."}
{"ts": "114:35", "speaker": "I", "text": "Gab es seit der Anpassung weitere ähnliche Incidents?"}
{"ts": "114:39", "speaker": "E", "text": "Nein, wir hatten bei Ticket RB-MOB-024 zwar ein kurzes UI-Freeze bei schlechter Netzqualität, aber der neue Retry-Loop hat verhindert, dass der Benutzer komplett hängen bleibt. QA hat das als 'resolved by design' geschlossen."}
{"ts": "114:46", "speaker": "I", "text": "Interessant. Und wie dokumentieren Sie solche Lessons Learned für die Skalierung?"}
{"ts": "114:50", "speaker": "E", "text": "Wir pflegen ein internes UX-Knowledge-Base-Confluence, wo jedes größere Incident-Postmortem auch die Designentscheidungen dokumentiert. Für Atlas Mobile haben wir ein eigenes Kapitel 'Pilotphase Patterns', das nach dem Go-Live in die globalen UX-Guidelines migriert wird."}
{"ts": "114:58", "speaker": "I", "text": "Welche Rolle spielen dabei die Metriken, die Sie vorhin genannt haben?"}
{"ts": "115:02", "speaker": "E", "text": "Wir korrelieren die Metriken wie 'Time to interactive' und 'Error recovery rate' direkt mit den Postmortem-Daten. Wenn z.B. die Recovery Rate nach einem UX-Pattern-Update messbar steigt, gilt das als positiver KPI für den Rollout."}
{"ts": "115:09", "speaker": "I", "text": "Haben Sie dafür automatisierte Dashboards?"}
{"ts": "115:13", "speaker": "E", "text": "Ja, wir nutzen ein internes Grafana-Board 'UX-SLO Atlas', das QA- und Telemetrie-Daten aggregiert. Dort sehe ich in Echtzeit, ob wir nahe an unsere SLA-Grenzen kommen und kann frühzeitig Design-Optimierungen anstoßen."}
{"ts": "115:20", "speaker": "I", "text": "Wie priorisieren Sie unter SLA-Druck, wenn mehrere UX-Issues gleichzeitig auftreten?"}
{"ts": "115:24", "speaker": "E", "text": "Wir wenden einen Mix aus Impact-Scoring und SLA-Risikoanalyse an. Ein Issue, das 0,1% der Nutzer betrifft, aber ein SLA-Breach auslösen könnte, bekommt Vorrang. Das ist auch so in unserem Runbook UX-PRIO-02 verankert."}
{"ts": "116:00", "speaker": "I", "text": "Bevor wir zum Abschluss kommen, würde mich interessieren, ob es in der letzten Woche noch neue Findings aus der QA gab, die Sie aus UX-Sicht relevant finden."}
{"ts": "116:15", "speaker": "E", "text": "Ja, wir hatten den QA-Report QA-MOB-447, der einen Edge Case beim Offline-Sync beschrieben hat: Nutzer konnten in einer seltenen Race Condition doppelte Einträge erzeugen. Aus UX-Perspektive haben wir sofort im Prototypen die visuelle Bestätigung nach dem Sync ergänzt, um mehr Klarheit zu schaffen."}
{"ts": "116:39", "speaker": "I", "text": "Wie lief in so einem Fall die Abstimmung mit dem Platform-Team, gerade wenn es um den Sync-Algorithmus geht?"}
{"ts": "116:52", "speaker": "E", "text": "Wir haben im Runbook RB-SYNC-003 festgehalten, dass UX-Änderungen bei Datenkonflikten immer in einem gemeinsamen Grooming mit Platform geprüft werden. Das war hier wichtig, weil wir z. B. die Lade-Indikatoren nur anzeigen dürfen, wenn das API-Flag 'syncStatus' tatsächlich auf 'pending' steht."}
{"ts": "117:20", "speaker": "I", "text": "Gab es dabei technische Einschränkungen, die Ihr Design beeinflusst haben?"}
{"ts": "117:31", "speaker": "E", "text": "Definitiv. Die Sync-Logs liegen nur alle 5 Sekunden aktualisiert vor, was eine sofortige Rückmeldung erschwert. Wir mussten daher einen Hybrid-Approach wählen: sofortige lokale Bestätigung plus spätere Statuskorrektur, falls der Server einen Konflikt meldet."}
{"ts": "117:55", "speaker": "I", "text": "Wie bewerten Sie den Einfluss solcher Workarounds auf die SLA-Einhaltung?"}
{"ts": "118:06", "speaker": "E", "text": "Aus Erfahrung wissen wir, dass leichte Verzögerungen in der Statusanzeige weniger SLA-relevant sind als Datenverlust. Unser SLA 99,5 % Data Integrity hat hier Priorität, selbst wenn die 'UI latency' Metrik kurzfristig steigt."}
{"ts": "118:28", "speaker": "I", "text": "Hat das auch Einfluss auf künftige Feature-Flag-Strategien?"}
{"ts": "118:39", "speaker": "E", "text": "Ja, wir planen, Flags für 'enhancedSyncUI' separat zu steuern, um in der Skalierungsphase A/B-Tests fahren zu können. Lessons Learned aus der Pilotphase zeigen, dass wir so UX-Iterationen risikoärmer in den Livebetrieb bringen."}
{"ts": "119:02", "speaker": "I", "text": "Gab es in der Vergangenheit Missverständnisse zwischen UX und QA, die Sie unbedingt vermeiden wollen?"}
{"ts": "119:15", "speaker": "E", "text": "Einmal, bei Incident MOB-CRL-019, haben wir zu spät verstanden, dass ein visuelles Element im Crash-Loop mitausgelöst wurde. Seitdem ist in RB-MOB-021 festgehalten, dass QA bei UI-Anomalien sofort einen UX-Review anfordert."}
{"ts": "119:41", "speaker": "I", "text": "Sehen Sie bei der Skalierung Risiken, dass solche Prozeduren aufgeweicht werden?"}
{"ts": "119:53", "speaker": "E", "text": "Das Risiko ist real. Mit mehr Teams steigt die Gefahr von Prozessabweichungen. Wir überlegen daher, Runbook-Checks in das CI/CD-Gate einzubauen, damit kein Release Candidate ohne UX-QA-Review durchkommt."}
{"ts": "120:15", "speaker": "I", "text": "Würden Sie sagen, dass diese formalen Gates auch die Kreativität im UX-Design beeinflussen?"}
{"ts": "120:28", "speaker": "E", "text": "Ein Stück weit ja, aber die Sicherheit der User Experience hat Vorrang. Wir versuchen, Kreativität in frühen Prototyping-Sprints auszuleben, bevor die SLA- und Runbook-basierten Restriktionen greifen."}
{"ts": "132:00", "speaker": "I", "text": "Zum Abschluss würde mich interessieren: Wie haben Sie im Atlas Mobile Pilot konkret das DS-ATLAS v2 Artefakt in Verbindung mit Feature Flags orchestriert?"}
{"ts": "132:10", "speaker": "E", "text": "Wir haben das Tokenized Components Paket im Design System Repo versioniert und über ein internes npm-Registry-Proxy gezogen. Im Pilot haben wir pro Feature Flag eine Mapping-Tabelle gepflegt, die in unserem Runbook RB-UX-017 dokumentiert ist. Das half, die Komponenten konsistent zu toggeln, ohne dass QA jedes Mal ein komplettes Regression-Set fahren musste."}
{"ts": "132:25", "speaker": "I", "text": "Gab es dabei Abhängigkeiten zur Plattform-Architektur, die Sie berücksichtigen mussten?"}
{"ts": "132:35", "speaker": "E", "text": "Ja, eindeutig. Die Multi-hop-Verknüpfung bestand darin, dass Feature Flag Evaluations im Backend-Config-Service stattfanden, während die UI sofort reaktiv adaptieren musste. Wir mussten also asynchrone States im Redux-Store korrekt mappen, sonst kam es zu Inkonsistenzen zwischen Android und iOS. Das steht so auch im Cross-Platform Sync Guide Abschnitt 4.2."}
{"ts": "132:55", "speaker": "I", "text": "Und wie haben Sie QA hier eingebunden, insbesondere beim Release Candidate Gate?"}
{"ts": "133:05", "speaker": "E", "text": "Wir haben QA früh in den RC-Plan integriert: Vor jedem Gate gab es einen UX-Review-Checkpoint. Funde wie \"Button misaligned under FF-BETA-022\" wurden als JIRA UX-Defects geloggt und mit Priorität P2 unter SLA 48h fixiert. Das Incident-Handling war dann schlank, weil die Steps im QA-UX-Handover-Runbook klar definiert sind."}
{"ts": "133:25", "speaker": "I", "text": "Stichwort Incidents, Sie hatten vorhin Crash Loops erwähnt – konkret RB-MOB-021. Wie sah Ihre Rolle bei der Behebung aus?"}
{"ts": "133:35", "speaker": "E", "text": "Bei RB-MOB-021 war der Auslöser ein Offline-Sync-Modul, das bei bestimmten Network Timeouts in eine Endlosschleife ging. Aus UX-Sicht haben wir sofort ein Degradationspattern aktiviert, dokumentiert in UX-RUN-DEC-05, das eine Fallback-Anzeige bringt, statt die App einfrieren zu lassen. Parallel haben wir mit QA die Repro-Steps verifiziert und mit Platform den Patch getestet."}
{"ts": "133:55", "speaker": "I", "text": "Fließen solche Incident-Erkenntnisse systematisch in künftige UX-Entscheidungen ein?"}
{"ts": "134:05", "speaker": "E", "text": "Ja, wir haben einen Abschnitt 'UX Postmortem' in jedem Incident-Report. Die Learnings wandern in das Pattern-Library-Backlog. So ist aus RB-MOB-021 z.B. das 'Graceful Sync Degrade'-Pattern entstanden, das jetzt Teil von DS-ATLAS v2.3 ist."}
{"ts": "134:20", "speaker": "I", "text": "Wenn Sie SLAs betrachten, welche Metriken sind für Sie gerade im Pilotbetrieb am wichtigsten?"}
{"ts": "134:30", "speaker": "E", "text": "Crash-Free-Session-Rate über 99%, Time-to-Interactive unter 1,8 Sekunden und eine Error-Budget-Auslastung unter 70%. Diese Werte sind hart in unserem SLO-Dashboard verankert. Unter SLA-Druck priorisieren wir immer Issues, die diese Metriken gefährden, selbst wenn es bedeutet, weniger sichtbare Features zu verschieben."}
{"ts": "134:50", "speaker": "I", "text": "Sehen Sie bei der Skalierung nach der Pilotphase besondere UX-Risiken?"}
{"ts": "135:00", "speaker": "E", "text": "Ja, der größte Risikofaktor ist die Fragmentierung der UI, wenn mehrere Feature-Streams parallel laufen. Ohne strikte DS-Governance drohen Inkonsistenzen. Außerdem steigt die Komplexität im Offline-Sync, was bei internationalen Rollouts zu Latenzmustern führen kann, die wir noch nicht getestet haben."}
{"ts": "135:20", "speaker": "I", "text": "Wie planen Sie, das Design System für neue Feature-Sets anzupassen?"}
{"ts": "135:30", "speaker": "E", "text": "Wir wollen DS-ATLAS modularisieren: Core Tokens bleiben stabil, Feature-spezifische Module können schneller iterieren. Dazu definieren wir in RFC-UX-044 eine Versionierungsstrategie, die sowohl mit Feature Flagging als auch mit QA-Gates kompatibel ist. So können wir Risiken gezielt isolieren und unter Kontrolle halten."}
{"ts": "140:00", "speaker": "I", "text": "Lassen Sie uns noch einmal auf die Lessons Learned eingehen – welche spezifischen UX-Muster aus der Pilotphase möchten Sie auf jeden Fall in die Skalierung mitnehmen?"}
{"ts": "140:12", "speaker": "E", "text": "Ein klarer Punkt ist unser offline-first Pattern. Das hat in der Pilotphase, laut Runbook RB-UX-014, 92 % der Sync-Probleme abgefangen. Ich würde auch das Token-Color-Mapping beibehalten, weil es in der QA-Kette sehr stabil war."}
{"ts": "140:30", "speaker": "I", "text": "Gab es dazu Feedback von den Entwicklern oder der QA, das Ihre Entscheidung beeinflusst hat?"}
{"ts": "140:41", "speaker": "E", "text": "Ja, QA hat in Ticket QA-ATL-477 vermerkt, dass die konsistenten Tokens die Testskripte erleichtert haben. Development meinte, die offline-first Logik sei im Sync-Engine Modul klar isoliert, was spätere Feature Flags vereinfacht."}
{"ts": "140:58", "speaker": "I", "text": "Sie sprachen von Feature Flags – wie planen Sie die Flag-Strategie bei wachsender Nutzerzahl anzupassen?"}
{"ts": "141:10", "speaker": "E", "text": "Wir wollen im Scaling-Plan auf gruppenbasierte Flags umsteigen. Das heißt, wir aktivieren Features für Kohorten, um UX-Regressionen schneller zu entdecken. Das haben wir in RFC-ATL-FF-03 dokumentiert."}
{"ts": "141:28", "speaker": "I", "text": "Und welche Risiken sehen Sie bei diesem Ansatz?"}
{"ts": "141:36", "speaker": "E", "text": "Riskant ist, dass gruppenbasierte Rollouts komplexere Monitoring-Segmente brauchen. Wenn wir hier die Crash-Free-Rate pro Kohorte nicht sauber tracken, verlieren wir SLA-Transparenz."}
{"ts": "141:52", "speaker": "I", "text": "Wie planen Sie, das Monitoring entsprechend zu erweitern?"}
{"ts": "142:02", "speaker": "E", "text": "Wir integrieren in das DS-ATLAS Dashboard eine Kohorten-Ansicht. Die Metriken Time-to-Interactive und Error-Budget-Consumption werden dort auf Feature-Flag-Level runtergebrochen."}
{"ts": "142:18", "speaker": "I", "text": "Klingt gut. Gibt es von der Pilotphase noch offene Incidents, die Sie vor dem Scaling lösen müssen?"}
{"ts": "142:28", "speaker": "E", "text": "RB-MOB-021, der Crash Loop beim Resume aus Offline-Mode, ist noch in Bearbeitung. UX-seitig haben wir die Reconnect-Dialoge überarbeitet, um den Nutzerpfad klarer zu machen."}
{"ts": "142:44", "speaker": "I", "text": "Wie koordinieren Sie solche Änderungen mit QA unter Zeitdruck?"}
{"ts": "142:54", "speaker": "E", "text": "Wir nutzen das Release Candidate Gate, aber bei kritischen UX-Änderungen wie hier machen wir einen zusätzlichen Exploratory Test-Slot. Das ist in Runbook RB-QA-UX-ExtraSteps beschrieben."}
{"ts": "143:10", "speaker": "I", "text": "Abschließend: Worauf werden Sie in den ersten zwei Wochen nach dem Go-Live besonders achten?"}
{"ts": "143:22", "speaker": "E", "text": "Auf die SLA-relevanten KPIs: Crash-Free-Rate > 99 %, Time-to-Interactive < 2,5 s, und dass keine Accessibility-Regressionen gemeldet werden. Diese Checks laufen automatisiert und werden täglich ins UX-Board gepusht."}
{"ts": "148:00", "speaker": "I", "text": "Lassen Sie uns jetzt noch auf die Lessons Learned der Pilotphase schauen. Gab es aus UX-Perspektive ein Muster, das Sie überraschte?"}
{"ts": "148:10", "speaker": "E", "text": "Ja, eines der auffälligsten Muster war, dass Nutzer im Offline-Modus deutlich länger in der App verweilen, aber die Navigation intuitiver erwarten. Das war so nicht in unseren Hypothesen. Wir haben daraufhin unser Offline-Sync-Overlay gemäß Runbook UX-OFF-014 überarbeitet."}
{"ts": "148:25", "speaker": "I", "text": "Interessant, und wie haben Sie diese Anpassung technisch validiert?"}
{"ts": "148:34", "speaker": "E", "text": "Wir haben in der Staging-Umgebung einen Feature Flag 'offline_nav_beta' aktiviert und mit einer 20%-Kohorte A/B getestet. Die QA hat uns dann mit einem speziellen Testplan aus TP-ATL-53 unterstützt, um auch Barrierefreiheit zu verifizieren."}
{"ts": "148:50", "speaker": "I", "text": "Gab es bei diesem Test auch Schnittstellen zu Platform- oder Backend-Teams?"}
{"ts": "149:00", "speaker": "E", "text": "Unbedingt. Wir mussten die Sync-Queue-Logik anpassen, was direkt das Backend betraf. Das bedeutete, dass die Platform-Engineers zusammen mit uns und QA eine dreistufige Freigabe nach RFC-ATL-19 umsetzten."}
{"ts": "149:17", "speaker": "I", "text": "Wie haben Sie sichergestellt, dass das DS-ATLAS v2 Design System konsistent blieb?"}
{"ts": "149:27", "speaker": "E", "text": "Wir haben die tokenisierten Komponenten erst in einer isolierten Storybook-Instanz aktualisiert und via CI-Check gegen die Design Tokens YAML-Datei validiert. Das hat uns geholfen, Regressionen zu vermeiden, die bei Feature Flags gern mal passieren."}
{"ts": "149:44", "speaker": "I", "text": "Gab es in dieser Phase auch kritische Incidents?"}
{"ts": "149:53", "speaker": "E", "text": "Ja, wir hatten einen Crash Loop, Ticket RB-MOB-021-EXT, der nur unter iOS 14 auftrat. Meine Rolle war, die User Journey zu rekonstruieren und mit QA die minimal nötigen UI-Änderungen zu identifizieren, um unter SLA D-UX-001 unter 4h eine Hotfix-Patch zu liefern."}
{"ts": "150:12", "speaker": "I", "text": "Wie flossen diese Erkenntnisse in zukünftige Designs ein?"}
{"ts": "150:21", "speaker": "E", "text": "Wir haben unsere Heuristik zur Abwärtskompatibilität erweitert, in dem wir ein Preflight-Skript in den Build-Prozess einfügten, das UI-Komponenten gegen alte OS-Versionen rendert. Das ist jetzt Teil unseres Standard-Runbooks UX-BLD-007."}
{"ts": "150:38", "speaker": "I", "text": "Wenn Sie an die Skalierung nach der Pilotphase denken, was ist das größte UX-Risiko?"}
{"ts": "150:47", "speaker": "E", "text": "Das größte Risiko ist, dass die Feature-Flag-Matrix zu komplex wird, um konsistente Erlebnisse zu gewährleisten. Ohne ein robustes Mapping zwischen Flags und Design Tokens könnten wir Inkonsistenzen einführen, die SLA-relevant werden."}
{"ts": "151:02", "speaker": "I", "text": "Welche Trade-offs müssen Sie dabei eingehen?"}
{"ts": "151:10", "speaker": "E", "text": "Wir müssen abwägen zwischen schneller Feature-Auslieferung und der Stabilität des Design Systems. Belege wie die Metriken aus QA-Report QAR-ATL-77 zeigen, dass zu viele parallele Flags die Crash-Free-Rate um bis zu 3% senken. Deshalb setzen wir künftig auf ein gestaffeltes Rollout-Schema."}
{"ts": "152:00", "speaker": "I", "text": "Wir hatten eben schon über SLAs gesprochen. Mich würde interessieren, wie Sie im Atlas Mobile Pilot mit unerwarteten Performance-Degradationen umgehen, bevor sie gegen das SLO laufen."}
{"ts": "152:15", "speaker": "E", "text": "Ja, also wir haben da im Runbook RB-PERF-004 einen Abschnitt, der frühzeitige Warnsignale beschreibt. Wenn z. B. die Time-to-Interactive im Staging-Canary um mehr als 15 % ansteigt, triggert unser Alerting und wir fahren einen Feature-Flag-Rollback. Das halten wir auch während des Pilotbetriebs so konsequent."}
{"ts": "152:39", "speaker": "I", "text": "Und wie koordinieren Sie das mit dem Platform-Team?"}
{"ts": "152:46", "speaker": "E", "text": "Da gibt es einen festen Slack-Channel #atlas-perf-alerts, wo QA, Platform und wir aus UX sofort ein gemeinsames Triage-Board öffnen. Wir hatten z. B. letzte Woche einen Fall, Ticket P-ATL-312, bei dem ein neues Animationspattern auf älteren Android-Geräten die GPU-Last verdoppelt hat."}
{"ts": "153:10", "speaker": "I", "text": "Wie haben Sie da reagiert?"}
{"ts": "153:15", "speaker": "E", "text": "Wir haben die Animation per Feature Flag deaktiviert und gleichzeitig im DS-ATLAS v2 einen Low-Motion-Token ergänzt, der künftig bei Geräten mit unter 2 GB RAM automatisch greift. Damit bleibt die Konsistenz erhalten, ohne die Performance zu opfern."}
{"ts": "153:38", "speaker": "I", "text": "Gab es da auch Accessibility-Implikationen?"}
{"ts": "153:44", "speaker": "E", "text": "Ja, tatsächlich. Der Low-Motion-Token orientiert sich nicht nur an der Hardware, sondern auch an den OS-Accessibility-Einstellungen wie 'Bewegung reduzieren'. Das kam als Feedback aus unserem Beta-Test in der Pilotgruppe, dokumentiert in UX-FEED-089."}
{"ts": "154:05", "speaker": "I", "text": "Das klingt nach einer Verzahnung von mehreren Subsystemen – Hardware-Erkennung, Feature Flags, Accessibility."}
{"ts": "154:12", "speaker": "E", "text": "Genau, und das ist im Pilot essentiell. Wir haben das in der Multi-Hop-Architektur-Übersicht A-Map-02 dokumentiert: Das UX-Layer sendet bei App-Start ein Capability-Profile, das sowohl im Flag-Service als auch in der Accessibility-Engine ausgewertet wird."}
{"ts": "154:34", "speaker": "I", "text": "Wenn wir auf die Zukunft schauen – nach der Pilotphase – wie wollen Sie verhindern, dass die Komplexität dieser Kopplungen zu mehr Incidents führt?"}
{"ts": "154:46", "speaker": "E", "text": "Das ist tatsächlich einer der größten Risiken. Wir planen eine Refactoring-Epic für Q3, RFC-ATL-27, um die Feature-Flag-Logik stärker zu modularisieren. Ziel ist, dass Flags für Performance und Accessibility getrennt ausgerollt werden können, um Kaskadenfehler zu vermeiden."}
{"ts": "155:08", "speaker": "I", "text": "Und wie wirkt sich das auf die SLA-Einhaltung aus?"}
{"ts": "155:14", "speaker": "E", "text": "Kurzfristig kann das die Deploy-Zyklen verlängern, aber wir haben berechnet, dass wir dadurch 30 % weniger Incident-Tickets in dieser Kategorie erwarten. Das sichert langfristig die Crash-Free-Rate von > 99,3 %, die in unserem SLA verankert ist."}
{"ts": "155:34", "speaker": "I", "text": "Gibt es Lessons Learned, die Sie aus diesen Fällen mitnehmen?"}
{"ts": "155:40", "speaker": "E", "text": "Ja – vor allem, dass wir UX-Änderungen immer mit Telemetrie-Hooks ausstatten müssen, bevor wir in den Pilot gehen. So können wir in den ersten 48 h nach Rollout sehr granular sehen, ob wir uns dem Error Budget gefährlich nähern, und im Zweifel zurückrollen."}
{"ts": "160:00", "speaker": "I", "text": "Lassen Sie uns gern nochmal auf die bevorstehende Skalierung nach der Pilotphase eingehen. Welche spezifischen UX-Risiken haben Sie aktuell auf dem Radar, wenn Atlas Mobile in Produktion geht?"}
{"ts": "160:04", "speaker": "E", "text": "Also, eines der größten Risiken ist tatsächlich die Offline-Sync-Performance bei sehr großen Datensätzen. Wir haben in der Pilotphase max. 1.200 Records pro Sync gesehen, in Produktion erwarten wir bis zu 8.000. Das beeinflusst nicht nur Time-to-Interactive, sondern auch die wahrgenommene App-Stabilität."}
{"ts": "160:10", "speaker": "I", "text": "Verstehe, und wie gehen Sie damit um?"}
{"ts": "160:13", "speaker": "E", "text": "Wir haben in RFC-ATL-339 eine Lazy-Load-Strategie dokumentiert, kombiniert mit einem Feature Flag `ff_lazy_sync_ui`. Damit können wir in Wellen ausrollen und QA gezielt A/B-Tests fahren. Außerdem steht im Runbook RB-SYNC-07, wie wir bei Überschreitung des SLO 'Sync-Completion unter 15s' reagieren."}
{"ts": "160:20", "speaker": "I", "text": "Können Sie ein Beispiel geben, wie QA hier eingebunden wird?"}
{"ts": "160:24", "speaker": "E", "text": "Ja, QA nutzt den Release Candidate Gate-Check P-ATL-QA-015. Dort wird neben funktionalen Tests auch ein UX-Checklist-Durchlauf gemacht, z. B. ob Progress-Indicator konsistent angezeigt wird. Wir hatten z. B. in Ticket MOB-UX-442 einen Fall, wo der Indicator in iOS verschwand, was zu Abbrüchen führte."}
{"ts": "160:31", "speaker": "I", "text": "Gab es dabei auch Auswirkungen auf SLA oder Error Budget?"}
{"ts": "160:35", "speaker": "E", "text": "Ja, der Fehler trieb kurzfristig die Crash-Free-Rate unter 97,5 %, womit wir 0,3 % des monatlichen Error Budgets in zwei Tagen verbrauchten. Deshalb war die Priorisierung klar: Hotfix innerhalb 24h gemäß Runbook RB-HOTFIX-02."}
{"ts": "160:42", "speaker": "I", "text": "Das klingt nach enger Verzahnung. Wie fließen solche Learnings zurück ins Design System?"}
{"ts": "160:46", "speaker": "E", "text": "Wir haben im DS-ATLAS v2 jetzt eine Standardkomponente `AsyncProgressModal` ergänzt, die platform-unabhängig den Sync-Status hält, selbst wenn der View neu geladen wird. Das ist ein Pattern, das aus genau diesem Incident stammt."}
{"ts": "160:52", "speaker": "I", "text": "Gibt es weitere Trade-offs, die Sie bei der Skalierung bewusst eingehen?"}
{"ts": "160:56", "speaker": "E", "text": "Ja, wir nehmen in Kauf, dass initial mehr Memory genutzt wird, um Caching für die Top-10-Userflows vorzuhalten. Das reduziert Latenz, kostet aber 15 MB extra. In SLA-Terminologie ist das ein bewusster Performance-vs.-Ressourcen-Trade-off, der in RFC-ATL-355 diskutiert ist."}
{"ts": "161:03", "speaker": "I", "text": "Wie sichern Sie ab, dass diese extra Ressourcennutzung nicht auf Low-End-Geräten zu Problemen führt?"}
{"ts": "161:07", "speaker": "E", "text": "Wir haben ein Device Capability Flagging eingeführt. Geräte mit weniger als 2 GB RAM bekommen das Caching nicht aktiviert. QA validiert das gegen die Geräteliste in P-ATL-HW-Inventory."}
{"ts": "161:12", "speaker": "I", "text": "Zum Schluss: Gibt es ein Lesson Learned aus der Pilotphase, das Sie unbedingt mitnehmen?"}
{"ts": "161:16", "speaker": "E", "text": "Definitiv: Frühzeitige Einbindung von QA in UX-Design-Entscheidungen spart massiv Zeit. In der Pilotphase haben wir das bei Feature `offline_forms` gemacht – Ergebnis: keine Blocker im RC-Gate, und alle UX-SLOs erfüllt. Das bleibt unser Standardprozess."}
{"ts": "161:36", "speaker": "I", "text": "Lassen Sie uns noch einmal auf die Lessons Learned aus der Pilotphase eingehen. Welche davon werden Sie definitiv in die Skalierungsphase mitnehmen?"}
{"ts": "161:46", "speaker": "E", "text": "Eines der wichtigsten Learnings ist, dass wir Feature Flags nicht nur technisch, sondern auch UX-seitig sauber versionieren müssen. Wir hatten in Sprint 7 zum Beispiel das Flag 'offline_sync_v2' gleichzeitig auf iOS und Android aktiviert, ohne die begleitenden UI-Texte synchron zu deployen – das hat zu Irritationen geführt. Unser Runbook RB-DS-014 sieht jetzt vor, dass jede Flag-Aktivierung einen Check im DS-Atlas Repo triggert."}
{"ts": "161:59", "speaker": "I", "text": "Gab es dabei besondere Abstimmungen mit QA?"}
{"ts": "162:05", "speaker": "E", "text": "Ja, QA hat eine Flag-Matrix gepflegt, in der wir pro Plattform und Build-Kanal sehen konnten, welche Variationen aktiv sind. Das hat uns geholfen, gezielt Testcases für die UX-Regression zu definieren. Wir haben in QA-Ticket QA-MOB-332 dokumentiert, dass ohne diese Matrix zwei Inkonsistenzen unbemerkt geblieben wären."}
{"ts": "162:22", "speaker": "I", "text": "Wie fließen solche QA-Erkenntnisse in Ihr Design System zurück?"}
{"ts": "162:29", "speaker": "E", "text": "Wir haben im DS-ATLAS v2 jetzt eine Komponente 'FlagAwareButton', die sowohl optisch als auch funktional auf den Flag-Status reagieren kann. Die Specs dafür stehen in Confluence-Seite DS-COMP-FlagBtn, und QA nutzt diese Specs als Referenz für automatisierte Snapshot-Tests."}
{"ts": "162:45", "speaker": "I", "text": "Stichwort Accessibility – gab es zuletzt Findings, die direkt zur Änderung geführt haben?"}
{"ts": "162:52", "speaker": "E", "text": "Ja, im Accessibility-Audit vom 03.05. (Ticket ACC-MOB-089) wurde festgestellt, dass der Kontrast im Offline-Banner unter 4.5:1 lag. Wir haben daraufhin im Token-Set 'color.alertBackground' angepasst und ein neues Dark-Mode-Token eingeführt. Das Update ist in Build 1.4.3.2 ausgerollt."}
{"ts": "163:09", "speaker": "I", "text": "Wie bewerten Sie das Risiko, dass solche Anpassungen unter Zeitdruck passieren müssen?"}
{"ts": "163:15", "speaker": "E", "text": "Unter SLA-Druck ist das riskant, weil visuelle Regressionen schnell durchrutschen. Daher haben wir im Incident-Runbook RB-UX-005 einen Fast-Track definiert: Accessibility-Fixes dürfen nur via Minor Release und nach automatisierter Regression-Analyse deployt werden. Das reduziert die Gefahr von Nebeneffekten."}
{"ts": "163:32", "speaker": "I", "text": "Und welche Metriken helfen Ihnen zu entscheiden, ob ein solcher Fix sofort oder später kommen sollte?"}
{"ts": "163:39", "speaker": "E", "text": "Wir schauen auf den Accessibility Error Score aus unserem Monitoring-Tool, gepaart mit der Nutzerzahl auf der betroffenen View. Wenn der Score über 15% liegt und die View in der Top-5-Nutzung ist, geht der Fix sofort in den Fast-Track."}
{"ts": "163:54", "speaker": "I", "text": "Abschließend: Welche Risiken sehen Sie konkret für die Skalierung nach der Pilotphase?"}
{"ts": "164:00", "speaker": "E", "text": "Ein Risiko ist, dass sich die Komplexität der Feature Flag-Kombinationen exponentiell erhöht, wodurch QA- und UX-Tests teurer werden. Ein weiteres ist die Performance im Offline-Modus – unsere TTI-Metrik könnte unter Last in Regionen mit schlechter Netzabdeckung steigen. Wir haben in RFC-ATL-024 beschrieben, wie wir den Synchronisations-Algorithmus anpassen wollen."}
{"ts": "164:18", "speaker": "I", "text": "Werden Sie dafür auch das Design System erweitern?"}
{"ts": "164:24", "speaker": "E", "text": "Ja, wir planen ein Offline-Indicator-Pattern, das adaptive Icons und Texte einsetzt, abhängig von der Netzqualität. Das Muster ist Teil des DS-ATLAS v3 Backlogs und wird in Jira-Story DS3-MOB-112 verfolgt."}
{"ts": "170:56", "speaker": "I", "text": "Sie hatten vorhin die Crash-Free-Rate erwähnt. Mich würde interessieren, wie Sie diese mit konkreten UI-Änderungen verknüpfen konnten, etwa beim RB-MOB-021 Incident."}
{"ts": "171:00", "speaker": "E", "text": "Ja, bei RB-MOB-021 hatten wir einen Crash Loop im Offline-Sync-Flow. Aus UX-Sicht haben wir das Retry-Pattern im DS-ATLAS angepasst, damit der Nutzer visuell den Sync pausieren kann. Das hat direkt die Crash-Free-Rate um etwa 2 % verbessert laut unserem letzten QA-Runbook-Eintrag #QAR-334."}
{"ts": "171:11", "speaker": "I", "text": "Wie wurde dieses Pattern technisch unter Feature Flags aktiviert?"}
{"ts": "171:15", "speaker": "E", "text": "Wir haben in der Atlas Mobile App einen Flag 'sync_retry_v2' definiert. Der UI-Container für Offline-Sync lädt die Komponente nur, wenn das Flag aktiv ist. QA hat das in Staging mit simulierten Netzabbrüchen getestet, siehe Protokoll in Ticket MOB-QA-562."}
{"ts": "171:28", "speaker": "I", "text": "Gab es dabei Abhängigkeiten zum Platform-Team?"}
{"ts": "171:32", "speaker": "E", "text": "Genau, das ist ein klassischer Cross-Team-Fall: Platform stellte die API-Hooks für das Pausieren bereit, wir im UX haben die Komponente gestaltet, und QA hat die End-to-End-Ketten verifiziert. Ohne die API-Änderung wäre das Pattern gar nicht interaktiv gewesen."}
{"ts": "171:46", "speaker": "I", "text": "Und wie haben Sie Barrierefreiheit dabei sichergestellt?"}
{"ts": "171:50", "speaker": "E", "text": "Wir haben im DS-ATLAS schon vorgefertigte ARIA-Labels für Steuerbuttons. Die 'Pause'- und 'Fortsetzen'-Buttons erhielten Screenreader-Texte, QA hat das mit VoiceOver und TalkBack geprüft. Das war in Runbook-Abschnitt A11y-04 dokumentiert."}
{"ts": "172:02", "speaker": "I", "text": "Gab es Zielkonflikte zwischen Performance und Accessibility?"}
{"ts": "172:07", "speaker": "E", "text": "Teilweise, ja. Die Live-Updates der Sync-Progressbar haben wir für Screenreader throttled, um nicht ständig Events auszulösen. Das erhöht die Wahrnehmbarkeit, aber wir mussten das Event-Intervall so wählen, dass Time-to-Interactive nicht leidet."}
{"ts": "172:21", "speaker": "I", "text": "Wie messen Sie, ob solche Änderungen im Pilotbetrieb erfolgreich sind?"}
{"ts": "172:25", "speaker": "E", "text": "Wir kombinieren Metriken: Crash-Free-Rate aus Sentry-ähnlichen Logs, Time-to-Interactive aus unserer Telemetrie und qualitative Nutzerbefragungen. Bei RB-MOB-021 haben wir alle drei herangezogen, bevor wir das Feature Flag für 100 % der Pilotnutzer gesetzt haben."}
{"ts": "172:39", "speaker": "I", "text": "Welche Risiken sehen Sie, wenn dieses Pattern später in die Skalierungsphase geht?"}
{"ts": "172:44", "speaker": "E", "text": "Das Hauptrisiko ist, dass bei höherer Nutzerzahl die API-Hooks unter Last langsamer reagieren. Das würde den UX-Gewinn schmälern. Wir haben dazu in RFC-ATL-57 einen Stress-Test-Plan aufgenommen, um die Latenzen im Blick zu behalten."}
{"ts": "172:57", "speaker": "I", "text": "Und unter SLA-Druck, wie priorisieren Sie dann?"}
{"ts": "173:02", "speaker": "E", "text": "Wenn z. B. die Crash-Free-Rate im Monatsmittel unter 98 % fällt, hat das SLA-Priorität. In so einem Fall würden wir auch UX-Optimierungen verschieben, die nicht direkt auf Stabilität einzahlen. Das ist klar so im Incident-Runbook Kapitel 5.2 hinterlegt."}
{"ts": "173:36", "speaker": "I", "text": "Sie hatten vorhin schon die Crash Loops erwähnt. Mich würde interessieren: wie genau haben Sie aus dem Ticket RB-MOB-021 dann konkrete UX-Workflows abgeleitet?"}
{"ts": "173:50", "speaker": "E", "text": "Also, wir sind nach Runbook UX-INC-04 vorgegangen, das beschreibt die Analysepfade, um UI-Fehlerketten aus Logdaten zu extrahieren. Wir haben gesehen, dass bei bestimmten Feature-Flag-Kombinationen die Offline-Sync-UI hängen blieb. Daraus haben wir dann im Design System die Ladeindikatoren entkoppelt."}
{"ts": "174:12", "speaker": "I", "text": "Das heißt, Sie haben direkt im DS-ATLAS v2 Änderungen gemacht?"}
{"ts": "174:20", "speaker": "E", "text": "Genau, wir haben in den tokenized components die ProgressBar-Variante angepasst, sodass sie unabhängig vom Sync-Thread läuft. Das war ein kleiner Eingriff, aber wichtig, um Race Conditions zu vermeiden."}
{"ts": "174:38", "speaker": "I", "text": "Wie lief dabei die Abstimmung mit QA im Release Candidate Gate?"}
{"ts": "174:46", "speaker": "E", "text": "Wir haben einen zusätzlichen UX-QA-Checkpoint eingeführt. QA hat über das Testskript QA-MOB-FF-07 gezielt die betroffenen Flag-Kombinationen geprüft, während wir visuell und per Telemetrie gegengecheckt haben."}
{"ts": "175:05", "speaker": "I", "text": "Gab es in diesem Prozess auch Konflikte mit Performance-Vorgaben aus den SLOs?"}
{"ts": "175:14", "speaker": "E", "text": "Ja, minimal. Durch die Entkopplung hatten wir initial 30 ms mehr Latenz im UI-Thread. Wir mussten dann mit dem Platform-Team ein Microbatching einführen, um wieder unter die 200 ms Interaktionszeit zu kommen, wie es SLO-UX-02 fordert."}
{"ts": "175:36", "speaker": "I", "text": "Wie priorisieren Sie in so einem Fall — Accessibility gegen Performance?"}
{"ts": "175:44", "speaker": "E", "text": "Wir nutzen eine Priorisierungsmatrix aus dem internen Heuristik-Dokument UX-PRIO-Guide, wo Accessibility-Blocker als P1 gelten. Performance-Degradierungen werden toleriert, solange sie unterhalb der SLA-Grenze bleiben."}
{"ts": "176:04", "speaker": "I", "text": "Gibt es ein Beispiel, wo Sie diese Matrix in der Pilotphase schon mal umdrehen mussten?"}
{"ts": "176:14", "speaker": "E", "text": "Ja, beim Ticket RB-MOB-015, da war ein Screenreader-Fix so rechenintensiv, dass alte Geräte unter 15 FPS fielen. Da haben wir einen Hotfix mit reduzierter Animationsrate priorisiert, um die SLA-Vorgabe für Renderzeit zu halten."}
{"ts": "176:36", "speaker": "I", "text": "Wie fließen solche Lessons Learned in Ihre Planung für die Skalierung nach der Pilotphase ein?"}
{"ts": "176:45", "speaker": "E", "text": "Wir bauen eine UX-Retrofit-Liste, die im RFC-Plan für Atlas Mobile 1.0 verankert ist. Darin markieren wir Komponenten, die bei Feature-Flag-Wechseln oder unter SLA-Druck historisch Probleme hatten, und planen Refactors vor dem Rollout."}
{"ts": "177:06", "speaker": "I", "text": "Und wie stellen Sie sicher, dass diese Refactors nicht neue Incidents erzeugen?"}
{"ts": "177:14", "speaker": "E", "text": "Wir koppeln jeden Refactor an automatisierte visuelle Regressionstests und lassen sie zunächst in der Staging-Umgebung mit synthetischen Feature-Flag-Profilen laufen. Erst wenn die KPIs aus dem SLO-Dashboard grün sind, geht es ins RC-Gate."}
{"ts": "181:36", "speaker": "I", "text": "Sie hatten vorhin erwähnt, dass bestimmte Accessibility-Anpassungen auch unmittelbare Performance-Auswirkungen hatten. Können Sie ein Beispiel aus dem Atlas Mobile Pilot nennen, wo dieser Trade-off konkret sichtbar wurde?"}
{"ts": "181:44", "speaker": "E", "text": "Ja, klar. Das prominenteste Beispiel war die Einführung der erweiterten Screenreader-Labels für unsere Offline-Sync-Widgets. Laut Runbook UX-ACC-042 mussten wir diese Labels mit zusätzlichen Kontextinformationen versehen, was dazu führte, dass die Rendering-Pipeline im Android-Build um ca. 120 ms langsamer wurde. Im SLA-Kontext war das noch im grünen Bereich, aber bei Feature Flag 'sync_offline_v2' mussten wir gezielt Profiling einsetzen."}
{"ts": "181:59", "speaker": "I", "text": "Wie haben Sie die Entscheidung getroffen, dieses Feature dennoch live zu lassen?"}
{"ts": "182:04", "speaker": "E", "text": "Das war eine Abwägung im Incident Review Board. Wir haben anhand der SLO-Definition UX-RSP-009 festgestellt, dass die Accessibility-Verbesserung für blinde Nutzer:innen signifikant war. Mit Development und QA haben wir dann ein Micro-Optimization-Ticket (UX-OPT-317) aufgemacht, um die Latenz wieder zu reduzieren, ohne die Labels zu kürzen."}
{"ts": "182:19", "speaker": "I", "text": "Interessant. Gab es dabei auch spezifische Zusammenarbeit mit dem Platform-Team?"}
{"ts": "182:23", "speaker": "E", "text": "Ja, die Platform Engineers haben uns ein spezielles Lazy-Loading-Pattern vorgeschlagen, das sie schon für andere Async-Komponenten nutzen. Wir mussten das im DS-ATLAS v2 Token-System adaptieren, damit die Farbtokens und Schriftgrößen konsistent nachgeladen werden, ohne dass Screenreader eine Unterbrechung erfahren."}
{"ts": "182:38", "speaker": "I", "text": "Gab es bei der Implementierung dieser Lazy-Loading-Lösung unerwartete Probleme?"}
{"ts": "182:42", "speaker": "E", "text": "Ja, tatsächlich. In den ersten Staging-Builds traten bei iOS sporadisch 'UI Freeze'-Incidents auf, die als MOB-FRZ-112 ins Ticket-System gingen. Ursache war ein Race Condition bei der Initialisierung der ARIA-Tags. Wir haben das durch eine kleine Verzögerung im Init-Handler gelöst, dokumentiert im QA-RFC-77."}
{"ts": "182:57", "speaker": "I", "text": "Wie fließen solche Lessons Learned jetzt in die Skalierungsplanung nach der Pilotphase ein?"}
{"ts": "183:02", "speaker": "E", "text": "Wir haben im Skalierungs-Backlog einen eigenen Epic 'UX Scale & Perf' angelegt. Darin sind alle Findings aus Tickets wie RB-MOB-021 oder MOB-FRZ-112 verlinkt, mit Querverweisen auf betroffene DS-ATLAS v2-Komponenten. So stellen wir sicher, dass bei der Ausrollung auf weitere Märkte diese Optimierungen schon im Baseline-Template drin sind."}
{"ts": "183:17", "speaker": "I", "text": "Und was sehen Sie als größtes Risiko für die UX, wenn wir in den Vollbetrieb gehen?"}
{"ts": "183:21", "speaker": "E", "text": "Das größte Risiko sehe ich in der Fragmentierung der UI, wenn Feature Flags zu lange parallel aktiv bleiben. Das kann zu inkonsistenten Nutzererfahrungen führen und im schlimmsten Fall SLA-Verletzungen, wenn bestimmte Varianten schlechter performen. Deshalb haben wir im Runbook FF-CLEAN-003 klare Deprecation-Timelines festgelegt."}
{"ts": "183:36", "speaker": "I", "text": "Wie setzen Sie diese Deprecation-Timelines praktisch um?"}
{"ts": "183:40", "speaker": "E", "text": "Wir fahren einen zweiwöchigen Audit-Zyklus mit QA und Product Owners. Dabei checken wir alle aktiven Flags gegen das Launch-Board. Flags, die ihre Hypothese erfüllt haben, gehen in ein 'Sunset'-Ticket. Der UX-Part besteht darin, Übergangszustände so zu gestalten, dass Nutzer nicht abrupt eine komplett andere UI sehen."}
{"ts": "183:55", "speaker": "I", "text": "Gibt es noch eine konkrete Maßnahme aus der Pilotphase, die Sie unbedingt beibehalten wollen?"}
{"ts": "184:00", "speaker": "E", "text": "Ja, die enge Verzahnung von Incident-Postmortems mit Design-Reviews. Der Abgleich von Crash- und Error-Logs mit UX-Patterns hat uns mehrfach vor Rollout-Fehlern bewahrt. Dieses Vorgehen ist jetzt fester Bestandteil unseres Prozess-Handbuchs UX-PROC-015."}
{"ts": "189:36", "speaker": "I", "text": "Lassen Sie uns gern noch einmal auf die Zusammenarbeit mit QA eingehen – speziell beim Release Candidate Gate im Pilotbetrieb. Wie sah Ihr letzter Durchlauf aus?"}
{"ts": "189:48", "speaker": "E", "text": "Beim letzten Gate haben wir den QA-Runbook-Eintrag RCG-07 befolgt. Das heißt, wir haben ein 48-Stunden-Freeze-Fenster genutzt, um alle UI-relevanten Bugfixes aus den Feature-Flag-Builds in den Stabilitätszweig zu mergen und parallel Accessibility-Checks gegen unsere WCAG-2.1-Checkliste gefahren."}
{"ts": "190:15", "speaker": "I", "text": "Gab es dabei besondere Findings, die für das UX-Team relevant waren?"}
{"ts": "190:21", "speaker": "E", "text": "Ja, ein kritischer Fall war der Ticket-Thread QA-MOB-442: Unter iOS 16 führte ein falsch tokenisierter Farbwert im DS-ATLAS v2 dazu, dass Kontraste im Dark Mode nicht SLA-konform waren. Wir mussten kurzfristig das Token-Set neu generieren und im Nightly-Build validieren."}
{"ts": "190:49", "speaker": "I", "text": "Das klingt nach einer engen Verzahnung von technischer Umsetzung und Design System. Wie koordinieren Sie solche Hotfixes?"}
{"ts": "190:56", "speaker": "E", "text": "Wir haben ein Mini-Hotfix-Protokoll im Runbook DS-HF-02. Das erlaubt uns, innerhalb von 4 Stunden einen Patch-Branch zu erstellen, der nur Token-Änderungen enthält. QA bekommt dann einen speziellen Flag \u0000EAfeature.ds_hotfix=true\u0000EE um gezielt die betroffenen Screens zu testen."}
{"ts": "191:22", "speaker": "I", "text": "Und wie stellen Sie sicher, dass solche kurzfristigen Änderungen nicht zu Regressionen führen?"}
{"ts": "191:28", "speaker": "E", "text": "Wir fahren automatisierte Snapshot-Tests für alle Plattformen – Android, iOS und Web-Wrapper. Zusätzlich sichten wir die Top-5 User Journeys manuell, basierend auf den Telemetrie-Daten, die im Pilotbetrieb am häufigsten genutzt werden."}
{"ts": "191:48", "speaker": "I", "text": "Vorhin hatten Sie SLA-Themen angesprochen. Können Sie ein Beispiel geben, wie Sie unter SLA-Druck priorisieren mussten?"}
{"ts": "191:56", "speaker": "E", "text": "Bei Incident RB-MOB-021 hatten wir 72 Stunden, um den Crash Loop zu beheben. Wir haben zugunsten der Stabilität die Auslieferung eines neuen Onboarding-Screens verschoben, obwohl der bereits zu 90% fertig war. Der SLA für App-Verfügbarkeit von 99,5% im Pilot musste Vorrang haben."}
{"ts": "192:22", "speaker": "I", "text": "Und welche Metriken beobachten Sie kontinuierlich, um UX-Qualität im Sinne des SLA sicherzustellen?"}
{"ts": "192:29", "speaker": "E", "text": "Wir tracken Time-to-Interactive, Error Rate per Session und die Rate erfolgreich abgeschlossener Critical User Journeys. Die werden stündlich ins UX-Qualitätsdashboard gepusht und mit den SLOs verglichen."}
{"ts": "192:47", "speaker": "I", "text": "Wenn Sie jetzt auf die Skalierung blicken – welche Risiken sehen Sie für die UX, wenn wir aus dem Pilot in den Rollout gehen?"}
{"ts": "192:55", "speaker": "E", "text": "Das größte Risiko ist Fragmentierung: Mehr Plattformversionen, mehr gleichzeitige Feature Flags. Ohne strikte Governance im DS-ATLAS v2 riskieren wir Inkonsistenzen. Dazu kommt, dass Offline-Sync bei größerer Nutzerbasis stärker auf Latenzen reagiert, was UX-Flow unterbrechen kann."}
{"ts": "193:21", "speaker": "I", "text": "Gibt es Lessons Learned aus der Pilotphase, die Sie unbedingt beibehalten möchten?"}
{"ts": "193:28", "speaker": "E", "text": "Definitiv das enge Incident-to-UX-Loop-Verfahren: Jedes Ticket mit User Impact bekommt sofort einen UX-Review-Slot. Außerdem behalten wir das Feature-Flag-Kanban bei, um Änderungen visuell zu tracken. Diese Transparenz hat uns mehrfach vor SLA-Verstößen bewahrt."}
{"ts": "197:36", "speaker": "I", "text": "Lassen Sie uns noch einmal die Brücke schlagen zwischen QA und UX im Pilotbetrieb – konkret, wie lief der letzte Release Candidate Gate-Check aus Ihrer Sicht?"}
{"ts": "197:44", "speaker": "E", "text": "Beim letzten Gate haben wir gemeinsam mit QA die Runbook-Sequenz RC-MOB-045 durchgegangen. Wir mussten zwei UI-Inkonsistenzen im Offline-Sync-Dialog beheben, die QA mit Screenreader-Tests identifiziert hatte."}
{"ts": "197:56", "speaker": "I", "text": "Gab es dabei Abhängigkeiten zu Feature Flags, die Sie berücksichtigen mussten?"}
{"ts": "198:02", "speaker": "E", "text": "Ja, die betroffenen Dialoge waren hinter dem Flag FF-OFFSYNC-UI versteckt. Wir mussten im DS-ATLAS v2 die tokenisierten Farbwerte synchron für Flag-on und Flag-off Varianten anpassen, um keine regressions im Dark Mode zu riskieren."}
{"ts": "198:18", "speaker": "I", "text": "Und wie hat sich das auf die Testdauer ausgewirkt?"}
{"ts": "198:22", "speaker": "E", "text": "Minimal – etwa plus 90 Minuten. Wir hatten das in der Runbook-Checkliste bereits als potenziellen Schritt markiert, sodass QA- und Dev-Teams parallel arbeiten konnten."}
{"ts": "198:32", "speaker": "I", "text": "Sie hatten vorhin RB-MOB-021 erwähnt. Gab es ähnliche Patterns jetzt?"}
{"ts": "198:38", "speaker": "E", "text": "Nicht direkt Crash Loops, aber ein Memory Leak bei aktiviertem Accessibility Zoom. Durch unsere Incident Lessons Learned aus RB-MOB-021 haben wir sofort das Monitoring-Flag UX-MEM-ALERT aktiviert."}
{"ts": "198:52", "speaker": "I", "text": "Und das Monitoring liefert Ihnen Metriken, die in SLA-Entscheidungen einfließen?"}
{"ts": "198:58", "speaker": "E", "text": "Genau. Wir vergleichen die Frame Drop Rate und Time-to-Interactive gegen unser SLO von 1.5 Sekunden. Wenn wir drüber liegen, priorisieren wir UI-Optimierungen selbst unter Feature-Druck."}
{"ts": "199:10", "speaker": "I", "text": "Wie haben Sie diesen Trade-off im letzten Sprint konkret entschieden?"}
{"ts": "199:15", "speaker": "E", "text": "Wir haben die neue Animation für den Atlas-Login verschoben, obwohl Marketing drauf drängte. Die SLA-Risiken bei schwächeren Geräten waren zu hoch – basierend auf den Daten aus dem Staging-Monitor UX-PERF-202."}
{"ts": "199:28", "speaker": "I", "text": "Sehen Sie darin ein Muster für die Skalierungsphase nach der Pilotphase?"}
{"ts": "199:33", "speaker": "E", "text": "Absolut. Wir werden ein UX-Governance-Board einrichten, das Feature-Priorisierung gegen SLA/SLO-Risiken abwägt. Lessons Learned wie aus RB-MOB-021 fließen dort standardmäßig ein."}
{"ts": "199:45", "speaker": "I", "text": "Welche Risiken sehen Sie beim Hochskalieren der Nutzerbasis in Bezug auf Accessibility?"}
{"ts": "199:51", "speaker": "E", "text": "Vor allem, dass selten genutzte Accessibility-Flows ungetestet bleiben. Deshalb wollen wir in unserem QA-Plan für Q3 einen automatisierten Accessibility Regression Run gemäß Runbook ACC-REG-017 aufnehmen, um diese Lücken früh zu schließen."}
{"ts": "205:36", "speaker": "I", "text": "Lassen Sie uns jetzt ein wenig in die Zukunft blicken: Welche UX-Risiken sehen Sie ganz konkret, wenn Atlas Mobile aus der Pilotphase in den breiten Rollout geht?"}
{"ts": "205:52", "speaker": "E", "text": "Ein zentrales Risiko ist, dass unser Offline-Sync-Mechanismus bei höherer Nutzungsdichte Latenzen erzeugt, die im Pilotbetrieb noch tolerabel waren. Wir haben in unserem internen Runbook RB-UX-014 schon eine Schwelle bei >1,8 Sekunden definiert, die wir im Livebetrieb nicht überschreiten dürfen."}
{"ts": "206:18", "speaker": "I", "text": "Heißt das, Sie planen, die Sync-Logik vor Rollout noch einmal zu refactoren?"}
{"ts": "206:29", "speaker": "E", "text": "Ja, wir haben dafür ein RFC-Dokument RFC-ATL-SYNC-07 angelegt. Darin ist auch ein Vorschlag, wie wir Prefetching im Hintergrund priorisieren, ohne die Rendering-Pipeline zu blockieren."}
{"ts": "206:47", "speaker": "I", "text": "Und wie spielt dabei das Design System eine Rolle?"}
{"ts": "206:55", "speaker": "E", "text": "DS-ATLAS v2 enthält inzwischen asynchrone Platzhalter-Komponenten, die wir mit Feature Flags toggeln können. Das erlaubt uns, in einer Testgruppe zu evaluieren, ob ein Skeleton Screen die wahrgenommene Ladezeit reduziert."}
{"ts": "207:17", "speaker": "I", "text": "Das klingt nach einem Experiment-Driven-Ansatz. Haben Sie dafür bestimmte QA-Gates definiert?"}
{"ts": "207:26", "speaker": "E", "text": "Ja, wir haben mit QA vereinbart, dass jedes neue UI-Pattern erst durch das Release Candidate Gate mit den SLO-Kriterien für Time-to-Interactive >95% innerhalb von 1,5 Sekunden muss, bevor es in den Flagged-Bereich kommt."}
{"ts": "207:49", "speaker": "I", "text": "Welche Rolle spielen hier Lessons Learned aus der Pilotphase?"}
{"ts": "208:00", "speaker": "E", "text": "Eine der größten Learnings war, dass wir Accessibility-Änderungen frühzeitig in die Komponenten einbetten müssen. Beim Incident RB-MOB-021 haben wir gesehen, dass späte Anpassungen an Screenreader-Tags Performance kosten können."}
{"ts": "208:22", "speaker": "I", "text": "Das heißt, Sie würden Accessibility künftig als integralen Bestandteil des Component Lifecycles sehen?"}
{"ts": "208:31", "speaker": "E", "text": "Absolut. Wir haben in der DS-ATLAS-Dokumentation jetzt einen Accessibility-Checklist-Abschnitt, der parallel zu den Performance-Benchmarks gepflegt wird."}
{"ts": "208:48", "speaker": "I", "text": "Wie priorisieren Sie diese Änderungen unter SLA-Druck?"}
{"ts": "208:58", "speaker": "E", "text": "Wir nutzen ein internes Priorisierungsschema P-Matrix v3. Accessibility-Fixes mit direktem Einfluss auf SLA-relevante Metriken, wie etwa Fehlerrate bei Formular-Submits, bekommen automatisch Priorität 1."}
{"ts": "209:18", "speaker": "I", "text": "Und was wäre ein konkretes Risiko, wenn Sie das nicht tun?"}
{"ts": "209:27", "speaker": "E", "text": "Worst-Case verlieren wir die SLA-Compliance und riskieren Vertragsstrafen. Zudem würde die Nutzerzufriedenheit sinken, was laut unserem KPI-Set UX-SAT-Index einen direkten Einfluss auf die Retention-Rate hätte."}
{"ts": "214:36", "speaker": "I", "text": "Könnten wir jetzt noch einmal genauer auf die Skalierungsphase eingehen? Mich interessiert, welche UX-Herausforderungen Sie konkret erwarten, wenn Atlas Mobile aus dem Pilot herausgeht."}
{"ts": "214:44", "speaker": "E", "text": "Ja, klar. Die größte Herausforderung wird das Handling der Offline-Sync-Queue bei viel höherer Nutzerlast sein. Im Pilot hatten wir laut Nutzungsbericht RUN-UX-087 einen Peak von 1200 gleichzeitigen Sync-Anfragen; in der Skalierung rechnen wir mit Faktor fünf. Das wirkt sich direkt auf den perceived Load im UI aus."}
{"ts": "214:57", "speaker": "I", "text": "Verstehe. Und wie würden Sie das aus UX-Sicht abfedern?"}
{"ts": "215:02", "speaker": "E", "text": "Wir planen ein progressives Feedback-Muster einzubauen, ähnlich unserem DS-ATLAS v2 Skeleton Loader Pattern, aber erweitert um adaptive Messaging. Das heißt, wir zeigen abhängig von SLA-Thresholds unterschiedliche Statusmeldungen, bevor wir überhaupt in einen Error State fallen."}
{"ts": "215:15", "speaker": "I", "text": "Gab es dazu schon interne Tests oder Prototypen?"}
{"ts": "215:19", "speaker": "E", "text": "Ja, im Prototypentestlauf PT-ATL-04 haben wir das mit 50 internen Testern simuliert. Wir haben bewusst die Sync-Latenz auf 7 Sekunden erhöht, um zu sehen, wie die User reagieren. Die Abbruchrate sank um 18 % im Vergleich zum alten Spinner-Only-Ansatz."}
{"ts": "215:33", "speaker": "I", "text": "Klingt nach einem klaren Gewinn. Welche Risiken verbinden Sie mit dieser Anpassung?"}
{"ts": "215:38", "speaker": "E", "text": "Ein Risiko ist, dass wir bei zu vielen adaptiven States die Konsistenz über Plattformen verlieren. iOS- und Android-Teams interpretieren die Design Tokens manchmal leicht unterschiedlich, vor allem bei Animation-Duration und Timing Functions. Wir müssen da eng mit DevOps und QA Abstimmungen fahren."}
{"ts": "215:52", "speaker": "I", "text": "Das klingt nach einer Schnittstellenaufgabe. Wie binden Sie QA hier konkret ein?"}
{"ts": "215:57", "speaker": "E", "text": "QA erhält von uns in den RC-Gates eine explizite State-Matrix aus dem Runbook UX-RB-013. Dort sind alle möglichen UI-Zustände samt Trigger und erwarteten Reaktionen dokumentiert. Sie setzen dann Cross-Device-Tests auf, um Abweichungen vor der Freigabe zu erkennen."}
{"ts": "216:11", "speaker": "I", "text": "Sie hatten vorhin SLA-Thresholds erwähnt. Welche Metriken nehmen Sie da als Grundlage?"}
{"ts": "216:16", "speaker": "E", "text": "Primär Time-to-First-Interaction (TTFI) und Completion-Rate bei Kernflows. Wir haben im SLA-Dokument SLA-ATL-UX festgelegt, dass 95 % der Nutzer einen Sync innerhalb von 5 Sekunden abschließen können müssen, sonst wird ein Feature-Flag für den betreffenden Flow gesetzt, um Last zu reduzieren."}
{"ts": "216:31", "speaker": "I", "text": "Und wenn der SLA gerissen wird, wie gehen Sie vor?"}
{"ts": "216:36", "speaker": "E", "text": "Dann greifen wir auf unser Incident-Playbook IPB-UX-02 zurück. Das sieht vor, dass UX sofort mit Backend und Support in einem War Room die Ursachen analysiert und temporär UI-Elemente ausblendet, die die Queue zusätzlich belasten. Das ist ein klarer Trade-off zwischen Feature-Reichtum und Stabilität."}
{"ts": "216:50", "speaker": "I", "text": "Also eine bewusste Funktionseinschränkung, um die Servicequalität zu sichern."}
{"ts": "216:54", "speaker": "E", "text": "Genau, und wir dokumentieren solche Entscheidungen in den Lessons-Learned-Abschnitten der jeweiligen Incident-Tickets, z. B. INC-ATL-092. Diese fließen dann in die nächsten Design-RFCs ein, damit wir bei der nächsten Skalierungswelle gewappnet sind."}
{"ts": "222:36", "speaker": "I", "text": "Wir hatten ja vorhin RB-MOB-021 angerissen. Mich würde interessieren, wie Sie die Erkenntnisse daraus konkret in Ihren letzten DS-ATLAS v2 Updates umgesetzt haben."}
{"ts": "222:42", "speaker": "E", "text": "Konkret haben wir nach dem Crash-Loop-Analysebericht aus Runbook MOB-INC-07 die Ladeanimationen in den Offline-Sync-Komponenten entkoppelt, um UI-Thread-Blocking zu verhindern. Das wurde im Tokenized Component 'SyncBadge_v2' unter Feature Flag FF-ATL-UX-042 ausgerollt."}
{"ts": "223:05", "speaker": "I", "text": "Und wie sah die Abstimmung mit QA in diesem Fall aus?"}
{"ts": "223:09", "speaker": "E", "text": "QA hat mit uns zusammen ein temporäres Release Candidate Gate eingeführt, basierend auf dem SLO 'Time-to-Interactive ≤ 2,5s'. Erst als die neuen Komponenten in den Cross-Platform-Smoke-Tests diese Schwelle stabil hielten, durften wir das Flag auf 100% setzen."}
{"ts": "223:32", "speaker": "I", "text": "Gab es dabei Performance-Einbußen, die Sie in Kauf nehmen mussten?"}
{"ts": "223:36", "speaker": "E", "text": "Ja, laut Ticket UX-PERF-118 hatten wir auf Low-End-Android-Geräten +150ms Renderzeit. Wir haben das akzeptiert, weil die Accessibility-Verbesserung für Screenreader-Nutzer deutlich überwog – das war im SLA-Korridor für Rendering noch im grünen Bereich."}
{"ts": "224:00", "speaker": "I", "text": "Wie kommunizieren Sie solche Trade-offs intern?"}
{"ts": "224:04", "speaker": "E", "text": "Über das wöchentliche Pilot-UX-Review, wo wir ein Ampelsystem nach Runbook UX-GOV-02 nutzen: Grün für SLA-konform, Gelb für tolerierte Abweichung unter dokumentierter Begründung, Rot für Blocker."}
{"ts": "224:24", "speaker": "I", "text": "Blicken wir auf die nächsten Schritte – welche Risiken sehen Sie beim Scale-out nach der Pilotphase?"}
{"ts": "224:28", "speaker": "E", "text": "Das größte Risiko ist Fragmentierung im Design System, wenn Feature Flags asynchron deaktiviert werden. Ohne stringente Governance könnten UI-Inkonsistenzen entstehen, die laut unserer Heuristik H-UX-17 direkt die Task-Completion-Rate senken."}
{"ts": "224:50", "speaker": "I", "text": "Planen Sie dazu Präventionsmaßnahmen?"}
{"ts": "224:53", "speaker": "E", "text": "Ja, wir haben ein 'Flag Sunset Protocol' im RFC-DS-044 definiert: Flags müssen innerhalb von zwei Sprints nach 100%-Rollout entfernt werden, parallel wird ein Regressionstest im DS-Validator gefahren."}
{"ts": "225:14", "speaker": "I", "text": "Wie fließen Lessons Learned aus der Pilotphase in dieses Protokoll ein?"}
{"ts": "225:17", "speaker": "E", "text": "Aus RB-MOB-021 haben wir gelernt, dass langsames Abschalten von Flags zu 'Zombie-Code' führt. Deshalb gibt es jetzt ein automatisches Jira-Reminder-Event nach 14 Tagen im Status 'Full Rollout', um UX und Dev gemeinsam zum Clean-up zu bewegen."}
{"ts": "225:38", "speaker": "I", "text": "Könnten Sie uns zum Abschluss noch ein Beispiel geben, wo Sie unter SLA-Druck eine UX-Verbesserung priorisieren mussten?"}
{"ts": "225:42", "speaker": "E", "text": "Beim Offline-Sync-Error-Dialog: Unser SLA für Error-Recovery lag bei ≤ 5s. Wir mussten innerhalb von zwei Tagen den Dialog so umgestalten, dass Nutzer klarere Handlungsoptionen sehen. Das reduzierte die Fehlerrate laut Monitoring-Report UX-MON-056 um 22%."}
{"ts": "231:36", "speaker": "I", "text": "Lassen Sie uns nochmal auf die Lessons Learned aus der Pilotphase eingehen, speziell was die Schnittstelle zu QA betrifft. Gab es da formale Änderungen im Release Candidate Gate?"}
{"ts": "231:50", "speaker": "E", "text": "Ja, wir haben seit Februar ein zusätzliches UX-Review-Checkpoint eingeführt, bevor QA das Candidate-Build sign-off gibt. Das basiert auf dem Runbook QA-UX-04, wo klar definiert ist, welche Screenflows mit Accessibility-Checklisten geprüft werden müssen."}
{"ts": "232:14", "speaker": "I", "text": "Und diese Checklisten, sind die im DS-ATLAS v2 verankert oder separat?"}
{"ts": "232:25", "speaker": "E", "text": "Die sind direkt im DS-ATLAS v2 hinterlegt, in Form von Token-Annotations. Zum Beispiel hat der ButtonPrimary jetzt ein 'a11yCritical'-Flag im Token-Set, damit Entwickler sofort sehen, dass dort Screenreader-Labelling Pflicht ist."}
{"ts": "232:48", "speaker": "I", "text": "Das klingt nach einer sehr direkten Integration. Gab es dadurch kürzere Feedback-Zyklen?"}
{"ts": "233:00", "speaker": "E", "text": "Genau, wir sind von im Schnitt 4 Tagen Rücklauf bei Accessibility-Findings auf unter 2 Tage gekommen. Das sehen wir auch in den QA-Dashboards für die Pilot-Phase, Ticket-Typ 'UX-DEF'."}
{"ts": "233:20", "speaker": "I", "text": "Wenn Sie an die SLAs denken, wie wirken sich solche Verbesserungen auf die Einhaltung der SLOs aus?"}
{"ts": "233:34", "speaker": "E", "text": "Wir haben ein SLO für 'Time-to-Fix UX-Blocking Defects' auf 72 Stunden. Durch die Integration ins Design System und die enge QA-Koordination erreichen wir aktuell 88% Compliance, vorher waren es 65%."}
{"ts": "233:54", "speaker": "I", "text": "Gab es dabei Zielkonflikte, etwa zwischen Performance-Optimierung und Accessibility?"}
{"ts": "234:05", "speaker": "E", "text": "Ja, z.B. beim Offline-Sync-Indicator. Wir wollten eine animierte Komponente für bessere Verständlichkeit, mussten aber zugunsten der Performance die Animation vereinfachen. Das Risiko bestand, dass Screenreader-Events nicht mehr synchron getriggert werden."}
{"ts": "234:28", "speaker": "I", "text": "Wie sind Sie mit diesem Risiko umgegangen?"}
{"ts": "234:36", "speaker": "E", "text": "Wir haben in RFC-UX-112 dokumentiert, dass für alle Critical-Indikatoren ein dualer Modus genutzt wird: visuelle Vereinfachung, aber erweiterte ARIA-Attribute im Code. Das QA-Team hat dafür eigene Testcases im Smoke-Test-Set MOB-SM-07 angelegt."}
{"ts": "234:58", "speaker": "I", "text": "Wenn Sie jetzt an die Skalierung nach der Pilotphase denken, was sind Ihre Top-3 Risiken aus UX-Sicht?"}
{"ts": "235:10", "speaker": "E", "text": "Erstens Fragmentierung der UI durch divergierende Feature-Flag-Kombinationen, zweitens erhöhte Latenz bei globalen Rollouts, was unser SLO 'First Contentful Paint <2s' gefährden könnte, und drittens kulturelle Unterschiede in der Iconographie, wenn wir in neue Märkte gehen."}
{"ts": "235:36", "speaker": "I", "text": "Welche Maßnahme halten Sie für die wichtigste, um diesen Risiken zu begegnen?"}
{"ts": "235:46", "speaker": "E", "text": "Wir planen ein Pre-Launch UX Risk Assessment als festen Bestandteil des Deployment-Runbooks DR-ATL-09. Das soll verhindern, dass wir Feature-Flag-Kombinationen ohne konsistente UI-Validierung ausliefern, und gleichzeitig ein Rahmenwerk für Performance- und Accessibility-Checks schaffen."}
{"ts": "240:36", "speaker": "I", "text": "Wir hatten zuletzt über die Crash Loops und deren Einfluss auf die UX gesprochen. Können Sie mir ein Beispiel geben, wie diese Erkenntnisse in Ihre künftige Roadmap eingeflossen sind?"}
{"ts": "240:41", "speaker": "E", "text": "Ja, wir haben nach RB-MOB-021 im Runbook UX-INC-014 die Empfehlung aufgenommen, bei Feature Flag Rollouts 5% Staggering zu nutzen, bevor wir die volle Nutzerbasis freischalten. Das reduziert nicht nur technische Risiken, sondern gibt uns auch Zeit für qualitative Feedback-Analysen im Pilotbetrieb."}
{"ts": "240:50", "speaker": "I", "text": "Das heißt, Sie koppeln technische Deploy-Strategien direkt mit UX-Testphasen?"}
{"ts": "240:54", "speaker": "E", "text": "Genau. Und wir haben diese Kopplung im DS-ATLAS v2 Guidelines-Dokument unter Abschnitt 4.3 ergänzt, sodass Entwickler und QA gleich sehen, welche UI-Elemente beim schrittweisen Flag-Rollout besonders kritisch sind."}
{"ts": "241:02", "speaker": "I", "text": "Gab es dabei Konflikte mit den SLA-Zielen, etwa bei der Performance?"}
{"ts": "241:06", "speaker": "E", "text": "Teilweise, ja. Wir mussten im SLO-Review vom April eine Anpassung vornehmen: die Latenz-Zielwerte um 50ms lockern, um mehr Barrierefreiheits-Funktionen serverseitig vorzuberechnen. Das war ein Trade-off, den wir gemeinsam mit Ops und Prod Management abgewogen haben."}
{"ts": "241:14", "speaker": "I", "text": "Wie haben Sie das den Stakeholdern kommuniziert?"}
{"ts": "241:18", "speaker": "E", "text": "Wir haben ein Incident Post-Mortem mit UX-Sektion erstellt, Ticket PM-UX-022, und im Steering Committee erläutert, wie die temporäre Performance-Einbuße zu einer nachhaltigen Reduktion von Support Cases führen kann."}
{"ts": "241:26", "speaker": "I", "text": "Können Sie ein Beispiel für so eine Support-Case-Reduktion nennen?"}
{"ts": "241:29", "speaker": "E", "text": "Vor der Änderung hatten wir pro Woche etwa 40 Meldungen zu Screen-Reader-Fehlern in Offline-Mode. Nach der Anpassung im Rendering-Pfad sind wir im Schnitt bei 5–7 Meldungen. Das ist signifikant und hat die Zufriedenheit in den Accessibility-Gruppen deutlich erhöht."}
{"ts": "241:38", "speaker": "I", "text": "Wie fließt so eine Erkenntnis in die Skalierungsplanung nach der Pilotphase?"}
{"ts": "241:42", "speaker": "E", "text": "Wir haben im Skalierungs-Backlog ein Epic UX-SCALE-005 angelegt, das genau diese Lessons Learned institutionalisiert: also Staggered Rollouts, frühzeitige Accessibility-Checks und ein enger Schulterschluss mit QA bei Feature Flag Tests."}
{"ts": "241:50", "speaker": "I", "text": "Sehen Sie Risiken, dass bei größerer Nutzerbasis neue Konflikte zwischen Performance und Accessibility auftreten?"}
{"ts": "241:54", "speaker": "E", "text": "Ja, insbesondere bei komplexeren Komponenten wie dem Atlas-Kalendermodul. Hier überlegen wir, ob wir ein asynchrones Rendering einführen, das zwar initial länger lädt, aber danach flüssiger reagiert. Das müsste aber im SLA-Kontext neu bewertet werden."}
{"ts": "242:02", "speaker": "I", "text": "Würden Sie dafür ein neues RFC aufsetzen?"}
{"ts": "242:06", "speaker": "E", "text": "Auf jeden Fall. Wir planen ein RFC-UX-031 in Q3, um die technischen und UX-seitigen Implikationen sauber zu dokumentieren, inklusive Metriken wie Time-to-Interactive und Error Rate nach dem ersten Render."}
{"ts": "242:36", "speaker": "I", "text": "Könnten wir jetzt noch etwas tiefer in die Lessons Learned aus der Pilotphase gehen, speziell in Bezug auf die Skalierung?"}
{"ts": "242:48", "speaker": "E", "text": "Ja, klar. Eine der größten Erkenntnisse war, dass unser Offline-Sync-Mechanismus im Feld viel stärker genutzt wurde als prognostiziert. Das beeinflusst die UX massiv, weil wir die Ladesymbole und Progress-States im DS-ATLAS v2 nachschärfen mussten."}
{"ts": "243:10", "speaker": "I", "text": "Das heißt, die Design Tokens für Ladezustände wurden angepasst?"}
{"ts": "243:16", "speaker": "E", "text": "Genau. Wir haben im Token-Set `sync-indicator` neue Variablen in der Runbook-Dokumentation DS-ATLAS-RB-006 ergänzt, damit die Devs bei Feature-Flag-Aktivierung sofort konsistente Styles sehen."}
{"ts": "243:34", "speaker": "I", "text": "Gab es dafür auch Abstimmungen mit QA?"}
{"ts": "243:38", "speaker": "E", "text": "Ja, QA hat im Release Candidate Gate darauf geachtet, dass die neue Animation keine zusätzlichen Render-Delays erzeugt – das war besonders wichtig, um die SLO von 1,2s First Contentful Paint einzuhalten."}
{"ts": "243:58", "speaker": "I", "text": "Wie haben Sie diese Optimierung priorisiert unter SLA-Druck?"}
{"ts": "244:04", "speaker": "E", "text": "Wir haben mit Hilfe von Incident-Analysen und Heatmaps entschieden. In Ticket UX-OPT-112 wurden z.B. die häufigsten Abbruchpunkte beim Sync visualisiert, das half beim Business-Case für sofortige Umsetzung."}
{"ts": "244:26", "speaker": "I", "text": "Sie hatten vorhin von unwritten rules gesprochen – gab es dabei auch solche internen Heuristiken?"}
{"ts": "244:34", "speaker": "E", "text": "Ja, eine Heuristik lautet: 'Visual feedback before backend ack'. Also lieber früh ein visuelles Feedback im UI zeigen, auch wenn der Server noch nicht bestätigt hat, um das Gefühl von Responsiveness zu steigern."}
{"ts": "244:52", "speaker": "I", "text": "Interessant. Welche Risiken sehen Sie, wenn wir das Projekt jetzt in die Breite ausrollen?"}
{"ts": "245:00", "speaker": "E", "text": "Das größte Risiko ist die Fragmentierung der UI bei unterschiedlich aktivierten Feature Flags in verschiedenen Märkten. Ohne striktes Token-Management im DS-ATLAS v2 droht Inkonsistenz."}
{"ts": "245:18", "speaker": "I", "text": "Haben Sie dafür schon einen Plan?"}
{"ts": "245:22", "speaker": "E", "text": "Ja, wir wollen eine Preflight-Checkliste integrieren, die per CI prüft, ob alle aktiven Flags mit den aktuellen Token-Mappings kompatibel sind. Das ist im RFC-ATL-024 beschrieben."}
{"ts": "245:40", "speaker": "I", "text": "Und falls die Prüfung fehlschlägt?"}
{"ts": "245:44", "speaker": "E", "text": "Dann blockiert der Merge ins Pilot-Branch und es wird automatisch ein Jira-Blocker erstellt. Wir haben das schon in einem Testlauf simuliert – Ticket QA-BLK-078 – und so zwei Inkonsistenzen vor dem Go-Live abgefangen."}
{"ts": "251:36", "speaker": "I", "text": "Wir hatten ja schon kurz über die Crash Loops gesprochen – könnten Sie bitte noch einmal detailliert erklären, wie die Erkenntnisse daraus in den aktuellen UX-Backlog eingeflossen sind?"}
{"ts": "251:48", "speaker": "E", "text": "Ja, klar. Also wir haben nach RB-MOB-021 ein Mini-Workshop mit QA und Platform gemacht. Daraus ist ein Runbook-Abschnitt 5.3.2 entstanden, der spezielle UI-Fallbacks für Offline-States beschreibt. Diese Fallbacks sind jetzt als eigene Story in unserem Pilot-Backlog priorisiert."}
{"ts": "252:08", "speaker": "I", "text": "Interessant. Und wie hat das konkret die Gestaltung von DS-ATLAS v2 beeinflusst?"}
{"ts": "252:15", "speaker": "E", "text": "Wir haben die Tokenized Components so erweitert, dass States wie 'Data Stale' oder 'Retry Available' klar visuell differenzierbar sind. Das war vorher nicht im Scope, aber durch den Incident haben wir das in v2.1 eingeführt."}
{"ts": "252:35", "speaker": "I", "text": "Gab es technische Hürden bei der Umsetzung dieser State-Darstellungen in Verbindung mit den Feature Flags?"}
{"ts": "252:44", "speaker": "E", "text": "Ja, vor allem, weil Feature Flags bei uns dynamisch per Remote Config umschalten. Wir mussten sicherstellen, dass Komponenten beim Flag-Toggle keine Render-Loops erzeugen. Das hat ein Refactoring im State-Management notwendig gemacht."}
{"ts": "253:05", "speaker": "I", "text": "Wie haben Sie diese Anpassungen QA-seitig abgesichert?"}
{"ts": "253:12", "speaker": "E", "text": "Wir haben mit QA ein spezielles Gate im Release Candidate aufgebaut, das unter simulierten Netzwerkausfällen die Flags toggelt. Da gibt’s jetzt im Testplan TC-MOB-FF-014, der genau diese Szenarien abdeckt."}
